{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee190bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "sys.path.append('../..')\n",
    "\n",
    "from solutions.convolution.conv1_model import Conv1Model\n",
    "from cgol.generator.uniform_density_generator import UniformDensityGenerator\n",
    "from cgol.simulator.minimal_architecture_simulator import MinimalArchitectureSimulator\n",
    "from cgol.dataloader.dataloader_2 import Dataloader2\n",
    "from cgol.loss.completion_loss import CompletionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a2814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('checkpoints_train_grok3/final.chkpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8b09cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataloader': {'type': 'Dataloader1',\n",
       "  'generator': {'type': 'UniformDensityGenerator', 'seed': 0},\n",
       "  'width': 20,\n",
       "  'height': 20,\n",
       "  'batch_size': 100,\n",
       "  'min_change_threshold': 0.1,\n",
       "  'max_sequence_age': 150},\n",
       " 'model': {'type': 'Conv1Model',\n",
       "  'is_toroidal': False,\n",
       "  'kernel_size': 5,\n",
       "  'activation': 'type',\n",
       "  'last_activation': 'type',\n",
       "  'n_hidden_layers': 4,\n",
       "  'n_channels': 2000,\n",
       "  'n_parameters': 102001,\n",
       "  'weight_init': 'xavier_uniform',\n",
       "  'bias_init': 'zeros_'},\n",
       " 'optimizer': {'type': 'Adam',\n",
       "  'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0},\n",
       " 'loss': {'type': 'MSELoss'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "width = 20\n",
    "height = 20\n",
    "batch_size = 100\n",
    "dtype = torch.float\n",
    "preprocess_device = 'cpu'\n",
    "model_device = 'cuda'\n",
    "\n",
    "simulator = MinimalArchitectureSimulator(device=preprocess_device, dtype=dtype)\n",
    "generator = UniformDensityGenerator(seed, preprocess_device, dtype)\n",
    "generator.rng.set_state(checkpoint['dataloader_state']['generator']['rng'])\n",
    "\n",
    "dataloader = Dataloader2(generator, simulator, \n",
    "                         batch_size, width, height, \n",
    "                         preprocess_device, model_device, dtype, \n",
    "                         0.1, 150)\n",
    "dataloader.last_batch = checkpoint['dataloader_state']['last_batch']\n",
    "dataloader.sequence_ages = checkpoint['dataloader_state']['sequence_ages']\n",
    "dataloader.step = checkpoint['dataloader_state']['step']\n",
    "\n",
    "model = Conv1Model(device=model_device, dtype=dtype, n_channels=2000, n_hidden_layers=4)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "lr = 0.001\n",
    "betas = (0.9,0.999)\n",
    "eps = 0.00000001\n",
    "weight_decay = 0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "config = {\n",
    "    \"dataloader\": dataloader.get_config(),\n",
    "    \"model\": model.get_config(),\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"Adam\",\n",
    "        \"lr\": lr,\n",
    "        \"betas\": betas,\n",
    "        \"eps\": eps,\n",
    "        \"weight_decay\": weight_decay\n",
    "    },\n",
    "    \"loss\": {\n",
    "        \"type\": \"MSELoss\"\n",
    "    }\n",
    "}\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_log = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f479ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_state(path: str, \n",
    "               model: torch.nn.Module, \n",
    "               optimizer: torch.nn.Module, \n",
    "               dataloader, \n",
    "               run_state: dict):\n",
    "    save_state = {\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'dataloader_state': dataloader.get_state(),\n",
    "        'run_state': run_state\n",
    "    }\n",
    "    torch.save(save_state, path)\n",
    "\n",
    "def train(\n",
    "        run_state: dict,\n",
    "        model: torch.nn.Module, \n",
    "        dataloader, \n",
    "        optimizer: torch.optim.Optimizer, \n",
    "        loss_fn: torch.nn.Module, \n",
    "        checkpoint_path: Path, \n",
    "        max_steps: int=300000, \n",
    "        patience: int=75000) -> dict:\n",
    "    run_state.update({\n",
    "        'step': 0,\n",
    "        'best_loss_step': 0,\n",
    "        'best_accuracy_micro_step': 0,\n",
    "        'best_accuracy_macro_step': 0,\n",
    "        'loss': sys.float_info.max,\n",
    "        'accuracy_micro': 0,\n",
    "        'accuracy_macro': 0,\n",
    "        'best_loss': sys.float_info.max,\n",
    "        'best_accuracy_micro': 0,\n",
    "        'best_accuracy_macro': 0\n",
    "    } | run_state)\n",
    "    do_train = True\n",
    "\n",
    "    safe_state(checkpoint_path/'initial.ckpt', model, optimizer, dataloader, run_state)\n",
    "    \n",
    "    if wandb_log:\n",
    "        wandb.init('llottenbach', 'cgol', resume='allow', resume_from=run_state['step'], id='lh6vi61e')\n",
    "\n",
    "    model.train()\n",
    "    try:\n",
    "        batch = next(dataloader)\n",
    "        new_batch = True\n",
    "        \n",
    "        while do_train:\n",
    "            logs = {}\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(batch[0])\n",
    "\n",
    "            # metrics\n",
    "            run_state['loss'] = loss_fn(output, batch[1])\n",
    "            run_state['accuracy_micro'] = (((output >= 0.5) == batch[1]).sum()\n",
    "                / (output.shape[0] * output.shape[1] * output.shape[2]))\n",
    "            run_state['accuracy_macro'] = (((output >= 0.5) == batch[1]).all((-1,-2)).sum()\n",
    "                / (output.shape[0]))\n",
    "            \n",
    "            # optimize\n",
    "            run_state['loss'].backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if new_batch:\n",
    "                # update highscore\n",
    "                if run_state['best_loss'] > run_state['loss']:\n",
    "                    run_state['best_loss'] = run_state['loss'].detach().clone()\n",
    "                    run_state['best_loss_step'] = run_state['step']\n",
    "                    safe_state(checkpoint_path/'best_loss.chkpt', model, optimizer, dataloader, run_state)\n",
    "                if run_state['best_accuracy_micro'] < run_state['accuracy_micro']:\n",
    "                    run_state['best_accuracy_micro'] = run_state['accuracy_micro'].detach().clone()\n",
    "                    run_state['best_accuracy_micro_step'] = run_state['step']\n",
    "                    safe_state(checkpoint_path/'best_acc_micro.chkpt', model, optimizer, dataloader, run_state)\n",
    "                if run_state['best_accuracy_macro'] < run_state['accuracy_macro']:\n",
    "                    run_state['best_accuracy_macro'] = run_state['accuracy_macro'].detach().clone()\n",
    "                    run_state['best_accuracy_macro_step'] = run_state['step']\n",
    "                    safe_state(checkpoint_path/'best_acc_macro.chkpt', model, optimizer, dataloader, run_state)\n",
    "\n",
    "                # log\n",
    "                logs = logs | {\n",
    "                    'train/first_encounter/loss': run_state['loss'],\n",
    "                    'train/first_encounter/accuracy_micro': run_state['accuracy_micro'],\n",
    "                    'train/first_encounter/accuracy_macro': run_state['accuracy_macro'],\n",
    "                    'dataloader/step': dataloader.step,\n",
    "                    'dataloader/batch_age/min': dataloader.sequence_ages.min(),\n",
    "                    'dataloader/batch_age/max': dataloader.sequence_ages.max(),\n",
    "                    'dataloader/batch_age/median': dataloader.sequence_ages.float().median(),\n",
    "                    'dataloader/batch_age/mean': dataloader.sequence_ages.float().mean(),\n",
    "                    'dataloader/batch_age/std': dataloader.sequence_ages.float().std(),\n",
    "                    'dataloader/batch_diffs_per_cell/min': dataloader.batch_diffs_per_cell.min(),\n",
    "                    'dataloader/batch_diffs_per_cell/max': dataloader.batch_diffs_per_cell.max(),\n",
    "                    'dataloader/batch_diffs_per_cell/median': dataloader.batch_diffs_per_cell.median(),\n",
    "                    'dataloader/batch_diffs_per_cell/mean': dataloader.batch_diffs_per_cell.mean(),\n",
    "                    'dataloader/batch_diffs_per_cell/std': dataloader.batch_diffs_per_cell.std(),\n",
    "                }\n",
    "            \n",
    "            # new batch condition\n",
    "            new_batch = False\n",
    "            if run_state['accuracy_macro'] >= .5:\n",
    "                batch = next(dataloader)\n",
    "                new_batch = True\n",
    "\n",
    "            # stop condition\n",
    "            if (max_steps <= run_state['step']\n",
    "                or run_state['best_loss_step'] + patience <= run_state['step']\n",
    "                or run_state['best_accuracy_micro_step'] + patience <= run_state['step']\n",
    "                or run_state['best_accuracy_macro_step'] + patience <= run_state['step']):\n",
    "                do_train = False\n",
    "\n",
    "            # SPLIT UP\n",
    "            # log\n",
    "            print(run_state)\n",
    "            print(f'step: {run_state[\"step\"]:7d},',\n",
    "                f'loss: {run_state[\"loss\"]:1.16f},',\n",
    "                f'accuracy-micro: {run_state[\"accuracy_micro\"]:1.16f},',\n",
    "                f'accuracy-macro: {run_state[\"accuracy_macro\"]:1.16f}')\n",
    "            logs = logs | {\n",
    "                'train/loss': run_state['loss'],\n",
    "                'train/accuracy-micro': run_state['accuracy_micro'],\n",
    "                'train/accuracy-macro': run_state['accuracy_macro']\n",
    "            }\n",
    "            \n",
    "            if wandb_log:\n",
    "                wandb.log(logs, run_state['step'])\n",
    "\n",
    "            if do_train:\n",
    "                run_state['step'] += 1\n",
    "            else:\n",
    "                safe_state(checkpoint_path/'stop.chkpt', model, optimizer, dataloader, run_state)\n",
    "    except BaseException as e:\n",
    "        safe_state(checkpoint_path/'error.chkpt', model, optimizer, dataloader, run_state)\n",
    "        raise e\n",
    "\n",
    "    return run_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3d46e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if wandb_log:\n",
    "    wandb.login()\n",
    "# bigger model\n",
    "# slight weight decay\n",
    "\n",
    "# new loss function\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3a1bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 9911, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3191, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6337, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9911, loss: 0.3191135525703430, accuracy-micro: 0.6337499618530273, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9912, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3176, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6368, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9912, loss: 0.3176259994506836, accuracy-micro: 0.6368499994277954, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9913, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3153, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6402, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9913, loss: 0.3152936697006226, accuracy-micro: 0.6401749849319458, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9914, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3127, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6453, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9914, loss: 0.3126645982265472, accuracy-micro: 0.6452999711036682, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9915, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3102, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6503, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9915, loss: 0.3102122843265533, accuracy-micro: 0.6503250002861023, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9916, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3083, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6543, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9916, loss: 0.3082624375820160, accuracy-micro: 0.6543250083923340, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9917, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3069, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6582, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9917, loss: 0.3069008588790894, accuracy-micro: 0.6581749916076660, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9918, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3059, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6611, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9918, loss: 0.3059362173080444, accuracy-micro: 0.6611250042915344, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9919, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3050, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6629, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9919, loss: 0.3050146996974945, accuracy-micro: 0.6629250049591064, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9920, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3038, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6641, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9920, loss: 0.3038348853588104, accuracy-micro: 0.6641499996185303, accuracy-macro: 0.0000000000000000\n",
      "{'step': 9921, 'best_loss_step': 0, 'best_accuracy_micro_step': 9911, 'best_accuracy_macro_step': 0, 'loss': tensor(0.3022, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.6644, device='cuda:0'), 'accuracy_macro': tensor(0., device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.6337, device='cuda:0'), 'best_accuracy_macro': 0}\n",
      "step:    9921, loss: 0.3021888732910156, accuracy-micro: 0.6643750071525574, accuracy-macro: 0.0000000000000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14826/3324613572.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrun_checkpoint_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrun_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrun_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14826/513360944.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(run_state, model, dataloader, optimizer, loss_fn, checkpoint_path, max_steps, patience)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0msafe_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'error.chkpt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14826/513360944.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(run_state, model, dataloader, optimizer, loss_fn, checkpoint_path, max_steps, patience)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# SPLIT UP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             print(f'step: {run_state[\"step\"]:7d},',\n\u001b[1;32m    115\u001b[0m                 \u001b[0;34mf'loss: {run_state[\"loss\"]:1.16f},'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_checkpoint_path = Path('checkpoints_train_grok3_resume')\n",
    "run_checkpoint_path.mkdir(exist_ok=True)\n",
    "run_state = checkpoint['run_state']\n",
    "run_state = train(run_state, model, dataloader, optimizer, loss_fn, run_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcfe6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_state(run_checkpoint_path/'final.chkpt', model, optimizer, dataloader, run_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707adc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 9911, 'best_loss_step': 0, 'best_accuracy_micro_step': 0, 'best_accuracy_macro_step': 0, 'loss': tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>), 'accuracy_micro': tensor(0.9968, device='cuda:0'), 'accuracy_macro': tensor(0.6100, device='cuda:0'), 'best_loss': tensor(0.2501, device='cuda:0'), 'best_accuracy_micro': tensor(0.5182, device='cuda:0'), 'best_accuracy_macro': 0}\n"
     ]
    }
   ],
   "source": [
    "print(run_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ad7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'train_grok3_final_backup.chkpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b949459",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
