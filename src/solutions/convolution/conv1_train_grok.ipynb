{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee190bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "sys.path.append('../..')\n",
    "\n",
    "from solutions.convolution.conv1_model import Conv1Model\n",
    "from cgol.generator.uniform_density_generator import UniformDensityGenerator\n",
    "from cgol.simulator.minimal_architecture_simulator import MinimalArchitectureSimulator\n",
    "from cgol.dataloader.dataloader_2 import Dataloader2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8b09cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/cgol/src/solutions/convolution/../../solutions/convolution/conv1_model.py:73: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  init_weight_f(self.conv_start.weight)\n",
      "/workspaces/cgol/src/solutions/convolution/../../solutions/convolution/conv1_model.py:76: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  init_weight_f(hidden_conf.weight)\n",
      "/workspaces/cgol/src/solutions/convolution/../../solutions/convolution/conv1_model.py:78: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  init_weight_f(self.conv_end.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataloader': {'type': 'Dataloader1',\n",
       "  'generator': {'type': 'UniformDensityGenerator', 'seed': 0},\n",
       "  'width': 20,\n",
       "  'height': 20,\n",
       "  'batch_size': 10000,\n",
       "  'min_change_threshold': 0.1,\n",
       "  'max_sequence_age': 150},\n",
       " 'model': {'type': 'Conv1Model',\n",
       "  'is_toroidal': False,\n",
       "  'kernel_size': 5,\n",
       "  'activation': 'type',\n",
       "  'last_activation': 'type',\n",
       "  'n_hidden_layers': 3,\n",
       "  'n_channels': 100,\n",
       "  'n_parameters': 5101,\n",
       "  'weight_init': 'xavier_uniform',\n",
       "  'bias_init': 'zeros_'},\n",
       " 'optimizer': {'type': 'Adam',\n",
       "  'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0},\n",
       " 'loss': {'type': 'MSELoss'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "width = 20\n",
    "height = 20\n",
    "batch_size = 10000\n",
    "dtype = torch.float\n",
    "preprocess_device = 'cpu'\n",
    "model_device = 'cuda'\n",
    "\n",
    "simulator = MinimalArchitectureSimulator(device=preprocess_device, dtype=dtype)\n",
    "generator = UniformDensityGenerator(seed, preprocess_device, dtype)\n",
    "dataloader = Dataloader2(generator, simulator, \n",
    "                         batch_size, width, height, \n",
    "                         preprocess_device, model_device, dtype, \n",
    "                         0.1, 150)\n",
    "\n",
    "model = Conv1Model(device=model_device, dtype=dtype)\n",
    "model.initialize()\n",
    "lr = 0.001\n",
    "betas = (0.9,0.999)\n",
    "eps = 0.00000001\n",
    "weight_decay = 0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "config = {\n",
    "    \"dataloader\": dataloader.get_config(),\n",
    "    \"model\": model.get_config(),\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"Adam\",\n",
    "        \"lr\": lr,\n",
    "        \"betas\": betas,\n",
    "        \"eps\": eps,\n",
    "        \"weight_decay\": weight_decay\n",
    "    },\n",
    "    \"loss\": {\n",
    "        \"type\": \"MSELoss\"\n",
    "    }\n",
    "}\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65e9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_log = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f479ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_state(path: str, \n",
    "               model: torch.nn.Module, \n",
    "               optimizer: torch.nn.Module, \n",
    "               dataloader, \n",
    "               run_state: dict):\n",
    "    save_state = {\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'dataloader_state': dataloader.get_state(),\n",
    "        'run_state': run_state\n",
    "    }\n",
    "    torch.save(save_state, path)\n",
    "\n",
    "def train(\n",
    "        model: torch.nn.Module, \n",
    "        dataloader, \n",
    "        optimizer: torch.optim.Optimizer, \n",
    "        loss_fn: torch.nn.Module, \n",
    "        checkpoint_path: Path, \n",
    "        max_steps: int=300000, \n",
    "        patience: int=75000,\n",
    "        run_state: dict = {}) -> dict:\n",
    "    run_state = {\n",
    "        'step': 0,\n",
    "        'best_loss_step': 0,\n",
    "        'best_accuracy_micro_step': 0,\n",
    "        'best_accuracy_macro_step': 0,\n",
    "        'loss': sys.float_info.max,\n",
    "        'accuracy_micro': 0,\n",
    "        'accuracy_macro': 0,\n",
    "        'best_loss': sys.float_info.max,\n",
    "        'best_accuracy_micro': 0,\n",
    "        'best_accuracy_macro': 0\n",
    "    } | run_state\n",
    "    do_train = True\n",
    "\n",
    "    safe_state(checkpoint_path/'initial.ckpt', model, optimizer, dataloader, run_state)\n",
    "    \n",
    "    if wandb_log:\n",
    "        wandb.init('llottenbach', 'cgol', config={\n",
    "            \"config\": config\n",
    "        })\n",
    "\n",
    "    model.train()\n",
    "    try:\n",
    "        batch = next(dataloader)\n",
    "        new_batch = True\n",
    "        \n",
    "        while do_train:\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(batch[0])\n",
    "\n",
    "            # metrics\n",
    "            run_state['loss'] = loss_fn(output, batch[1])\n",
    "            run_state['accuracy_micro'] = (((output >= 0.5) == batch[1]).sum()\n",
    "                / (output.shape[0] * output.shape[1] * output.shape[2]))\n",
    "            run_state['accuracy_macro'] = (((output >= 0.5) == batch[1]).all((-1,-2)).sum()\n",
    "                / (output.shape[0]))\n",
    "            \n",
    "            # optimize\n",
    "            run_state['loss'].backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if new_batch:\n",
    "                # update highscore\n",
    "                if run_state['best_loss'] > run_state['loss']:\n",
    "                    run_state['best_loss'] = run_state['loss']\n",
    "                    run_state['best_loss_step'] = run_state['step']\n",
    "                    safe_state(checkpoint_path/'best_loss.chkpt', model, optimizer, dataloader, run_state)\n",
    "                if run_state['best_accuracy_micro'] < run_state['accuracy_micro']:\n",
    "                    run_state['best_accuracy_micro'] = run_state['accuracy_micro']\n",
    "                    run_state['best_accuracy_micro_step'] = run_state['step']\n",
    "                    safe_state(checkpoint_path/'best_acc_micro.chkpt', model, optimizer, dataloader, run_state)\n",
    "                if run_state['best_accuracy_macro'] < run_state['accuracy_macro']:\n",
    "                    run_state['best_accuracy_macro'] = run_state['accuracy_macro']\n",
    "                    run_state['best_accuracy_macro_step'] = run_state['step']\n",
    "                    safe_state(checkpoint_path/'best_acc_macro.chkpt', model, optimizer, dataloader, run_state)\n",
    "\n",
    "                # log\n",
    "                if wandb_log:\n",
    "                    wandb.log({\n",
    "                        'train/first_encounter/loss': run_state['loss'],\n",
    "                        'train/first_encounter/accuracy_micro': run_state['accuracy_micro'],\n",
    "                        'train/first_encounter/accuracy_macro': run_state['accuracy_macro'],\n",
    "                        'dataloader/step': dataloader.step,\n",
    "                        'dataloader/batch_age/min': dataloader.sequence_ages.min(),\n",
    "                        'dataloader/batch_age/max': dataloader.sequence_ages.max(),\n",
    "                        'dataloader/batch_age/median': dataloader.sequence_ages.float().median(),\n",
    "                        'dataloader/batch_age/mean': dataloader.sequence_ages.float().mean(),\n",
    "                        'dataloader/batch_age/std': dataloader.sequence_ages.float().std(),\n",
    "                        'dataloader/batch_diffs_per_cell/min': dataloader.batch_diffs_per_cell.min(),\n",
    "                        'dataloader/batch_diffs_per_cell/max': dataloader.batch_diffs_per_cell.max(),\n",
    "                        'dataloader/batch_diffs_per_cell/median': dataloader.batch_diffs_per_cell.median(),\n",
    "                        'dataloader/batch_diffs_per_cell/mean': dataloader.batch_diffs_per_cell.mean(),\n",
    "                        'dataloader/batch_diffs_per_cell/std': dataloader.batch_diffs_per_cell.std(),\n",
    "                    },\n",
    "                    run_state['step'])\n",
    "            \n",
    "            # new batch condition\n",
    "            new_batch = False\n",
    "            if run_state['accuracy_micro'] >= 1.:\n",
    "                batch = next(dataloader)\n",
    "                new_batch = True\n",
    "\n",
    "            # stop condition\n",
    "            if (max_steps <= run_state['step']\n",
    "                or run_state['best_loss_step'] + patience <= run_state['step']\n",
    "                or run_state['best_accuracy_micro_step'] + patience <= run_state['step']\n",
    "                or run_state['best_accuracy_macro_step'] + patience <= run_state['step']):\n",
    "                do_train = False\n",
    "\n",
    "            # SPLIT UP\n",
    "            # log\n",
    "            print(f'step: {run_state[\"step\"]:7d},',\n",
    "                f'loss: {run_state[\"loss\"]:1.16f},',\n",
    "                f'accuracy-micro: {run_state[\"accuracy_micro\"]:1.16f},',\n",
    "                f'accuracy-macro: {run_state[\"accuracy_macro\"]:1.16f}')\n",
    "            if wandb_log:\n",
    "                wandb.log({\n",
    "                    'train/loss': run_state['loss'],\n",
    "                    'train/accuracy-micro': run_state['accuracy_micro'],\n",
    "                    'train/accuracy-macro': run_state['accuracy_macro']\n",
    "                },\n",
    "                run_state['step'])\n",
    "\n",
    "            if do_train:\n",
    "                run_state['step'] += 1\n",
    "            else:\n",
    "                safe_state(checkpoint_path/'stop.chkpt', model, optimizer, dataloader, run_state)\n",
    "    except Exception as e:\n",
    "        safe_state(checkpoint_path/'error.chkpt', model, optimizer, dataloader, run_state)\n",
    "        raise e\n",
    "\n",
    "    return run_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d46e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukas-lottenbach\u001b[0m (\u001b[33mllottenbach-nlp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "if wandb_log:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a1bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/cgol/src/solutions/convolution/wandb/run-20251128_135750-lgvb539g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/llottenbach/cgol/runs/lgvb539g' target=\"_blank\">fine-frost-6</a></strong> to <a href='https://wandb.ai/llottenbach/cgol' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/llottenbach/cgol' target=\"_blank\">https://wandb.ai/llottenbach/cgol</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/llottenbach/cgol/runs/lgvb539g' target=\"_blank\">https://wandb.ai/llottenbach/cgol/runs/lgvb539g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:       0, loss: 0.2496806532144547, accuracy-micro: 0.4956170022487640, accuracy-macro: 0.0000000000000000\n",
      "step:       1, loss: 0.2491546571254730, accuracy-micro: 0.4633150100708008, accuracy-macro: 0.0000000000000000\n",
      "step:       2, loss: 0.2485430091619492, accuracy-micro: 0.4869394898414612, accuracy-macro: 0.0000000000000000\n",
      "step:       3, loss: 0.2479331195354462, accuracy-micro: 0.4971019923686981, accuracy-macro: 0.0000000000000000\n",
      "step:       4, loss: 0.2473610937595367, accuracy-micro: 0.4981142580509186, accuracy-macro: 0.0000000000000000\n",
      "step:       5, loss: 0.2468632757663727, accuracy-micro: 0.4990114867687225, accuracy-macro: 0.0000000000000000\n",
      "step:       6, loss: 0.2465060651302338, accuracy-micro: 0.5003467202186584, accuracy-macro: 0.0000000000000000\n",
      "step:       7, loss: 0.2463328838348389, accuracy-micro: 0.5022082328796387, accuracy-macro: 0.0000000000000000\n",
      "step:       8, loss: 0.2463134974241257, accuracy-micro: 0.5051130056381226, accuracy-macro: 0.0000000000000000\n",
      "step:       9, loss: 0.2463237792253494, accuracy-micro: 0.5108592510223389, accuracy-macro: 0.0000000000000000\n",
      "step:      10, loss: 0.2462414950132370, accuracy-micro: 0.5174949765205383, accuracy-macro: 0.0000000000000000\n",
      "step:      11, loss: 0.2460379302501678, accuracy-micro: 0.5270132422447205, accuracy-macro: 0.0000000000000000\n",
      "step:      12, loss: 0.2457567155361176, accuracy-micro: 0.5408502221107483, accuracy-macro: 0.0000000000000000\n",
      "step:      13, loss: 0.2454606294631958, accuracy-micro: 0.5549954771995544, accuracy-macro: 0.0000000000000000\n",
      "step:      14, loss: 0.2451977878808975, accuracy-micro: 0.5665867328643799, accuracy-macro: 0.0000000000000000\n",
      "step:      15, loss: 0.2449859827756882, accuracy-micro: 0.5779364705085754, accuracy-macro: 0.0037000000011176\n",
      "step:      16, loss: 0.2448141574859619, accuracy-micro: 0.5898697376251221, accuracy-macro: 0.0037000000011176\n",
      "step:      17, loss: 0.2446615993976593, accuracy-micro: 0.6016430258750916, accuracy-macro: 0.0037000000011176\n",
      "step:      18, loss: 0.2445020824670792, accuracy-micro: 0.6124755144119263, accuracy-macro: 0.0037000000011176\n",
      "step:      19, loss: 0.2443167567253113, accuracy-micro: 0.6219890117645264, accuracy-macro: 0.0037000000011176\n",
      "step:      20, loss: 0.2440947592258453, accuracy-micro: 0.6293464899063110, accuracy-macro: 0.0037000000011176\n",
      "step:      21, loss: 0.2438349723815918, accuracy-micro: 0.6351162195205688, accuracy-macro: 0.0037000000011176\n",
      "step:      22, loss: 0.2435437589883804, accuracy-micro: 0.6393294930458069, accuracy-macro: 0.0037000000011176\n",
      "step:      23, loss: 0.2432355582714081, accuracy-micro: 0.6425110101699829, accuracy-macro: 0.0037000000011176\n",
      "step:      24, loss: 0.2429234385490417, accuracy-micro: 0.6449850201606750, accuracy-macro: 0.0037000000011176\n",
      "step:      25, loss: 0.2426149696111679, accuracy-micro: 0.6471505165100098, accuracy-macro: 0.0037000000011176\n",
      "step:      26, loss: 0.2423088699579239, accuracy-micro: 0.6491932272911072, accuracy-macro: 0.0037000000011176\n",
      "step:      27, loss: 0.2419923692941666, accuracy-micro: 0.6513609886169434, accuracy-macro: 0.0037000000011176\n",
      "step:      28, loss: 0.2416465133428574, accuracy-micro: 0.6536834836006165, accuracy-macro: 0.0037000000011176\n",
      "step:      29, loss: 0.2412597388029099, accuracy-micro: 0.6559182405471802, accuracy-macro: 0.0037000000011176\n",
      "step:      30, loss: 0.2408333122730255, accuracy-micro: 0.6579807400703430, accuracy-macro: 0.0037000000011176\n",
      "step:      31, loss: 0.2403832823038101, accuracy-micro: 0.6597062349319458, accuracy-macro: 0.0037000000011176\n",
      "step:      32, loss: 0.2399230003356934, accuracy-micro: 0.6606594920158386, accuracy-macro: 0.0037000000011176\n",
      "step:      33, loss: 0.2394591867923737, accuracy-micro: 0.6611394882202148, accuracy-macro: 0.0037000000011176\n",
      "step:      34, loss: 0.2389776855707169, accuracy-micro: 0.6612147688865662, accuracy-macro: 0.0037000000011176\n",
      "step:      35, loss: 0.2384604066610336, accuracy-micro: 0.6610992550849915, accuracy-macro: 0.0037000000011176\n",
      "step:      36, loss: 0.2378962337970734, accuracy-micro: 0.6609410047531128, accuracy-macro: 0.0037000000011176\n",
      "step:      37, loss: 0.2372965961694717, accuracy-micro: 0.6607987284660339, accuracy-macro: 0.0037000000011176\n",
      "step:      38, loss: 0.2366745322942734, accuracy-micro: 0.6607962250709534, accuracy-macro: 0.0037000000011176\n",
      "step:      39, loss: 0.2360446453094482, accuracy-micro: 0.6607657670974731, accuracy-macro: 0.0037000000011176\n",
      "step:      40, loss: 0.2353965193033218, accuracy-micro: 0.6606247425079346, accuracy-macro: 0.0037000000011176\n",
      "step:      41, loss: 0.2347164005041122, accuracy-micro: 0.6603522300720215, accuracy-macro: 0.0037000000011176\n",
      "step:      42, loss: 0.2340045273303986, accuracy-micro: 0.6599109768867493, accuracy-macro: 0.0037000000011176\n",
      "step:      43, loss: 0.2332821190357208, accuracy-micro: 0.6592832207679749, accuracy-macro: 0.0037000000011176\n",
      "step:      44, loss: 0.2325592190027237, accuracy-micro: 0.6586664915084839, accuracy-macro: 0.0037000000011176\n",
      "step:      45, loss: 0.2318179905414581, accuracy-micro: 0.6582867503166199, accuracy-macro: 0.0037000000011176\n",
      "step:      46, loss: 0.2310426086187363, accuracy-micro: 0.6583237648010254, accuracy-macro: 0.0037000000011176\n",
      "step:      47, loss: 0.2302360534667969, accuracy-micro: 0.6586837768554688, accuracy-macro: 0.0037000000011176\n",
      "step:      48, loss: 0.2294279783964157, accuracy-micro: 0.6591475009918213, accuracy-macro: 0.0037000000011176\n",
      "step:      49, loss: 0.2286114394664764, accuracy-micro: 0.6595289707183838, accuracy-macro: 0.0037000000011176\n",
      "step:      50, loss: 0.2277707606554031, accuracy-micro: 0.6596407294273376, accuracy-macro: 0.0037000000011176\n",
      "step:      51, loss: 0.2269151955842972, accuracy-micro: 0.6596967577934265, accuracy-macro: 0.0037000000011176\n",
      "step:      52, loss: 0.2260597795248032, accuracy-micro: 0.6597342491149902, accuracy-macro: 0.0037000000011176\n",
      "step:      53, loss: 0.2251973301172256, accuracy-micro: 0.6600262522697449, accuracy-macro: 0.0037000000011176\n",
      "step:      54, loss: 0.2243171930313110, accuracy-micro: 0.6606464982032776, accuracy-macro: 0.0037000000011176\n",
      "step:      55, loss: 0.2234376519918442, accuracy-micro: 0.6614392399787903, accuracy-macro: 0.0037000000011176\n",
      "step:      56, loss: 0.2225672900676727, accuracy-micro: 0.6622455120086670, accuracy-macro: 0.0037000000011176\n",
      "step:      57, loss: 0.2216952145099640, accuracy-micro: 0.6629465222358704, accuracy-macro: 0.0037000000011176\n",
      "step:      58, loss: 0.2208232879638672, accuracy-micro: 0.6635177731513977, accuracy-macro: 0.0037000000011176\n",
      "step:      59, loss: 0.2199632078409195, accuracy-micro: 0.6641197204589844, accuracy-macro: 0.0037000000011176\n",
      "step:      60, loss: 0.2191151231527328, accuracy-micro: 0.6649312376976013, accuracy-macro: 0.0037000000011176\n",
      "step:      61, loss: 0.2182746827602386, accuracy-micro: 0.6658982634544373, accuracy-macro: 0.0037000000011176\n",
      "step:      62, loss: 0.2174523770809174, accuracy-micro: 0.6669139862060547, accuracy-macro: 0.0037000000011176\n",
      "step:      63, loss: 0.2166455984115601, accuracy-micro: 0.6678820252418518, accuracy-macro: 0.0037000000011176\n",
      "step:      64, loss: 0.2158518880605698, accuracy-micro: 0.6689010262489319, accuracy-macro: 0.0037000000011176\n",
      "step:      65, loss: 0.2150876671075821, accuracy-micro: 0.6699632406234741, accuracy-macro: 0.0037000000011176\n",
      "step:      66, loss: 0.2143414765596390, accuracy-micro: 0.6710787415504456, accuracy-macro: 0.0037000000011176\n",
      "step:      67, loss: 0.2136157602071762, accuracy-micro: 0.6721665263175964, accuracy-macro: 0.0037000000011176\n",
      "step:      68, loss: 0.2129067778587341, accuracy-micro: 0.6732425093650818, accuracy-macro: 0.0037000000011176\n",
      "step:      69, loss: 0.2122232615947723, accuracy-micro: 0.6744989752769470, accuracy-macro: 0.0037000000011176\n",
      "step:      70, loss: 0.2115705162286758, accuracy-micro: 0.6757509708404541, accuracy-macro: 0.0037000000011176\n",
      "step:      71, loss: 0.2109380662441254, accuracy-micro: 0.6769225001335144, accuracy-macro: 0.0037000000011176\n",
      "step:      72, loss: 0.2103228271007538, accuracy-micro: 0.6778720021247864, accuracy-macro: 0.0037000000011176\n",
      "step:      73, loss: 0.2097279727458954, accuracy-micro: 0.6789787411689758, accuracy-macro: 0.0037000000011176\n",
      "step:      74, loss: 0.2091500461101532, accuracy-micro: 0.6801984906196594, accuracy-macro: 0.0037000000011176\n",
      "step:      75, loss: 0.2085931897163391, accuracy-micro: 0.6812884807586670, accuracy-macro: 0.0037000000011176\n",
      "step:      76, loss: 0.2080532461404800, accuracy-micro: 0.6821442246437073, accuracy-macro: 0.0037000000011176\n",
      "step:      77, loss: 0.2075355798006058, accuracy-micro: 0.6831045150756836, accuracy-macro: 0.0037000000011176\n",
      "step:      78, loss: 0.2070354223251343, accuracy-micro: 0.6842089891433716, accuracy-macro: 0.0037000000011176\n",
      "step:      79, loss: 0.2065609097480774, accuracy-micro: 0.6850649714469910, accuracy-macro: 0.0037000000011176\n",
      "step:      80, loss: 0.2061082124710083, accuracy-micro: 0.6858404874801636, accuracy-macro: 0.0037000000011176\n",
      "step:      81, loss: 0.2056699097156525, accuracy-micro: 0.6867550015449524, accuracy-macro: 0.0037000000011176\n",
      "step:      82, loss: 0.2052516490221024, accuracy-micro: 0.6876720190048218, accuracy-macro: 0.0037000000011176\n",
      "step:      83, loss: 0.2048460990190506, accuracy-micro: 0.6883534789085388, accuracy-macro: 0.0037000000011176\n",
      "step:      84, loss: 0.2044532299041748, accuracy-micro: 0.6890934705734253, accuracy-macro: 0.0037000000011176\n",
      "step:      85, loss: 0.2040714472532272, accuracy-micro: 0.6899057626724243, accuracy-macro: 0.0037000000011176\n",
      "step:      86, loss: 0.2037007957696915, accuracy-micro: 0.6905484795570374, accuracy-macro: 0.0037000000011176\n",
      "step:      87, loss: 0.2033499032258987, accuracy-micro: 0.6912479996681213, accuracy-macro: 0.0037000000011176\n",
      "step:      88, loss: 0.2030098736286163, accuracy-micro: 0.6919917464256287, accuracy-macro: 0.0037000000011176\n",
      "step:      89, loss: 0.2026789337396622, accuracy-micro: 0.6925797462463379, accuracy-macro: 0.0037000000011176\n",
      "step:      90, loss: 0.2023563385009766, accuracy-micro: 0.6932672262191772, accuracy-macro: 0.0037000000011176\n",
      "step:      91, loss: 0.2020427137613297, accuracy-micro: 0.6940332651138306, accuracy-macro: 0.0037000000011176\n",
      "step:      92, loss: 0.2017358690500259, accuracy-micro: 0.6946127414703369, accuracy-macro: 0.0037000000011176\n",
      "step:      93, loss: 0.2014366835355759, accuracy-micro: 0.6952915191650391, accuracy-macro: 0.0037000000011176\n",
      "step:      94, loss: 0.2011460661888123, accuracy-micro: 0.6959847211837769, accuracy-macro: 0.0037000000011176\n",
      "step:      95, loss: 0.2008619159460068, accuracy-micro: 0.6965824961662292, accuracy-macro: 0.0037000000011176\n",
      "step:      96, loss: 0.2005838006734848, accuracy-micro: 0.6972755193710327, accuracy-macro: 0.0037000000011176\n",
      "step:      97, loss: 0.2003121078014374, accuracy-micro: 0.6978832483291626, accuracy-macro: 0.0037000000011176\n",
      "step:      98, loss: 0.2000498026609421, accuracy-micro: 0.6984837651252747, accuracy-macro: 0.0037000000011176\n",
      "step:      99, loss: 0.1997920125722885, accuracy-micro: 0.6990997195243835, accuracy-macro: 0.0037000000011176\n",
      "step:     100, loss: 0.1995393782854080, accuracy-micro: 0.6996762752532959, accuracy-macro: 0.0037000000011176\n",
      "step:     101, loss: 0.1992932558059692, accuracy-micro: 0.7002437710762024, accuracy-macro: 0.0037000000011176\n",
      "step:     102, loss: 0.1990533173084259, accuracy-micro: 0.7008217573165894, accuracy-macro: 0.0037000000011176\n",
      "step:     103, loss: 0.1988185346126556, accuracy-micro: 0.7013582587242126, accuracy-macro: 0.0037000000011176\n",
      "step:     104, loss: 0.1985907703638077, accuracy-micro: 0.7019837498664856, accuracy-macro: 0.0037000000011176\n",
      "step:     105, loss: 0.1983668655157089, accuracy-micro: 0.7024949789047241, accuracy-macro: 0.0037000000011176\n",
      "step:     106, loss: 0.1981478780508041, accuracy-micro: 0.7031027674674988, accuracy-macro: 0.0037000000011176\n",
      "step:     107, loss: 0.1979333460330963, accuracy-micro: 0.7036275267601013, accuracy-macro: 0.0037000000011176\n",
      "step:     108, loss: 0.1977240592241287, accuracy-micro: 0.7041429877281189, accuracy-macro: 0.0037000000011176\n",
      "step:     109, loss: 0.1975201666355133, accuracy-micro: 0.7046957612037659, accuracy-macro: 0.0037000000011176\n",
      "step:     110, loss: 0.1973213851451874, accuracy-micro: 0.7051270008087158, accuracy-macro: 0.0037000000011176\n",
      "step:     111, loss: 0.1971289068460464, accuracy-micro: 0.7056894898414612, accuracy-macro: 0.0037000000011176\n",
      "step:     112, loss: 0.1969428062438965, accuracy-micro: 0.7060340046882629, accuracy-macro: 0.0037000000011176\n",
      "step:     113, loss: 0.1967668086290359, accuracy-micro: 0.7066947221755981, accuracy-macro: 0.0037000000011176\n",
      "step:     114, loss: 0.1966064721345901, accuracy-micro: 0.7067790031433105, accuracy-macro: 0.0037000000011176\n",
      "step:     115, loss: 0.1964509934186935, accuracy-micro: 0.7075024843215942, accuracy-macro: 0.0037000000011176\n",
      "step:     116, loss: 0.1962839514017105, accuracy-micro: 0.7074829936027527, accuracy-macro: 0.0037000000011176\n",
      "step:     117, loss: 0.1960912793874741, accuracy-micro: 0.7082539796829224, accuracy-macro: 0.0037000000011176\n",
      "step:     118, loss: 0.1959218382835388, accuracy-micro: 0.7085555195808411, accuracy-macro: 0.0037000000011176\n",
      "step:     119, loss: 0.1957896500825882, accuracy-micro: 0.7086989879608154, accuracy-macro: 0.0037000000011176\n",
      "step:     120, loss: 0.1956512928009033, accuracy-micro: 0.7093582749366760, accuracy-macro: 0.0037000000011176\n",
      "step:     121, loss: 0.1954906582832336, accuracy-micro: 0.7094667553901672, accuracy-macro: 0.0037000000011176\n",
      "step:     122, loss: 0.1953341662883759, accuracy-micro: 0.7099517583847046, accuracy-macro: 0.0037000000011176\n",
      "step:     123, loss: 0.1952060312032700, accuracy-micro: 0.7103214859962463, accuracy-macro: 0.0037000000011176\n",
      "step:     124, loss: 0.1950822174549103, accuracy-micro: 0.7104039788246155, accuracy-macro: 0.0037000000011176\n",
      "step:     125, loss: 0.1949373632669449, accuracy-micro: 0.7109452486038208, accuracy-macro: 0.0037000000011176\n",
      "step:     126, loss: 0.1947956681251526, accuracy-micro: 0.7112025022506714, accuracy-macro: 0.0037000000011176\n",
      "step:     127, loss: 0.1946731805801392, accuracy-micro: 0.7114815115928650, accuracy-macro: 0.0037000000011176\n",
      "step:     128, loss: 0.1945559978485107, accuracy-micro: 0.7118409872055054, accuracy-macro: 0.0037000000011176\n",
      "step:     129, loss: 0.1944280266761780, accuracy-micro: 0.7120002508163452, accuracy-macro: 0.0037000000011176\n",
      "step:     130, loss: 0.1942943185567856, accuracy-micro: 0.7124074697494507, accuracy-macro: 0.0037000000011176\n",
      "step:     131, loss: 0.1941729635000229, accuracy-micro: 0.7126892209053040, accuracy-macro: 0.0037000000011176\n",
      "step:     132, loss: 0.1940611004829407, accuracy-micro: 0.7129032611846924, accuracy-macro: 0.0037000000011176\n",
      "step:     133, loss: 0.1939460039138794, accuracy-micro: 0.7133152484893799, accuracy-macro: 0.0037000000011176\n",
      "step:     134, loss: 0.1938239783048630, accuracy-micro: 0.7134877443313599, accuracy-macro: 0.0037000000011176\n",
      "step:     135, loss: 0.1937023401260376, accuracy-micro: 0.7138119935989380, accuracy-macro: 0.0037000000011176\n",
      "step:     136, loss: 0.1935886442661285, accuracy-micro: 0.7141362428665161, accuracy-macro: 0.0037000000011176\n",
      "step:     137, loss: 0.1934797167778015, accuracy-micro: 0.7143532633781433, accuracy-macro: 0.0037000000011176\n",
      "step:     138, loss: 0.1933701485395432, accuracy-micro: 0.7147402763366699, accuracy-macro: 0.0037000000011176\n",
      "step:     139, loss: 0.1932585686445236, accuracy-micro: 0.7149075269699097, accuracy-macro: 0.0037000000011176\n",
      "step:     140, loss: 0.1931459307670593, accuracy-micro: 0.7152667641639709, accuracy-macro: 0.0037000000011176\n",
      "step:     141, loss: 0.1930356621742249, accuracy-micro: 0.7155237197875977, accuracy-macro: 0.0037000000011176\n",
      "step:     142, loss: 0.1929299384355545, accuracy-micro: 0.7157815098762512, accuracy-macro: 0.0037000000011176\n",
      "step:     143, loss: 0.1928270608186722, accuracy-micro: 0.7160672545433044, accuracy-macro: 0.0037000000011176\n",
      "step:     144, loss: 0.1927258372306824, accuracy-micro: 0.7162579894065857, accuracy-macro: 0.0037000000011176\n",
      "step:     145, loss: 0.1926248371601105, accuracy-micro: 0.7166047692298889, accuracy-macro: 0.0037000000011176\n",
      "step:     146, loss: 0.1925233751535416, accuracy-micro: 0.7167400121688843, accuracy-macro: 0.0037000000011176\n",
      "step:     147, loss: 0.1924206018447876, accuracy-micro: 0.7170810103416443, accuracy-macro: 0.0037000000011176\n",
      "step:     148, loss: 0.1923182308673859, accuracy-micro: 0.7172340154647827, accuracy-macro: 0.0037000000011176\n",
      "step:     149, loss: 0.1922167837619781, accuracy-micro: 0.7175882458686829, accuracy-macro: 0.0037000000011176\n",
      "step:     150, loss: 0.1921174377202988, accuracy-micro: 0.7177345156669617, accuracy-macro: 0.0037000000011176\n",
      "step:     151, loss: 0.1920191496610641, accuracy-micro: 0.7179982662200928, accuracy-macro: 0.0037000000011176\n",
      "step:     152, loss: 0.1919230371713638, accuracy-micro: 0.7182089686393738, accuracy-macro: 0.0037000000011176\n",
      "step:     153, loss: 0.1918278187513351, accuracy-micro: 0.7184485197067261, accuracy-macro: 0.0037000000011176\n",
      "step:     154, loss: 0.1917344033718109, accuracy-micro: 0.7186999917030334, accuracy-macro: 0.0037000000011176\n",
      "step:     155, loss: 0.1916419714689255, accuracy-micro: 0.7188864946365356, accuracy-macro: 0.0037000000011176\n",
      "step:     156, loss: 0.1915519684553146, accuracy-micro: 0.7191460132598877, accuracy-macro: 0.0037000000011176\n",
      "step:     157, loss: 0.1914659738540649, accuracy-micro: 0.7192457318305969, accuracy-macro: 0.0037000000011176\n",
      "step:     158, loss: 0.1913861185312271, accuracy-micro: 0.7196210026741028, accuracy-macro: 0.0037000000011176\n",
      "step:     159, loss: 0.1913219839334488, accuracy-micro: 0.7195712327957153, accuracy-macro: 0.0037000000011176\n",
      "step:     160, loss: 0.1912740319967270, accuracy-micro: 0.7199932336807251, accuracy-macro: 0.0037000000011176\n",
      "step:     161, loss: 0.1912366747856140, accuracy-micro: 0.7197219729423523, accuracy-macro: 0.0037000000011176\n",
      "step:     162, loss: 0.1911290585994720, accuracy-micro: 0.7203342318534851, accuracy-macro: 0.0037000000011176\n",
      "step:     163, loss: 0.1909763067960739, accuracy-micro: 0.7203962206840515, accuracy-macro: 0.0037000000011176\n",
      "step:     164, loss: 0.1908753961324692, accuracy-micro: 0.7206782698631287, accuracy-macro: 0.0037000000011176\n",
      "step:     165, loss: 0.1908502131700516, accuracy-micro: 0.7209217548370361, accuracy-macro: 0.0037000000011176\n",
      "step:     166, loss: 0.1907978504896164, accuracy-micro: 0.7207459807395935, accuracy-macro: 0.0037000000011176\n",
      "step:     167, loss: 0.1906690597534180, accuracy-micro: 0.7212395071983337, accuracy-macro: 0.0037000000011176\n",
      "step:     168, loss: 0.1905782222747803, accuracy-micro: 0.7214497327804565, accuracy-macro: 0.0037000000011176\n",
      "step:     169, loss: 0.1905455887317657, accuracy-micro: 0.7213245034217834, accuracy-macro: 0.0037000000011176\n",
      "step:     170, loss: 0.1904754787683487, accuracy-micro: 0.7217429876327515, accuracy-macro: 0.0037000000011176\n",
      "step:     171, loss: 0.1903699040412903, accuracy-micro: 0.7217934727668762, accuracy-macro: 0.0037000000011176\n",
      "step:     172, loss: 0.1903016567230225, accuracy-micro: 0.7219317555427551, accuracy-macro: 0.0037000000011176\n",
      "step:     173, loss: 0.1902587860822678, accuracy-micro: 0.7221692204475403, accuracy-macro: 0.0037000000011176\n",
      "step:     174, loss: 0.1901822388172150, accuracy-micro: 0.7221437692642212, accuracy-macro: 0.0037000000011176\n",
      "step:     175, loss: 0.1900927275419235, accuracy-micro: 0.7224429845809937, accuracy-macro: 0.0037000000011176\n",
      "step:     176, loss: 0.1900355517864227, accuracy-micro: 0.7226085066795349, accuracy-macro: 0.0037000000011176\n",
      "step:     177, loss: 0.1899836361408234, accuracy-micro: 0.7225710153579712, accuracy-macro: 0.0037000000011176\n",
      "step:     178, loss: 0.1899054348468781, accuracy-micro: 0.7228940129280090, accuracy-macro: 0.0037000000011176\n",
      "step:     179, loss: 0.1898304075002670, accuracy-micro: 0.7230020165443420, accuracy-macro: 0.0037000000011176\n",
      "step:     180, loss: 0.1897756606340408, accuracy-micro: 0.7230612635612488, accuracy-macro: 0.0037000000011176\n",
      "step:     181, loss: 0.1897161304950714, accuracy-micro: 0.7233380079269409, accuracy-macro: 0.0037000000011176\n",
      "step:     182, loss: 0.1896439790725708, accuracy-micro: 0.7233955264091492, accuracy-macro: 0.0037000000011176\n",
      "step:     183, loss: 0.1895778775215149, accuracy-micro: 0.7235680222511292, accuracy-macro: 0.0037000000011176\n",
      "step:     184, loss: 0.1895223259925842, accuracy-micro: 0.7237472534179688, accuracy-macro: 0.0037000000011176\n",
      "step:     185, loss: 0.1894634366035461, accuracy-micro: 0.7237522602081299, accuracy-macro: 0.0037000000011176\n",
      "step:     186, loss: 0.1893956661224365, accuracy-micro: 0.7240032553672791, accuracy-macro: 0.0037000000011176\n",
      "step:     187, loss: 0.1893312186002731, accuracy-micro: 0.7241177558898926, accuracy-macro: 0.0037000000011176\n",
      "step:     188, loss: 0.1892755776643753, accuracy-micro: 0.7242197394371033, accuracy-macro: 0.0037000000011176\n",
      "step:     189, loss: 0.1892185211181641, accuracy-micro: 0.7243959903717041, accuracy-macro: 0.0037000000011176\n",
      "step:     190, loss: 0.1891546845436096, accuracy-micro: 0.7244932651519775, accuracy-macro: 0.0037000000011176\n",
      "step:     191, loss: 0.1890909224748611, accuracy-micro: 0.7246797680854797, accuracy-macro: 0.0037000000011176\n",
      "step:     192, loss: 0.1890331953763962, accuracy-micro: 0.7248100042343140, accuracy-macro: 0.0037000000011176\n",
      "step:     193, loss: 0.1889776587486267, accuracy-micro: 0.7249019742012024, accuracy-macro: 0.0037000000011176\n",
      "step:     194, loss: 0.1889187544584274, accuracy-micro: 0.7250639796257019, accuracy-macro: 0.0037000000011176\n",
      "step:     195, loss: 0.1888579726219177, accuracy-micro: 0.7251644730567932, accuracy-macro: 0.0037000000011176\n",
      "step:     196, loss: 0.1887991875410080, accuracy-micro: 0.7252917289733887, accuracy-macro: 0.0037000000011176\n",
      "step:     197, loss: 0.1887433379888535, accuracy-micro: 0.7254214882850647, accuracy-macro: 0.0037000000011176\n",
      "step:     198, loss: 0.1886880993843079, accuracy-micro: 0.7255030274391174, accuracy-macro: 0.0037000000011176\n",
      "step:     199, loss: 0.1886311471462250, accuracy-micro: 0.7256677746772766, accuracy-macro: 0.0037000000011176\n",
      "step:     200, loss: 0.1885732859373093, accuracy-micro: 0.7257467508316040, accuracy-macro: 0.0037000000011176\n",
      "step:     201, loss: 0.1885149031877518, accuracy-micro: 0.7258927226066589, accuracy-macro: 0.0037000000011176\n",
      "step:     202, loss: 0.1884582489728928, accuracy-micro: 0.7260212302207947, accuracy-macro: 0.0037000000011176\n",
      "step:     203, loss: 0.1884035915136337, accuracy-micro: 0.7261670231819153, accuracy-macro: 0.0037000000011176\n",
      "step:     204, loss: 0.1883500069379807, accuracy-micro: 0.7262472510337830, accuracy-macro: 0.0037000000011176\n",
      "step:     205, loss: 0.1882962286472321, accuracy-micro: 0.7263885140419006, accuracy-macro: 0.0037000000011176\n",
      "step:     206, loss: 0.1882416158914566, accuracy-micro: 0.7264897227287292, accuracy-macro: 0.0037000000011176\n",
      "step:     207, loss: 0.1881864517927170, accuracy-micro: 0.7266242504119873, accuracy-macro: 0.0037000000011176\n",
      "step:     208, loss: 0.1881311386823654, accuracy-micro: 0.7267500162124634, accuracy-macro: 0.0037000000011176\n",
      "step:     209, loss: 0.1880764663219452, accuracy-micro: 0.7268760204315186, accuracy-macro: 0.0037000000011176\n",
      "step:     210, loss: 0.1880230605602264, accuracy-micro: 0.7269797325134277, accuracy-macro: 0.0037000000011176\n",
      "step:     211, loss: 0.1879706829786301, accuracy-micro: 0.7270802259445190, accuracy-macro: 0.0037000000011176\n",
      "step:     212, loss: 0.1879189461469650, accuracy-micro: 0.7271860241889954, accuracy-macro: 0.0037000000011176\n",
      "step:     213, loss: 0.1878672838211060, accuracy-micro: 0.7272982597351074, accuracy-macro: 0.0037000000011176\n",
      "step:     214, loss: 0.1878164708614349, accuracy-micro: 0.7273795008659363, accuracy-macro: 0.0037000000011176\n",
      "step:     215, loss: 0.1877654343843460, accuracy-micro: 0.7274947762489319, accuracy-macro: 0.0037000000011176\n",
      "step:     216, loss: 0.1877139061689377, accuracy-micro: 0.7275999784469604, accuracy-macro: 0.0037000000011176\n",
      "step:     217, loss: 0.1876630932092667, accuracy-micro: 0.7276964783668518, accuracy-macro: 0.0037000000011176\n",
      "step:     218, loss: 0.1876130998134613, accuracy-micro: 0.7277944684028625, accuracy-macro: 0.0037000000011176\n",
      "step:     219, loss: 0.1875633597373962, accuracy-micro: 0.7279037237167358, accuracy-macro: 0.0037000000011176\n",
      "step:     220, loss: 0.1875147670507431, accuracy-micro: 0.7280024886131287, accuracy-macro: 0.0037000000011176\n",
      "step:     221, loss: 0.1874682754278183, accuracy-micro: 0.7281352281570435, accuracy-macro: 0.0037000000011176\n",
      "step:     222, loss: 0.1874260902404785, accuracy-micro: 0.7282072305679321, accuracy-macro: 0.0037000000011176\n",
      "step:     223, loss: 0.1873892843723297, accuracy-micro: 0.7283015251159668, accuracy-macro: 0.0037000000011176\n",
      "step:     224, loss: 0.1873627454042435, accuracy-micro: 0.7282832264900208, accuracy-macro: 0.0037000000011176\n",
      "step:     225, loss: 0.1873393952846527, accuracy-micro: 0.7284782528877258, accuracy-macro: 0.0037000000011176\n",
      "step:     226, loss: 0.1873186677694321, accuracy-micro: 0.7283527255058289, accuracy-macro: 0.0037000000011176\n",
      "step:     227, loss: 0.1872625052928925, accuracy-micro: 0.7286432385444641, accuracy-macro: 0.0037000000011176\n",
      "step:     228, loss: 0.1871779710054398, accuracy-micro: 0.7286419868469238, accuracy-macro: 0.0037000000011176\n",
      "step:     229, loss: 0.1870871484279633, accuracy-micro: 0.7288627624511719, accuracy-macro: 0.0037000000011176\n",
      "step:     230, loss: 0.1870380789041519, accuracy-micro: 0.7289742231369019, accuracy-macro: 0.0037000000011176\n",
      "step:     231, loss: 0.1870229393243790, accuracy-micro: 0.7289835214614868, accuracy-macro: 0.0037000000011176\n",
      "step:     232, loss: 0.1869989633560181, accuracy-micro: 0.7291167378425598, accuracy-macro: 0.0037000000011176\n",
      "step:     233, loss: 0.1869441866874695, accuracy-micro: 0.7291207313537598, accuracy-macro: 0.0037000000011176\n",
      "step:     234, loss: 0.1868700087070465, accuracy-micro: 0.7292975187301636, accuracy-macro: 0.0037000000011176\n",
      "step:     235, loss: 0.1868164837360382, accuracy-micro: 0.7293612360954285, accuracy-macro: 0.0037000000011176\n",
      "step:     236, loss: 0.1867890655994415, accuracy-micro: 0.7294652462005615, accuracy-macro: 0.0037000000011176\n",
      "step:     237, loss: 0.1867617219686508, accuracy-micro: 0.7295460104942322, accuracy-macro: 0.0037000000011176\n",
      "step:     238, loss: 0.1867156475782394, accuracy-micro: 0.7296117544174194, accuracy-macro: 0.0037000000011176\n",
      "step:     239, loss: 0.1866556555032730, accuracy-micro: 0.7297152280807495, accuracy-macro: 0.0037000000011176\n",
      "step:     240, loss: 0.1866052746772766, accuracy-micro: 0.7298062443733215, accuracy-macro: 0.0037000000011176\n",
      "step:     241, loss: 0.1865709722042084, accuracy-micro: 0.7298545241355896, accuracy-macro: 0.0037000000011176\n",
      "step:     242, loss: 0.1865404248237610, accuracy-micro: 0.7299672365188599, accuracy-macro: 0.0037000000011176\n",
      "step:     243, loss: 0.1865010708570480, accuracy-micro: 0.7299669981002808, accuracy-macro: 0.0037000000011176\n",
      "step:     244, loss: 0.1864496171474457, accuracy-micro: 0.7301309704780579, accuracy-macro: 0.0037000000011176\n",
      "step:     245, loss: 0.1863999962806702, accuracy-micro: 0.7301727533340454, accuracy-macro: 0.0037000000011176\n",
      "step:     246, loss: 0.1863615661859512, accuracy-micro: 0.7302507758140564, accuracy-macro: 0.0037000000011176\n",
      "step:     247, loss: 0.1863306909799576, accuracy-micro: 0.7303452491760254, accuracy-macro: 0.0037000000011176\n",
      "step:     248, loss: 0.1862963140010834, accuracy-micro: 0.7303624749183655, accuracy-macro: 0.0037000000011176\n",
      "step:     249, loss: 0.1862513422966003, accuracy-micro: 0.7304782271385193, accuracy-macro: 0.0037000000011176\n",
      "step:     250, loss: 0.1862027198076248, accuracy-micro: 0.7305579781532288, accuracy-macro: 0.0037000000011176\n",
      "step:     251, loss: 0.1861586272716522, accuracy-micro: 0.7306489944458008, accuracy-macro: 0.0037000000011176\n",
      "step:     252, loss: 0.1861230283975601, accuracy-micro: 0.7307415008544922, accuracy-macro: 0.0037000000011176\n",
      "step:     253, loss: 0.1860897988080978, accuracy-micro: 0.7307525277137756, accuracy-macro: 0.0037000000011176\n",
      "step:     254, loss: 0.1860520988702774, accuracy-micro: 0.7308862209320068, accuracy-macro: 0.0037000000011176\n",
      "step:     255, loss: 0.1860091835260391, accuracy-micro: 0.7309070229530334, accuracy-macro: 0.0037000000011176\n",
      "step:     256, loss: 0.1859653294086456, accuracy-micro: 0.7310324907302856, accuracy-macro: 0.0037000000011176\n",
      "step:     257, loss: 0.1859239935874939, accuracy-micro: 0.7311069965362549, accuracy-macro: 0.0037000000011176\n",
      "step:     258, loss: 0.1858873069286346, accuracy-micro: 0.7311497330665588, accuracy-macro: 0.0037000000011176\n",
      "step:     259, loss: 0.1858521848917007, accuracy-micro: 0.7312214970588684, accuracy-macro: 0.0037000000011176\n",
      "step:     260, loss: 0.1858154237270355, accuracy-micro: 0.7312474846839905, accuracy-macro: 0.0037000000011176\n",
      "step:     261, loss: 0.1857760995626450, accuracy-micro: 0.7313604950904846, accuracy-macro: 0.0037000000011176\n",
      "step:     262, loss: 0.1857358813285828, accuracy-micro: 0.7314272522926331, accuracy-macro: 0.0037000000011176\n",
      "step:     263, loss: 0.1856957376003265, accuracy-micro: 0.7314967513084412, accuracy-macro: 0.0037000000011176\n",
      "step:     264, loss: 0.1856573373079300, accuracy-micro: 0.7315822243690491, accuracy-macro: 0.0037000000011176\n",
      "step:     265, loss: 0.1856204420328140, accuracy-micro: 0.7316417694091797, accuracy-macro: 0.0037000000011176\n",
      "step:     266, loss: 0.1855852007865906, accuracy-micro: 0.7316972613334656, accuracy-macro: 0.0037000000011176\n",
      "step:     267, loss: 0.1855499595403671, accuracy-micro: 0.7317550182342529, accuracy-macro: 0.0037000000011176\n",
      "step:     268, loss: 0.1855140030384064, accuracy-micro: 0.7318492531776428, accuracy-macro: 0.0037000000011176\n",
      "step:     269, loss: 0.1854764223098755, accuracy-micro: 0.7318857312202454, accuracy-macro: 0.0037000000011176\n",
      "step:     270, loss: 0.1854381263256073, accuracy-micro: 0.7319970130920410, accuracy-macro: 0.0037000000011176\n",
      "step:     271, loss: 0.1853995025157928, accuracy-micro: 0.7320152521133423, accuracy-macro: 0.0037000000011176\n",
      "step:     272, loss: 0.1853613406419754, accuracy-micro: 0.7321414947509766, accuracy-macro: 0.0037000000011176\n",
      "step:     273, loss: 0.1853237748146057, accuracy-micro: 0.7321594953536987, accuracy-macro: 0.0037000000011176\n",
      "step:     274, loss: 0.1852869391441345, accuracy-micro: 0.7322620153427124, accuracy-macro: 0.0037000000011176\n",
      "step:     275, loss: 0.1852496266365051, accuracy-micro: 0.7323039770126343, accuracy-macro: 0.0037000000011176\n",
      "step:     276, loss: 0.1852128654718399, accuracy-micro: 0.7324075102806091, accuracy-macro: 0.0037000000011176\n",
      "step:     277, loss: 0.1851767152547836, accuracy-micro: 0.7324312329292297, accuracy-macro: 0.0037000000011176\n",
      "step:     278, loss: 0.1851405948400497, accuracy-micro: 0.7325277328491211, accuracy-macro: 0.0037000000011176\n",
      "step:     279, loss: 0.1851043999195099, accuracy-micro: 0.7325760126113892, accuracy-macro: 0.0037000000011176\n",
      "step:     280, loss: 0.1850686073303223, accuracy-micro: 0.7326779961585999, accuracy-macro: 0.0037000000011176\n",
      "step:     281, loss: 0.1850331276655197, accuracy-micro: 0.7327092289924622, accuracy-macro: 0.0037000000011176\n",
      "step:     282, loss: 0.1849972754716873, accuracy-micro: 0.7327972650527954, accuracy-macro: 0.0037000000011176\n",
      "step:     283, loss: 0.1849624067544937, accuracy-micro: 0.7328082323074341, accuracy-macro: 0.0037000000011176\n",
      "step:     284, loss: 0.1849275082349777, accuracy-micro: 0.7329199910163879, accuracy-macro: 0.0037000000011176\n",
      "step:     285, loss: 0.1848935037851334, accuracy-micro: 0.7329260110855103, accuracy-macro: 0.0037000000011176\n",
      "step:     286, loss: 0.1848608851432800, accuracy-micro: 0.7330294847488403, accuracy-macro: 0.0037000000011176\n",
      "step:     287, loss: 0.1848315000534058, accuracy-micro: 0.7330347299575806, accuracy-macro: 0.0037000000011176\n",
      "step:     288, loss: 0.1848072856664658, accuracy-micro: 0.7330687642097473, accuracy-macro: 0.0037000000011176\n",
      "step:     289, loss: 0.1847964674234390, accuracy-micro: 0.7330897450447083, accuracy-macro: 0.0037000000011176\n",
      "step:     290, loss: 0.1848037689924240, accuracy-micro: 0.7331179976463318, accuracy-macro: 0.0037000000011176\n",
      "step:     291, loss: 0.1848433613777161, accuracy-micro: 0.7328937649726868, accuracy-macro: 0.0037000000011176\n",
      "step:     292, loss: 0.1848576813936234, accuracy-micro: 0.7330304980278015, accuracy-macro: 0.0037000000011176\n",
      "step:     293, loss: 0.1848150491714478, accuracy-micro: 0.7329699993133545, accuracy-macro: 0.0037000000011176\n",
      "step:     294, loss: 0.1846545040607452, accuracy-micro: 0.7333564758300781, accuracy-macro: 0.0037000000011176\n",
      "step:     295, loss: 0.1845511049032211, accuracy-micro: 0.7335630059242249, accuracy-macro: 0.0037000000011176\n",
      "step:     296, loss: 0.1845718324184418, accuracy-micro: 0.7334737777709961, accuracy-macro: 0.0037000000011176\n",
      "step:     297, loss: 0.1846022456884384, accuracy-micro: 0.7334717512130737, accuracy-macro: 0.0037000000011176\n",
      "step:     298, loss: 0.1845443397760391, accuracy-micro: 0.7335100173950195, accuracy-macro: 0.0037000000011176\n",
      "step:     299, loss: 0.1844370514154434, accuracy-micro: 0.7337214946746826, accuracy-macro: 0.0037000000011176\n",
      "step:     300, loss: 0.1844153702259064, accuracy-micro: 0.7337312698364258, accuracy-macro: 0.0037000000011176\n",
      "step:     301, loss: 0.1844411343336105, accuracy-micro: 0.7336722612380981, accuracy-macro: 0.0037000000011176\n",
      "step:     302, loss: 0.1843949854373932, accuracy-micro: 0.7337737679481506, accuracy-macro: 0.0037000000011176\n",
      "step:     303, loss: 0.1843152344226837, accuracy-micro: 0.7339140176773071, accuracy-macro: 0.0037000000011176\n",
      "step:     304, loss: 0.1842893064022064, accuracy-micro: 0.7339475154876709, accuracy-macro: 0.0037000000011176\n",
      "step:     305, loss: 0.1842944025993347, accuracy-micro: 0.7339425086975098, accuracy-macro: 0.0037000000011176\n",
      "step:     306, loss: 0.1842583417892456, accuracy-micro: 0.7340167760848999, accuracy-macro: 0.0037000000011176\n",
      "step:     307, loss: 0.1841949522495270, accuracy-micro: 0.7341447472572327, accuracy-macro: 0.0037000000011176\n",
      "step:     308, loss: 0.1841696500778198, accuracy-micro: 0.7342022657394409, accuracy-macro: 0.0037000000011176\n",
      "step:     309, loss: 0.1841652542352676, accuracy-micro: 0.7341729998588562, accuracy-macro: 0.0037000000011176\n",
      "step:     310, loss: 0.1841288655996323, accuracy-micro: 0.7342569828033447, accuracy-macro: 0.0037000000011176\n",
      "step:     311, loss: 0.1840771883726120, accuracy-micro: 0.7343184947967529, accuracy-macro: 0.0037000000011176\n",
      "step:     312, loss: 0.1840522289276123, accuracy-micro: 0.7343697547912598, accuracy-macro: 0.0037000000011176\n",
      "step:     313, loss: 0.1840405017137527, accuracy-micro: 0.7343994975090027, accuracy-macro: 0.0037000000011176\n",
      "step:     314, loss: 0.1840068697929382, accuracy-micro: 0.7344387769699097, accuracy-macro: 0.0037000000011176\n",
      "step:     315, loss: 0.1839618682861328, accuracy-micro: 0.7345485091209412, accuracy-macro: 0.0037000000011176\n",
      "step:     316, loss: 0.1839369535446167, accuracy-micro: 0.7345987558364868, accuracy-macro: 0.0037000000011176\n",
      "step:     317, loss: 0.1839192211627960, accuracy-micro: 0.7345765233039856, accuracy-macro: 0.0037000000011176\n",
      "step:     318, loss: 0.1838856786489487, accuracy-micro: 0.7346850037574768, accuracy-macro: 0.0037000000011176\n",
      "step:     319, loss: 0.1838481724262238, accuracy-micro: 0.7347227334976196, accuracy-macro: 0.0037000000011176\n",
      "step:     320, loss: 0.1838218122720718, accuracy-micro: 0.7347660064697266, accuracy-macro: 0.0037000000011176\n",
      "step:     321, loss: 0.1838017851114273, accuracy-micro: 0.7348167300224304, accuracy-macro: 0.0037000000011176\n",
      "step:     322, loss: 0.1837728768587112, accuracy-micro: 0.7348340153694153, accuracy-macro: 0.0037000000011176\n",
      "step:     323, loss: 0.1837366670370102, accuracy-micro: 0.7349257469177246, accuracy-macro: 0.0037000000011176\n",
      "step:     324, loss: 0.1837083101272583, accuracy-micro: 0.7349672317504883, accuracy-macro: 0.0037000000011176\n",
      "step:     325, loss: 0.1836869120597839, accuracy-micro: 0.7349687218666077, accuracy-macro: 0.0037000000011176\n",
      "step:     326, loss: 0.1836599707603455, accuracy-micro: 0.7350572347640991, accuracy-macro: 0.0037000000011176\n",
      "step:     327, loss: 0.1836267858743668, accuracy-micro: 0.7351132631301880, accuracy-macro: 0.0037000000011176\n",
      "step:     328, loss: 0.1835958957672119, accuracy-micro: 0.7351465225219727, accuracy-macro: 0.0037000000011176\n",
      "step:     329, loss: 0.1835712045431137, accuracy-micro: 0.7351997494697571, accuracy-macro: 0.0037000000011176\n",
      "step:     330, loss: 0.1835461258888245, accuracy-micro: 0.7352452278137207, accuracy-macro: 0.0037000000011176\n",
      "step:     331, loss: 0.1835169941186905, accuracy-micro: 0.7353132367134094, accuracy-macro: 0.0037000000011176\n",
      "step:     332, loss: 0.1834866404533386, accuracy-micro: 0.7353360056877136, accuracy-macro: 0.0037000000011176\n",
      "step:     333, loss: 0.1834591925144196, accuracy-micro: 0.7353952527046204, accuracy-macro: 0.0037000000011176\n",
      "step:     334, loss: 0.1834345161914825, accuracy-micro: 0.7354425191879272, accuracy-macro: 0.0037000000011176\n",
      "step:     335, loss: 0.1834076195955276, accuracy-micro: 0.7354825139045715, accuracy-macro: 0.0037000000011176\n",
      "step:     336, loss: 0.1833786219358444, accuracy-micro: 0.7355257272720337, accuracy-macro: 0.0037000000011176\n",
      "step:     337, loss: 0.1833498477935791, accuracy-micro: 0.7355877757072449, accuracy-macro: 0.0037000000011176\n",
      "step:     338, loss: 0.1833228766918182, accuracy-micro: 0.7356265187263489, accuracy-macro: 0.0037000000011176\n",
      "step:     339, loss: 0.1832970678806305, accuracy-micro: 0.7356842756271362, accuracy-macro: 0.0037000000011176\n",
      "step:     340, loss: 0.1832703649997711, accuracy-micro: 0.7357067465782166, accuracy-macro: 0.0037000000011176\n",
      "step:     341, loss: 0.1832423061132431, accuracy-micro: 0.7357802391052246, accuracy-macro: 0.0037000000011176\n",
      "step:     342, loss: 0.1832143813371658, accuracy-micro: 0.7358372211456299, accuracy-macro: 0.0037000000011176\n",
      "step:     343, loss: 0.1831880658864975, accuracy-micro: 0.7358692288398743, accuracy-macro: 0.0037000000011176\n",
      "step:     344, loss: 0.1831624805927277, accuracy-micro: 0.7359447479248047, accuracy-macro: 0.0037000000011176\n",
      "step:     345, loss: 0.1831352114677429, accuracy-micro: 0.7359769940376282, accuracy-macro: 0.0037000000011176\n",
      "step:     346, loss: 0.1831070184707642, accuracy-micro: 0.7360550165176392, accuracy-macro: 0.0037000000011176\n",
      "step:     347, loss: 0.1830796003341675, accuracy-micro: 0.7360690236091614, accuracy-macro: 0.0037000000011176\n",
      "step:     348, loss: 0.1830531954765320, accuracy-micro: 0.7361124753952026, accuracy-macro: 0.0037000000011176\n",
      "step:     349, loss: 0.1830276697874069, accuracy-micro: 0.7361670136451721, accuracy-macro: 0.0037000000011176\n",
      "step:     350, loss: 0.1830024719238281, accuracy-micro: 0.7362097501754761, accuracy-macro: 0.0037000000011176\n",
      "step:     351, loss: 0.1829754263162613, accuracy-micro: 0.7362664937973022, accuracy-macro: 0.0037000000011176\n",
      "step:     352, loss: 0.1829477846622467, accuracy-micro: 0.7362797260284424, accuracy-macro: 0.0037000000011176\n",
      "step:     353, loss: 0.1829201877117157, accuracy-micro: 0.7363499999046326, accuracy-macro: 0.0037000000011176\n",
      "step:     354, loss: 0.1828929036855698, accuracy-micro: 0.7364132404327393, accuracy-macro: 0.0037000000011176\n",
      "step:     355, loss: 0.1828668713569641, accuracy-micro: 0.7364479899406433, accuracy-macro: 0.0037000000011176\n",
      "step:     356, loss: 0.1828413009643555, accuracy-micro: 0.7364822626113892, accuracy-macro: 0.0037000000011176\n",
      "step:     357, loss: 0.1828151941299438, accuracy-micro: 0.7365245223045349, accuracy-macro: 0.0037000000011176\n",
      "step:     358, loss: 0.1827881187200546, accuracy-micro: 0.7365720272064209, accuracy-macro: 0.0037000000011176\n",
      "step:     359, loss: 0.1827606260776520, accuracy-micro: 0.7365992665290833, accuracy-macro: 0.0037000000011176\n",
      "step:     360, loss: 0.1827341616153717, accuracy-micro: 0.7366727590560913, accuracy-macro: 0.0037000000011176\n",
      "step:     361, loss: 0.1827079355716705, accuracy-micro: 0.7367212772369385, accuracy-macro: 0.0037000000011176\n",
      "step:     362, loss: 0.1826822608709335, accuracy-micro: 0.7367062568664551, accuracy-macro: 0.0037000000011176\n",
      "step:     363, loss: 0.1826557815074921, accuracy-micro: 0.7368245124816895, accuracy-macro: 0.0037000000011176\n",
      "step:     364, loss: 0.1826287508010864, accuracy-micro: 0.7368174791336060, accuracy-macro: 0.0037000000011176\n",
      "step:     365, loss: 0.1826020628213882, accuracy-micro: 0.7368937730789185, accuracy-macro: 0.0037000000011176\n",
      "step:     366, loss: 0.1825758069753647, accuracy-micro: 0.7369359731674194, accuracy-macro: 0.0037000000011176\n",
      "step:     367, loss: 0.1825495064258575, accuracy-micro: 0.7369725108146667, accuracy-macro: 0.0037000000011176\n",
      "step:     368, loss: 0.1825233101844788, accuracy-micro: 0.7370240092277527, accuracy-macro: 0.0037000000011176\n",
      "step:     369, loss: 0.1824971288442612, accuracy-micro: 0.7370522618293762, accuracy-macro: 0.0037000000011176\n",
      "step:     370, loss: 0.1824705153703690, accuracy-micro: 0.7371112704277039, accuracy-macro: 0.0037000000011176\n",
      "step:     371, loss: 0.1824442446231842, accuracy-micro: 0.7371510267257690, accuracy-macro: 0.0037000000011176\n",
      "step:     372, loss: 0.1824181824922562, accuracy-micro: 0.7371910214424133, accuracy-macro: 0.0037000000011176\n",
      "step:     373, loss: 0.1823923736810684, accuracy-micro: 0.7372367382049561, accuracy-macro: 0.0037000000011176\n",
      "step:     374, loss: 0.1823663115501404, accuracy-micro: 0.7372807264328003, accuracy-macro: 0.0037000000011176\n",
      "step:     375, loss: 0.1823407411575317, accuracy-micro: 0.7373167276382446, accuracy-macro: 0.0037000000011176\n",
      "step:     376, loss: 0.1823148727416992, accuracy-micro: 0.7373672723770142, accuracy-macro: 0.0037000000011176\n",
      "step:     377, loss: 0.1822885125875473, accuracy-micro: 0.7374004721641541, accuracy-macro: 0.0037000000011176\n",
      "step:     378, loss: 0.1822621524333954, accuracy-micro: 0.7374615073204041, accuracy-macro: 0.0037000000011176\n",
      "step:     379, loss: 0.1822361052036285, accuracy-micro: 0.7374732494354248, accuracy-macro: 0.0037000000011176\n",
      "step:     380, loss: 0.1822103410959244, accuracy-micro: 0.7375314831733704, accuracy-macro: 0.0037000000011176\n",
      "step:     381, loss: 0.1821846961975098, accuracy-micro: 0.7375692725181580, accuracy-macro: 0.0037000000011176\n",
      "step:     382, loss: 0.1821593493223190, accuracy-micro: 0.7376049757003784, accuracy-macro: 0.0037000000011176\n",
      "step:     383, loss: 0.1821339428424835, accuracy-micro: 0.7376452684402466, accuracy-macro: 0.0037000000011176\n",
      "step:     384, loss: 0.1821093112230301, accuracy-micro: 0.7376539707183838, accuracy-macro: 0.0037000000011176\n",
      "step:     385, loss: 0.1820848733186722, accuracy-micro: 0.7377445101737976, accuracy-macro: 0.0037000000011176\n",
      "step:     386, loss: 0.1820603162050247, accuracy-micro: 0.7377582192420959, accuracy-macro: 0.0037000000011176\n",
      "step:     387, loss: 0.1820362806320190, accuracy-micro: 0.7378190159797668, accuracy-macro: 0.0037000000011176\n",
      "step:     388, loss: 0.1820126473903656, accuracy-micro: 0.7378529906272888, accuracy-macro: 0.0037000000011176\n",
      "step:     389, loss: 0.1819917559623718, accuracy-micro: 0.7378817200660706, accuracy-macro: 0.0037000000011176\n",
      "step:     390, loss: 0.1819738745689392, accuracy-micro: 0.7379032373428345, accuracy-macro: 0.0037000000011176\n",
      "step:     391, loss: 0.1819608062505722, accuracy-micro: 0.7378727197647095, accuracy-macro: 0.0037000000011176\n",
      "step:     392, loss: 0.1819494962692261, accuracy-micro: 0.7379724979400635, accuracy-macro: 0.0037000000011176\n",
      "step:     393, loss: 0.1819451302289963, accuracy-micro: 0.7379517555236816, accuracy-macro: 0.0037000000011176\n",
      "step:     394, loss: 0.1819397360086441, accuracy-micro: 0.7379387617111206, accuracy-macro: 0.0037000000011176\n",
      "step:     395, loss: 0.1819382309913635, accuracy-micro: 0.7379385232925415, accuracy-macro: 0.0037000000011176\n",
      "step:     396, loss: 0.1819078922271729, accuracy-micro: 0.7379854917526245, accuracy-macro: 0.0037000000011176\n",
      "step:     397, loss: 0.1818583011627197, accuracy-micro: 0.7380647659301758, accuracy-macro: 0.0037000000011176\n",
      "step:     398, loss: 0.1817891448736191, accuracy-micro: 0.7382697463035583, accuracy-macro: 0.0037000000011176\n",
      "step:     399, loss: 0.1817364096641541, accuracy-micro: 0.7383157610893250, accuracy-macro: 0.0037000000011176\n",
      "step:     400, loss: 0.1817135363817215, accuracy-micro: 0.7383432388305664, accuracy-macro: 0.0037000000011176\n",
      "step:     401, loss: 0.1817110031843185, accuracy-micro: 0.7383862733840942, accuracy-macro: 0.0037000000011176\n",
      "step:     402, loss: 0.1817092150449753, accuracy-micro: 0.7383275032043457, accuracy-macro: 0.0037000000011176\n",
      "step:     403, loss: 0.1816868931055069, accuracy-micro: 0.7383995056152344, accuracy-macro: 0.0037000000011176\n",
      "step:     404, loss: 0.1816479116678238, accuracy-micro: 0.7384092211723328, accuracy-macro: 0.0037000000011176\n",
      "step:     405, loss: 0.1816019266843796, accuracy-micro: 0.7384997606277466, accuracy-macro: 0.0037000000011176\n",
      "step:     406, loss: 0.1815679967403412, accuracy-micro: 0.7385457754135132, accuracy-macro: 0.0037000000011176\n",
      "step:     407, loss: 0.1815503388643265, accuracy-micro: 0.7385805249214172, accuracy-macro: 0.0037000000011176\n",
      "step:     408, loss: 0.1815405637025833, accuracy-micro: 0.7386440038681030, accuracy-macro: 0.0037000000011176\n",
      "step:     409, loss: 0.1815261542797089, accuracy-micro: 0.7386310100555420, accuracy-macro: 0.0037000000011176\n",
      "step:     410, loss: 0.1814989000558853, accuracy-micro: 0.7387105226516724, accuracy-macro: 0.0037000000011176\n",
      "step:     411, loss: 0.1814639717340469, accuracy-micro: 0.7387412190437317, accuracy-macro: 0.0037000000011176\n",
      "step:     412, loss: 0.1814297139644623, accuracy-micro: 0.7387877702713013, accuracy-macro: 0.0037000000011176\n",
      "step:     413, loss: 0.1814074367284775, accuracy-micro: 0.7388160228729248, accuracy-macro: 0.0037000000011176\n",
      "step:     414, loss: 0.1813931912183762, accuracy-micro: 0.7388499975204468, accuracy-macro: 0.0037000000011176\n",
      "step:     415, loss: 0.1813774704933167, accuracy-micro: 0.7388727664947510, accuracy-macro: 0.0037000000011176\n",
      "step:     416, loss: 0.1813549250364304, accuracy-micro: 0.7389192581176758, accuracy-macro: 0.0037000000011176\n",
      "step:     417, loss: 0.1813247352838516, accuracy-micro: 0.7389697432518005, accuracy-macro: 0.0037000000011176\n",
      "step:     418, loss: 0.1812942177057266, accuracy-micro: 0.7389992475509644, accuracy-macro: 0.0037000000011176\n",
      "step:     419, loss: 0.1812674105167389, accuracy-micro: 0.7390582561492920, accuracy-macro: 0.0037000000011176\n",
      "step:     420, loss: 0.1812477856874466, accuracy-micro: 0.7390592694282532, accuracy-macro: 0.0037000000011176\n",
      "step:     421, loss: 0.1812313646078110, accuracy-micro: 0.7390967607498169, accuracy-macro: 0.0037000000011176\n",
      "step:     422, loss: 0.1812120079994202, accuracy-micro: 0.7391282320022583, accuracy-macro: 0.0037000000011176\n",
      "step:     423, loss: 0.1811876893043518, accuracy-micro: 0.7391765117645264, accuracy-macro: 0.0037000000011176\n",
      "step:     424, loss: 0.1811593472957611, accuracy-micro: 0.7391932606697083, accuracy-macro: 0.0037000000011176\n",
      "step:     425, loss: 0.1811327785253525, accuracy-micro: 0.7392519712448120, accuracy-macro: 0.0037000000011176\n",
      "step:     426, loss: 0.1811095923185349, accuracy-micro: 0.7392802238464355, accuracy-macro: 0.0037000000011176\n",
      "step:     427, loss: 0.1810892820358276, accuracy-micro: 0.7393119931221008, accuracy-macro: 0.0037000000011176\n",
      "step:     428, loss: 0.1810698807239532, accuracy-micro: 0.7393417358398438, accuracy-macro: 0.0037000000011176\n",
      "step:     429, loss: 0.1810494065284729, accuracy-micro: 0.7393900156021118, accuracy-macro: 0.0037000000011176\n",
      "step:     430, loss: 0.1810269206762314, accuracy-micro: 0.7394147515296936, accuracy-macro: 0.0037000000011176\n",
      "step:     431, loss: 0.1810024082660675, accuracy-micro: 0.7394394874572754, accuracy-macro: 0.0037000000011176\n",
      "step:     432, loss: 0.1809773743152618, accuracy-micro: 0.7394989728927612, accuracy-macro: 0.0037000000011176\n",
      "step:     433, loss: 0.1809534430503845, accuracy-micro: 0.7395355105400085, accuracy-macro: 0.0037000000011176\n",
      "step:     434, loss: 0.1809314638376236, accuracy-micro: 0.7395659685134888, accuracy-macro: 0.0037000000011176\n",
      "step:     435, loss: 0.1809106469154358, accuracy-micro: 0.7396032214164734, accuracy-macro: 0.0037000000011176\n",
      "step:     436, loss: 0.1808897852897644, accuracy-micro: 0.7396272420883179, accuracy-macro: 0.0037000000011176\n",
      "step:     437, loss: 0.1808679699897766, accuracy-micro: 0.7396702766418457, accuracy-macro: 0.0037000000011176\n",
      "step:     438, loss: 0.1808463484048843, accuracy-micro: 0.7396975159645081, accuracy-macro: 0.0037000000011176\n",
      "step:     439, loss: 0.1808243691921234, accuracy-micro: 0.7397397756576538, accuracy-macro: 0.0037000000011176\n",
      "step:     440, loss: 0.1808016449213028, accuracy-micro: 0.7397812604904175, accuracy-macro: 0.0037000000011176\n",
      "step:     441, loss: 0.1807782799005508, accuracy-micro: 0.7398099899291992, accuracy-macro: 0.0037000000011176\n",
      "step:     442, loss: 0.1807558685541153, accuracy-micro: 0.7398574948310852, accuracy-macro: 0.0037000000011176\n",
      "step:     443, loss: 0.1807343810796738, accuracy-micro: 0.7398625016212463, accuracy-macro: 0.0037000000011176\n",
      "step:     444, loss: 0.1807139962911606, accuracy-micro: 0.7399092316627502, accuracy-macro: 0.0037000000011176\n",
      "step:     445, loss: 0.1806933134794235, accuracy-micro: 0.7399474978446960, accuracy-macro: 0.0037000000011176\n",
      "step:     446, loss: 0.1806730926036835, accuracy-micro: 0.7399617433547974, accuracy-macro: 0.0037000000011176\n",
      "step:     447, loss: 0.1806520521640778, accuracy-micro: 0.7399860024452209, accuracy-macro: 0.0037000000011176\n",
      "step:     448, loss: 0.1806317269802094, accuracy-micro: 0.7400462627410889, accuracy-macro: 0.0037000000011176\n",
      "step:     449, loss: 0.1806116700172424, accuracy-micro: 0.7400540113449097, accuracy-macro: 0.0037000000011176\n",
      "step:     450, loss: 0.1805919408798218, accuracy-micro: 0.7401160001754761, accuracy-macro: 0.0037000000011176\n",
      "step:     451, loss: 0.1805723309516907, accuracy-micro: 0.7401180267333984, accuracy-macro: 0.0037000000011176\n",
      "step:     452, loss: 0.1805520355701447, accuracy-micro: 0.7401827573776245, accuracy-macro: 0.0037000000011176\n",
      "step:     453, loss: 0.1805301606655121, accuracy-micro: 0.7401762604713440, accuracy-macro: 0.0037000000011176\n",
      "step:     454, loss: 0.1805074810981750, accuracy-micro: 0.7402537465095520, accuracy-macro: 0.0037000000011176\n",
      "step:     455, loss: 0.1804840564727783, accuracy-micro: 0.7402347326278687, accuracy-macro: 0.0037000000011176\n",
      "step:     456, loss: 0.1804607808589935, accuracy-micro: 0.7403242588043213, accuracy-macro: 0.0037000000011176\n",
      "step:     457, loss: 0.1804378032684326, accuracy-micro: 0.7403129935264587, accuracy-macro: 0.0037000000011176\n",
      "step:     458, loss: 0.1804150640964508, accuracy-micro: 0.7403817772865295, accuracy-macro: 0.0037000000011176\n",
      "step:     459, loss: 0.1803932338953018, accuracy-micro: 0.7403752207756042, accuracy-macro: 0.0037000000011176\n",
      "step:     460, loss: 0.1803713738918304, accuracy-micro: 0.7404450178146362, accuracy-macro: 0.0037000000011176\n",
      "step:     461, loss: 0.1803502738475800, accuracy-micro: 0.7404412627220154, accuracy-macro: 0.0037000000011176\n",
      "step:     462, loss: 0.1803288757801056, accuracy-micro: 0.7405012249946594, accuracy-macro: 0.0037000000011176\n",
      "step:     463, loss: 0.1803078949451447, accuracy-micro: 0.7405062317848206, accuracy-macro: 0.0037000000011176\n",
      "step:     464, loss: 0.1802860349416733, accuracy-micro: 0.7405685186386108, accuracy-macro: 0.0037000000011176\n",
      "step:     465, loss: 0.1802645027637482, accuracy-micro: 0.7405772209167480, accuracy-macro: 0.0037000000011176\n",
      "step:     466, loss: 0.1802432835102081, accuracy-micro: 0.7406292557716370, accuracy-macro: 0.0037000000011176\n",
      "step:     467, loss: 0.1802220940589905, accuracy-micro: 0.7406520247459412, accuracy-macro: 0.0037000000011176\n",
      "step:     468, loss: 0.1802016049623489, accuracy-micro: 0.7406932711601257, accuracy-macro: 0.0037000000011176\n",
      "step:     469, loss: 0.1801807284355164, accuracy-micro: 0.7406845092773438, accuracy-macro: 0.0037000000011176\n",
      "step:     470, loss: 0.1801606267690659, accuracy-micro: 0.7407737374305725, accuracy-macro: 0.0037000000011176\n",
      "step:     471, loss: 0.1801406145095825, accuracy-micro: 0.7407525181770325, accuracy-macro: 0.0037000000011176\n",
      "step:     472, loss: 0.1801209747791290, accuracy-micro: 0.7408480048179626, accuracy-macro: 0.0037000000011176\n",
      "step:     473, loss: 0.1801005303859711, accuracy-micro: 0.7407907247543335, accuracy-macro: 0.0037000000011176\n",
      "step:     474, loss: 0.1800808757543564, accuracy-micro: 0.7409297227859497, accuracy-macro: 0.0037000000011176\n",
      "step:     475, loss: 0.1800631880760193, accuracy-micro: 0.7408672571182251, accuracy-macro: 0.0037000000011176\n",
      "step:     476, loss: 0.1800484359264374, accuracy-micro: 0.7409757375717163, accuracy-macro: 0.0037000000011176\n",
      "step:     477, loss: 0.1800384223461151, accuracy-micro: 0.7408922314643860, accuracy-macro: 0.0037000000011176\n",
      "step:     478, loss: 0.1800375133752823, accuracy-micro: 0.7409905195236206, accuracy-macro: 0.0037000000011176\n",
      "step:     479, loss: 0.1800447851419449, accuracy-micro: 0.7408587336540222, accuracy-macro: 0.0037000000011176\n",
      "step:     480, loss: 0.1800684034824371, accuracy-micro: 0.7409664988517761, accuracy-macro: 0.0037000000011176\n",
      "step:     481, loss: 0.1800855249166489, accuracy-micro: 0.7407957315444946, accuracy-macro: 0.0037000000011176\n",
      "step:     482, loss: 0.1801030039787292, accuracy-micro: 0.7408867478370667, accuracy-macro: 0.0037000000011176\n",
      "step:     483, loss: 0.1800529956817627, accuracy-micro: 0.7408137321472168, accuracy-macro: 0.0037000000011176\n",
      "step:     484, loss: 0.1799707859754562, accuracy-micro: 0.7411042451858521, accuracy-macro: 0.0037000000011176\n",
      "step:     485, loss: 0.1798751801252365, accuracy-micro: 0.7411419749259949, accuracy-macro: 0.0037000000011176\n",
      "step:     486, loss: 0.1798378974199295, accuracy-micro: 0.7412065267562866, accuracy-macro: 0.0037000000011176\n",
      "step:     487, loss: 0.1798576563596725, accuracy-micro: 0.7412534952163696, accuracy-macro: 0.0037000000011176\n",
      "step:     488, loss: 0.1798757463693619, accuracy-micro: 0.7411162257194519, accuracy-macro: 0.0037000000011176\n",
      "step:     489, loss: 0.1798546463251114, accuracy-micro: 0.7412905097007751, accuracy-macro: 0.0037000000011176\n",
      "step:     490, loss: 0.1797908991575241, accuracy-micro: 0.7412710189819336, accuracy-macro: 0.0037000000011176\n",
      "step:     491, loss: 0.1797419041395187, accuracy-micro: 0.7413807511329651, accuracy-macro: 0.0037000000011176\n",
      "step:     492, loss: 0.1797346025705338, accuracy-micro: 0.7414297461509705, accuracy-macro: 0.0037000000011176\n",
      "step:     493, loss: 0.1797460317611694, accuracy-micro: 0.7413367629051208, accuracy-macro: 0.0037000000011176\n",
      "step:     494, loss: 0.1797392517328262, accuracy-micro: 0.7414402365684509, accuracy-macro: 0.0037000000011176\n",
      "step:     495, loss: 0.1796966195106506, accuracy-micro: 0.7414027452468872, accuracy-macro: 0.0037000000011176\n",
      "step:     496, loss: 0.1796524077653885, accuracy-micro: 0.7415312528610229, accuracy-macro: 0.0037000000011176\n",
      "step:     497, loss: 0.1796325147151947, accuracy-micro: 0.7415622472763062, accuracy-macro: 0.0037000000011176\n",
      "step:     498, loss: 0.1796313971281052, accuracy-micro: 0.7415300011634827, accuracy-macro: 0.0037000000011176\n",
      "step:     499, loss: 0.1796228140592575, accuracy-micro: 0.7416219711303711, accuracy-macro: 0.0037000000011176\n",
      "step:     500, loss: 0.1795933991670609, accuracy-micro: 0.7415735125541687, accuracy-macro: 0.0037000000011176\n",
      "step:     501, loss: 0.1795598566532135, accuracy-micro: 0.7416922450065613, accuracy-macro: 0.0037000000011176\n",
      "step:     502, loss: 0.1795389950275421, accuracy-micro: 0.7416980266571045, accuracy-macro: 0.0037000000011176\n",
      "step:     503, loss: 0.1795312315225601, accuracy-micro: 0.7416939735412598, accuracy-macro: 0.0037000000011176\n",
      "step:     504, loss: 0.1795216798782349, accuracy-micro: 0.7417740225791931, accuracy-macro: 0.0037000000011176\n",
      "step:     505, loss: 0.1794976145029068, accuracy-micro: 0.7417302727699280, accuracy-macro: 0.0037000000011176\n",
      "step:     506, loss: 0.1794692426919937, accuracy-micro: 0.7418090105056763, accuracy-macro: 0.0037000000011176\n",
      "step:     507, loss: 0.1794461309909821, accuracy-micro: 0.7418465018272400, accuracy-macro: 0.0037000000011176\n",
      "step:     508, loss: 0.1794317364692688, accuracy-micro: 0.7418267726898193, accuracy-macro: 0.0037000000011176\n",
      "step:     509, loss: 0.1794192641973495, accuracy-micro: 0.7418987751007080, accuracy-macro: 0.0037000000011176\n",
      "step:     510, loss: 0.1794016212224960, accuracy-micro: 0.7418747544288635, accuracy-macro: 0.0037000000011176\n",
      "step:     511, loss: 0.1793788969516754, accuracy-micro: 0.7419584989547729, accuracy-macro: 0.0037000000011176\n",
      "step:     512, loss: 0.1793561875820160, accuracy-micro: 0.7419322729110718, accuracy-macro: 0.0037000000011176\n",
      "step:     513, loss: 0.1793387532234192, accuracy-micro: 0.7419497370719910, accuracy-macro: 0.0037000000011176\n",
      "step:     514, loss: 0.1793246269226074, accuracy-micro: 0.7420369982719421, accuracy-macro: 0.0037000000011176\n",
      "step:     515, loss: 0.1793094873428345, accuracy-micro: 0.7419980168342590, accuracy-macro: 0.0037000000011176\n",
      "step:     516, loss: 0.1792900562286377, accuracy-micro: 0.7421047687530518, accuracy-macro: 0.0037000000011176\n",
      "step:     517, loss: 0.1792676597833633, accuracy-micro: 0.7420840263366699, accuracy-macro: 0.0037000000011176\n",
      "step:     518, loss: 0.1792481541633606, accuracy-micro: 0.7421277761459351, accuracy-macro: 0.0037000000011176\n",
      "step:     519, loss: 0.1792317926883698, accuracy-micro: 0.7421849966049194, accuracy-macro: 0.0037000000011176\n",
      "step:     520, loss: 0.1792157739400864, accuracy-micro: 0.7421542406082153, accuracy-macro: 0.0037000000011176\n",
      "step:     521, loss: 0.1791993379592896, accuracy-micro: 0.7422227263450623, accuracy-macro: 0.0037000000011176\n",
      "step:     522, loss: 0.1791795194149017, accuracy-micro: 0.7422009706497192, accuracy-macro: 0.0037000000011176\n",
      "step:     523, loss: 0.1791600435972214, accuracy-micro: 0.7422789931297302, accuracy-macro: 0.0037000000011176\n",
      "step:     524, loss: 0.1791419237852097, accuracy-micro: 0.7422847747802734, accuracy-macro: 0.0037000000011176\n",
      "step:     525, loss: 0.1791250556707382, accuracy-micro: 0.7422915101051331, accuracy-macro: 0.0037000000011176\n",
      "step:     526, loss: 0.1791089028120041, accuracy-micro: 0.7423859834671021, accuracy-macro: 0.0037000000011176\n",
      "step:     527, loss: 0.1790912747383118, accuracy-micro: 0.7423465251922607, accuracy-macro: 0.0037000000011176\n",
      "step:     528, loss: 0.1790722012519836, accuracy-micro: 0.7424117326736450, accuracy-macro: 0.0037000000011176\n",
      "step:     529, loss: 0.1790539622306824, accuracy-micro: 0.7424064874649048, accuracy-macro: 0.0037000000011176\n",
      "step:     530, loss: 0.1790370494127274, accuracy-micro: 0.7424362301826477, accuracy-macro: 0.0037000000011176\n",
      "step:     531, loss: 0.1790211796760559, accuracy-micro: 0.7424977421760559, accuracy-macro: 0.0037000000011176\n",
      "step:     532, loss: 0.1790049821138382, accuracy-micro: 0.7424799799919128, accuracy-macro: 0.0037000000011176\n",
      "step:     533, loss: 0.1789876520633698, accuracy-micro: 0.7425627708435059, accuracy-macro: 0.0037000000011176\n",
      "step:     534, loss: 0.1789691895246506, accuracy-micro: 0.7425342202186584, accuracy-macro: 0.0037000000011176\n",
      "step:     535, loss: 0.1789502501487732, accuracy-micro: 0.7425857186317444, accuracy-macro: 0.0037000000011176\n",
      "step:     536, loss: 0.1789316534996033, accuracy-micro: 0.7426124811172485, accuracy-macro: 0.0037000000011176\n",
      "step:     537, loss: 0.1789142787456512, accuracy-micro: 0.7426257729530334, accuracy-macro: 0.0037000000011176\n",
      "step:     538, loss: 0.1788976192474365, accuracy-micro: 0.7426654696464539, accuracy-macro: 0.0037000000011176\n",
      "step:     539, loss: 0.1788814365863800, accuracy-micro: 0.7426685094833374, accuracy-macro: 0.0037000000011176\n",
      "step:     540, loss: 0.1788640916347504, accuracy-micro: 0.7427287697792053, accuracy-macro: 0.0037000000011176\n",
      "step:     541, loss: 0.1788465678691864, accuracy-micro: 0.7427012324333191, accuracy-macro: 0.0037000000011176\n",
      "step:     542, loss: 0.1788288503885269, accuracy-micro: 0.7427750229835510, accuracy-macro: 0.0037000000011176\n",
      "step:     543, loss: 0.1788105517625809, accuracy-micro: 0.7427677512168884, accuracy-macro: 0.0037000000011176\n",
      "step:     544, loss: 0.1787932664155960, accuracy-micro: 0.7428227663040161, accuracy-macro: 0.0037000000011176\n",
      "step:     545, loss: 0.1787754744291306, accuracy-micro: 0.7428544759750366, accuracy-macro: 0.0037000000011176\n",
      "step:     546, loss: 0.1787584722042084, accuracy-micro: 0.7428449988365173, accuracy-macro: 0.0037000000011176\n",
      "step:     547, loss: 0.1787414103746414, accuracy-micro: 0.7428812384605408, accuracy-macro: 0.0037000000011176\n",
      "step:     548, loss: 0.1787240505218506, accuracy-micro: 0.7428849935531616, accuracy-macro: 0.0037000000011176\n",
      "step:     549, loss: 0.1787073165178299, accuracy-micro: 0.7429277300834656, accuracy-macro: 0.0037000000011176\n",
      "step:     550, loss: 0.1786900609731674, accuracy-micro: 0.7429327368736267, accuracy-macro: 0.0037000000011176\n",
      "step:     551, loss: 0.1786732375621796, accuracy-micro: 0.7429869771003723, accuracy-macro: 0.0037000000011176\n",
      "step:     552, loss: 0.1786562502384186, accuracy-micro: 0.7429915070533752, accuracy-macro: 0.0037000000011176\n",
      "step:     553, loss: 0.1786390691995621, accuracy-micro: 0.7430199980735779, accuracy-macro: 0.0037000000011176\n",
      "step:     554, loss: 0.1786219626665115, accuracy-micro: 0.7430340051651001, accuracy-macro: 0.0037000000011176\n",
      "step:     555, loss: 0.1786053180694580, accuracy-micro: 0.7430765032768250, accuracy-macro: 0.0037000000011176\n",
      "step:     556, loss: 0.1785882562398911, accuracy-micro: 0.7430694699287415, accuracy-macro: 0.0037000000011176\n",
      "step:     557, loss: 0.1785707771778107, accuracy-micro: 0.7431070208549500, accuracy-macro: 0.0037000000011176\n",
      "step:     558, loss: 0.1785540282726288, accuracy-micro: 0.7431349754333496, accuracy-macro: 0.0037000000011176\n",
      "step:     559, loss: 0.1785377711057663, accuracy-micro: 0.7431517243385315, accuracy-macro: 0.0037000000011176\n",
      "step:     560, loss: 0.1785213202238083, accuracy-micro: 0.7431952357292175, accuracy-macro: 0.0037000000011176\n",
      "step:     561, loss: 0.1785041689872742, accuracy-micro: 0.7431910037994385, accuracy-macro: 0.0037000000011176\n",
      "step:     562, loss: 0.1784871816635132, accuracy-micro: 0.7432312369346619, accuracy-macro: 0.0037000000011176\n",
      "step:     563, loss: 0.1784709393978119, accuracy-micro: 0.7432472705841064, accuracy-macro: 0.0037000000011176\n",
      "step:     564, loss: 0.1784542798995972, accuracy-micro: 0.7432897686958313, accuracy-macro: 0.0037000000011176\n",
      "step:     565, loss: 0.1784375756978989, accuracy-micro: 0.7432785034179688, accuracy-macro: 0.0037000000011176\n",
      "step:     566, loss: 0.1784203648567200, accuracy-micro: 0.7433342337608337, accuracy-macro: 0.0037000000011176\n",
      "step:     567, loss: 0.1784040629863739, accuracy-micro: 0.7433502674102783, accuracy-macro: 0.0037000000011176\n",
      "step:     568, loss: 0.1783874332904816, accuracy-micro: 0.7433977723121643, accuracy-macro: 0.0037000000011176\n",
      "step:     569, loss: 0.1783709973096848, accuracy-micro: 0.7434124946594238, accuracy-macro: 0.0037000000011176\n",
      "step:     570, loss: 0.1783545166254044, accuracy-micro: 0.7434599995613098, accuracy-macro: 0.0037000000011176\n",
      "step:     571, loss: 0.1783384084701538, accuracy-micro: 0.7434639930725098, accuracy-macro: 0.0037000000011176\n",
      "step:     572, loss: 0.1783223748207092, accuracy-micro: 0.7435305118560791, accuracy-macro: 0.0037000000011176\n",
      "step:     573, loss: 0.1783062517642975, accuracy-micro: 0.7434955239295959, accuracy-macro: 0.0037000000011176\n",
      "step:     574, loss: 0.1782905608415604, accuracy-micro: 0.7435770034790039, accuracy-macro: 0.0037000000011176\n",
      "step:     575, loss: 0.1782748103141785, accuracy-micro: 0.7435399889945984, accuracy-macro: 0.0037000000011176\n",
      "step:     576, loss: 0.1782601624727249, accuracy-micro: 0.7436559796333313, accuracy-macro: 0.0037000000011176\n",
      "step:     577, loss: 0.1782459616661072, accuracy-micro: 0.7436025142669678, accuracy-macro: 0.0037000000011176\n",
      "step:     578, loss: 0.1782322525978088, accuracy-micro: 0.7437030076980591, accuracy-macro: 0.0037000000011176\n",
      "step:     579, loss: 0.1782191842794418, accuracy-micro: 0.7436249852180481, accuracy-macro: 0.0037000000011176\n",
      "step:     580, loss: 0.1782074868679047, accuracy-micro: 0.7437354922294617, accuracy-macro: 0.0037000000011176\n",
      "step:     581, loss: 0.1781958192586899, accuracy-micro: 0.7436624765396118, accuracy-macro: 0.0037000000011176\n",
      "step:     582, loss: 0.1781863421201706, accuracy-micro: 0.7437647581100464, accuracy-macro: 0.0037000000011176\n",
      "step:     583, loss: 0.1781783103942871, accuracy-micro: 0.7436854839324951, accuracy-macro: 0.0037000000011176\n",
      "step:     584, loss: 0.1781740933656693, accuracy-micro: 0.7437842488288879, accuracy-macro: 0.0037000000011176\n",
      "step:     585, loss: 0.1781679689884186, accuracy-micro: 0.7436689734458923, accuracy-macro: 0.0037000000011176\n",
      "step:     586, loss: 0.1781636625528336, accuracy-micro: 0.7437729835510254, accuracy-macro: 0.0037000000011176\n",
      "step:     587, loss: 0.1781502515077591, accuracy-micro: 0.7436720132827759, accuracy-macro: 0.0037000000011176\n",
      "step:     588, loss: 0.1781351268291473, accuracy-micro: 0.7438102364540100, accuracy-macro: 0.0037000000011176\n",
      "step:     589, loss: 0.1781056225299835, accuracy-micro: 0.7437457442283630, accuracy-macro: 0.0037000000011176\n",
      "step:     590, loss: 0.1780726611614227, accuracy-micro: 0.7439262270927429, accuracy-macro: 0.0037000000011176\n",
      "step:     591, loss: 0.1780380606651306, accuracy-micro: 0.7439175248146057, accuracy-macro: 0.0037000000011176\n",
      "step:     592, loss: 0.1780090332031250, accuracy-micro: 0.7440677285194397, accuracy-macro: 0.0037000000011176\n",
      "step:     593, loss: 0.1779880374670029, accuracy-micro: 0.7440242767333984, accuracy-macro: 0.0037000000011176\n",
      "step:     594, loss: 0.1779745519161224, accuracy-micro: 0.7440252304077148, accuracy-macro: 0.0037000000011176\n",
      "step:     595, loss: 0.1779669970273972, accuracy-micro: 0.7441350221633911, accuracy-macro: 0.0037000000011176\n",
      "step:     596, loss: 0.1779596805572510, accuracy-micro: 0.7440617680549622, accuracy-macro: 0.0037000000011176\n",
      "step:     597, loss: 0.1779475361108780, accuracy-micro: 0.7441397309303284, accuracy-macro: 0.0037000000011176\n",
      "step:     598, loss: 0.1779287457466125, accuracy-micro: 0.7441237568855286, accuracy-macro: 0.0037000000011176\n",
      "step:     599, loss: 0.1779077500104904, accuracy-micro: 0.7442464828491211, accuracy-macro: 0.0037000000011176\n",
      "step:     600, loss: 0.1778862178325653, accuracy-micro: 0.7441677451133728, accuracy-macro: 0.0037000000011176\n",
      "step:     601, loss: 0.1778671145439148, accuracy-micro: 0.7442482709884644, accuracy-macro: 0.0037000000011176\n",
      "step:     602, loss: 0.1778514236211777, accuracy-micro: 0.7442629933357239, accuracy-macro: 0.0037000000011176\n",
      "step:     603, loss: 0.1778384298086166, accuracy-micro: 0.7442747354507446, accuracy-macro: 0.0037000000011176\n",
      "step:     604, loss: 0.1778260171413422, accuracy-micro: 0.7443069815635681, accuracy-macro: 0.0037000000011176\n",
      "step:     605, loss: 0.1778123378753662, accuracy-micro: 0.7442922592163086, accuracy-macro: 0.0037000000011176\n",
      "step:     606, loss: 0.1777969747781754, accuracy-micro: 0.7443599700927734, accuracy-macro: 0.0037000000011176\n",
      "step:     607, loss: 0.1777808219194412, accuracy-micro: 0.7443435192108154, accuracy-macro: 0.0037000000011176\n",
      "step:     608, loss: 0.1777643412351608, accuracy-micro: 0.7443922758102417, accuracy-macro: 0.0037000000011176\n",
      "step:     609, loss: 0.1777478456497192, accuracy-micro: 0.7444162368774414, accuracy-macro: 0.0037000000011176\n",
      "step:     610, loss: 0.1777325570583344, accuracy-micro: 0.7444222569465637, accuracy-macro: 0.0037000000011176\n",
      "step:     611, loss: 0.1777175664901733, accuracy-micro: 0.7444404959678650, accuracy-macro: 0.0037000000011176\n",
      "step:     612, loss: 0.1777029931545258, accuracy-micro: 0.7444704771041870, accuracy-macro: 0.0037000000011176\n",
      "step:     613, loss: 0.1776890605688095, accuracy-micro: 0.7444800138473511, accuracy-macro: 0.0037000000011176\n",
      "step:     614, loss: 0.1776753067970276, accuracy-micro: 0.7445157766342163, accuracy-macro: 0.0037000000011176\n",
      "step:     615, loss: 0.1776617020368576, accuracy-micro: 0.7445384860038757, accuracy-macro: 0.0037000000011176\n",
      "step:     616, loss: 0.1776479482650757, accuracy-micro: 0.7445380091667175, accuracy-macro: 0.0037000000011176\n",
      "step:     617, loss: 0.1776337772607803, accuracy-micro: 0.7445715069770813, accuracy-macro: 0.0037000000011176\n",
      "step:     618, loss: 0.1776188760995865, accuracy-micro: 0.7445780038833618, accuracy-macro: 0.0037000000011176\n",
      "step:     619, loss: 0.1776045560836792, accuracy-micro: 0.7446077466011047, accuracy-macro: 0.0037000000011176\n",
      "step:     620, loss: 0.1775897741317749, accuracy-micro: 0.7446227669715881, accuracy-macro: 0.0037000000011176\n",
      "step:     621, loss: 0.1775747835636139, accuracy-micro: 0.7446494698524475, accuracy-macro: 0.0037000000011176\n",
      "step:     622, loss: 0.1775593310594559, accuracy-micro: 0.7446827292442322, accuracy-macro: 0.0037000000011176\n",
      "step:     623, loss: 0.1775440573692322, accuracy-micro: 0.7446987628936768, accuracy-macro: 0.0037000000011176\n",
      "step:     624, loss: 0.1775289028882980, accuracy-micro: 0.7447222471237183, accuracy-macro: 0.0037000000011176\n",
      "step:     625, loss: 0.1775132864713669, accuracy-micro: 0.7447402477264404, accuracy-macro: 0.0037000000011176\n",
      "step:     626, loss: 0.1774986684322357, accuracy-micro: 0.7447630167007446, accuracy-macro: 0.0037000000011176\n",
      "step:     627, loss: 0.1774843037128448, accuracy-micro: 0.7447879910469055, accuracy-macro: 0.0037000000011176\n",
      "step:     628, loss: 0.1774703562259674, accuracy-micro: 0.7448047399520874, accuracy-macro: 0.0037000000011176\n",
      "step:     629, loss: 0.1774566769599915, accuracy-micro: 0.7448329925537109, accuracy-macro: 0.0037000000011176\n",
      "step:     630, loss: 0.1774434149265289, accuracy-micro: 0.7448597550392151, accuracy-macro: 0.0037000000011176\n",
      "step:     631, loss: 0.1774303764104843, accuracy-micro: 0.7448455095291138, accuracy-macro: 0.0037000000011176\n",
      "step:     632, loss: 0.1774175018072128, accuracy-micro: 0.7448964715003967, accuracy-macro: 0.0037000000011176\n",
      "step:     633, loss: 0.1774052232503891, accuracy-micro: 0.7448804974555969, accuracy-macro: 0.0037000000011176\n",
      "step:     634, loss: 0.1773936301469803, accuracy-micro: 0.7449232339859009, accuracy-macro: 0.0037000000011176\n",
      "step:     635, loss: 0.1773829460144043, accuracy-micro: 0.7449107766151428, accuracy-macro: 0.0037000000011176\n",
      "step:     636, loss: 0.1773735880851746, accuracy-micro: 0.7449774742126465, accuracy-macro: 0.0037000000011176\n",
      "step:     637, loss: 0.1773638725280762, accuracy-micro: 0.7449095249176025, accuracy-macro: 0.0037000000011176\n",
      "step:     638, loss: 0.1773551702499390, accuracy-micro: 0.7449935078620911, accuracy-macro: 0.0037000000011176\n",
      "step:     639, loss: 0.1773449182510376, accuracy-micro: 0.7449225187301636, accuracy-macro: 0.0037000000011176\n",
      "step:     640, loss: 0.1773362755775452, accuracy-micro: 0.7450317740440369, accuracy-macro: 0.0037000000011176\n",
      "step:     641, loss: 0.1773237138986588, accuracy-micro: 0.7449399828910828, accuracy-macro: 0.0037000000011176\n",
      "step:     642, loss: 0.1773121953010559, accuracy-micro: 0.7450417280197144, accuracy-macro: 0.0037000000011176\n",
      "step:     643, loss: 0.1772971749305725, accuracy-micro: 0.7449607253074646, accuracy-macro: 0.0037000000011176\n",
      "step:     644, loss: 0.1772800236940384, accuracy-micro: 0.7450870275497437, accuracy-macro: 0.0037000000011176\n",
      "step:     645, loss: 0.1772563755512238, accuracy-micro: 0.7450444698333740, accuracy-macro: 0.0037000000011176\n",
      "step:     646, loss: 0.1772334724664688, accuracy-micro: 0.7451942563056946, accuracy-macro: 0.0037000000011176\n",
      "step:     647, loss: 0.1772121191024780, accuracy-micro: 0.7451467514038086, accuracy-macro: 0.0037000000011176\n",
      "step:     648, loss: 0.1771929115056992, accuracy-micro: 0.7452137470245361, accuracy-macro: 0.0037000000011176\n",
      "step:     649, loss: 0.1771770566701889, accuracy-micro: 0.7452175021171570, accuracy-macro: 0.0037000000011176\n",
      "step:     650, loss: 0.1771637797355652, accuracy-micro: 0.7452329993247986, accuracy-macro: 0.0037000000011176\n",
      "step:     651, loss: 0.1771522164344788, accuracy-micro: 0.7452727556228638, accuracy-macro: 0.0037000000011176\n",
      "step:     652, loss: 0.1771413683891296, accuracy-micro: 0.7452509999275208, accuracy-macro: 0.0037000000011176\n",
      "step:     653, loss: 0.1771312206983566, accuracy-micro: 0.7453219890594482, accuracy-macro: 0.0037000000011176\n",
      "step:     654, loss: 0.1771218776702881, accuracy-micro: 0.7452882528305054, accuracy-macro: 0.0037000000011176\n",
      "step:     655, loss: 0.1771120280027390, accuracy-micro: 0.7453532218933105, accuracy-macro: 0.0037000000011176\n",
      "step:     656, loss: 0.1770997643470764, accuracy-micro: 0.7453144788742065, accuracy-macro: 0.0037000000011176\n",
      "step:     657, loss: 0.1770866662263870, accuracy-micro: 0.7453979849815369, accuracy-macro: 0.0037000000011176\n",
      "step:     658, loss: 0.1770732849836349, accuracy-micro: 0.7453377246856689, accuracy-macro: 0.0037000000011176\n",
      "step:     659, loss: 0.1770603805780411, accuracy-micro: 0.7454382777214050, accuracy-macro: 0.0037000000011176\n",
      "step:     660, loss: 0.1770459413528442, accuracy-micro: 0.7453887462615967, accuracy-macro: 0.0037000000011176\n",
      "step:     661, loss: 0.1770306080579758, accuracy-micro: 0.7455109953880310, accuracy-macro: 0.0037000000011176\n",
      "step:     662, loss: 0.1770140826702118, accuracy-micro: 0.7454605102539062, accuracy-macro: 0.0037000000011176\n",
      "step:     663, loss: 0.1769971996545792, accuracy-micro: 0.7455282211303711, accuracy-macro: 0.0037000000011176\n",
      "step:     664, loss: 0.1769808679819107, accuracy-micro: 0.7454882264137268, accuracy-macro: 0.0037000000011176\n",
      "step:     665, loss: 0.1769655346870422, accuracy-micro: 0.7455582618713379, accuracy-macro: 0.0037000000011176\n",
      "step:     666, loss: 0.1769509166479111, accuracy-micro: 0.7455599904060364, accuracy-macro: 0.0037000000011176\n",
      "step:     667, loss: 0.1769372820854187, accuracy-micro: 0.7455672621726990, accuracy-macro: 0.0037000000011176\n",
      "step:     668, loss: 0.1769248694181442, accuracy-micro: 0.7455980181694031, accuracy-macro: 0.0037000000011176\n",
      "step:     669, loss: 0.1769123375415802, accuracy-micro: 0.7456024885177612, accuracy-macro: 0.0037000000011176\n",
      "step:     670, loss: 0.1768997311592102, accuracy-micro: 0.7456697225570679, accuracy-macro: 0.0037000000011176\n",
      "step:     671, loss: 0.1768877506256104, accuracy-micro: 0.7456152439117432, accuracy-macro: 0.0037000000011176\n",
      "step:     672, loss: 0.1768753528594971, accuracy-micro: 0.7456899881362915, accuracy-macro: 0.0037000000011176\n",
      "step:     673, loss: 0.1768635511398315, accuracy-micro: 0.7456524968147278, accuracy-macro: 0.0037000000011176\n",
      "step:     674, loss: 0.1768513768911362, accuracy-micro: 0.7457144856452942, accuracy-macro: 0.0037000000011176\n",
      "step:     675, loss: 0.1768399626016617, accuracy-micro: 0.7456802725791931, accuracy-macro: 0.0037000000011176\n",
      "step:     676, loss: 0.1768285185098648, accuracy-micro: 0.7457662224769592, accuracy-macro: 0.0037000000011176\n",
      "step:     677, loss: 0.1768159419298172, accuracy-micro: 0.7457292675971985, accuracy-macro: 0.0037000000011176\n",
      "step:     678, loss: 0.1768032014369965, accuracy-micro: 0.7457969784736633, accuracy-macro: 0.0037000000011176\n",
      "step:     679, loss: 0.1767896860837936, accuracy-micro: 0.7457572221755981, accuracy-macro: 0.0037000000011176\n",
      "step:     680, loss: 0.1767768561840057, accuracy-micro: 0.7458245158195496, accuracy-macro: 0.0037000000011176\n",
      "step:     681, loss: 0.1767639070749283, accuracy-micro: 0.7457935214042664, accuracy-macro: 0.0037000000011176\n",
      "step:     682, loss: 0.1767520010471344, accuracy-micro: 0.7458622455596924, accuracy-macro: 0.0037000000011176\n",
      "step:     683, loss: 0.1767407804727554, accuracy-micro: 0.7458282709121704, accuracy-macro: 0.0037000000011176\n",
      "step:     684, loss: 0.1767297834157944, accuracy-micro: 0.7458912730216980, accuracy-macro: 0.0037000000011176\n",
      "step:     685, loss: 0.1767184287309647, accuracy-micro: 0.7458772659301758, accuracy-macro: 0.0037000000011176\n",
      "step:     686, loss: 0.1767068505287170, accuracy-micro: 0.7459275126457214, accuracy-macro: 0.0037000000011176\n",
      "step:     687, loss: 0.1766936928033829, accuracy-micro: 0.7459110021591187, accuracy-macro: 0.0037000000011176\n",
      "step:     688, loss: 0.1766816228628159, accuracy-micro: 0.7459589838981628, accuracy-macro: 0.0037000000011176\n",
      "step:     689, loss: 0.1766691803932190, accuracy-micro: 0.7459562420845032, accuracy-macro: 0.0037000000011176\n",
      "step:     690, loss: 0.1766579598188400, accuracy-micro: 0.7459964752197266, accuracy-macro: 0.0037000000011176\n",
      "step:     691, loss: 0.1766455024480820, accuracy-micro: 0.7460010051727295, accuracy-macro: 0.0037000000011176\n",
      "step:     692, loss: 0.1766339689493179, accuracy-micro: 0.7460250258445740, accuracy-macro: 0.0037000000011176\n",
      "step:     693, loss: 0.1766235381364822, accuracy-micro: 0.7460324764251709, accuracy-macro: 0.0037000000011176\n",
      "step:     694, loss: 0.1766139119863510, accuracy-micro: 0.7460597753524780, accuracy-macro: 0.0037000000011176\n",
      "step:     695, loss: 0.1766045838594437, accuracy-micro: 0.7460470199584961, accuracy-macro: 0.0037000000011176\n",
      "step:     696, loss: 0.1765964031219482, accuracy-micro: 0.7460762262344360, accuracy-macro: 0.0037000000011176\n",
      "step:     697, loss: 0.1765856891870499, accuracy-micro: 0.7460657358169556, accuracy-macro: 0.0037000000011176\n",
      "step:     698, loss: 0.1765752881765366, accuracy-micro: 0.7461025118827820, accuracy-macro: 0.0037000000011176\n",
      "step:     699, loss: 0.1765631139278412, accuracy-micro: 0.7460994720458984, accuracy-macro: 0.0037000000011176\n",
      "step:     700, loss: 0.1765515059232712, accuracy-micro: 0.7461397647857666, accuracy-macro: 0.0037000000011176\n",
      "step:     701, loss: 0.1765382438898087, accuracy-micro: 0.7461534738540649, accuracy-macro: 0.0037000000011176\n",
      "step:     702, loss: 0.1765241175889969, accuracy-micro: 0.7462019920349121, accuracy-macro: 0.0037000000011176\n",
      "step:     703, loss: 0.1765082478523254, accuracy-micro: 0.7462287545204163, accuracy-macro: 0.0037000000011176\n",
      "step:     704, loss: 0.1764907538890839, accuracy-micro: 0.7462597489356995, accuracy-macro: 0.0037000000011176\n",
      "step:     705, loss: 0.1764729619026184, accuracy-micro: 0.7462679743766785, accuracy-macro: 0.0037000000011176\n",
      "step:     706, loss: 0.1764570325613022, accuracy-micro: 0.7463129758834839, accuracy-macro: 0.0037000000011176\n",
      "step:     707, loss: 0.1764421612024307, accuracy-micro: 0.7463032603263855, accuracy-macro: 0.0037000000011176\n",
      "step:     708, loss: 0.1764285713434219, accuracy-micro: 0.7463827729225159, accuracy-macro: 0.0037000000011176\n",
      "step:     709, loss: 0.1764162182807922, accuracy-micro: 0.7463502287864685, accuracy-macro: 0.0037000000011176\n",
      "step:     710, loss: 0.1764035373926163, accuracy-micro: 0.7463909983634949, accuracy-macro: 0.0037000000011176\n",
      "step:     711, loss: 0.1763919740915298, accuracy-micro: 0.7463937401771545, accuracy-macro: 0.0037000000011176\n",
      "step:     712, loss: 0.1763799935579300, accuracy-micro: 0.7464140057563782, accuracy-macro: 0.0037000000011176\n",
      "step:     713, loss: 0.1763689368963242, accuracy-micro: 0.7464362382888794, accuracy-macro: 0.0037000000011176\n",
      "step:     714, loss: 0.1763584613800049, accuracy-micro: 0.7464359998703003, accuracy-macro: 0.0037000000011176\n",
      "step:     715, loss: 0.1763482987880707, accuracy-micro: 0.7464849948883057, accuracy-macro: 0.0037000000011176\n",
      "step:     716, loss: 0.1763388216495514, accuracy-micro: 0.7464889883995056, accuracy-macro: 0.0037000000011176\n",
      "step:     717, loss: 0.1763298213481903, accuracy-micro: 0.7465062737464905, accuracy-macro: 0.0037000000011176\n",
      "step:     718, loss: 0.1763219535350800, accuracy-micro: 0.7464962601661682, accuracy-macro: 0.0037000000011176\n",
      "step:     719, loss: 0.1763145923614502, accuracy-micro: 0.7465354800224304, accuracy-macro: 0.0037000000011176\n",
      "step:     720, loss: 0.1763075590133667, accuracy-micro: 0.7465097308158875, accuracy-macro: 0.0037000000011176\n",
      "step:     721, loss: 0.1763019710779190, accuracy-micro: 0.7465530037879944, accuracy-macro: 0.0037000000011176\n",
      "step:     722, loss: 0.1762963235378265, accuracy-micro: 0.7465199828147888, accuracy-macro: 0.0037000000011176\n",
      "step:     723, loss: 0.1762924492359161, accuracy-micro: 0.7465860247612000, accuracy-macro: 0.0037000000011176\n",
      "step:     724, loss: 0.1762856245040894, accuracy-micro: 0.7465062737464905, accuracy-macro: 0.0037000000011176\n",
      "step:     725, loss: 0.1762762814760208, accuracy-micro: 0.7465997338294983, accuracy-macro: 0.0037000000011176\n",
      "step:     726, loss: 0.1762582361698151, accuracy-micro: 0.7465764880180359, accuracy-macro: 0.0037000000011176\n",
      "step:     727, loss: 0.1762383431196213, accuracy-micro: 0.7466777563095093, accuracy-macro: 0.0037000000011176\n",
      "step:     728, loss: 0.1762146502733231, accuracy-micro: 0.7466442584991455, accuracy-macro: 0.0037000000011176\n",
      "step:     729, loss: 0.1761929988861084, accuracy-micro: 0.7467284798622131, accuracy-macro: 0.0037000000011176\n",
      "step:     730, loss: 0.1761749386787415, accuracy-micro: 0.7467282414436340, accuracy-macro: 0.0037000000011176\n",
      "step:     731, loss: 0.1761621385812759, accuracy-micro: 0.7467502355575562, accuracy-macro: 0.0037000000011176\n",
      "step:     732, loss: 0.1761533766984940, accuracy-micro: 0.7467742562294006, accuracy-macro: 0.0037000000011176\n",
      "step:     733, loss: 0.1761454641819000, accuracy-micro: 0.7467722296714783, accuracy-macro: 0.0037000000011176\n",
      "step:     734, loss: 0.1761377751827240, accuracy-micro: 0.7467939853668213, accuracy-macro: 0.0037000000011176\n",
      "step:     735, loss: 0.1761303097009659, accuracy-micro: 0.7467742562294006, accuracy-macro: 0.0037000000011176\n",
      "step:     736, loss: 0.1761219501495361, accuracy-micro: 0.7468397617340088, accuracy-macro: 0.0037000000011176\n",
      "step:     737, loss: 0.1761118769645691, accuracy-micro: 0.7468169927597046, accuracy-macro: 0.0037000000011176\n",
      "step:     738, loss: 0.1760989427566528, accuracy-micro: 0.7468755245208740, accuracy-macro: 0.0037000000011176\n",
      "step:     739, loss: 0.1760855317115784, accuracy-micro: 0.7468515038490295, accuracy-macro: 0.0037000000011176\n",
      "step:     740, loss: 0.1760717630386353, accuracy-micro: 0.7469217777252197, accuracy-macro: 0.0037000000011176\n",
      "step:     741, loss: 0.1760585904121399, accuracy-micro: 0.7469037771224976, accuracy-macro: 0.0037000000011176\n",
      "step:     742, loss: 0.1760450601577759, accuracy-micro: 0.7469447255134583, accuracy-macro: 0.0037000000011176\n",
      "step:     743, loss: 0.1760318726301193, accuracy-micro: 0.7469394803047180, accuracy-macro: 0.0037000000011176\n",
      "step:     744, loss: 0.1760192066431046, accuracy-micro: 0.7469997406005859, accuracy-macro: 0.0037000000011176\n",
      "step:     745, loss: 0.1760082840919495, accuracy-micro: 0.7469897270202637, accuracy-macro: 0.0037000000011176\n",
      "step:     746, loss: 0.1759968400001526, accuracy-micro: 0.7470107674598694, accuracy-macro: 0.0037000000011176\n",
      "step:     747, loss: 0.1759864389896393, accuracy-micro: 0.7470622658729553, accuracy-macro: 0.0037000000011176\n",
      "step:     748, loss: 0.1759760677814484, accuracy-micro: 0.7470514774322510, accuracy-macro: 0.0037000000011176\n",
      "step:     749, loss: 0.1759659647941589, accuracy-micro: 0.7470972537994385, accuracy-macro: 0.0037000000011176\n",
      "step:     750, loss: 0.1759561598300934, accuracy-micro: 0.7470625042915344, accuracy-macro: 0.0037000000011176\n",
      "step:     751, loss: 0.1759476661682129, accuracy-micro: 0.7471004724502563, accuracy-macro: 0.0037000000011176\n",
      "step:     752, loss: 0.1759401708841324, accuracy-micro: 0.7470849752426147, accuracy-macro: 0.0037000000011176\n",
      "step:     753, loss: 0.1759339720010757, accuracy-micro: 0.7471294999122620, accuracy-macro: 0.0037000000011176\n",
      "step:     754, loss: 0.1759254783391953, accuracy-micro: 0.7470979690551758, accuracy-macro: 0.0037000000011176\n",
      "step:     755, loss: 0.1759173721075058, accuracy-micro: 0.7471592426300049, accuracy-macro: 0.0037000000011176\n",
      "step:     756, loss: 0.1759084463119507, accuracy-micro: 0.7471100091934204, accuracy-macro: 0.0037000000011176\n",
      "step:     757, loss: 0.1758992969989777, accuracy-micro: 0.7471839785575867, accuracy-macro: 0.0037000000011176\n",
      "step:     758, loss: 0.1758874803781509, accuracy-micro: 0.7471447587013245, accuracy-macro: 0.0037000000011176\n",
      "step:     759, loss: 0.1758747398853302, accuracy-micro: 0.7472165226936340, accuracy-macro: 0.0037000000011176\n",
      "step:     760, loss: 0.1758612245321274, accuracy-micro: 0.7471969723701477, accuracy-macro: 0.0037000000011176\n",
      "step:     761, loss: 0.1758476197719574, accuracy-micro: 0.7472767233848572, accuracy-macro: 0.0037000000011176\n",
      "step:     762, loss: 0.1758343130350113, accuracy-micro: 0.7472592592239380, accuracy-macro: 0.0037000000011176\n",
      "step:     763, loss: 0.1758207231760025, accuracy-micro: 0.7473065257072449, accuracy-macro: 0.0037000000011176\n",
      "step:     764, loss: 0.1758067458868027, accuracy-micro: 0.7473164796829224, accuracy-macro: 0.0037000000011176\n",
      "step:     765, loss: 0.1757945716381073, accuracy-micro: 0.7473432421684265, accuracy-macro: 0.0037000000011176\n",
      "step:     766, loss: 0.1757836937904358, accuracy-micro: 0.7473679780960083, accuracy-macro: 0.0037000000011176\n",
      "step:     767, loss: 0.1757735908031464, accuracy-micro: 0.7473819851875305, accuracy-macro: 0.0037000000011176\n",
      "step:     768, loss: 0.1757653057575226, accuracy-micro: 0.7474177479743958, accuracy-macro: 0.0037000000011176\n",
      "step:     769, loss: 0.1757570058107376, accuracy-micro: 0.7473934888839722, accuracy-macro: 0.0037000000011176\n",
      "step:     770, loss: 0.1757492125034332, accuracy-micro: 0.7474474906921387, accuracy-macro: 0.0037000000011176\n",
      "step:     771, loss: 0.1757418066263199, accuracy-micro: 0.7473775148391724, accuracy-macro: 0.0037000000011176\n",
      "step:     772, loss: 0.1757353842258453, accuracy-micro: 0.7474547624588013, accuracy-macro: 0.0037000000011176\n",
      "step:     773, loss: 0.1757294386625290, accuracy-micro: 0.7473907470703125, accuracy-macro: 0.0037000000011176\n",
      "step:     774, loss: 0.1757226288318634, accuracy-micro: 0.7475072741508484, accuracy-macro: 0.0037000000011176\n",
      "step:     775, loss: 0.1757142394781113, accuracy-micro: 0.7474259734153748, accuracy-macro: 0.0037000000011176\n",
      "step:     776, loss: 0.1757048070430756, accuracy-micro: 0.7475437521934509, accuracy-macro: 0.0037000000011176\n",
      "step:     777, loss: 0.1756934076547623, accuracy-micro: 0.7474562525749207, accuracy-macro: 0.0037000000011176\n",
      "step:     778, loss: 0.1756827384233475, accuracy-micro: 0.7475665211677551, accuracy-macro: 0.0037000000011176\n",
      "step:     779, loss: 0.1756696850061417, accuracy-micro: 0.7474855184555054, accuracy-macro: 0.0037000000011176\n",
      "step:     780, loss: 0.1756559312343597, accuracy-micro: 0.7475987672805786, accuracy-macro: 0.0037000000011176\n",
      "step:     781, loss: 0.1756428778171539, accuracy-micro: 0.7475360035896301, accuracy-macro: 0.0037000000011176\n",
      "step:     782, loss: 0.1756300330162048, accuracy-micro: 0.7476467490196228, accuracy-macro: 0.0037000000011176\n",
      "step:     783, loss: 0.1756166815757751, accuracy-micro: 0.7475872635841370, accuracy-macro: 0.0037000000011176\n",
      "step:     784, loss: 0.1756042838096619, accuracy-micro: 0.7477024793624878, accuracy-macro: 0.0037000000011176\n",
      "step:     785, loss: 0.1755911856889725, accuracy-micro: 0.7476369738578796, accuracy-macro: 0.0037000000011176\n",
      "step:     786, loss: 0.1755789965391159, accuracy-micro: 0.7476850152015686, accuracy-macro: 0.0037000000011176\n",
      "step:     787, loss: 0.1755682080984116, accuracy-micro: 0.7476925253868103, accuracy-macro: 0.0037000000011176\n",
      "step:     788, loss: 0.1755572110414505, accuracy-micro: 0.7477070093154907, accuracy-macro: 0.0037000000011176\n",
      "step:     789, loss: 0.1755474060773849, accuracy-micro: 0.7477282285690308, accuracy-macro: 0.0037000000011176\n",
      "step:     790, loss: 0.1755376905202866, accuracy-micro: 0.7477437257766724, accuracy-macro: 0.0037000000011176\n",
      "step:     791, loss: 0.1755290329456329, accuracy-micro: 0.7477740049362183, accuracy-macro: 0.0037000000011176\n",
      "step:     792, loss: 0.1755206584930420, accuracy-micro: 0.7477409839630127, accuracy-macro: 0.0037000000011176\n",
      "step:     793, loss: 0.1755138486623764, accuracy-micro: 0.7478274703025818, accuracy-macro: 0.0037000000011176\n",
      "step:     794, loss: 0.1755074113607407, accuracy-micro: 0.7477342486381531, accuracy-macro: 0.0037000000011176\n",
      "step:     795, loss: 0.1755013763904572, accuracy-micro: 0.7478650212287903, accuracy-macro: 0.0037000000011176\n",
      "step:     796, loss: 0.1754927784204483, accuracy-micro: 0.7477250099182129, accuracy-macro: 0.0037000000011176\n",
      "step:     797, loss: 0.1754826605319977, accuracy-micro: 0.7479062676429749, accuracy-macro: 0.0037000000011176\n",
      "step:     798, loss: 0.1754708141088486, accuracy-micro: 0.7477759718894958, accuracy-macro: 0.0037000000011176\n",
      "step:     799, loss: 0.1754602193832397, accuracy-micro: 0.7479410171508789, accuracy-macro: 0.0037000000011176\n",
      "step:     800, loss: 0.1754478663206100, accuracy-micro: 0.7478255033493042, accuracy-macro: 0.0037000000011176\n",
      "step:     801, loss: 0.1754350662231445, accuracy-micro: 0.7480055093765259, accuracy-macro: 0.0037000000011176\n",
      "step:     802, loss: 0.1754226386547089, accuracy-micro: 0.7478914856910706, accuracy-macro: 0.0037000000011176\n",
      "step:     803, loss: 0.1754114627838135, accuracy-micro: 0.7479827404022217, accuracy-macro: 0.0037000000011176\n",
      "step:     804, loss: 0.1754001528024673, accuracy-micro: 0.7479259967803955, accuracy-macro: 0.0037000000011176\n",
      "step:     805, loss: 0.1753896921873093, accuracy-micro: 0.7479827404022217, accuracy-macro: 0.0037000000011176\n",
      "step:     806, loss: 0.1753789633512497, accuracy-micro: 0.7479802370071411, accuracy-macro: 0.0037000000011176\n",
      "step:     807, loss: 0.1753689944744110, accuracy-micro: 0.7480250000953674, accuracy-macro: 0.0037000000011176\n",
      "step:     808, loss: 0.1753594875335693, accuracy-micro: 0.7480187416076660, accuracy-macro: 0.0037000000011176\n",
      "step:     809, loss: 0.1753493398427963, accuracy-micro: 0.7480507493019104, accuracy-macro: 0.0037000000011176\n",
      "step:     810, loss: 0.1753395646810532, accuracy-micro: 0.7480597496032715, accuracy-macro: 0.0037000000011176\n",
      "step:     811, loss: 0.1753299385309219, accuracy-micro: 0.7480785250663757, accuracy-macro: 0.0037000000011176\n",
      "step:     812, loss: 0.1753207743167877, accuracy-micro: 0.7480790019035339, accuracy-macro: 0.0037000000011176\n",
      "step:     813, loss: 0.1753116548061371, accuracy-micro: 0.7481225132942200, accuracy-macro: 0.0037000000011176\n",
      "step:     814, loss: 0.1753020286560059, accuracy-micro: 0.7480937242507935, accuracy-macro: 0.0037000000011176\n",
      "step:     815, loss: 0.1752926558256149, accuracy-micro: 0.7481672763824463, accuracy-macro: 0.0037000000011176\n",
      "step:     816, loss: 0.1752832233905792, accuracy-micro: 0.7481402754783630, accuracy-macro: 0.0037000000011176\n",
      "step:     817, loss: 0.1752737462520599, accuracy-micro: 0.7482157349586487, accuracy-macro: 0.0037000000011176\n",
      "step:     818, loss: 0.1752645224332809, accuracy-micro: 0.7481682300567627, accuracy-macro: 0.0037000000011176\n",
      "step:     819, loss: 0.1752550601959229, accuracy-micro: 0.7482489943504333, accuracy-macro: 0.0037000000011176\n",
      "step:     820, loss: 0.1752470433712006, accuracy-micro: 0.7481737732887268, accuracy-macro: 0.0037000000011176\n",
      "step:     821, loss: 0.1752407699823380, accuracy-micro: 0.7483149766921997, accuracy-macro: 0.0037000000011176\n",
      "step:     822, loss: 0.1752368658781052, accuracy-micro: 0.7481482625007629, accuracy-macro: 0.0037000000011176\n",
      "step:     823, loss: 0.1752372235059738, accuracy-micro: 0.7483572363853455, accuracy-macro: 0.0037000000011176\n",
      "step:     824, loss: 0.1752424985170364, accuracy-micro: 0.7481197714805603, accuracy-macro: 0.0037000000011176\n",
      "step:     825, loss: 0.1752584129571915, accuracy-micro: 0.7483352422714233, accuracy-macro: 0.0037000000011176\n",
      "step:     826, loss: 0.1752794384956360, accuracy-micro: 0.7480277419090271, accuracy-macro: 0.0037000000011176\n",
      "step:     827, loss: 0.1753139048814774, accuracy-micro: 0.7482619881629944, accuracy-macro: 0.0037000000011176\n",
      "step:     828, loss: 0.1753339618444443, accuracy-micro: 0.7478904724121094, accuracy-macro: 0.0037000000011176\n",
      "step:     829, loss: 0.1753474622964859, accuracy-micro: 0.7482397556304932, accuracy-macro: 0.0037000000011176\n",
      "step:     830, loss: 0.1752993464469910, accuracy-micro: 0.7479349970817566, accuracy-macro: 0.0037000000011176\n",
      "step:     831, loss: 0.1752290129661560, accuracy-micro: 0.7483844757080078, accuracy-macro: 0.0037000000011176\n",
      "step:     832, loss: 0.1751535236835480, accuracy-micro: 0.7482784986495972, accuracy-macro: 0.0037000000011176\n",
      "step:     833, loss: 0.1751221865415573, accuracy-micro: 0.7483942508697510, accuracy-macro: 0.0037000000011176\n",
      "step:     834, loss: 0.1751371920108795, accuracy-micro: 0.7485085129737854, accuracy-macro: 0.0037000000011176\n",
      "step:     835, loss: 0.1751669198274612, accuracy-micro: 0.7482067346572876, accuracy-macro: 0.0037000000011176\n",
      "step:     836, loss: 0.1751805394887924, accuracy-micro: 0.7484664916992188, accuracy-macro: 0.0037000000011176\n",
      "step:     837, loss: 0.1751476228237152, accuracy-micro: 0.7482302188873291, accuracy-macro: 0.0037000000011176\n",
      "step:     838, loss: 0.1750993132591248, accuracy-micro: 0.7485612630844116, accuracy-macro: 0.0037000000011176\n",
      "step:     839, loss: 0.1750689893960953, accuracy-micro: 0.7484775185585022, accuracy-macro: 0.0037000000011176\n",
      "step:     840, loss: 0.1750705689191818, accuracy-micro: 0.7484222650527954, accuracy-macro: 0.0037000000011176\n",
      "step:     841, loss: 0.1750838160514832, accuracy-micro: 0.7485907673835754, accuracy-macro: 0.0037000000011176\n",
      "step:     842, loss: 0.1750799715518951, accuracy-micro: 0.7483835220336914, accuracy-macro: 0.0037000000011176\n",
      "step:     843, loss: 0.1750579029321671, accuracy-micro: 0.7486349940299988, accuracy-macro: 0.0037000000011176\n",
      "step:     844, loss: 0.1750307232141495, accuracy-micro: 0.7484759688377380, accuracy-macro: 0.0037000000011176\n",
      "step:     845, loss: 0.1750161498785019, accuracy-micro: 0.7485727667808533, accuracy-macro: 0.0037000000011176\n",
      "step:     846, loss: 0.1750140637159348, accuracy-micro: 0.7486259937286377, accuracy-macro: 0.0037000000011176\n",
      "step:     847, loss: 0.1750159412622452, accuracy-micro: 0.7484967708587646, accuracy-macro: 0.0037000000011176\n",
      "step:     848, loss: 0.1750109940767288, accuracy-micro: 0.7486897706985474, accuracy-macro: 0.0037000000011176\n",
      "step:     849, loss: 0.1749958097934723, accuracy-micro: 0.7485107183456421, accuracy-macro: 0.0037000000011176\n",
      "step:     850, loss: 0.1749777644872665, accuracy-micro: 0.7486709952354431, accuracy-macro: 0.0037000000011176\n",
      "step:     851, loss: 0.1749640405178070, accuracy-micro: 0.7486547231674194, accuracy-macro: 0.0037000000011176\n",
      "step:     852, loss: 0.1749565601348877, accuracy-micro: 0.7486577630043030, accuracy-macro: 0.0037000000011176\n",
      "step:     853, loss: 0.1749506890773773, accuracy-micro: 0.7487084865570068, accuracy-macro: 0.0037000000011176\n",
      "step:     854, loss: 0.1749444305896759, accuracy-micro: 0.7486477494239807, accuracy-macro: 0.0037000000011176\n",
      "step:     855, loss: 0.1749355345964432, accuracy-micro: 0.7487455010414124, accuracy-macro: 0.0037000000011176\n",
      "step:     856, loss: 0.1749240905046463, accuracy-micro: 0.7486987709999084, accuracy-macro: 0.0037000000011176\n",
      "step:     857, loss: 0.1749123632907867, accuracy-micro: 0.7487652301788330, accuracy-macro: 0.0037000000011176\n",
      "step:     858, loss: 0.1749046593904495, accuracy-micro: 0.7487900257110596, accuracy-macro: 0.0037000000011176\n",
      "step:     859, loss: 0.1748993694782257, accuracy-micro: 0.7487382292747498, accuracy-macro: 0.0037000000011176\n",
      "step:     860, loss: 0.1748927533626556, accuracy-micro: 0.7488260269165039, accuracy-macro: 0.0037000000011176\n",
      "step:     861, loss: 0.1748833507299423, accuracy-micro: 0.7487515211105347, accuracy-macro: 0.0037000000011176\n",
      "step:     862, loss: 0.1748719662427902, accuracy-micro: 0.7488497495651245, accuracy-macro: 0.0037000000011176\n",
      "step:     863, loss: 0.1748614609241486, accuracy-micro: 0.7488182187080383, accuracy-macro: 0.0037000000011176\n",
      "step:     864, loss: 0.1748534142971039, accuracy-micro: 0.7488442659378052, accuracy-macro: 0.0037000000011176\n",
      "step:     865, loss: 0.1748473644256592, accuracy-micro: 0.7488872408866882, accuracy-macro: 0.0037000000011176\n",
      "step:     866, loss: 0.1748415380716324, accuracy-micro: 0.7488257288932800, accuracy-macro: 0.0037000000011176\n",
      "step:     867, loss: 0.1748344302177429, accuracy-micro: 0.7489244937896729, accuracy-macro: 0.0037000000011176\n",
      "step:     868, loss: 0.1748250871896744, accuracy-micro: 0.7488564848899841, accuracy-macro: 0.0037000000011176\n",
      "step:     869, loss: 0.1748145371675491, accuracy-micro: 0.7489492297172546, accuracy-macro: 0.0037000000011176\n",
      "step:     870, loss: 0.1748037338256836, accuracy-micro: 0.7489234805107117, accuracy-macro: 0.0037000000011176\n",
      "step:     871, loss: 0.1747941821813583, accuracy-micro: 0.7489707469940186, accuracy-macro: 0.0037000000011176\n",
      "step:     872, loss: 0.1747861206531525, accuracy-micro: 0.7489904761314392, accuracy-macro: 0.0037000000011176\n",
      "step:     873, loss: 0.1747827827930450, accuracy-micro: 0.7489334940910339, accuracy-macro: 0.0037000000011176\n",
      "step:     874, loss: 0.1747781932353973, accuracy-micro: 0.7490040063858032, accuracy-macro: 0.0037000000011176\n",
      "step:     875, loss: 0.1747703403234482, accuracy-micro: 0.7489492297172546, accuracy-macro: 0.0037000000011176\n",
      "step:     876, loss: 0.1747584342956543, accuracy-micro: 0.7490192651748657, accuracy-macro: 0.0037000000011176\n",
      "step:     877, loss: 0.1747458130121231, accuracy-micro: 0.7489907741546631, accuracy-macro: 0.0037000000011176\n",
      "step:     878, loss: 0.1747354567050934, accuracy-micro: 0.7490587234497070, accuracy-macro: 0.0037000000011176\n",
      "step:     879, loss: 0.1747284978628159, accuracy-micro: 0.7490777373313904, accuracy-macro: 0.0037000000011176\n",
      "step:     880, loss: 0.1747235655784607, accuracy-micro: 0.7490274906158447, accuracy-macro: 0.0037000000011176\n",
      "step:     881, loss: 0.1747179478406906, accuracy-micro: 0.7490827441215515, accuracy-macro: 0.0037000000011176\n",
      "step:     882, loss: 0.1747076809406281, accuracy-micro: 0.7490435242652893, accuracy-macro: 0.0037000000011176\n",
      "step:     883, loss: 0.1746963113546371, accuracy-micro: 0.7491245269775391, accuracy-macro: 0.0037000000011176\n",
      "step:     884, loss: 0.1746868491172791, accuracy-micro: 0.7491260170936584, accuracy-macro: 0.0037000000011176\n",
      "step:     885, loss: 0.1746781319379807, accuracy-micro: 0.7491444945335388, accuracy-macro: 0.0037000000011176\n",
      "step:     886, loss: 0.1746705472469330, accuracy-micro: 0.7491549849510193, accuracy-macro: 0.0037000000011176\n",
      "step:     887, loss: 0.1746628731489182, accuracy-micro: 0.7491577267646790, accuracy-macro: 0.0037000000011176\n",
      "step:     888, loss: 0.1746549010276794, accuracy-micro: 0.7491825222969055, accuracy-macro: 0.0037000000011176\n",
      "step:     889, loss: 0.1746460497379303, accuracy-micro: 0.7491794824600220, accuracy-macro: 0.0037000000011176\n",
      "step:     890, loss: 0.1746377497911453, accuracy-micro: 0.7492037415504456, accuracy-macro: 0.0037000000011176\n",
      "step:     891, loss: 0.1746292412281036, accuracy-micro: 0.7492222189903259, accuracy-macro: 0.0037000000011176\n",
      "step:     892, loss: 0.1746212840080261, accuracy-micro: 0.7492399811744690, accuracy-macro: 0.0037000000011176\n",
      "step:     893, loss: 0.1746146231889725, accuracy-micro: 0.7492787241935730, accuracy-macro: 0.0037000000011176\n",
      "step:     894, loss: 0.1746084094047546, accuracy-micro: 0.7492262721061707, accuracy-macro: 0.0037000000011176\n",
      "step:     895, loss: 0.1746022552251816, accuracy-micro: 0.7493255138397217, accuracy-macro: 0.0037000000011176\n",
      "step:     896, loss: 0.1745939403772354, accuracy-micro: 0.7492522597312927, accuracy-macro: 0.0037000000011176\n",
      "step:     897, loss: 0.1745843887329102, accuracy-micro: 0.7493577599525452, accuracy-macro: 0.0037000000011176\n",
      "step:     898, loss: 0.1745746880769730, accuracy-micro: 0.7493035197257996, accuracy-macro: 0.0037000000011176\n",
      "step:     899, loss: 0.1745658069849014, accuracy-micro: 0.7493742704391479, accuracy-macro: 0.0037000000011176\n",
      "step:     900, loss: 0.1745568066835403, accuracy-micro: 0.7493552565574646, accuracy-macro: 0.0037000000011176\n",
      "step:     901, loss: 0.1745489090681076, accuracy-micro: 0.7493552565574646, accuracy-macro: 0.0037000000011176\n",
      "step:     902, loss: 0.1745412200689316, accuracy-micro: 0.7493792772293091, accuracy-macro: 0.0037000000011176\n",
      "step:     903, loss: 0.1745342165231705, accuracy-micro: 0.7493795156478882, accuracy-macro: 0.0037000000011176\n",
      "step:     904, loss: 0.1745262444019318, accuracy-micro: 0.7494287490844727, accuracy-macro: 0.0037000000011176\n",
      "step:     905, loss: 0.1745172142982483, accuracy-micro: 0.7494162321090698, accuracy-macro: 0.0037000000011176\n",
      "step:     906, loss: 0.1745088249444962, accuracy-micro: 0.7494214773178101, accuracy-macro: 0.0037000000011176\n",
      "step:     907, loss: 0.1745009720325470, accuracy-micro: 0.7494512200355530, accuracy-macro: 0.0037000000011176\n",
      "step:     908, loss: 0.1744942665100098, accuracy-micro: 0.7494524717330933, accuracy-macro: 0.0037000000011176\n",
      "step:     909, loss: 0.1744870692491531, accuracy-micro: 0.7494879961013794, accuracy-macro: 0.0037000000011176\n",
      "step:     910, loss: 0.1744817048311234, accuracy-micro: 0.7494220137596130, accuracy-macro: 0.0037000000011176\n",
      "step:     911, loss: 0.1744756847620010, accuracy-micro: 0.7495587468147278, accuracy-macro: 0.0037000000011176\n",
      "step:     912, loss: 0.1744675040245056, accuracy-micro: 0.7494347691535950, accuracy-macro: 0.0037000000011176\n",
      "step:     913, loss: 0.1744576096534729, accuracy-micro: 0.7495734691619873, accuracy-macro: 0.0037000000011176\n",
      "step:     914, loss: 0.1744476556777954, accuracy-micro: 0.7494972348213196, accuracy-macro: 0.0037000000011176\n",
      "step:     915, loss: 0.1744380891323090, accuracy-micro: 0.7495662569999695, accuracy-macro: 0.0037000000011176\n",
      "step:     916, loss: 0.1744299829006195, accuracy-micro: 0.7495694756507874, accuracy-macro: 0.0037000000011176\n",
      "step:     917, loss: 0.1744236201047897, accuracy-micro: 0.7495327591896057, accuracy-macro: 0.0037000000011176\n",
      "step:     918, loss: 0.1744184345006943, accuracy-micro: 0.7496324777603149, accuracy-macro: 0.0037000000011176\n",
      "step:     919, loss: 0.1744136512279510, accuracy-micro: 0.7495092749595642, accuracy-macro: 0.0037000000011176\n",
      "step:     920, loss: 0.1744088679552078, accuracy-micro: 0.7496487498283386, accuracy-macro: 0.0037000000011176\n",
      "step:     921, loss: 0.1744020581245422, accuracy-micro: 0.7495250105857849, accuracy-macro: 0.0037000000011176\n",
      "step:     922, loss: 0.1743932813405991, accuracy-micro: 0.7496667504310608, accuracy-macro: 0.0037000000011176\n",
      "step:     923, loss: 0.1743854284286499, accuracy-micro: 0.7495512366294861, accuracy-macro: 0.0037000000011176\n",
      "step:     924, loss: 0.1743775606155396, accuracy-micro: 0.7496947646141052, accuracy-macro: 0.0037000000011176\n",
      "step:     925, loss: 0.1743684113025665, accuracy-micro: 0.7495895028114319, accuracy-macro: 0.0037000000011176\n",
      "step:     926, loss: 0.1743584424257278, accuracy-micro: 0.7497342228889465, accuracy-macro: 0.0037000000011176\n",
      "step:     927, loss: 0.1743474751710892, accuracy-micro: 0.7496557235717773, accuracy-macro: 0.0037000000011176\n",
      "step:     928, loss: 0.1743375211954117, accuracy-micro: 0.7497387528419495, accuracy-macro: 0.0037000000011176\n",
      "step:     929, loss: 0.1743290573358536, accuracy-micro: 0.7497352361679077, accuracy-macro: 0.0037000000011176\n",
      "step:     930, loss: 0.1743209213018417, accuracy-micro: 0.7497357726097107, accuracy-macro: 0.0037000000011176\n",
      "step:     931, loss: 0.1743140518665314, accuracy-micro: 0.7497877478599548, accuracy-macro: 0.0037000000011176\n",
      "step:     932, loss: 0.1743073016405106, accuracy-micro: 0.7497327327728271, accuracy-macro: 0.0037000000011176\n",
      "step:     933, loss: 0.1743013709783554, accuracy-micro: 0.7498312592506409, accuracy-macro: 0.0037000000011176\n",
      "step:     934, loss: 0.1742957830429077, accuracy-micro: 0.7497289776802063, accuracy-macro: 0.0037000000011176\n",
      "step:     935, loss: 0.1742907464504242, accuracy-micro: 0.7498622536659241, accuracy-macro: 0.0037000000011176\n",
      "step:     936, loss: 0.1742837876081467, accuracy-micro: 0.7497320175170898, accuracy-macro: 0.0037000000011176\n",
      "step:     937, loss: 0.1742765903472900, accuracy-micro: 0.7498702406883240, accuracy-macro: 0.0037000000011176\n",
      "step:     938, loss: 0.1742664724588394, accuracy-micro: 0.7497754693031311, accuracy-macro: 0.0037000000011176\n",
      "step:     939, loss: 0.1742558181285858, accuracy-micro: 0.7499042749404907, accuracy-macro: 0.0037000000011176\n",
      "step:     940, loss: 0.1742451488971710, accuracy-micro: 0.7498657703399658, accuracy-macro: 0.0037000000011176\n",
      "step:     941, loss: 0.1742370277643204, accuracy-micro: 0.7498840093612671, accuracy-macro: 0.0037000000011176\n",
      "step:     942, loss: 0.1742308437824249, accuracy-micro: 0.7499492764472961, accuracy-macro: 0.0037000000011176\n",
      "step:     943, loss: 0.1742275953292847, accuracy-micro: 0.7498237490653992, accuracy-macro: 0.0037000000011176\n",
      "step:     944, loss: 0.1742249131202698, accuracy-micro: 0.7499752640724182, accuracy-macro: 0.0037000000011176\n",
      "step:     945, loss: 0.1742230057716370, accuracy-micro: 0.7498332262039185, accuracy-macro: 0.0037000000011176\n",
      "step:     946, loss: 0.1742197871208191, accuracy-micro: 0.7499787211418152, accuracy-macro: 0.0037000000011176\n",
      "step:     947, loss: 0.1742135733366013, accuracy-micro: 0.7498452663421631, accuracy-macro: 0.0037000000011176\n",
      "step:     948, loss: 0.1742061525583267, accuracy-micro: 0.7500014901161194, accuracy-macro: 0.0037000000011176\n",
      "step:     949, loss: 0.1741964370012283, accuracy-micro: 0.7498735189437866, accuracy-macro: 0.0037000000011176\n",
      "step:     950, loss: 0.1741878092288971, accuracy-micro: 0.7500314712524414, accuracy-macro: 0.0037000000011176\n",
      "step:     951, loss: 0.1741794645786285, accuracy-micro: 0.7499085068702698, accuracy-macro: 0.0037000000011176\n",
      "step:     952, loss: 0.1741719096899033, accuracy-micro: 0.7500485181808472, accuracy-macro: 0.0037000000011176\n",
      "step:     953, loss: 0.1741615980863571, accuracy-micro: 0.7499472498893738, accuracy-macro: 0.0037000000011176\n",
      "step:     954, loss: 0.1741503626108170, accuracy-micro: 0.7500994801521301, accuracy-macro: 0.0037000000011176\n",
      "step:     955, loss: 0.1741389036178589, accuracy-micro: 0.7500039935112000, accuracy-macro: 0.0037000000011176\n",
      "step:     956, loss: 0.1741284579038620, accuracy-micro: 0.7501117587089539, accuracy-macro: 0.0037000000011176\n",
      "step:     957, loss: 0.1741187423467636, accuracy-micro: 0.7500707507133484, accuracy-macro: 0.0037000000011176\n",
      "step:     958, loss: 0.1741101145744324, accuracy-micro: 0.7501099705696106, accuracy-macro: 0.0037000000011176\n",
      "step:     959, loss: 0.1741032749414444, accuracy-micro: 0.7501202225685120, accuracy-macro: 0.0037000000011176\n",
      "step:     960, loss: 0.1740969568490982, accuracy-micro: 0.7501230239868164, accuracy-macro: 0.0037000000011176\n",
      "step:     961, loss: 0.1740914732217789, accuracy-micro: 0.7501724958419800, accuracy-macro: 0.0037000000011176\n",
      "step:     962, loss: 0.1740854978561401, accuracy-micro: 0.7501092553138733, accuracy-macro: 0.0037000000011176\n",
      "step:     963, loss: 0.1740811914205551, accuracy-micro: 0.7501782774925232, accuracy-macro: 0.0037000000011176\n",
      "step:     964, loss: 0.1740766316652298, accuracy-micro: 0.7500887513160706, accuracy-macro: 0.0037000000011176\n",
      "step:     965, loss: 0.1740705668926239, accuracy-micro: 0.7502149939537048, accuracy-macro: 0.0037000000011176\n",
      "step:     966, loss: 0.1740647554397583, accuracy-micro: 0.7500964999198914, accuracy-macro: 0.0037000000011176\n",
      "step:     967, loss: 0.1740571260452271, accuracy-micro: 0.7502319812774658, accuracy-macro: 0.0037000000011176\n",
      "step:     968, loss: 0.1740496605634689, accuracy-micro: 0.7501170039176941, accuracy-macro: 0.0037000000011176\n",
      "step:     969, loss: 0.1740437448024750, accuracy-micro: 0.7502572536468506, accuracy-macro: 0.0037000000011176\n",
      "step:     970, loss: 0.1740380376577377, accuracy-micro: 0.7501304745674133, accuracy-macro: 0.0037000000011176\n",
      "step:     971, loss: 0.1740328073501587, accuracy-micro: 0.7502704858779907, accuracy-macro: 0.0037000000011176\n",
      "step:     972, loss: 0.1740244925022125, accuracy-micro: 0.7501425147056580, accuracy-macro: 0.0037000000011176\n",
      "step:     973, loss: 0.1740161776542664, accuracy-micro: 0.7502957582473755, accuracy-macro: 0.0037000000011176\n",
      "step:     974, loss: 0.1740051060914993, accuracy-micro: 0.7501777410507202, accuracy-macro: 0.0037000000011176\n",
      "step:     975, loss: 0.1739929318428040, accuracy-micro: 0.7503095269203186, accuracy-macro: 0.0037000000011176\n",
      "step:     976, loss: 0.1739820241928101, accuracy-micro: 0.7502894997596741, accuracy-macro: 0.0037000000011176\n",
      "step:     977, loss: 0.1739727109670639, accuracy-micro: 0.7503460049629211, accuracy-macro: 0.0037000000011176\n",
      "step:     978, loss: 0.1739656925201416, accuracy-micro: 0.7503625154495239, accuracy-macro: 0.0037000000011176\n",
      "step:     979, loss: 0.1739593446254730, accuracy-micro: 0.7503562569618225, accuracy-macro: 0.0037000000011176\n",
      "step:     980, loss: 0.1739536821842194, accuracy-micro: 0.7503864765167236, accuracy-macro: 0.0037000000011176\n",
      "step:     981, loss: 0.1739486902952194, accuracy-micro: 0.7503479719161987, accuracy-macro: 0.0037000000011176\n",
      "step:     982, loss: 0.1739431172609329, accuracy-micro: 0.7503935098648071, accuracy-macro: 0.0037000000011176\n",
      "step:     983, loss: 0.1739374995231628, accuracy-micro: 0.7503307461738586, accuracy-macro: 0.0037000000011176\n",
      "step:     984, loss: 0.1739311814308167, accuracy-micro: 0.7504142522811890, accuracy-macro: 0.0037000000011176\n",
      "step:     985, loss: 0.1739242672920227, accuracy-micro: 0.7503332495689392, accuracy-macro: 0.0037000000011176\n",
      "step:     986, loss: 0.1739163398742676, accuracy-micro: 0.7504190206527710, accuracy-macro: 0.0037000000011176\n",
      "step:     987, loss: 0.1739071458578110, accuracy-micro: 0.7503822445869446, accuracy-macro: 0.0037000000011176\n",
      "step:     988, loss: 0.1738979667425156, accuracy-micro: 0.7504812479019165, accuracy-macro: 0.0037000000011176\n",
      "step:     989, loss: 0.1738892197608948, accuracy-micro: 0.7504515051841736, accuracy-macro: 0.0037000000011176\n",
      "step:     990, loss: 0.1738807708024979, accuracy-micro: 0.7504850029945374, accuracy-macro: 0.0037000000011176\n",
      "step:     991, loss: 0.1738731563091278, accuracy-micro: 0.7504875063896179, accuracy-macro: 0.0037000000011176\n",
      "step:     992, loss: 0.1738663762807846, accuracy-micro: 0.7504994869232178, accuracy-macro: 0.0037000000011176\n",
      "step:     993, loss: 0.1738606244325638, accuracy-micro: 0.7505212426185608, accuracy-macro: 0.0037000000011176\n",
      "step:     994, loss: 0.1738554388284683, accuracy-micro: 0.7504994869232178, accuracy-macro: 0.0037000000011176\n",
      "step:     995, loss: 0.1738512068986893, accuracy-micro: 0.7505584955215454, accuracy-macro: 0.0037000000011176\n",
      "step:     996, loss: 0.1738460808992386, accuracy-micro: 0.7505022287368774, accuracy-macro: 0.0037000000011176\n",
      "step:     997, loss: 0.1738386601209641, accuracy-micro: 0.7505692243576050, accuracy-macro: 0.0037000000011176\n",
      "step:     998, loss: 0.1738316267728806, accuracy-micro: 0.7505220174789429, accuracy-macro: 0.0037000000011176\n",
      "step:     999, loss: 0.1738247126340866, accuracy-micro: 0.7505879998207092, accuracy-macro: 0.0037000000011176\n",
      "step:    1000, loss: 0.1738175898790359, accuracy-micro: 0.7505499720573425, accuracy-macro: 0.0037000000011176\n",
      "step:    1001, loss: 0.1738110035657883, accuracy-micro: 0.7506135106086731, accuracy-macro: 0.0037000000011176\n",
      "step:    1002, loss: 0.1738046109676361, accuracy-micro: 0.7505679726600647, accuracy-macro: 0.0037000000011176\n",
      "step:    1003, loss: 0.1737984120845795, accuracy-micro: 0.7506399750709534, accuracy-macro: 0.0037000000011176\n",
      "step:    1004, loss: 0.1737921535968781, accuracy-micro: 0.7505807280540466, accuracy-macro: 0.0037000000011176\n",
      "step:    1005, loss: 0.1737855970859528, accuracy-micro: 0.7506777644157410, accuracy-macro: 0.0037000000011176\n",
      "step:    1006, loss: 0.1737788319587708, accuracy-micro: 0.7506070137023926, accuracy-macro: 0.0037000000011176\n",
      "step:    1007, loss: 0.1737729012966156, accuracy-micro: 0.7506997585296631, accuracy-macro: 0.0037000000011176\n",
      "step:    1008, loss: 0.1737662255764008, accuracy-micro: 0.7506265044212341, accuracy-macro: 0.0037000000011176\n",
      "step:    1009, loss: 0.1737587153911591, accuracy-micro: 0.7507172226905823, accuracy-macro: 0.0037000000011176\n",
      "step:    1010, loss: 0.1737512052059174, accuracy-micro: 0.7506467700004578, accuracy-macro: 0.0037000000011176\n",
      "step:    1011, loss: 0.1737441569566727, accuracy-micro: 0.7507315278053284, accuracy-macro: 0.0037000000011176\n",
      "step:    1012, loss: 0.1737365871667862, accuracy-micro: 0.7506899833679199, accuracy-macro: 0.0037000000011176\n",
      "step:    1013, loss: 0.1737284064292908, accuracy-micro: 0.7507579922676086, accuracy-macro: 0.0037000000011176\n",
      "step:    1014, loss: 0.1737197786569595, accuracy-micro: 0.7507374882698059, accuracy-macro: 0.0037000000011176\n",
      "step:    1015, loss: 0.1737112253904343, accuracy-micro: 0.7507709860801697, accuracy-macro: 0.0037000000011176\n",
      "step:    1016, loss: 0.1737022846937180, accuracy-micro: 0.7507932186126709, accuracy-macro: 0.0037000000011176\n",
      "step:    1017, loss: 0.1736942678689957, accuracy-micro: 0.7508032321929932, accuracy-macro: 0.0037000000011176\n",
      "step:    1018, loss: 0.1736865937709808, accuracy-micro: 0.7508002519607544, accuracy-macro: 0.0037000000011176\n",
      "step:    1019, loss: 0.1736797243356705, accuracy-micro: 0.7508249878883362, accuracy-macro: 0.0037000000011176\n",
      "step:    1020, loss: 0.1736724674701691, accuracy-micro: 0.7508385181427002, accuracy-macro: 0.0037000000011176\n",
      "step:    1021, loss: 0.1736664324998856, accuracy-micro: 0.7508324980735779, accuracy-macro: 0.0037000000011176\n",
      "step:    1022, loss: 0.1736607253551483, accuracy-micro: 0.7508522272109985, accuracy-macro: 0.0037000000011176\n",
      "step:    1023, loss: 0.1736559122800827, accuracy-micro: 0.7508649826049805, accuracy-macro: 0.0037000000011176\n",
      "step:    1024, loss: 0.1736539304256439, accuracy-micro: 0.7508902549743652, accuracy-macro: 0.0037000000011176\n",
      "step:    1025, loss: 0.1736537963151932, accuracy-micro: 0.7508304715156555, accuracy-macro: 0.0037000000011176\n",
      "step:    1026, loss: 0.1736550033092499, accuracy-micro: 0.7509250044822693, accuracy-macro: 0.0037000000011176\n",
      "step:    1027, loss: 0.1736546307802200, accuracy-micro: 0.7507669925689697, accuracy-macro: 0.0037000000011176\n",
      "step:    1028, loss: 0.1736557930707932, accuracy-micro: 0.7509229779243469, accuracy-macro: 0.0037000000011176\n",
      "step:    1029, loss: 0.1736566424369812, accuracy-micro: 0.7507349848747253, accuracy-macro: 0.0037000000011176\n",
      "step:    1030, loss: 0.1736588180065155, accuracy-micro: 0.7509532570838928, accuracy-macro: 0.0037000000011176\n",
      "step:    1031, loss: 0.1736572533845901, accuracy-micro: 0.7507282495498657, accuracy-macro: 0.0037000000011176\n",
      "step:    1032, loss: 0.1736577600240707, accuracy-micro: 0.7509614825248718, accuracy-macro: 0.0037000000011176\n",
      "step:    1033, loss: 0.1736497431993484, accuracy-micro: 0.7507604956626892, accuracy-macro: 0.0037000000011176\n",
      "step:    1034, loss: 0.1736377328634262, accuracy-micro: 0.7510179877281189, accuracy-macro: 0.0037000000011176\n",
      "step:    1035, loss: 0.1736167669296265, accuracy-micro: 0.7508184909820557, accuracy-macro: 0.0037000000011176\n",
      "step:    1036, loss: 0.1735945641994476, accuracy-micro: 0.7510322332382202, accuracy-macro: 0.0037000000011176\n",
      "step:    1037, loss: 0.1735739409923553, accuracy-micro: 0.7509572505950928, accuracy-macro: 0.0037000000011176\n",
      "step:    1038, loss: 0.1735579818487167, accuracy-micro: 0.7510802745819092, accuracy-macro: 0.0037000000011176\n",
      "step:    1039, loss: 0.1735473573207855, accuracy-micro: 0.7510604858398438, accuracy-macro: 0.0037000000011176\n",
      "step:    1040, loss: 0.1735400557518005, accuracy-micro: 0.7510952353477478, accuracy-macro: 0.0037000000011176\n",
      "step:    1041, loss: 0.1735352128744125, accuracy-micro: 0.7511157393455505, accuracy-macro: 0.0037000000011176\n",
      "step:    1042, loss: 0.1735319048166275, accuracy-micro: 0.7510780096054077, accuracy-macro: 0.0037000000011176\n",
      "step:    1043, loss: 0.1735273748636246, accuracy-micro: 0.7511469721794128, accuracy-macro: 0.0037000000011176\n",
      "step:    1044, loss: 0.1735210567712784, accuracy-micro: 0.7510765194892883, accuracy-macro: 0.0037000000011176\n",
      "step:    1045, loss: 0.1735136210918427, accuracy-micro: 0.7511720061302185, accuracy-macro: 0.0037000000011176\n",
      "step:    1046, loss: 0.1735045313835144, accuracy-micro: 0.7511385083198547, accuracy-macro: 0.0037000000011176\n",
      "step:    1047, loss: 0.1734958589076996, accuracy-micro: 0.7512000203132629, accuracy-macro: 0.0037000000011176\n",
      "step:    1048, loss: 0.1734889149665833, accuracy-micro: 0.7511832714080811, accuracy-macro: 0.0037000000011176\n",
      "step:    1049, loss: 0.1734822243452072, accuracy-micro: 0.7512084841728210, accuracy-macro: 0.0037000000011176\n",
      "step:    1050, loss: 0.1734766662120819, accuracy-micro: 0.7512145042419434, accuracy-macro: 0.0037000000011176\n",
      "step:    1051, loss: 0.1734699308872223, accuracy-micro: 0.7512067556381226, accuracy-macro: 0.0037000000011176\n",
      "step:    1052, loss: 0.1734656095504761, accuracy-micro: 0.7512335181236267, accuracy-macro: 0.0037000000011176\n",
      "step:    1053, loss: 0.1734616905450821, accuracy-micro: 0.7511919736862183, accuracy-macro: 0.0037000000011176\n",
      "step:    1054, loss: 0.1734582483768463, accuracy-micro: 0.7512664794921875, accuracy-macro: 0.0037000000011176\n",
      "step:    1055, loss: 0.1734538525342941, accuracy-micro: 0.7511752247810364, accuracy-macro: 0.0037000000011176\n",
      "step:    1056, loss: 0.1734483689069748, accuracy-micro: 0.7512832283973694, accuracy-macro: 0.0037000000011176\n",
      "step:    1057, loss: 0.1734420359134674, accuracy-micro: 0.7511662244796753, accuracy-macro: 0.0037000000011176\n",
      "step:    1058, loss: 0.1734358370304108, accuracy-micro: 0.7512980103492737, accuracy-macro: 0.0037000000011176\n",
      "step:    1059, loss: 0.1734287738800049, accuracy-micro: 0.7512015104293823, accuracy-macro: 0.0037000000011176\n",
      "step:    1060, loss: 0.1734214127063751, accuracy-micro: 0.7513312697410583, accuracy-macro: 0.0037000000011176\n",
      "step:    1061, loss: 0.1734143048524857, accuracy-micro: 0.7512512207031250, accuracy-macro: 0.0037000000011176\n",
      "step:    1062, loss: 0.1734058111906052, accuracy-micro: 0.7513415217399597, accuracy-macro: 0.0037000000011176\n",
      "step:    1063, loss: 0.1733969897031784, accuracy-micro: 0.7513497471809387, accuracy-macro: 0.0037000000011176\n",
      "step:    1064, loss: 0.1733887344598770, accuracy-micro: 0.7513572573661804, accuracy-macro: 0.0037000000011176\n",
      "step:    1065, loss: 0.1733814030885696, accuracy-micro: 0.7513765096664429, accuracy-macro: 0.0037000000011176\n",
      "step:    1066, loss: 0.1733768433332443, accuracy-micro: 0.7513964772224426, accuracy-macro: 0.0037000000011176\n",
      "step:    1067, loss: 0.1733744144439697, accuracy-micro: 0.7514002323150635, accuracy-macro: 0.0037000000011176\n",
      "step:    1068, loss: 0.1733723431825638, accuracy-micro: 0.7512992620468140, accuracy-macro: 0.0037000000011176\n",
      "step:    1069, loss: 0.1733710318803787, accuracy-micro: 0.7514039874076843, accuracy-macro: 0.0037000000011176\n",
      "step:    1070, loss: 0.1733671873807907, accuracy-micro: 0.7512957453727722, accuracy-macro: 0.0037000000011176\n",
      "step:    1071, loss: 0.1733612567186356, accuracy-micro: 0.7514182329177856, accuracy-macro: 0.0037000000011176\n",
      "step:    1072, loss: 0.1733556836843491, accuracy-micro: 0.7513195276260376, accuracy-macro: 0.0037000000011176\n",
      "step:    1073, loss: 0.1733517199754715, accuracy-micro: 0.7514535188674927, accuracy-macro: 0.0037000000011176\n",
      "step:    1074, loss: 0.1733484715223312, accuracy-micro: 0.7513407468795776, accuracy-macro: 0.0037000000011176\n",
      "step:    1075, loss: 0.1733475327491760, accuracy-micro: 0.7514860033988953, accuracy-macro: 0.0037000000011176\n",
      "step:    1076, loss: 0.1733420491218567, accuracy-micro: 0.7513570189476013, accuracy-macro: 0.0037000000011176\n",
      "step:    1077, loss: 0.1733341813087463, accuracy-micro: 0.7515155076980591, accuracy-macro: 0.0037000000011176\n",
      "step:    1078, loss: 0.1733228713274002, accuracy-micro: 0.7513884902000427, accuracy-macro: 0.0037000000011176\n",
      "step:    1079, loss: 0.1733112782239914, accuracy-micro: 0.7515159845352173, accuracy-macro: 0.0037000000011176\n",
      "step:    1080, loss: 0.1732977777719498, accuracy-micro: 0.7514625191688538, accuracy-macro: 0.0037000000011176\n",
      "step:    1081, loss: 0.1732849925756454, accuracy-micro: 0.7515410184860229, accuracy-macro: 0.0037000000011176\n",
      "step:    1082, loss: 0.1732774674892426, accuracy-micro: 0.7515507340431213, accuracy-macro: 0.0037000000011176\n",
      "step:    1083, loss: 0.1732721179723740, accuracy-micro: 0.7515597343444824, accuracy-macro: 0.0037000000011176\n",
      "step:    1084, loss: 0.1732684671878815, accuracy-micro: 0.7515760064125061, accuracy-macro: 0.0037000000011176\n",
      "step:    1085, loss: 0.1732652187347412, accuracy-micro: 0.7515362501144409, accuracy-macro: 0.0037000000011176\n",
      "step:    1086, loss: 0.1732620000839233, accuracy-micro: 0.7516097426414490, accuracy-macro: 0.0037000000011176\n",
      "step:    1087, loss: 0.1732560396194458, accuracy-micro: 0.7515509724617004, accuracy-macro: 0.0037000000011176\n",
      "step:    1088, loss: 0.1732482910156250, accuracy-micro: 0.7516407370567322, accuracy-macro: 0.0037000000011176\n",
      "step:    1089, loss: 0.1732406765222549, accuracy-micro: 0.7515890002250671, accuracy-macro: 0.0037000000011176\n",
      "step:    1090, loss: 0.1732324510812759, accuracy-micro: 0.7516147494316101, accuracy-macro: 0.0037000000011176\n",
      "step:    1091, loss: 0.1732247918844223, accuracy-micro: 0.7516222596168518, accuracy-macro: 0.0037000000011176\n",
      "step:    1092, loss: 0.1732178181409836, accuracy-micro: 0.7516527771949768, accuracy-macro: 0.0037000000011176\n",
      "step:    1093, loss: 0.1732112616300583, accuracy-micro: 0.7516562342643738, accuracy-macro: 0.0037000000011176\n",
      "step:    1094, loss: 0.1732058376073837, accuracy-micro: 0.7516667246818542, accuracy-macro: 0.0037000000011176\n",
      "step:    1095, loss: 0.1731999367475510, accuracy-micro: 0.7516980171203613, accuracy-macro: 0.0037000000011176\n",
      "step:    1096, loss: 0.1731942594051361, accuracy-micro: 0.7516894936561584, accuracy-macro: 0.0037000000011176\n",
      "step:    1097, loss: 0.1731882095336914, accuracy-micro: 0.7517139911651611, accuracy-macro: 0.0037000000011176\n",
      "step:    1098, loss: 0.1731824427843094, accuracy-micro: 0.7517052292823792, accuracy-macro: 0.0037000000011176\n",
      "step:    1099, loss: 0.1731768548488617, accuracy-micro: 0.7517395019531250, accuracy-macro: 0.0037000000011176\n",
      "step:    1100, loss: 0.1731714755296707, accuracy-micro: 0.7517087459564209, accuracy-macro: 0.0037000000011176\n",
      "step:    1101, loss: 0.1731661260128021, accuracy-micro: 0.7517392635345459, accuracy-macro: 0.0037000000011176\n",
      "step:    1102, loss: 0.1731607019901276, accuracy-micro: 0.7517150044441223, accuracy-macro: 0.0037000000011176\n",
      "step:    1103, loss: 0.1731555908918381, accuracy-micro: 0.7517677545547485, accuracy-macro: 0.0037000000011176\n",
      "step:    1104, loss: 0.1731495559215546, accuracy-micro: 0.7517420053482056, accuracy-macro: 0.0037000000011176\n",
      "step:    1105, loss: 0.1731439381837845, accuracy-micro: 0.7517947554588318, accuracy-macro: 0.0037000000011176\n",
      "step:    1106, loss: 0.1731379777193069, accuracy-micro: 0.7517667412757874, accuracy-macro: 0.0037000000011176\n",
      "step:    1107, loss: 0.1731318682432175, accuracy-micro: 0.7518169879913330, accuracy-macro: 0.0037000000011176\n",
      "step:    1108, loss: 0.1731252968311310, accuracy-micro: 0.7517882585525513, accuracy-macro: 0.0037000000011176\n",
      "step:    1109, loss: 0.1731191873550415, accuracy-micro: 0.7518322467803955, accuracy-macro: 0.0037000000011176\n",
      "step:    1110, loss: 0.1731128096580505, accuracy-micro: 0.7518154978752136, accuracy-macro: 0.0037000000011176\n",
      "step:    1111, loss: 0.1731065362691879, accuracy-micro: 0.7518342733383179, accuracy-macro: 0.0037000000011176\n",
      "step:    1112, loss: 0.1731002032756805, accuracy-micro: 0.7518547773361206, accuracy-macro: 0.0037000000011176\n",
      "step:    1113, loss: 0.1730943024158478, accuracy-micro: 0.7518684864044189, accuracy-macro: 0.0037000000011176\n",
      "step:    1114, loss: 0.1730880439281464, accuracy-micro: 0.7518882751464844, accuracy-macro: 0.0037000000011176\n",
      "step:    1115, loss: 0.1730831861495972, accuracy-micro: 0.7518757581710815, accuracy-macro: 0.0037000000011176\n",
      "step:    1116, loss: 0.1730779409408569, accuracy-micro: 0.7519069910049438, accuracy-macro: 0.0037000000011176\n",
      "step:    1117, loss: 0.1730730235576630, accuracy-micro: 0.7518597245216370, accuracy-macro: 0.0037000000011176\n",
      "step:    1118, loss: 0.1730695962905884, accuracy-micro: 0.7519519925117493, accuracy-macro: 0.0037000000011176\n",
      "step:    1119, loss: 0.1730670928955078, accuracy-micro: 0.7518559694290161, accuracy-macro: 0.0037000000011176\n",
      "step:    1120, loss: 0.1730653643608093, accuracy-micro: 0.7519887685775757, accuracy-macro: 0.0037000000011176\n",
      "step:    1121, loss: 0.1730650514364243, accuracy-micro: 0.7518407702445984, accuracy-macro: 0.0037000000011176\n",
      "step:    1122, loss: 0.1730685234069824, accuracy-micro: 0.7520300149917603, accuracy-macro: 0.0037000000011176\n",
      "step:    1123, loss: 0.1730741262435913, accuracy-micro: 0.7517794966697693, accuracy-macro: 0.0037000000011176\n",
      "step:    1124, loss: 0.1730822771787643, accuracy-micro: 0.7520269751548767, accuracy-macro: 0.0037000000011176\n",
      "step:    1125, loss: 0.1730906516313553, accuracy-micro: 0.7517110109329224, accuracy-macro: 0.0037000000011176\n",
      "step:    1126, loss: 0.1731003075838089, accuracy-micro: 0.7520080208778381, accuracy-macro: 0.0037000000011176\n",
      "step:    1127, loss: 0.1730957031250000, accuracy-micro: 0.7516804933547974, accuracy-macro: 0.0037000000011176\n",
      "step:    1128, loss: 0.1730878055095673, accuracy-micro: 0.7520204782485962, accuracy-macro: 0.0037000000011176\n",
      "step:    1129, loss: 0.1730664819478989, accuracy-micro: 0.7517549991607666, accuracy-macro: 0.0037000000011176\n",
      "step:    1130, loss: 0.1730436533689499, accuracy-micro: 0.7520995140075684, accuracy-macro: 0.0037000000011176\n",
      "step:    1131, loss: 0.1730150729417801, accuracy-micro: 0.7519177198410034, accuracy-macro: 0.0037000000011176\n",
      "step:    1132, loss: 0.1729932427406311, accuracy-micro: 0.7521077394485474, accuracy-macro: 0.0037000000011176\n",
      "step:    1133, loss: 0.1729810088872910, accuracy-micro: 0.7520689964294434, accuracy-macro: 0.0037000000011176\n",
      "step:    1134, loss: 0.1729787439107895, accuracy-micro: 0.7520272731781006, accuracy-macro: 0.0037000000011176\n",
      "step:    1135, loss: 0.1729825288057327, accuracy-micro: 0.7521537542343140, accuracy-macro: 0.0037000000011176\n",
      "step:    1136, loss: 0.1729846000671387, accuracy-micro: 0.7519599795341492, accuracy-macro: 0.0037000000011176\n",
      "step:    1137, loss: 0.1729835867881775, accuracy-micro: 0.7521845102310181, accuracy-macro: 0.0037000000011176\n",
      "step:    1138, loss: 0.1729763448238373, accuracy-micro: 0.7519745230674744, accuracy-macro: 0.0037000000011176\n",
      "step:    1139, loss: 0.1729658246040344, accuracy-micro: 0.7522284984588623, accuracy-macro: 0.0037000000011176\n",
      "step:    1140, loss: 0.1729535907506943, accuracy-micro: 0.7520545125007629, accuracy-macro: 0.0037000000011176\n",
      "step:    1141, loss: 0.1729420274496078, accuracy-micro: 0.7522117495536804, accuracy-macro: 0.0037000000011176\n",
      "step:    1142, loss: 0.1729323863983154, accuracy-micro: 0.7521430253982544, accuracy-macro: 0.0037000000011176\n",
      "step:    1143, loss: 0.1729261875152588, accuracy-micro: 0.7521790266036987, accuracy-macro: 0.0037000000011176\n",
      "step:    1144, loss: 0.1729234755039215, accuracy-micro: 0.7522234916687012, accuracy-macro: 0.0037000000011176\n",
      "step:    1145, loss: 0.1729239970445633, accuracy-micro: 0.7521337270736694, accuracy-macro: 0.0037000000011176\n",
      "step:    1146, loss: 0.1729248762130737, accuracy-micro: 0.7522687315940857, accuracy-macro: 0.0037000000011176\n",
      "step:    1147, loss: 0.1729235351085663, accuracy-micro: 0.7520777583122253, accuracy-macro: 0.0037000000011176\n",
      "step:    1148, loss: 0.1729167848825455, accuracy-micro: 0.7522777318954468, accuracy-macro: 0.0037000000011176\n",
      "step:    1149, loss: 0.1729049235582352, accuracy-micro: 0.7521212697029114, accuracy-macro: 0.0037000000011176\n",
      "step:    1150, loss: 0.1728927493095398, accuracy-micro: 0.7522825002670288, accuracy-macro: 0.0037000000011176\n",
      "step:    1151, loss: 0.1728827059268951, accuracy-micro: 0.7522322535514832, accuracy-macro: 0.0037000000011176\n",
      "step:    1152, loss: 0.1728773713111877, accuracy-micro: 0.7522502541542053, accuracy-macro: 0.0037000000011176\n",
      "step:    1153, loss: 0.1728745549917221, accuracy-micro: 0.7523210048675537, accuracy-macro: 0.0037000000011176\n",
      "step:    1154, loss: 0.1728726178407669, accuracy-micro: 0.7522277235984802, accuracy-macro: 0.0037000000011176\n",
      "step:    1155, loss: 0.1728706806898117, accuracy-micro: 0.7523344755172729, accuracy-macro: 0.0037000000011176\n",
      "step:    1156, loss: 0.1728671342134476, accuracy-micro: 0.7522084712982178, accuracy-macro: 0.0037000000011176\n",
      "step:    1157, loss: 0.1728619784116745, accuracy-micro: 0.7523589730262756, accuracy-macro: 0.0037000000011176\n",
      "step:    1158, loss: 0.1728540658950806, accuracy-micro: 0.7522295117378235, accuracy-macro: 0.0037000000011176\n",
      "step:    1159, loss: 0.1728462427854538, accuracy-micro: 0.7523612380027771, accuracy-macro: 0.0037000000011176\n",
      "step:    1160, loss: 0.1728371083736420, accuracy-micro: 0.7522900104522705, accuracy-macro: 0.0037000000011176\n",
      "step:    1161, loss: 0.1728291958570480, accuracy-micro: 0.7523760199546814, accuracy-macro: 0.0037000000011176\n",
      "step:    1162, loss: 0.1728236526250839, accuracy-micro: 0.7523767352104187, accuracy-macro: 0.0037000000011176\n",
      "step:    1163, loss: 0.1728191822767258, accuracy-micro: 0.7523344755172729, accuracy-macro: 0.0037000000011176\n",
      "step:    1164, loss: 0.1728145331144333, accuracy-micro: 0.7523992657661438, accuracy-macro: 0.0037000000011176\n",
      "step:    1165, loss: 0.1728108674287796, accuracy-micro: 0.7523217201232910, accuracy-macro: 0.0037000000011176\n",
      "step:    1166, loss: 0.1728048473596573, accuracy-micro: 0.7524154782295227, accuracy-macro: 0.0037000000011176\n",
      "step:    1167, loss: 0.1728000044822693, accuracy-micro: 0.7523310184478760, accuracy-macro: 0.0037000000011176\n",
      "step:    1168, loss: 0.1727941632270813, accuracy-micro: 0.7524359822273254, accuracy-macro: 0.0037000000011176\n",
      "step:    1169, loss: 0.1727889776229858, accuracy-micro: 0.7523664832115173, accuracy-macro: 0.0037000000011176\n",
      "step:    1170, loss: 0.1727834045886993, accuracy-micro: 0.7524669766426086, accuracy-macro: 0.0037000000011176\n",
      "step:    1171, loss: 0.1727770864963531, accuracy-micro: 0.7523922324180603, accuracy-macro: 0.0037000000011176\n",
      "step:    1172, loss: 0.1727717220783234, accuracy-micro: 0.7525022625923157, accuracy-macro: 0.0037000000011176\n",
      "step:    1173, loss: 0.1727658659219742, accuracy-micro: 0.7524394989013672, accuracy-macro: 0.0037000000011176\n",
      "step:    1174, loss: 0.1727608293294907, accuracy-micro: 0.7525079846382141, accuracy-macro: 0.0037000000011176\n",
      "step:    1175, loss: 0.1727554649114609, accuracy-micro: 0.7524497509002686, accuracy-macro: 0.0037000000011176\n",
      "step:    1176, loss: 0.1727503985166550, accuracy-micro: 0.7525337338447571, accuracy-macro: 0.0037000000011176\n",
      "step:    1177, loss: 0.1727455258369446, accuracy-micro: 0.7524455189704895, accuracy-macro: 0.0037000000011176\n",
      "step:    1178, loss: 0.1727401912212372, accuracy-micro: 0.7525447607040405, accuracy-macro: 0.0037000000011176\n",
      "step:    1179, loss: 0.1727354824542999, accuracy-micro: 0.7524537444114685, accuracy-macro: 0.0037000000011176\n",
      "step:    1180, loss: 0.1727311611175537, accuracy-micro: 0.7525720000267029, accuracy-macro: 0.0037000000011176\n",
      "step:    1181, loss: 0.1727257072925568, accuracy-micro: 0.7524775266647339, accuracy-macro: 0.0037000000011176\n",
      "step:    1182, loss: 0.1727205365896225, accuracy-micro: 0.7526012659072876, accuracy-macro: 0.0037000000011176\n",
      "step:    1183, loss: 0.1727139651775360, accuracy-micro: 0.7525097727775574, accuracy-macro: 0.0037000000011176\n",
      "step:    1184, loss: 0.1727084368467331, accuracy-micro: 0.7526082396507263, accuracy-macro: 0.0037000000011176\n",
      "step:    1185, loss: 0.1727032810449600, accuracy-micro: 0.7525207400321960, accuracy-macro: 0.0037000000011176\n",
      "step:    1186, loss: 0.1726980358362198, accuracy-micro: 0.7526012659072876, accuracy-macro: 0.0037000000011176\n",
      "step:    1187, loss: 0.1726924777030945, accuracy-micro: 0.7525657415390015, accuracy-macro: 0.0037000000011176\n",
      "step:    1188, loss: 0.1726870089769363, accuracy-micro: 0.7525967359542847, accuracy-macro: 0.0037000000011176\n",
      "step:    1189, loss: 0.1726825535297394, accuracy-micro: 0.7526292204856873, accuracy-macro: 0.0037000000011176\n",
      "step:    1190, loss: 0.1726777553558350, accuracy-micro: 0.7525960206985474, accuracy-macro: 0.0037000000011176\n",
      "step:    1191, loss: 0.1726724356412888, accuracy-micro: 0.7526594996452332, accuracy-macro: 0.0037000000011176\n",
      "step:    1192, loss: 0.1726677715778351, accuracy-micro: 0.7525807619094849, accuracy-macro: 0.0037000000011176\n",
      "step:    1193, loss: 0.1726626753807068, accuracy-micro: 0.7526594996452332, accuracy-macro: 0.0037000000011176\n",
      "step:    1194, loss: 0.1726577132940292, accuracy-micro: 0.7525977492332458, accuracy-macro: 0.0037000000011176\n",
      "step:    1195, loss: 0.1726532876491547, accuracy-micro: 0.7527147531509399, accuracy-macro: 0.0037000000011176\n",
      "step:    1196, loss: 0.1726492941379547, accuracy-micro: 0.7526040077209473, accuracy-macro: 0.0037000000011176\n",
      "step:    1197, loss: 0.1726446300745010, accuracy-micro: 0.7527244687080383, accuracy-macro: 0.0037000000011176\n",
      "step:    1198, loss: 0.1726391315460205, accuracy-micro: 0.7526212334632874, accuracy-macro: 0.0037000000011176\n",
      "step:    1199, loss: 0.1726333796977997, accuracy-micro: 0.7527362704277039, accuracy-macro: 0.0037000000011176\n",
      "step:    1200, loss: 0.1726280301809311, accuracy-micro: 0.7526397705078125, accuracy-macro: 0.0037000000011176\n",
      "step:    1201, loss: 0.1726229637861252, accuracy-micro: 0.7527444958686829, accuracy-macro: 0.0037000000011176\n",
      "step:    1202, loss: 0.1726177632808685, accuracy-micro: 0.7526639699935913, accuracy-macro: 0.0037000000011176\n",
      "step:    1203, loss: 0.1726131141185760, accuracy-micro: 0.7527602314949036, accuracy-macro: 0.0037000000011176\n",
      "step:    1204, loss: 0.1726095676422119, accuracy-micro: 0.7526452541351318, accuracy-macro: 0.0037000000011176\n",
      "step:    1205, loss: 0.1726065427064896, accuracy-micro: 0.7527882456779480, accuracy-macro: 0.0037000000011176\n",
      "step:    1206, loss: 0.1726036518812180, accuracy-micro: 0.7526737451553345, accuracy-macro: 0.0037000000011176\n",
      "step:    1207, loss: 0.1726026237010956, accuracy-micro: 0.7528667449951172, accuracy-macro: 0.0037000000011176\n",
      "step:    1208, loss: 0.1726039499044418, accuracy-micro: 0.7526419758796692, accuracy-macro: 0.0037000000011176\n",
      "step:    1209, loss: 0.1726083159446716, accuracy-micro: 0.7528312206268311, accuracy-macro: 0.0037000000011176\n",
      "step:    1210, loss: 0.1726131588220596, accuracy-micro: 0.7525927424430847, accuracy-macro: 0.0037000000011176\n",
      "step:    1211, loss: 0.1726167649030685, accuracy-micro: 0.7527917623519897, accuracy-macro: 0.0037000000011176\n",
      "step:    1212, loss: 0.1726119369268417, accuracy-micro: 0.7525830268859863, accuracy-macro: 0.0037000000011176\n",
      "step:    1213, loss: 0.1726065576076508, accuracy-micro: 0.7527972459793091, accuracy-macro: 0.0037000000011176\n",
      "step:    1214, loss: 0.1725962758064270, accuracy-micro: 0.7526242733001709, accuracy-macro: 0.0037000000011176\n",
      "step:    1215, loss: 0.1725845038890839, accuracy-micro: 0.7528612613677979, accuracy-macro: 0.0037000000011176\n",
      "step:    1216, loss: 0.1725690364837646, accuracy-micro: 0.7526915073394775, accuracy-macro: 0.0037000000011176\n",
      "step:    1217, loss: 0.1725536882877350, accuracy-micro: 0.7529302239418030, accuracy-macro: 0.0037000000011176\n",
      "step:    1218, loss: 0.1725409775972366, accuracy-micro: 0.7528175115585327, accuracy-macro: 0.0037000000011176\n",
      "step:    1219, loss: 0.1725314706563950, accuracy-micro: 0.7528715133666992, accuracy-macro: 0.0037000000011176\n",
      "step:    1220, loss: 0.1725246161222458, accuracy-micro: 0.7528510093688965, accuracy-macro: 0.0037000000011176\n",
      "step:    1221, loss: 0.1725205630064011, accuracy-micro: 0.7528722286224365, accuracy-macro: 0.0037000000011176\n",
      "step:    1222, loss: 0.1725164949893951, accuracy-micro: 0.7529115080833435, accuracy-macro: 0.0037000000011176\n",
      "step:    1223, loss: 0.1725129187107086, accuracy-micro: 0.7528247237205505, accuracy-macro: 0.0037000000011176\n",
      "step:    1224, loss: 0.1725088655948639, accuracy-micro: 0.7529237270355225, accuracy-macro: 0.0037000000011176\n",
      "step:    1225, loss: 0.1725037693977356, accuracy-micro: 0.7528622746467590, accuracy-macro: 0.0037000000011176\n",
      "step:    1226, loss: 0.1724979579448700, accuracy-micro: 0.7529137730598450, accuracy-macro: 0.0037000000011176\n",
      "step:    1227, loss: 0.1724924147129059, accuracy-micro: 0.7528560161590576, accuracy-macro: 0.0037000000011176\n",
      "step:    1228, loss: 0.1724862456321716, accuracy-micro: 0.7529444694519043, accuracy-macro: 0.0037000000011176\n",
      "step:    1229, loss: 0.1724805682897568, accuracy-micro: 0.7529069781303406, accuracy-macro: 0.0037000000011176\n",
      "step:    1230, loss: 0.1724755614995956, accuracy-micro: 0.7529622316360474, accuracy-macro: 0.0037000000011176\n",
      "step:    1231, loss: 0.1724702268838882, accuracy-micro: 0.7529507279396057, accuracy-macro: 0.0037000000011176\n",
      "step:    1232, loss: 0.1724649965763092, accuracy-micro: 0.7529687285423279, accuracy-macro: 0.0037000000011176\n",
      "step:    1233, loss: 0.1724604666233063, accuracy-micro: 0.7529875040054321, accuracy-macro: 0.0037000000011176\n",
      "step:    1234, loss: 0.1724559813737869, accuracy-micro: 0.7529529929161072, accuracy-macro: 0.0037000000011176\n",
      "step:    1235, loss: 0.1724513173103333, accuracy-micro: 0.7529990077018738, accuracy-macro: 0.0037000000011176\n",
      "step:    1236, loss: 0.1724460870027542, accuracy-micro: 0.7529634833335876, accuracy-macro: 0.0037000000011176\n",
      "step:    1237, loss: 0.1724415719509125, accuracy-micro: 0.7530530095100403, accuracy-macro: 0.0037000000011176\n",
      "step:    1238, loss: 0.1724367737770081, accuracy-micro: 0.7529634833335876, accuracy-macro: 0.0037000000011176\n",
      "step:    1239, loss: 0.1724313497543335, accuracy-micro: 0.7530419826507568, accuracy-macro: 0.0037000000011176\n",
      "step:    1240, loss: 0.1724257767200470, accuracy-micro: 0.7530155181884766, accuracy-macro: 0.0037000000011176\n",
      "step:    1241, loss: 0.1724211722612381, accuracy-micro: 0.7530099749565125, accuracy-macro: 0.0037000000011176\n",
      "step:    1242, loss: 0.1724171936511993, accuracy-micro: 0.7530627250671387, accuracy-macro: 0.0037000000011176\n",
      "step:    1243, loss: 0.1724136471748352, accuracy-micro: 0.7530062198638916, accuracy-macro: 0.0037000000011176\n",
      "step:    1244, loss: 0.1724115759134293, accuracy-micro: 0.7531024813652039, accuracy-macro: 0.0037000000011176\n",
      "step:    1245, loss: 0.1724093705415726, accuracy-micro: 0.7530182600021362, accuracy-macro: 0.0037000000011176\n",
      "step:    1246, loss: 0.1724082678556442, accuracy-micro: 0.7531104683876038, accuracy-macro: 0.0037000000011176\n",
      "step:    1247, loss: 0.1724079400300980, accuracy-micro: 0.7530390024185181, accuracy-macro: 0.0037000000011176\n",
      "step:    1248, loss: 0.1724094748497009, accuracy-micro: 0.7531167268753052, accuracy-macro: 0.0037000000011176\n",
      "step:    1249, loss: 0.1724103242158890, accuracy-micro: 0.7530242204666138, accuracy-macro: 0.0037000000011176\n",
      "step:    1250, loss: 0.1724127233028412, accuracy-micro: 0.7531325221061707, accuracy-macro: 0.0037000000011176\n",
      "step:    1251, loss: 0.1724129617214203, accuracy-micro: 0.7529617547988892, accuracy-macro: 0.0037000000011176\n",
      "step:    1252, loss: 0.1724105328321457, accuracy-micro: 0.7531149983406067, accuracy-macro: 0.0037000000011176\n",
      "step:    1253, loss: 0.1724017709493637, accuracy-micro: 0.7529914975166321, accuracy-macro: 0.0037000000011176\n",
      "step:    1254, loss: 0.1723919957876205, accuracy-micro: 0.7531542778015137, accuracy-macro: 0.0037000000011176\n",
      "step:    1255, loss: 0.1723793894052505, accuracy-micro: 0.7530779838562012, accuracy-macro: 0.0037000000011176\n",
      "step:    1256, loss: 0.1723674833774567, accuracy-micro: 0.7531579732894897, accuracy-macro: 0.0037000000011176\n",
      "step:    1257, loss: 0.1723550260066986, accuracy-micro: 0.7531164884567261, accuracy-macro: 0.0037000000011176\n",
      "step:    1258, loss: 0.1723445504903793, accuracy-micro: 0.7532062530517578, accuracy-macro: 0.0037000000011176\n",
      "step:    1259, loss: 0.1723354160785675, accuracy-micro: 0.7531625032424927, accuracy-macro: 0.0037000000011176\n",
      "step:    1260, loss: 0.1723287850618362, accuracy-micro: 0.7532282471656799, accuracy-macro: 0.0037000000011176\n",
      "step:    1261, loss: 0.1723249107599258, accuracy-micro: 0.7532332539558411, accuracy-macro: 0.0037000000011176\n",
      "step:    1262, loss: 0.1723223179578781, accuracy-micro: 0.7531585097312927, accuracy-macro: 0.0037000000011176\n",
      "step:    1263, loss: 0.1723203063011169, accuracy-micro: 0.7532405257225037, accuracy-macro: 0.0037000000011176\n",
      "step:    1264, loss: 0.1723175197839737, accuracy-micro: 0.7531912326812744, accuracy-macro: 0.0037000000011176\n",
      "step:    1265, loss: 0.1723146885633469, accuracy-micro: 0.7532550096511841, accuracy-macro: 0.0037000000011176\n",
      "step:    1266, loss: 0.1723107695579529, accuracy-micro: 0.7532037496566772, accuracy-macro: 0.0037000000011176\n",
      "step:    1267, loss: 0.1723056435585022, accuracy-micro: 0.7532772421836853, accuracy-macro: 0.0037000000011176\n",
      "step:    1268, loss: 0.1722990870475769, accuracy-micro: 0.7532219886779785, accuracy-macro: 0.0037000000011176\n",
      "step:    1269, loss: 0.1722922176122665, accuracy-micro: 0.7532882690429688, accuracy-macro: 0.0037000000011176\n",
      "step:    1270, loss: 0.1722851097583771, accuracy-micro: 0.7532234787940979, accuracy-macro: 0.0037000000011176\n",
      "step:    1271, loss: 0.1722784340381622, accuracy-micro: 0.7533000111579895, accuracy-macro: 0.0037000000011176\n",
      "step:    1272, loss: 0.1722725331783295, accuracy-micro: 0.7532722353935242, accuracy-macro: 0.0037000000011176\n",
      "step:    1273, loss: 0.1722669303417206, accuracy-micro: 0.7533050179481506, accuracy-macro: 0.0037000000011176\n",
      "step:    1274, loss: 0.1722636222839355, accuracy-micro: 0.7533437609672546, accuracy-macro: 0.0037000000011176\n",
      "step:    1275, loss: 0.1722609400749207, accuracy-micro: 0.7532847523689270, accuracy-macro: 0.0037000000011176\n",
      "step:    1276, loss: 0.1722578406333923, accuracy-micro: 0.7533540129661560, accuracy-macro: 0.0037000000011176\n",
      "step:    1277, loss: 0.1722545474767685, accuracy-micro: 0.7532937526702881, accuracy-macro: 0.0037000000011176\n",
      "step:    1278, loss: 0.1722499728202820, accuracy-micro: 0.7533674836158752, accuracy-macro: 0.0037000000011176\n",
      "step:    1279, loss: 0.1722459048032761, accuracy-micro: 0.7533119916915894, accuracy-macro: 0.0037000000011176\n",
      "step:    1280, loss: 0.1722419112920761, accuracy-micro: 0.7533965110778809, accuracy-macro: 0.0037000000011176\n",
      "step:    1281, loss: 0.1722383499145508, accuracy-micro: 0.7533320188522339, accuracy-macro: 0.0037000000011176\n",
      "step:    1282, loss: 0.1722346842288971, accuracy-micro: 0.7533802390098572, accuracy-macro: 0.0037000000011176\n",
      "step:    1283, loss: 0.1722302734851837, accuracy-micro: 0.7533452510833740, accuracy-macro: 0.0037000000011176\n",
      "step:    1284, loss: 0.1722249090671539, accuracy-micro: 0.7534034848213196, accuracy-macro: 0.0037000000011176\n",
      "step:    1285, loss: 0.1722191274166107, accuracy-micro: 0.7533735036849976, accuracy-macro: 0.0037000000011176\n",
      "step:    1286, loss: 0.1722123175859451, accuracy-micro: 0.7534224987030029, accuracy-macro: 0.0037000000011176\n",
      "step:    1287, loss: 0.1722063124179840, accuracy-micro: 0.7534042596817017, accuracy-macro: 0.0037000000011176\n",
      "step:    1288, loss: 0.1721998602151871, accuracy-micro: 0.7534212470054626, accuracy-macro: 0.0037000000011176\n",
      "step:    1289, loss: 0.1721942424774170, accuracy-micro: 0.7534365057945251, accuracy-macro: 0.0037000000011176\n",
      "step:    1290, loss: 0.1721890866756439, accuracy-micro: 0.7534534931182861, accuracy-macro: 0.0037000000011176\n",
      "step:    1291, loss: 0.1721843034029007, accuracy-micro: 0.7534645199775696, accuracy-macro: 0.0037000000011176\n",
      "step:    1292, loss: 0.1721789091825485, accuracy-micro: 0.7534777522087097, accuracy-macro: 0.0037000000011176\n",
      "step:    1293, loss: 0.1721744686365128, accuracy-micro: 0.7534915208816528, accuracy-macro: 0.0037000000011176\n",
      "step:    1294, loss: 0.1721695661544800, accuracy-micro: 0.7534959912300110, accuracy-macro: 0.0037000000011176\n",
      "step:    1295, loss: 0.1721649318933487, accuracy-micro: 0.7534742355346680, accuracy-macro: 0.0037000000011176\n",
      "step:    1296, loss: 0.1721605360507965, accuracy-micro: 0.7534970045089722, accuracy-macro: 0.0037000000011176\n",
      "step:    1297, loss: 0.1721566617488861, accuracy-micro: 0.7534955143928528, accuracy-macro: 0.0037000000011176\n",
      "step:    1298, loss: 0.1721535325050354, accuracy-micro: 0.7535127401351929, accuracy-macro: 0.0037000000011176\n",
      "step:    1299, loss: 0.1721515953540802, accuracy-micro: 0.7535294890403748, accuracy-macro: 0.0037000000011176\n",
      "step:    1300, loss: 0.1721509695053101, accuracy-micro: 0.7535022497177124, accuracy-macro: 0.0037000000011176\n",
      "step:    1301, loss: 0.1721532195806503, accuracy-micro: 0.7535575032234192, accuracy-macro: 0.0037000000011176\n",
      "step:    1302, loss: 0.1721550673246384, accuracy-micro: 0.7534557580947876, accuracy-macro: 0.0037000000011176\n",
      "step:    1303, loss: 0.1721584349870682, accuracy-micro: 0.7535622715950012, accuracy-macro: 0.0037000000011176\n",
      "step:    1304, loss: 0.1721605211496353, accuracy-micro: 0.7534402608871460, accuracy-macro: 0.0037000000011176\n",
      "step:    1305, loss: 0.1721644699573517, accuracy-micro: 0.7535967230796814, accuracy-macro: 0.0037000000011176\n",
      "step:    1306, loss: 0.1721647530794144, accuracy-micro: 0.7534267306327820, accuracy-macro: 0.0037000000011176\n",
      "step:    1307, loss: 0.1721635609865189, accuracy-micro: 0.7536004781723022, accuracy-macro: 0.0037000000011176\n",
      "step:    1308, loss: 0.1721540391445160, accuracy-micro: 0.7534447312355042, accuracy-macro: 0.0037000000011176\n",
      "step:    1309, loss: 0.1721410602331161, accuracy-micro: 0.7536192536354065, accuracy-macro: 0.0037000000011176\n",
      "step:    1310, loss: 0.1721233427524567, accuracy-micro: 0.7535102367401123, accuracy-macro: 0.0037000000011176\n",
      "step:    1311, loss: 0.1721064895391464, accuracy-micro: 0.7536395192146301, accuracy-macro: 0.0037000000011176\n",
      "step:    1312, loss: 0.1720921397209167, accuracy-micro: 0.7536194920539856, accuracy-macro: 0.0037000000011176\n",
      "step:    1313, loss: 0.1720824688673019, accuracy-micro: 0.7536537647247314, accuracy-macro: 0.0037000000011176\n",
      "step:    1314, loss: 0.1720790416002274, accuracy-micro: 0.7536479830741882, accuracy-macro: 0.0037000000011176\n",
      "step:    1315, loss: 0.1720782518386841, accuracy-micro: 0.7536454796791077, accuracy-macro: 0.0037000000011176\n",
      "step:    1316, loss: 0.1720784306526184, accuracy-micro: 0.7537065148353577, accuracy-macro: 0.0037000000011176\n",
      "step:    1317, loss: 0.1720768064260483, accuracy-micro: 0.7536399960517883, accuracy-macro: 0.0037000000011176\n",
      "step:    1318, loss: 0.1720732152462006, accuracy-micro: 0.7537127733230591, accuracy-macro: 0.0037000000011176\n",
      "step:    1319, loss: 0.1720672845840454, accuracy-micro: 0.7536494731903076, accuracy-macro: 0.0037000000011176\n",
      "step:    1320, loss: 0.1720603704452515, accuracy-micro: 0.7537034749984741, accuracy-macro: 0.0037000000011176\n",
      "step:    1321, loss: 0.1720517724752426, accuracy-micro: 0.7536795139312744, accuracy-macro: 0.0037000000011176\n",
      "step:    1322, loss: 0.1720443069934845, accuracy-micro: 0.7537272572517395, accuracy-macro: 0.0037000000011176\n",
      "step:    1323, loss: 0.1720377206802368, accuracy-micro: 0.7537467479705811, accuracy-macro: 0.0037000000011176\n",
      "step:    1324, loss: 0.1720332801342010, accuracy-micro: 0.7537612318992615, accuracy-macro: 0.0037000000011176\n",
      "step:    1325, loss: 0.1720305234193802, accuracy-micro: 0.7537714838981628, accuracy-macro: 0.0037000000011176\n",
      "step:    1326, loss: 0.1720288097858429, accuracy-micro: 0.7537392377853394, accuracy-macro: 0.0037000000011176\n",
      "step:    1327, loss: 0.1720290035009384, accuracy-micro: 0.7537840008735657, accuracy-macro: 0.0037000000011176\n",
      "step:    1328, loss: 0.1720277369022369, accuracy-micro: 0.7537437677383423, accuracy-macro: 0.0037000000011176\n",
      "step:    1329, loss: 0.1720253378152847, accuracy-micro: 0.7538017630577087, accuracy-macro: 0.0037000000011176\n",
      "step:    1330, loss: 0.1720212250947952, accuracy-micro: 0.7537717223167419, accuracy-macro: 0.0037000000011176\n",
      "step:    1331, loss: 0.1720152497291565, accuracy-micro: 0.7538077235221863, accuracy-macro: 0.0037000000011176\n",
      "step:    1332, loss: 0.1720082461833954, accuracy-micro: 0.7537785172462463, accuracy-macro: 0.0037000000011176\n",
      "step:    1333, loss: 0.1720014363527298, accuracy-micro: 0.7538362741470337, accuracy-macro: 0.0037000000011176\n",
      "step:    1334, loss: 0.1719941049814224, accuracy-micro: 0.7538095116615295, accuracy-macro: 0.0037000000011176\n",
      "step:    1335, loss: 0.1719874739646912, accuracy-micro: 0.7538262605667114, accuracy-macro: 0.0037000000011176\n",
      "step:    1336, loss: 0.1719807833433151, accuracy-micro: 0.7538604736328125, accuracy-macro: 0.0037000000011176\n",
      "step:    1337, loss: 0.1719752401113510, accuracy-micro: 0.7538682222366333, accuracy-macro: 0.0037000000011176\n",
      "step:    1338, loss: 0.1719713807106018, accuracy-micro: 0.7538787722587585, accuracy-macro: 0.0037000000011176\n",
      "step:    1339, loss: 0.1719680577516556, accuracy-micro: 0.7538794875144958, accuracy-macro: 0.0037000000011176\n",
      "step:    1340, loss: 0.1719651669263840, accuracy-micro: 0.7538757324218750, accuracy-macro: 0.0037000000011176\n",
      "step:    1341, loss: 0.1719633638858795, accuracy-micro: 0.7538524866104126, accuracy-macro: 0.0037000000011176\n",
      "step:    1342, loss: 0.1719619035720825, accuracy-micro: 0.7539112567901611, accuracy-macro: 0.0037000000011176\n",
      "step:    1343, loss: 0.1719621568918228, accuracy-micro: 0.7538637518882751, accuracy-macro: 0.0037000000011176\n",
      "step:    1344, loss: 0.1719643473625183, accuracy-micro: 0.7539287209510803, accuracy-macro: 0.0037000000011176\n",
      "step:    1345, loss: 0.1719669103622437, accuracy-micro: 0.7538292407989502, accuracy-macro: 0.0037000000011176\n",
      "step:    1346, loss: 0.1719665974378586, accuracy-micro: 0.7539215087890625, accuracy-macro: 0.0037000000011176\n",
      "step:    1347, loss: 0.1719592809677124, accuracy-micro: 0.7538292407989502, accuracy-macro: 0.0037000000011176\n",
      "step:    1348, loss: 0.1719488948583603, accuracy-micro: 0.7539544701576233, accuracy-macro: 0.0037000000011176\n",
      "step:    1349, loss: 0.1719371229410172, accuracy-micro: 0.7538955211639404, accuracy-macro: 0.0037000000011176\n",
      "step:    1350, loss: 0.1719264090061188, accuracy-micro: 0.7539722323417664, accuracy-macro: 0.0037000000011176\n",
      "step:    1351, loss: 0.1719183325767517, accuracy-micro: 0.7539479732513428, accuracy-macro: 0.0037000000011176\n",
      "step:    1352, loss: 0.1719114482402802, accuracy-micro: 0.7539860010147095, accuracy-macro: 0.0037000000011176\n",
      "step:    1353, loss: 0.1719057559967041, accuracy-micro: 0.7540032267570496, accuracy-macro: 0.0037000000011176\n",
      "step:    1354, loss: 0.1719015985727310, accuracy-micro: 0.7540274858474731, accuracy-macro: 0.0037000000011176\n",
      "step:    1355, loss: 0.1718999743461609, accuracy-micro: 0.7540277242660522, accuracy-macro: 0.0037000000011176\n",
      "step:    1356, loss: 0.1718982011079788, accuracy-micro: 0.7539994716644287, accuracy-macro: 0.0037000000011176\n",
      "step:    1357, loss: 0.1718979626893997, accuracy-micro: 0.7540182471275330, accuracy-macro: 0.0037000000011176\n",
      "step:    1358, loss: 0.1718994379043579, accuracy-micro: 0.7539625167846680, accuracy-macro: 0.0037000000011176\n",
      "step:    1359, loss: 0.1719006896018982, accuracy-micro: 0.7540637254714966, accuracy-macro: 0.0037000000011176\n",
      "step:    1360, loss: 0.1718983799219131, accuracy-micro: 0.7539550065994263, accuracy-macro: 0.0037000000011176\n",
      "step:    1361, loss: 0.1718933433294296, accuracy-micro: 0.7540907263755798, accuracy-macro: 0.0037000000011176\n",
      "step:    1362, loss: 0.1718845069408417, accuracy-micro: 0.7539962530136108, accuracy-macro: 0.0037000000011176\n",
      "step:    1363, loss: 0.1718749552965164, accuracy-micro: 0.7540877461433411, accuracy-macro: 0.0037000000011176\n",
      "step:    1364, loss: 0.1718646138906479, accuracy-micro: 0.7540439963340759, accuracy-macro: 0.0037000000011176\n",
      "step:    1365, loss: 0.1718566417694092, accuracy-micro: 0.7540777325630188, accuracy-macro: 0.0037000000011176\n",
      "step:    1366, loss: 0.1718502193689346, accuracy-micro: 0.7540997266769409, accuracy-macro: 0.0037000000011176\n",
      "step:    1367, loss: 0.1718463897705078, accuracy-micro: 0.7541000247001648, accuracy-macro: 0.0037000000011176\n",
      "step:    1368, loss: 0.1718456298112869, accuracy-micro: 0.7541239857673645, accuracy-macro: 0.0037000000011176\n",
      "step:    1369, loss: 0.1718462854623795, accuracy-micro: 0.7540807723999023, accuracy-macro: 0.0037000000011176\n",
      "step:    1370, loss: 0.1718460023403168, accuracy-micro: 0.7541425228118896, accuracy-macro: 0.0037000000011176\n",
      "step:    1371, loss: 0.1718431562185287, accuracy-micro: 0.7540657520294189, accuracy-macro: 0.0037000000011176\n",
      "step:    1372, loss: 0.1718393564224243, accuracy-micro: 0.7541637420654297, accuracy-macro: 0.0037000000011176\n",
      "step:    1373, loss: 0.1718345582485199, accuracy-micro: 0.7540825009346008, accuracy-macro: 0.0037000000011176\n",
      "step:    1374, loss: 0.1718271672725677, accuracy-micro: 0.7541700005531311, accuracy-macro: 0.0037000000011176\n",
      "step:    1375, loss: 0.1718189418315887, accuracy-micro: 0.7541145086288452, accuracy-macro: 0.0037000000011176\n",
      "step:    1376, loss: 0.1718116700649261, accuracy-micro: 0.7541992664337158, accuracy-macro: 0.0037000000011176\n",
      "step:    1377, loss: 0.1718047112226486, accuracy-micro: 0.7541769742965698, accuracy-macro: 0.0037000000011176\n",
      "step:    1378, loss: 0.1717996895313263, accuracy-micro: 0.7541802525520325, accuracy-macro: 0.0037000000011176\n",
      "step:    1379, loss: 0.1717951148748398, accuracy-micro: 0.7541842460632324, accuracy-macro: 0.0037000000011176\n",
      "step:    1380, loss: 0.1717916131019592, accuracy-micro: 0.7541872262954712, accuracy-macro: 0.0037000000011176\n",
      "step:    1381, loss: 0.1717889755964279, accuracy-micro: 0.7542114853858948, accuracy-macro: 0.0037000000011176\n",
      "step:    1382, loss: 0.1717864722013474, accuracy-micro: 0.7541617751121521, accuracy-macro: 0.0037000000011176\n",
      "step:    1383, loss: 0.1717842221260071, accuracy-micro: 0.7542610168457031, accuracy-macro: 0.0037000000011176\n",
      "step:    1384, loss: 0.1717815548181534, accuracy-micro: 0.7541712522506714, accuracy-macro: 0.0037000000011176\n",
      "step:    1385, loss: 0.1717781573534012, accuracy-micro: 0.7542642354965210, accuracy-macro: 0.0037000000011176\n",
      "step:    1386, loss: 0.1717728078365326, accuracy-micro: 0.7541689872741699, accuracy-macro: 0.0037000000011176\n",
      "step:    1387, loss: 0.1717670559883118, accuracy-micro: 0.7542937397956848, accuracy-macro: 0.0037000000011176\n",
      "step:    1388, loss: 0.1717611849308014, accuracy-micro: 0.7542315125465393, accuracy-macro: 0.0037000000011176\n",
      "step:    1389, loss: 0.1717553436756134, accuracy-micro: 0.7543052434921265, accuracy-macro: 0.0037000000011176\n",
      "step:    1390, loss: 0.1717500239610672, accuracy-micro: 0.7542639970779419, accuracy-macro: 0.0037000000011176\n",
      "step:    1391, loss: 0.1717445254325867, accuracy-micro: 0.7542905211448669, accuracy-macro: 0.0037000000011176\n",
      "step:    1392, loss: 0.1717403382062912, accuracy-micro: 0.7542945146560669, accuracy-macro: 0.0037000000011176\n",
      "step:    1393, loss: 0.1717360168695450, accuracy-micro: 0.7542877197265625, accuracy-macro: 0.0037000000011176\n",
      "step:    1394, loss: 0.1717329472303391, accuracy-micro: 0.7543432712554932, accuracy-macro: 0.0037000000011176\n",
      "step:    1395, loss: 0.1717303395271301, accuracy-micro: 0.7543187737464905, accuracy-macro: 0.0037000000011176\n",
      "step:    1396, loss: 0.1717283427715302, accuracy-micro: 0.7543592453002930, accuracy-macro: 0.0037000000011176\n",
      "step:    1397, loss: 0.1717261523008347, accuracy-micro: 0.7543010115623474, accuracy-macro: 0.0037000000011176\n",
      "step:    1398, loss: 0.1717236787080765, accuracy-micro: 0.7543690204620361, accuracy-macro: 0.0037000000011176\n",
      "step:    1399, loss: 0.1717194020748138, accuracy-micro: 0.7542922496795654, accuracy-macro: 0.0037000000011176\n",
      "step:    1400, loss: 0.1717152595520020, accuracy-micro: 0.7543845176696777, accuracy-macro: 0.0037000000011176\n",
      "step:    1401, loss: 0.1717099994421005, accuracy-micro: 0.7543244957923889, accuracy-macro: 0.0037000000011176\n",
      "step:    1402, loss: 0.1717050969600677, accuracy-micro: 0.7544022202491760, accuracy-macro: 0.0037000000011176\n",
      "step:    1403, loss: 0.1716999709606171, accuracy-micro: 0.7543562650680542, accuracy-macro: 0.0037000000011176\n",
      "step:    1404, loss: 0.1716945022344589, accuracy-micro: 0.7544332742691040, accuracy-macro: 0.0037000000011176\n",
      "step:    1405, loss: 0.1716907471418381, accuracy-micro: 0.7543709874153137, accuracy-macro: 0.0037000000011176\n",
      "step:    1406, loss: 0.1716869026422501, accuracy-micro: 0.7544429898262024, accuracy-macro: 0.0037000000011176\n",
      "step:    1407, loss: 0.1716829687356949, accuracy-micro: 0.7543762326240540, accuracy-macro: 0.0037000000011176\n",
      "step:    1408, loss: 0.1716784089803696, accuracy-micro: 0.7544812560081482, accuracy-macro: 0.0037000000011176\n",
      "step:    1409, loss: 0.1716732829809189, accuracy-micro: 0.7543895244598389, accuracy-macro: 0.0037000000011176\n",
      "step:    1410, loss: 0.1716684550046921, accuracy-micro: 0.7544800043106079, accuracy-macro: 0.0037000000011176\n",
      "step:    1411, loss: 0.1716635972261429, accuracy-micro: 0.7544205188751221, accuracy-macro: 0.0037000000011176\n",
      "step:    1412, loss: 0.1716586798429489, accuracy-micro: 0.7544967532157898, accuracy-macro: 0.0037000000011176\n",
      "step:    1413, loss: 0.1716537773609161, accuracy-micro: 0.7544804811477661, accuracy-macro: 0.0037000000011176\n",
      "step:    1414, loss: 0.1716507375240326, accuracy-micro: 0.7544580101966858, accuracy-macro: 0.0037000000011176\n",
      "step:    1415, loss: 0.1716491281986237, accuracy-micro: 0.7545347213745117, accuracy-macro: 0.0037000000011176\n",
      "step:    1416, loss: 0.1716501265764236, accuracy-micro: 0.7544015049934387, accuracy-macro: 0.0037000000011176\n",
      "step:    1417, loss: 0.1716555655002594, accuracy-micro: 0.7545310258865356, accuracy-macro: 0.0037000000011176\n",
      "step:    1418, loss: 0.1716621816158295, accuracy-micro: 0.7543594837188721, accuracy-macro: 0.0037000000011176\n",
      "step:    1419, loss: 0.1716709434986115, accuracy-micro: 0.7545147538185120, accuracy-macro: 0.0037000000011176\n",
      "step:    1420, loss: 0.1716752946376801, accuracy-micro: 0.7542999982833862, accuracy-macro: 0.0037000000011176\n",
      "step:    1421, loss: 0.1716790944337845, accuracy-micro: 0.7545352578163147, accuracy-macro: 0.0037000000011176\n",
      "step:    1422, loss: 0.1716743111610413, accuracy-micro: 0.7542784810066223, accuracy-macro: 0.0037000000011176\n",
      "step:    1423, loss: 0.1716648787260056, accuracy-micro: 0.7545499801635742, accuracy-macro: 0.0037000000011176\n",
      "step:    1424, loss: 0.1716499626636505, accuracy-micro: 0.7543572187423706, accuracy-macro: 0.0037000000011176\n",
      "step:    1425, loss: 0.1716325730085373, accuracy-micro: 0.7545760273933411, accuracy-macro: 0.0037000000011176\n",
      "step:    1426, loss: 0.1716150492429733, accuracy-micro: 0.7544580101966858, accuracy-macro: 0.0037000000011176\n",
      "step:    1427, loss: 0.1716025024652481, accuracy-micro: 0.7546072602272034, accuracy-macro: 0.0037000000011176\n",
      "step:    1428, loss: 0.1715946644544601, accuracy-micro: 0.7545822262763977, accuracy-macro: 0.0037000000011176\n",
      "step:    1429, loss: 0.1715894639492035, accuracy-micro: 0.7546064853668213, accuracy-macro: 0.0037000000011176\n",
      "step:    1430, loss: 0.1715864539146423, accuracy-micro: 0.7546190023422241, accuracy-macro: 0.0037000000011176\n",
      "step:    1431, loss: 0.1715838462114334, accuracy-micro: 0.7545647621154785, accuracy-macro: 0.0037000000011176\n",
      "step:    1432, loss: 0.1715804636478424, accuracy-micro: 0.7546585202217102, accuracy-macro: 0.0037000000011176\n",
      "step:    1433, loss: 0.1715780943632126, accuracy-micro: 0.7545710206031799, accuracy-macro: 0.0037000000011176\n",
      "step:    1434, loss: 0.1715757399797440, accuracy-micro: 0.7546715140342712, accuracy-macro: 0.0037000000011176\n",
      "step:    1435, loss: 0.1715723723173141, accuracy-micro: 0.7545782327651978, accuracy-macro: 0.0037000000011176\n",
      "step:    1436, loss: 0.1715672463178635, accuracy-micro: 0.7546709775924683, accuracy-macro: 0.0037000000011176\n",
      "step:    1437, loss: 0.1715622842311859, accuracy-micro: 0.7545924782752991, accuracy-macro: 0.0037000000011176\n",
      "step:    1438, loss: 0.1715569794178009, accuracy-micro: 0.7546889781951904, accuracy-macro: 0.0037000000011176\n",
      "step:    1439, loss: 0.1715514063835144, accuracy-micro: 0.7546125054359436, accuracy-macro: 0.0037000000011176\n",
      "step:    1440, loss: 0.1715468168258667, accuracy-micro: 0.7547104954719543, accuracy-macro: 0.0037000000011176\n",
      "step:    1441, loss: 0.1715420037508011, accuracy-micro: 0.7546859979629517, accuracy-macro: 0.0037000000011176\n",
      "step:    1442, loss: 0.1715383380651474, accuracy-micro: 0.7546772360801697, accuracy-macro: 0.0037000000011176\n",
      "step:    1443, loss: 0.1715349704027176, accuracy-micro: 0.7547392249107361, accuracy-macro: 0.0037000000011176\n",
      "step:    1444, loss: 0.1715324372053146, accuracy-micro: 0.7546644806861877, accuracy-macro: 0.0037000000011176\n",
      "step:    1445, loss: 0.1715288758277893, accuracy-micro: 0.7547259926795959, accuracy-macro: 0.0037000000011176\n",
      "step:    1446, loss: 0.1715249121189117, accuracy-micro: 0.7546709775924683, accuracy-macro: 0.0037000000011176\n",
      "step:    1447, loss: 0.1715204715728760, accuracy-micro: 0.7547515034675598, accuracy-macro: 0.0037000000011176\n",
      "step:    1448, loss: 0.1715149730443954, accuracy-micro: 0.7547057271003723, accuracy-macro: 0.0037000000011176\n",
      "step:    1449, loss: 0.1715105324983597, accuracy-micro: 0.7547644972801208, accuracy-macro: 0.0037000000011176\n",
      "step:    1450, loss: 0.1715067476034164, accuracy-micro: 0.7547615170478821, accuracy-macro: 0.0037000000011176\n",
      "step:    1451, loss: 0.1715029925107956, accuracy-micro: 0.7547295093536377, accuracy-macro: 0.0037000000011176\n",
      "step:    1452, loss: 0.1715000718832016, accuracy-micro: 0.7547649741172791, accuracy-macro: 0.0037000000011176\n",
      "step:    1453, loss: 0.1714965552091599, accuracy-micro: 0.7547374963760376, accuracy-macro: 0.0037000000011176\n",
      "step:    1454, loss: 0.1714920252561569, accuracy-micro: 0.7547682523727417, accuracy-macro: 0.0037000000011176\n",
      "step:    1455, loss: 0.1714874356985092, accuracy-micro: 0.7547730207443237, accuracy-macro: 0.0037000000011176\n",
      "step:    1456, loss: 0.1714832186698914, accuracy-micro: 0.7548012733459473, accuracy-macro: 0.0037000000011176\n",
      "step:    1457, loss: 0.1714785993099213, accuracy-micro: 0.7548017501831055, accuracy-macro: 0.0037000000011176\n",
      "step:    1458, loss: 0.1714754253625870, accuracy-micro: 0.7547950148582458, accuracy-macro: 0.0037000000011176\n",
      "step:    1459, loss: 0.1714718788862228, accuracy-micro: 0.7548059821128845, accuracy-macro: 0.0037000000011176\n",
      "step:    1460, loss: 0.1714676916599274, accuracy-micro: 0.7548077702522278, accuracy-macro: 0.0037000000011176\n",
      "step:    1461, loss: 0.1714636534452438, accuracy-micro: 0.7548254728317261, accuracy-macro: 0.0037000000011176\n",
      "step:    1462, loss: 0.1714600473642349, accuracy-micro: 0.7548490166664124, accuracy-macro: 0.0037000000011176\n",
      "step:    1463, loss: 0.1714562624692917, accuracy-micro: 0.7548429965972900, accuracy-macro: 0.0037000000011176\n",
      "step:    1464, loss: 0.1714523285627365, accuracy-micro: 0.7548534870147705, accuracy-macro: 0.0037000000011176\n",
      "step:    1465, loss: 0.1714487820863724, accuracy-micro: 0.7548289895057678, accuracy-macro: 0.0037000000011176\n",
      "step:    1466, loss: 0.1714451909065247, accuracy-micro: 0.7548645138740540, accuracy-macro: 0.0037000000011176\n",
      "step:    1467, loss: 0.1714417636394501, accuracy-micro: 0.7548632621765137, accuracy-macro: 0.0037000000011176\n",
      "step:    1468, loss: 0.1714370399713516, accuracy-micro: 0.7548952698707581, accuracy-macro: 0.0037000000011176\n",
      "step:    1469, loss: 0.1714324653148651, accuracy-micro: 0.7548637390136719, accuracy-macro: 0.0037000000011176\n",
      "step:    1470, loss: 0.1714280247688293, accuracy-micro: 0.7548822760581970, accuracy-macro: 0.0037000000011176\n",
      "step:    1471, loss: 0.1714242547750473, accuracy-micro: 0.7548900246620178, accuracy-macro: 0.0037000000011176\n",
      "step:    1472, loss: 0.1714215278625488, accuracy-micro: 0.7548737525939941, accuracy-macro: 0.0037000000011176\n",
      "step:    1473, loss: 0.1714188605546951, accuracy-micro: 0.7549045085906982, accuracy-macro: 0.0037000000011176\n",
      "step:    1474, loss: 0.1714160144329071, accuracy-micro: 0.7548829913139343, accuracy-macro: 0.0037000000011176\n",
      "step:    1475, loss: 0.1714142560958862, accuracy-micro: 0.7549329996109009, accuracy-macro: 0.0037000000011176\n",
      "step:    1476, loss: 0.1714152842760086, accuracy-micro: 0.7548850178718567, accuracy-macro: 0.0037000000011176\n",
      "step:    1477, loss: 0.1714175939559937, accuracy-micro: 0.7549394965171814, accuracy-macro: 0.0037000000011176\n",
      "step:    1478, loss: 0.1714204102754593, accuracy-micro: 0.7547755241394043, accuracy-macro: 0.0037000000011176\n",
      "step:    1479, loss: 0.1714236587285995, accuracy-micro: 0.7549507617950439, accuracy-macro: 0.0037000000011176\n",
      "step:    1480, loss: 0.1714258342981339, accuracy-micro: 0.7547332644462585, accuracy-macro: 0.0037000000011176\n",
      "step:    1481, loss: 0.1714286357164383, accuracy-micro: 0.7549644708633423, accuracy-macro: 0.0037000000011176\n",
      "step:    1482, loss: 0.1714293062686920, accuracy-micro: 0.7547184824943542, accuracy-macro: 0.0037000000011176\n",
      "step:    1483, loss: 0.1714296489953995, accuracy-micro: 0.7549392580986023, accuracy-macro: 0.0037000000011176\n",
      "step:    1484, loss: 0.1714223772287369, accuracy-micro: 0.7547232508659363, accuracy-macro: 0.0037000000011176\n",
      "step:    1485, loss: 0.1714163571596146, accuracy-micro: 0.7549729943275452, accuracy-macro: 0.0037000000011176\n",
      "step:    1486, loss: 0.1714054495096207, accuracy-micro: 0.7547600269317627, accuracy-macro: 0.0037000000011176\n",
      "step:    1487, loss: 0.1713947206735611, accuracy-micro: 0.7550069689750671, accuracy-macro: 0.0037000000011176\n",
      "step:    1488, loss: 0.1713807433843613, accuracy-micro: 0.7548900246620178, accuracy-macro: 0.0037000000011176\n",
      "step:    1489, loss: 0.1713668256998062, accuracy-micro: 0.7550259828567505, accuracy-macro: 0.0037000000011176\n",
      "step:    1490, loss: 0.1713555008172989, accuracy-micro: 0.7549884915351868, accuracy-macro: 0.0037000000011176\n",
      "step:    1491, loss: 0.1713480651378632, accuracy-micro: 0.7550157308578491, accuracy-macro: 0.0037000000011176\n",
      "step:    1492, loss: 0.1713442504405975, accuracy-micro: 0.7550462484359741, accuracy-macro: 0.0037000000011176\n",
      "step:    1493, loss: 0.1713431775569916, accuracy-micro: 0.7550050020217896, accuracy-macro: 0.0037000000011176\n",
      "step:    1494, loss: 0.1713440865278244, accuracy-micro: 0.7550464868545532, accuracy-macro: 0.0037000000011176\n",
      "step:    1495, loss: 0.1713436990976334, accuracy-micro: 0.7550017237663269, accuracy-macro: 0.0037000000011176\n",
      "step:    1496, loss: 0.1713434010744095, accuracy-micro: 0.7550640106201172, accuracy-macro: 0.0037000000011176\n",
      "step:    1497, loss: 0.1713401079177856, accuracy-micro: 0.7549664974212646, accuracy-macro: 0.0037000000011176\n",
      "step:    1498, loss: 0.1713349074125290, accuracy-micro: 0.7550920248031616, accuracy-macro: 0.0037000000011176\n",
      "step:    1499, loss: 0.1713274121284485, accuracy-micro: 0.7550287246704102, accuracy-macro: 0.0037000000011176\n",
      "step:    1500, loss: 0.1713190972805023, accuracy-micro: 0.7550992369651794, accuracy-macro: 0.0037000000011176\n",
      "step:    1501, loss: 0.1713124066591263, accuracy-micro: 0.7550577521324158, accuracy-macro: 0.0037000000011176\n",
      "step:    1502, loss: 0.1713064908981323, accuracy-micro: 0.7551000118255615, accuracy-macro: 0.0037000000011176\n",
      "step:    1503, loss: 0.1713026314973831, accuracy-micro: 0.7551000118255615, accuracy-macro: 0.0037000000011176\n",
      "step:    1504, loss: 0.1712997555732727, accuracy-micro: 0.7550927400588989, accuracy-macro: 0.0037000000011176\n",
      "step:    1505, loss: 0.1712978780269623, accuracy-micro: 0.7551077604293823, accuracy-macro: 0.0037000000011176\n",
      "step:    1506, loss: 0.1712960898876190, accuracy-micro: 0.7550827264785767, accuracy-macro: 0.0037000000011176\n",
      "step:    1507, loss: 0.1712942868471146, accuracy-micro: 0.7551410198211670, accuracy-macro: 0.0037000000011176\n",
      "step:    1508, loss: 0.1712918430566788, accuracy-micro: 0.7551075220108032, accuracy-macro: 0.0037000000011176\n",
      "step:    1509, loss: 0.1712886393070221, accuracy-micro: 0.7551580071449280, accuracy-macro: 0.0037000000011176\n",
      "step:    1510, loss: 0.1712847203016281, accuracy-micro: 0.7550957202911377, accuracy-macro: 0.0037000000011176\n",
      "step:    1511, loss: 0.1712812185287476, accuracy-micro: 0.7551567554473877, accuracy-macro: 0.0037000000011176\n",
      "step:    1512, loss: 0.1712771058082581, accuracy-micro: 0.7551029920578003, accuracy-macro: 0.0037000000011176\n",
      "step:    1513, loss: 0.1712721288204193, accuracy-micro: 0.7551680207252502, accuracy-macro: 0.0037000000011176\n",
      "step:    1514, loss: 0.1712662130594254, accuracy-micro: 0.7551332712173462, accuracy-macro: 0.0037000000011176\n",
      "step:    1515, loss: 0.1712607592344284, accuracy-micro: 0.7551532387733459, accuracy-macro: 0.0037000000011176\n",
      "step:    1516, loss: 0.1712552458047867, accuracy-micro: 0.7551452517509460, accuracy-macro: 0.0037000000011176\n",
      "step:    1517, loss: 0.1712508499622345, accuracy-micro: 0.7551572322845459, accuracy-macro: 0.0037000000011176\n",
      "step:    1518, loss: 0.1712469756603241, accuracy-micro: 0.7551565170288086, accuracy-macro: 0.0037000000011176\n",
      "step:    1519, loss: 0.1712435036897659, accuracy-micro: 0.7551599740982056, accuracy-macro: 0.0037000000011176\n",
      "step:    1520, loss: 0.1712406426668167, accuracy-micro: 0.7551689743995667, accuracy-macro: 0.0037000000011176\n",
      "step:    1521, loss: 0.1712374836206436, accuracy-micro: 0.7551747560501099, accuracy-macro: 0.0037000000011176\n",
      "step:    1522, loss: 0.1712335944175720, accuracy-micro: 0.7552102208137512, accuracy-macro: 0.0037000000011176\n",
      "step:    1523, loss: 0.1712302565574646, accuracy-micro: 0.7551829814910889, accuracy-macro: 0.0037000000011176\n",
      "step:    1524, loss: 0.1712265610694885, accuracy-micro: 0.7552245259284973, accuracy-macro: 0.0037000000011176\n",
      "step:    1525, loss: 0.1712229102849960, accuracy-micro: 0.7551944851875305, accuracy-macro: 0.0037000000011176\n",
      "step:    1526, loss: 0.1712189614772797, accuracy-micro: 0.7552142739295959, accuracy-macro: 0.0037000000011176\n",
      "step:    1527, loss: 0.1712150424718857, accuracy-micro: 0.7551812529563904, accuracy-macro: 0.0037000000011176\n",
      "step:    1528, loss: 0.1712116301059723, accuracy-micro: 0.7552437186241150, accuracy-macro: 0.0037000000011176\n",
      "step:    1529, loss: 0.1712093055248260, accuracy-micro: 0.7551980018615723, accuracy-macro: 0.0037000000011176\n",
      "step:    1530, loss: 0.1712055504322052, accuracy-micro: 0.7552747726440430, accuracy-macro: 0.0037000000011176\n",
      "step:    1531, loss: 0.1712017804384232, accuracy-micro: 0.7552232742309570, accuracy-macro: 0.0037000000011176\n",
      "step:    1532, loss: 0.1711982190608978, accuracy-micro: 0.7552842497825623, accuracy-macro: 0.0037000000011176\n",
      "step:    1533, loss: 0.1711945235729218, accuracy-micro: 0.7552232742309570, accuracy-macro: 0.0037000000011176\n",
      "step:    1534, loss: 0.1711904406547546, accuracy-micro: 0.7552970051765442, accuracy-macro: 0.0037000000011176\n",
      "step:    1535, loss: 0.1711866557598114, accuracy-micro: 0.7552567720413208, accuracy-macro: 0.0037000000011176\n",
      "step:    1536, loss: 0.1711842864751816, accuracy-micro: 0.7553309798240662, accuracy-macro: 0.0037000000011176\n",
      "step:    1537, loss: 0.1711811870336533, accuracy-micro: 0.7552557587623596, accuracy-macro: 0.0037000000011176\n",
      "step:    1538, loss: 0.1711777448654175, accuracy-micro: 0.7553434967994690, accuracy-macro: 0.0037000000011176\n",
      "step:    1539, loss: 0.1711747199296951, accuracy-micro: 0.7552750110626221, accuracy-macro: 0.0037000000011176\n",
      "step:    1540, loss: 0.1711703687906265, accuracy-micro: 0.7553474903106689, accuracy-macro: 0.0037000000011176\n",
      "step:    1541, loss: 0.1711665987968445, accuracy-micro: 0.7552880048751831, accuracy-macro: 0.0037000000011176\n",
      "step:    1542, loss: 0.1711636185646057, accuracy-micro: 0.7553774714469910, accuracy-macro: 0.0037000000011176\n",
      "step:    1543, loss: 0.1711602807044983, accuracy-micro: 0.7553072571754456, accuracy-macro: 0.0037000000011176\n",
      "step:    1544, loss: 0.1711565256118774, accuracy-micro: 0.7553929686546326, accuracy-macro: 0.0037000000011176\n",
      "step:    1545, loss: 0.1711540520191193, accuracy-micro: 0.7553344964981079, accuracy-macro: 0.0037000000011176\n",
      "step:    1546, loss: 0.1711501628160477, accuracy-micro: 0.7554129958152771, accuracy-macro: 0.0037000000011176\n",
      "step:    1547, loss: 0.1711462438106537, accuracy-micro: 0.7553352713584900, accuracy-macro: 0.0037000000011176\n",
      "step:    1548, loss: 0.1711429059505463, accuracy-micro: 0.7554132342338562, accuracy-macro: 0.0037000000011176\n",
      "step:    1549, loss: 0.1711392253637314, accuracy-micro: 0.7553487420082092, accuracy-macro: 0.0037000000011176\n",
      "step:    1550, loss: 0.1711355596780777, accuracy-micro: 0.7554312348365784, accuracy-macro: 0.0037000000011176\n",
      "step:    1551, loss: 0.1711309105157852, accuracy-micro: 0.7553657293319702, accuracy-macro: 0.0037000000011176\n",
      "step:    1552, loss: 0.1711264848709106, accuracy-micro: 0.7554382681846619, accuracy-macro: 0.0037000000011176\n",
      "step:    1553, loss: 0.1711223423480988, accuracy-micro: 0.7553757429122925, accuracy-macro: 0.0037000000011176\n",
      "step:    1554, loss: 0.1711188703775406, accuracy-micro: 0.7554572224617004, accuracy-macro: 0.0037000000011176\n",
      "step:    1555, loss: 0.1711148321628571, accuracy-micro: 0.7553839683532715, accuracy-macro: 0.0037000000011176\n",
      "step:    1556, loss: 0.1711115688085556, accuracy-micro: 0.7554870247840881, accuracy-macro: 0.0037000000011176\n",
      "step:    1557, loss: 0.1711079627275467, accuracy-micro: 0.7554067373275757, accuracy-macro: 0.0037000000011176\n",
      "step:    1558, loss: 0.1711049675941467, accuracy-micro: 0.7555077672004700, accuracy-macro: 0.0037000000011176\n",
      "step:    1559, loss: 0.1711028367280960, accuracy-micro: 0.7554115056991577, accuracy-macro: 0.0037000000011176\n",
      "step:    1560, loss: 0.1711006909608841, accuracy-micro: 0.7554929852485657, accuracy-macro: 0.0037000000011176\n",
      "step:    1561, loss: 0.1710979044437408, accuracy-micro: 0.7554112672805786, accuracy-macro: 0.0037000000011176\n",
      "step:    1562, loss: 0.1710970550775528, accuracy-micro: 0.7555170059204102, accuracy-macro: 0.0037000000011176\n",
      "step:    1563, loss: 0.1710967272520065, accuracy-micro: 0.7554202675819397, accuracy-macro: 0.0037000000011176\n",
      "step:    1564, loss: 0.1710980683565140, accuracy-micro: 0.7555037736892700, accuracy-macro: 0.0037000000011176\n",
      "step:    1565, loss: 0.1710995286703110, accuracy-micro: 0.7554072737693787, accuracy-macro: 0.0037000000011176\n",
      "step:    1566, loss: 0.1711030602455139, accuracy-micro: 0.7555164694786072, accuracy-macro: 0.0037000000011176\n",
      "step:    1567, loss: 0.1711072474718094, accuracy-micro: 0.7554035186767578, accuracy-macro: 0.0037000000011176\n",
      "step:    1568, loss: 0.1711125671863556, accuracy-micro: 0.7555434703826904, accuracy-macro: 0.0037000000011176\n",
      "step:    1569, loss: 0.1711108684539795, accuracy-micro: 0.7553702592849731, accuracy-macro: 0.0037000000011176\n",
      "step:    1570, loss: 0.1711061894893646, accuracy-micro: 0.7555537223815918, accuracy-macro: 0.0037000000011176\n",
      "step:    1571, loss: 0.1710940301418304, accuracy-micro: 0.7554244995117188, accuracy-macro: 0.0037000000011176\n",
      "step:    1572, loss: 0.1710819154977798, accuracy-micro: 0.7555699944496155, accuracy-macro: 0.0037000000011176\n",
      "step:    1573, loss: 0.1710682064294815, accuracy-micro: 0.7554732561111450, accuracy-macro: 0.0037000000011176\n",
      "step:    1574, loss: 0.1710556298494339, accuracy-micro: 0.7555652260780334, accuracy-macro: 0.0037000000011176\n",
      "step:    1575, loss: 0.1710457205772400, accuracy-micro: 0.7555282711982727, accuracy-macro: 0.0037000000011176\n",
      "step:    1576, loss: 0.1710396260023117, accuracy-micro: 0.7555699944496155, accuracy-macro: 0.0037000000011176\n",
      "step:    1577, loss: 0.1710382848978043, accuracy-micro: 0.7555947303771973, accuracy-macro: 0.0037000000011176\n",
      "step:    1578, loss: 0.1710385978221893, accuracy-micro: 0.7555299997329712, accuracy-macro: 0.0037000000011176\n",
      "step:    1579, loss: 0.1710393428802490, accuracy-micro: 0.7556017637252808, accuracy-macro: 0.0037000000011176\n",
      "step:    1580, loss: 0.1710409075021744, accuracy-micro: 0.7554892301559448, accuracy-macro: 0.0037000000011176\n",
      "step:    1581, loss: 0.1710402965545654, accuracy-micro: 0.7556297183036804, accuracy-macro: 0.0037000000011176\n",
      "step:    1582, loss: 0.1710352301597595, accuracy-micro: 0.7555220127105713, accuracy-macro: 0.0037000000011176\n",
      "step:    1583, loss: 0.1710305809974670, accuracy-micro: 0.7556357383728027, accuracy-macro: 0.0037000000011176\n",
      "step:    1584, loss: 0.1710251420736313, accuracy-micro: 0.7555427551269531, accuracy-macro: 0.0037000000011176\n",
      "step:    1585, loss: 0.1710202097892761, accuracy-micro: 0.7556380033493042, accuracy-macro: 0.0037000000011176\n",
      "step:    1586, loss: 0.1710151731967926, accuracy-micro: 0.7555670142173767, accuracy-macro: 0.0037000000011176\n",
      "step:    1587, loss: 0.1710097640752792, accuracy-micro: 0.7556507587432861, accuracy-macro: 0.0037000000011176\n",
      "step:    1588, loss: 0.1710014641284943, accuracy-micro: 0.7556099891662598, accuracy-macro: 0.0037000000011176\n",
      "step:    1589, loss: 0.1709958612918854, accuracy-micro: 0.7556595206260681, accuracy-macro: 0.0037000000011176\n",
      "step:    1590, loss: 0.1709925979375839, accuracy-micro: 0.7556642293930054, accuracy-macro: 0.0037000000011176\n",
      "step:    1591, loss: 0.1709894984960556, accuracy-micro: 0.7556589841842651, accuracy-macro: 0.0037000000011176\n",
      "step:    1592, loss: 0.1709864437580109, accuracy-micro: 0.7556689977645874, accuracy-macro: 0.0037000000011176\n",
      "step:    1593, loss: 0.1709840744733810, accuracy-micro: 0.7556474804878235, accuracy-macro: 0.0037000000011176\n",
      "step:    1594, loss: 0.1709818989038467, accuracy-micro: 0.7557049989700317, accuracy-macro: 0.0037000000011176\n",
      "step:    1595, loss: 0.1709813922643661, accuracy-micro: 0.7556357383728027, accuracy-macro: 0.0037000000011176\n",
      "step:    1596, loss: 0.1709794998168945, accuracy-micro: 0.7557207345962524, accuracy-macro: 0.0037000000011176\n",
      "step:    1597, loss: 0.1709766536951065, accuracy-micro: 0.7556787729263306, accuracy-macro: 0.0037000000011176\n",
      "step:    1598, loss: 0.1709730178117752, accuracy-micro: 0.7557307481765747, accuracy-macro: 0.0037000000011176\n",
      "step:    1599, loss: 0.1709690690040588, accuracy-micro: 0.7556890249252319, accuracy-macro: 0.0037000000011176\n",
      "step:    1600, loss: 0.1709651798009872, accuracy-micro: 0.7557359933853149, accuracy-macro: 0.0037000000011176\n",
      "step:    1601, loss: 0.1709599643945694, accuracy-micro: 0.7556985020637512, accuracy-macro: 0.0037000000011176\n",
      "step:    1602, loss: 0.1709556430578232, accuracy-micro: 0.7557269930839539, accuracy-macro: 0.0037000000011176\n",
      "step:    1603, loss: 0.1709517538547516, accuracy-micro: 0.7557229995727539, accuracy-macro: 0.0037000000011176\n",
      "step:    1604, loss: 0.1709480285644531, accuracy-micro: 0.7557529807090759, accuracy-macro: 0.0037000000011176\n",
      "step:    1605, loss: 0.1709430515766144, accuracy-micro: 0.7557417750358582, accuracy-macro: 0.0037000000011176\n",
      "step:    1606, loss: 0.1709384620189667, accuracy-micro: 0.7557502388954163, accuracy-macro: 0.0037000000011176\n",
      "step:    1607, loss: 0.1709353774785995, accuracy-micro: 0.7557669878005981, accuracy-macro: 0.0037000000011176\n",
      "step:    1608, loss: 0.1709347069263458, accuracy-micro: 0.7557510137557983, accuracy-macro: 0.0037000000011176\n",
      "step:    1609, loss: 0.1709340363740921, accuracy-micro: 0.7557834982872009, accuracy-macro: 0.0037000000011176\n",
      "step:    1610, loss: 0.1709320992231369, accuracy-micro: 0.7557585239410400, accuracy-macro: 0.0037000000011176\n",
      "step:    1611, loss: 0.1709292829036713, accuracy-micro: 0.7558012604713440, accuracy-macro: 0.0037000000011176\n",
      "step:    1612, loss: 0.1709244549274445, accuracy-micro: 0.7557632327079773, accuracy-macro: 0.0037000000011176\n",
      "step:    1613, loss: 0.1709201186895370, accuracy-micro: 0.7558004856109619, accuracy-macro: 0.0037000000011176\n",
      "step:    1614, loss: 0.1709149330854416, accuracy-micro: 0.7557847499847412, accuracy-macro: 0.0037000000011176\n",
      "step:    1615, loss: 0.1709107011556625, accuracy-micro: 0.7558352351188660, accuracy-macro: 0.0037000000011176\n",
      "step:    1616, loss: 0.1709061264991760, accuracy-micro: 0.7557979822158813, accuracy-macro: 0.0037000000011176\n",
      "step:    1617, loss: 0.1709023118019104, accuracy-micro: 0.7558352351188660, accuracy-macro: 0.0037000000011176\n",
      "step:    1618, loss: 0.1708989739418030, accuracy-micro: 0.7558075189590454, accuracy-macro: 0.0037000000011176\n",
      "step:    1619, loss: 0.1708963364362717, accuracy-micro: 0.7558537721633911, accuracy-macro: 0.0037000000011176\n",
      "step:    1620, loss: 0.1708924323320389, accuracy-micro: 0.7558367252349854, accuracy-macro: 0.0037000000011176\n",
      "step:    1621, loss: 0.1708892136812210, accuracy-micro: 0.7558810114860535, accuracy-macro: 0.0037000000011176\n",
      "step:    1622, loss: 0.1708868145942688, accuracy-micro: 0.7558402419090271, accuracy-macro: 0.0037000000011176\n",
      "step:    1623, loss: 0.1708835065364838, accuracy-micro: 0.7558917403221130, accuracy-macro: 0.0037000000011176\n",
      "step:    1624, loss: 0.1708813309669495, accuracy-micro: 0.7558404803276062, accuracy-macro: 0.0037000000011176\n",
      "step:    1625, loss: 0.1708782166242599, accuracy-micro: 0.7558887600898743, accuracy-macro: 0.0037000000011176\n",
      "step:    1626, loss: 0.1708761006593704, accuracy-micro: 0.7558529973030090, accuracy-macro: 0.0037000000011176\n",
      "step:    1627, loss: 0.1708753705024719, accuracy-micro: 0.7559224963188171, accuracy-macro: 0.0037000000011176\n",
      "step:    1628, loss: 0.1708741933107376, accuracy-micro: 0.7558522224426270, accuracy-macro: 0.0037000000011176\n",
      "step:    1629, loss: 0.1708743125200272, accuracy-micro: 0.7559325098991394, accuracy-macro: 0.0037000000011176\n",
      "step:    1630, loss: 0.1708758771419525, accuracy-micro: 0.7558527588844299, accuracy-macro: 0.0037000000011176\n",
      "step:    1631, loss: 0.1708778738975525, accuracy-micro: 0.7559127211570740, accuracy-macro: 0.0037000000011176\n",
      "step:    1632, loss: 0.1708822846412659, accuracy-micro: 0.7558140158653259, accuracy-macro: 0.0037000000011176\n",
      "step:    1633, loss: 0.1708887517452240, accuracy-micro: 0.7559404969215393, accuracy-macro: 0.0037000000011176\n",
      "step:    1634, loss: 0.1708912998437881, accuracy-micro: 0.7557839751243591, accuracy-macro: 0.0037000000011176\n",
      "step:    1635, loss: 0.1708904653787613, accuracy-micro: 0.7559647560119629, accuracy-macro: 0.0037000000011176\n",
      "step:    1636, loss: 0.1708832532167435, accuracy-micro: 0.7557920217514038, accuracy-macro: 0.0037000000011176\n",
      "step:    1637, loss: 0.1708751618862152, accuracy-micro: 0.7559737563133240, accuracy-macro: 0.0037000000011176\n",
      "step:    1638, loss: 0.1708623766899109, accuracy-micro: 0.7558402419090271, accuracy-macro: 0.0037000000011176\n",
      "step:    1639, loss: 0.1708506047725677, accuracy-micro: 0.7559689879417419, accuracy-macro: 0.0037000000011176\n",
      "step:    1640, loss: 0.1708372086286545, accuracy-micro: 0.7559375166893005, accuracy-macro: 0.0037000000011176\n",
      "step:    1641, loss: 0.1708268076181412, accuracy-micro: 0.7560187578201294, accuracy-macro: 0.0037000000011176\n",
      "step:    1642, loss: 0.1708200871944427, accuracy-micro: 0.7559852600097656, accuracy-macro: 0.0037000000011176\n",
      "step:    1643, loss: 0.1708167791366577, accuracy-micro: 0.7559867501258850, accuracy-macro: 0.0037000000011176\n",
      "step:    1644, loss: 0.1708178371191025, accuracy-micro: 0.7560560107231140, accuracy-macro: 0.0037000000011176\n",
      "step:    1645, loss: 0.1708205789327621, accuracy-micro: 0.7559622526168823, accuracy-macro: 0.0037000000011176\n",
      "step:    1646, loss: 0.1708233952522278, accuracy-micro: 0.7560082674026489, accuracy-macro: 0.0037000000011176\n",
      "step:    1647, loss: 0.1708251684904099, accuracy-micro: 0.7559502720832825, accuracy-macro: 0.0037000000011176\n",
      "step:    1648, loss: 0.1708251386880875, accuracy-micro: 0.7560309767723083, accuracy-macro: 0.0037000000011176\n",
      "step:    1649, loss: 0.1708229035139084, accuracy-micro: 0.7559597492218018, accuracy-macro: 0.0037000000011176\n",
      "step:    1650, loss: 0.1708189249038696, accuracy-micro: 0.7560642361640930, accuracy-macro: 0.0037000000011176\n",
      "step:    1651, loss: 0.1708111912012100, accuracy-micro: 0.7559850215911865, accuracy-macro: 0.0037000000011176\n",
      "step:    1652, loss: 0.1708022803068161, accuracy-micro: 0.7560639977455139, accuracy-macro: 0.0037000000011176\n",
      "step:    1653, loss: 0.1707915961742401, accuracy-micro: 0.7560229897499084, accuracy-macro: 0.0037000000011176\n",
      "step:    1654, loss: 0.1707833856344223, accuracy-micro: 0.7560912370681763, accuracy-macro: 0.0037000000011176\n",
      "step:    1655, loss: 0.1707780957221985, accuracy-micro: 0.7560932636260986, accuracy-macro: 0.0037000000011176\n",
      "step:    1656, loss: 0.1707749366760254, accuracy-micro: 0.7560957670211792, accuracy-macro: 0.0037000000011176\n",
      "step:    1657, loss: 0.1707742661237717, accuracy-micro: 0.7561297416687012, accuracy-macro: 0.0037000000011176\n",
      "step:    1658, loss: 0.1707772910594940, accuracy-micro: 0.7560472488403320, accuracy-macro: 0.0037000000011176\n",
      "step:    1659, loss: 0.1707823276519775, accuracy-micro: 0.7561339735984802, accuracy-macro: 0.0037000000011176\n",
      "step:    1660, loss: 0.1707863360643387, accuracy-micro: 0.7560197710990906, accuracy-macro: 0.0037000000011176\n",
      "step:    1661, loss: 0.1707857847213745, accuracy-micro: 0.7561562657356262, accuracy-macro: 0.0037000000011176\n",
      "step:    1662, loss: 0.1707806587219238, accuracy-micro: 0.7560244798660278, accuracy-macro: 0.0037000000011176\n",
      "step:    1663, loss: 0.1707721203565598, accuracy-micro: 0.7561715245246887, accuracy-macro: 0.0037000000011176\n",
      "step:    1664, loss: 0.1707622110843658, accuracy-micro: 0.7560870051383972, accuracy-macro: 0.0037000000011176\n",
      "step:    1665, loss: 0.1707531064748764, accuracy-micro: 0.7561597228050232, accuracy-macro: 0.0037000000011176\n",
      "step:    1666, loss: 0.1707454621791840, accuracy-micro: 0.7561452388763428, accuracy-macro: 0.0037000000011176\n",
      "step:    1667, loss: 0.1707399189472198, accuracy-micro: 0.7562009692192078, accuracy-macro: 0.0037000000011176\n",
      "step:    1668, loss: 0.1707358956336975, accuracy-micro: 0.7561860084533691, accuracy-macro: 0.0037000000011176\n",
      "step:    1669, loss: 0.1707343161106110, accuracy-micro: 0.7561722397804260, accuracy-macro: 0.0037000000011176\n",
      "step:    1670, loss: 0.1707329750061035, accuracy-micro: 0.7561929821968079, accuracy-macro: 0.0037000000011176\n",
      "step:    1671, loss: 0.1707316190004349, accuracy-micro: 0.7561494708061218, accuracy-macro: 0.0037000000011176\n",
      "step:    1672, loss: 0.1707294732332230, accuracy-micro: 0.7562122344970703, accuracy-macro: 0.0037000000011176\n",
      "step:    1673, loss: 0.1707269698381424, accuracy-micro: 0.7561737298965454, accuracy-macro: 0.0037000000011176\n",
      "step:    1674, loss: 0.1707237511873245, accuracy-micro: 0.7562375068664551, accuracy-macro: 0.0037000000011176\n",
      "step:    1675, loss: 0.1707198470830917, accuracy-micro: 0.7561917304992676, accuracy-macro: 0.0037000000011176\n",
      "step:    1676, loss: 0.1707148253917694, accuracy-micro: 0.7562249898910522, accuracy-macro: 0.0037000000011176\n",
      "step:    1677, loss: 0.1707097738981247, accuracy-micro: 0.7562245130538940, accuracy-macro: 0.0037000000011176\n",
      "step:    1678, loss: 0.1707052141427994, accuracy-micro: 0.7562522292137146, accuracy-macro: 0.0037000000011176\n",
      "step:    1679, loss: 0.1707012057304382, accuracy-micro: 0.7562689781188965, accuracy-macro: 0.0037000000011176\n",
      "step:    1680, loss: 0.1706996709108353, accuracy-micro: 0.7562354803085327, accuracy-macro: 0.0037000000011176\n",
      "step:    1681, loss: 0.1706994622945786, accuracy-micro: 0.7562722563743591, accuracy-macro: 0.0037000000011176\n",
      "step:    1682, loss: 0.1706987470388412, accuracy-micro: 0.7562279701232910, accuracy-macro: 0.0037000000011176\n",
      "step:    1683, loss: 0.1706960797309875, accuracy-micro: 0.7562879920005798, accuracy-macro: 0.0037000000011176\n",
      "step:    1684, loss: 0.1706924140453339, accuracy-micro: 0.7562417387962341, accuracy-macro: 0.0037000000011176\n",
      "step:    1685, loss: 0.1706875264644623, accuracy-micro: 0.7562990188598633, accuracy-macro: 0.0037000000011176\n",
      "step:    1686, loss: 0.1706825047731400, accuracy-micro: 0.7562662363052368, accuracy-macro: 0.0037000000011176\n",
      "step:    1687, loss: 0.1706775575876236, accuracy-micro: 0.7563149929046631, accuracy-macro: 0.0037000000011176\n",
      "step:    1688, loss: 0.1706729829311371, accuracy-micro: 0.7563154697418213, accuracy-macro: 0.0037000000011176\n",
      "step:    1689, loss: 0.1706708520650864, accuracy-micro: 0.7562852501869202, accuracy-macro: 0.0037000000011176\n",
      "step:    1690, loss: 0.1706716120243073, accuracy-micro: 0.7563422322273254, accuracy-macro: 0.0037000000011176\n",
      "step:    1691, loss: 0.1706734001636505, accuracy-micro: 0.7562642693519592, accuracy-macro: 0.0037000000011176\n",
      "step:    1692, loss: 0.1706767827272415, accuracy-micro: 0.7563459873199463, accuracy-macro: 0.0037000000011176\n",
      "step:    1693, loss: 0.1706795990467072, accuracy-micro: 0.7562155127525330, accuracy-macro: 0.0037000000011176\n",
      "step:    1694, loss: 0.1706811189651489, accuracy-micro: 0.7563532590866089, accuracy-macro: 0.0037000000011176\n",
      "step:    1695, loss: 0.1706784814596176, accuracy-micro: 0.7562364935874939, accuracy-macro: 0.0037000000011176\n",
      "step:    1696, loss: 0.1706729829311371, accuracy-micro: 0.7563812732696533, accuracy-macro: 0.0037000000011176\n",
      "step:    1697, loss: 0.1706638187170029, accuracy-micro: 0.7562697529792786, accuracy-macro: 0.0037000000011176\n",
      "step:    1698, loss: 0.1706542223691940, accuracy-micro: 0.7563627362251282, accuracy-macro: 0.0037000000011176\n",
      "step:    1699, loss: 0.1706445813179016, accuracy-micro: 0.7563019990921021, accuracy-macro: 0.0037000000011176\n",
      "step:    1700, loss: 0.1706375926733017, accuracy-micro: 0.7563912272453308, accuracy-macro: 0.0037000000011176\n",
      "step:    1701, loss: 0.1706328392028809, accuracy-micro: 0.7563830018043518, accuracy-macro: 0.0037000000011176\n",
      "step:    1702, loss: 0.1706292778253555, accuracy-micro: 0.7563827633857727, accuracy-macro: 0.0037000000011176\n",
      "step:    1703, loss: 0.1706276386976242, accuracy-micro: 0.7564074993133545, accuracy-macro: 0.0037000000011176\n",
      "step:    1704, loss: 0.1706258058547974, accuracy-micro: 0.7563585042953491, accuracy-macro: 0.0037000000011176\n",
      "step:    1705, loss: 0.1706243008375168, accuracy-micro: 0.7564164996147156, accuracy-macro: 0.0037000000011176\n",
      "step:    1706, loss: 0.1706215441226959, accuracy-micro: 0.7563642263412476, accuracy-macro: 0.0037000000011176\n",
      "step:    1707, loss: 0.1706192642450333, accuracy-micro: 0.7564259767532349, accuracy-macro: 0.0037000000011176\n",
      "step:    1708, loss: 0.1706162691116333, accuracy-micro: 0.7563744783401489, accuracy-macro: 0.0037000000011176\n",
      "step:    1709, loss: 0.1706132441759109, accuracy-micro: 0.7564362287521362, accuracy-macro: 0.0037000000011176\n",
      "step:    1710, loss: 0.1706085950136185, accuracy-micro: 0.7563920021057129, accuracy-macro: 0.0037000000011176\n",
      "step:    1711, loss: 0.1706037819385529, accuracy-micro: 0.7564617395401001, accuracy-macro: 0.0037000000011176\n",
      "step:    1712, loss: 0.1705998182296753, accuracy-micro: 0.7564020156860352, accuracy-macro: 0.0037000000011176\n",
      "step:    1713, loss: 0.1705962270498276, accuracy-micro: 0.7564654946327209, accuracy-macro: 0.0037000000011176\n",
      "step:    1714, loss: 0.1705923378467560, accuracy-micro: 0.7564492225646973, accuracy-macro: 0.0037000000011176\n",
      "step:    1715, loss: 0.1705891340970993, accuracy-micro: 0.7564589977264404, accuracy-macro: 0.0037000000011176\n",
      "step:    1716, loss: 0.1705862879753113, accuracy-micro: 0.7564529776573181, accuracy-macro: 0.0037000000011176\n",
      "step:    1717, loss: 0.1705832779407501, accuracy-micro: 0.7564587593078613, accuracy-macro: 0.0037000000011176\n",
      "step:    1718, loss: 0.1705802530050278, accuracy-micro: 0.7564694881439209, accuracy-macro: 0.0037000000011176\n",
      "step:    1719, loss: 0.1705767512321472, accuracy-micro: 0.7564709782600403, accuracy-macro: 0.0037000000011176\n",
      "step:    1720, loss: 0.1705742478370667, accuracy-micro: 0.7564892768859863, accuracy-macro: 0.0037000000011176\n",
      "step:    1721, loss: 0.1705708503723145, accuracy-micro: 0.7564972639083862, accuracy-macro: 0.0037000000011176\n",
      "step:    1722, loss: 0.1705675870180130, accuracy-micro: 0.7565102577209473, accuracy-macro: 0.0037000000011176\n",
      "step:    1723, loss: 0.1705650985240936, accuracy-micro: 0.7564812302589417, accuracy-macro: 0.0037000000011176\n",
      "step:    1724, loss: 0.1705631613731384, accuracy-micro: 0.7565360069274902, accuracy-macro: 0.0037000000011176\n",
      "step:    1725, loss: 0.1705610603094101, accuracy-micro: 0.7565017342567444, accuracy-macro: 0.0037000000011176\n",
      "step:    1726, loss: 0.1705603003501892, accuracy-micro: 0.7565332651138306, accuracy-macro: 0.0037000000011176\n",
      "step:    1727, loss: 0.1705590635538101, accuracy-micro: 0.7564822435379028, accuracy-macro: 0.0037000000011176\n",
      "step:    1728, loss: 0.1705574989318848, accuracy-micro: 0.7565400004386902, accuracy-macro: 0.0037000000011176\n",
      "step:    1729, loss: 0.1705570966005325, accuracy-micro: 0.7564784884452820, accuracy-macro: 0.0037000000011176\n",
      "step:    1730, loss: 0.1705579012632370, accuracy-micro: 0.7565634846687317, accuracy-macro: 0.0037000000011176\n",
      "step:    1731, loss: 0.1705574393272400, accuracy-micro: 0.7564827203750610, accuracy-macro: 0.0037000000011176\n",
      "step:    1732, loss: 0.1705554127693176, accuracy-micro: 0.7565697431564331, accuracy-macro: 0.0037000000011176\n",
      "step:    1733, loss: 0.1705504655838013, accuracy-micro: 0.7565000057220459, accuracy-macro: 0.0037000000011176\n",
      "step:    1734, loss: 0.1705447882413864, accuracy-micro: 0.7565637230873108, accuracy-macro: 0.0037000000011176\n",
      "step:    1735, loss: 0.1705376803874969, accuracy-micro: 0.7565112709999084, accuracy-macro: 0.0037000000011176\n",
      "step:    1736, loss: 0.1705290973186493, accuracy-micro: 0.7565902471542358, accuracy-macro: 0.0037000000011176\n",
      "step:    1737, loss: 0.1705224961042404, accuracy-micro: 0.7565879821777344, accuracy-macro: 0.0037000000011176\n",
      "step:    1738, loss: 0.1705194264650345, accuracy-micro: 0.7565954923629761, accuracy-macro: 0.0037000000011176\n",
      "step:    1739, loss: 0.1705191135406494, accuracy-micro: 0.7566007375717163, accuracy-macro: 0.0037000000011176\n",
      "step:    1740, loss: 0.1705223321914673, accuracy-micro: 0.7565342187881470, accuracy-macro: 0.0037000000011176\n",
      "step:    1741, loss: 0.1705280244350433, accuracy-micro: 0.7565907239913940, accuracy-macro: 0.0037000000011176\n",
      "step:    1742, loss: 0.1705314964056015, accuracy-micro: 0.7565037608146667, accuracy-macro: 0.0037000000011176\n",
      "step:    1743, loss: 0.1705331802368164, accuracy-micro: 0.7566312551498413, accuracy-macro: 0.0037000000011176\n",
      "step:    1744, loss: 0.1705312430858612, accuracy-micro: 0.7565197348594666, accuracy-macro: 0.0037000000011176\n",
      "step:    1745, loss: 0.1705275624990463, accuracy-micro: 0.7566457390785217, accuracy-macro: 0.0037000000011176\n",
      "step:    1746, loss: 0.1705196201801300, accuracy-micro: 0.7565385103225708, accuracy-macro: 0.0037000000011176\n",
      "step:    1747, loss: 0.1705089211463928, accuracy-micro: 0.7566252350807190, accuracy-macro: 0.0037000000011176\n",
      "step:    1748, loss: 0.1704990118741989, accuracy-micro: 0.7566034793853760, accuracy-macro: 0.0037000000011176\n",
      "step:    1749, loss: 0.1704905927181244, accuracy-micro: 0.7566540241241455, accuracy-macro: 0.0037000000011176\n",
      "step:    1750, loss: 0.1704838573932648, accuracy-micro: 0.7566785216331482, accuracy-macro: 0.0037000000011176\n",
      "step:    1751, loss: 0.1704803407192230, accuracy-micro: 0.7566587328910828, accuracy-macro: 0.0037000000011176\n",
      "step:    1752, loss: 0.1704797446727753, accuracy-micro: 0.7566559910774231, accuracy-macro: 0.0037000000011176\n",
      "step:    1753, loss: 0.1704824417829514, accuracy-micro: 0.7566297650337219, accuracy-macro: 0.0037000000011176\n",
      "step:    1754, loss: 0.1704846769571304, accuracy-micro: 0.7566742300987244, accuracy-macro: 0.0037000000011176\n",
      "step:    1755, loss: 0.1704845875501633, accuracy-micro: 0.7566142678260803, accuracy-macro: 0.0037000000011176\n",
      "step:    1756, loss: 0.1704837977886200, accuracy-micro: 0.7567157745361328, accuracy-macro: 0.0037000000011176\n",
      "step:    1757, loss: 0.1704800277948380, accuracy-micro: 0.7566232681274414, accuracy-macro: 0.0037000000011176\n",
      "step:    1758, loss: 0.1704742014408112, accuracy-micro: 0.7566972374916077, accuracy-macro: 0.0037000000011176\n",
      "step:    1759, loss: 0.1704664528369904, accuracy-micro: 0.7566437721252441, accuracy-macro: 0.0037000000011176\n",
      "step:    1760, loss: 0.1704594790935516, accuracy-micro: 0.7567027211189270, accuracy-macro: 0.0037000000011176\n",
      "step:    1761, loss: 0.1704531311988831, accuracy-micro: 0.7567160129547119, accuracy-macro: 0.0037000000011176\n",
      "step:    1762, loss: 0.1704475283622742, accuracy-micro: 0.7567192316055298, accuracy-macro: 0.0037000000011176\n",
      "step:    1763, loss: 0.1704441308975220, accuracy-micro: 0.7567617297172546, accuracy-macro: 0.0037000000011176\n",
      "step:    1764, loss: 0.1704413145780563, accuracy-micro: 0.7567347288131714, accuracy-macro: 0.0037000000011176\n",
      "step:    1765, loss: 0.1704387813806534, accuracy-micro: 0.7567319869995117, accuracy-macro: 0.0037000000011176\n",
      "step:    1766, loss: 0.1704358160495758, accuracy-micro: 0.7567484974861145, accuracy-macro: 0.0037000000011176\n",
      "step:    1767, loss: 0.1704338639974594, accuracy-micro: 0.7567614912986755, accuracy-macro: 0.0037000000011176\n",
      "step:    1768, loss: 0.1704314500093460, accuracy-micro: 0.7567647695541382, accuracy-macro: 0.0037000000011176\n",
      "step:    1769, loss: 0.1704294085502625, accuracy-micro: 0.7567407488822937, accuracy-macro: 0.0037000000011176\n",
      "step:    1770, loss: 0.1704258173704147, accuracy-micro: 0.7567537426948547, accuracy-macro: 0.0037000000011176\n",
      "step:    1771, loss: 0.1704232543706894, accuracy-micro: 0.7567600011825562, accuracy-macro: 0.0037000000011176\n",
      "step:    1772, loss: 0.1704191714525223, accuracy-micro: 0.7567712664604187, accuracy-macro: 0.0037000000011176\n",
      "step:    1773, loss: 0.1704163551330566, accuracy-micro: 0.7567817568778992, accuracy-macro: 0.0037000000011176\n",
      "step:    1774, loss: 0.1704131513834000, accuracy-micro: 0.7567877769470215, accuracy-macro: 0.0037000000011176\n",
      "step:    1775, loss: 0.1704110950231552, accuracy-micro: 0.7567805051803589, accuracy-macro: 0.0037000000011176\n",
      "step:    1776, loss: 0.1704078018665314, accuracy-micro: 0.7567752599716187, accuracy-macro: 0.0037000000011176\n",
      "step:    1777, loss: 0.1704047769308090, accuracy-micro: 0.7567877769470215, accuracy-macro: 0.0037000000011176\n",
      "step:    1778, loss: 0.1704022139310837, accuracy-micro: 0.7568184733390808, accuracy-macro: 0.0037000000011176\n",
      "step:    1779, loss: 0.1703987121582031, accuracy-micro: 0.7568167448043823, accuracy-macro: 0.0037000000011176\n",
      "step:    1780, loss: 0.1703955382108688, accuracy-micro: 0.7567937374114990, accuracy-macro: 0.0037000000011176\n",
      "step:    1781, loss: 0.1703923046588898, accuracy-micro: 0.7568014860153198, accuracy-macro: 0.0037000000011176\n",
      "step:    1782, loss: 0.1703894734382629, accuracy-micro: 0.7568024992942810, accuracy-macro: 0.0037000000011176\n",
      "step:    1783, loss: 0.1703867018222809, accuracy-micro: 0.7568035125732422, accuracy-macro: 0.0037000000011176\n",
      "step:    1784, loss: 0.1703834980726242, accuracy-micro: 0.7568309903144836, accuracy-macro: 0.0037000000011176\n",
      "step:    1785, loss: 0.1703800559043884, accuracy-micro: 0.7568380236625671, accuracy-macro: 0.0037000000011176\n",
      "step:    1786, loss: 0.1703781187534332, accuracy-micro: 0.7568402290344238, accuracy-macro: 0.0037000000011176\n",
      "step:    1787, loss: 0.1703755259513855, accuracy-micro: 0.7568352222442627, accuracy-macro: 0.0037000000011176\n",
      "step:    1788, loss: 0.1703739017248154, accuracy-micro: 0.7568600177764893, accuracy-macro: 0.0037000000011176\n",
      "step:    1789, loss: 0.1703722774982452, accuracy-micro: 0.7568452358245850, accuracy-macro: 0.0037000000011176\n",
      "step:    1790, loss: 0.1703700125217438, accuracy-micro: 0.7568727731704712, accuracy-macro: 0.0037000000011176\n",
      "step:    1791, loss: 0.1703668534755707, accuracy-micro: 0.7568652629852295, accuracy-macro: 0.0037000000011176\n",
      "step:    1792, loss: 0.1703636497259140, accuracy-micro: 0.7568737268447876, accuracy-macro: 0.0037000000011176\n",
      "step:    1793, loss: 0.1703599989414215, accuracy-micro: 0.7568734884262085, accuracy-macro: 0.0037000000011176\n",
      "step:    1794, loss: 0.1703569740056992, accuracy-micro: 0.7568897604942322, accuracy-macro: 0.0037000000011176\n",
      "step:    1795, loss: 0.1703538596630096, accuracy-micro: 0.7568814754486084, accuracy-macro: 0.0037000000011176\n",
      "step:    1796, loss: 0.1703504323959351, accuracy-micro: 0.7569010257720947, accuracy-macro: 0.0037000000011176\n",
      "step:    1797, loss: 0.1703458428382874, accuracy-micro: 0.7568874955177307, accuracy-macro: 0.0037000000011176\n",
      "step:    1798, loss: 0.1703433692455292, accuracy-micro: 0.7569177746772766, accuracy-macro: 0.0037000000011176\n",
      "step:    1799, loss: 0.1703404933214188, accuracy-micro: 0.7569097280502319, accuracy-macro: 0.0037000000011176\n",
      "step:    1800, loss: 0.1703367382287979, accuracy-micro: 0.7569159865379333, accuracy-macro: 0.0037000000011176\n",
      "step:    1801, loss: 0.1703339964151382, accuracy-micro: 0.7569029927253723, accuracy-macro: 0.0037000000011176\n",
      "step:    1802, loss: 0.1703311204910278, accuracy-micro: 0.7569202184677124, accuracy-macro: 0.0037000000011176\n",
      "step:    1803, loss: 0.1703279316425323, accuracy-micro: 0.7569377422332764, accuracy-macro: 0.0037000000011176\n",
      "step:    1804, loss: 0.1703253388404846, accuracy-micro: 0.7569469809532166, accuracy-macro: 0.0037000000011176\n",
      "step:    1805, loss: 0.1703222543001175, accuracy-micro: 0.7569364905357361, accuracy-macro: 0.0037000000011176\n",
      "step:    1806, loss: 0.1703194528818130, accuracy-micro: 0.7569192647933960, accuracy-macro: 0.0037000000011176\n",
      "step:    1807, loss: 0.1703165620565414, accuracy-micro: 0.7569487690925598, accuracy-macro: 0.0037000000011176\n",
      "step:    1808, loss: 0.1703140288591385, accuracy-micro: 0.7569427490234375, accuracy-macro: 0.0037000000011176\n",
      "step:    1809, loss: 0.1703115254640579, accuracy-micro: 0.7569837570190430, accuracy-macro: 0.0037000000011176\n",
      "step:    1810, loss: 0.1703087985515594, accuracy-micro: 0.7569632530212402, accuracy-macro: 0.0037000000011176\n",
      "step:    1811, loss: 0.1703062206506729, accuracy-micro: 0.7569777369499207, accuracy-macro: 0.0037000000011176\n",
      "step:    1812, loss: 0.1703035980463028, accuracy-micro: 0.7569530010223389, accuracy-macro: 0.0037000000011176\n",
      "step:    1813, loss: 0.1703003793954849, accuracy-micro: 0.7569959759712219, accuracy-macro: 0.0037000000011176\n",
      "step:    1814, loss: 0.1702975332736969, accuracy-micro: 0.7569810152053833, accuracy-macro: 0.0037000000011176\n",
      "step:    1815, loss: 0.1702939122915268, accuracy-micro: 0.7570177316665649, accuracy-macro: 0.0037000000011176\n",
      "step:    1816, loss: 0.1702911257743835, accuracy-micro: 0.7569929957389832, accuracy-macro: 0.0037000000011176\n",
      "step:    1817, loss: 0.1702877134084702, accuracy-micro: 0.7569950222969055, accuracy-macro: 0.0037000000011176\n",
      "step:    1818, loss: 0.1702848076820374, accuracy-micro: 0.7569932341575623, accuracy-macro: 0.0037000000011176\n",
      "step:    1819, loss: 0.1702823787927628, accuracy-micro: 0.7570080161094666, accuracy-macro: 0.0037000000011176\n",
      "step:    1820, loss: 0.1702795922756195, accuracy-micro: 0.7570492625236511, accuracy-macro: 0.0037000000011176\n",
      "step:    1821, loss: 0.1702777743339539, accuracy-micro: 0.7570097446441650, accuracy-macro: 0.0037000000011176\n",
      "step:    1822, loss: 0.1702749729156494, accuracy-micro: 0.7570562362670898, accuracy-macro: 0.0037000000011176\n",
      "step:    1823, loss: 0.1702731698751450, accuracy-micro: 0.7570137381553650, accuracy-macro: 0.0037000000011176\n",
      "step:    1824, loss: 0.1702725887298584, accuracy-micro: 0.7570539712905884, accuracy-macro: 0.0037000000011176\n",
      "step:    1825, loss: 0.1702721267938614, accuracy-micro: 0.7570007443428040, accuracy-macro: 0.0037000000011176\n",
      "step:    1826, loss: 0.1702724695205688, accuracy-micro: 0.7570822238922119, accuracy-macro: 0.0037000000011176\n",
      "step:    1827, loss: 0.1702733784914017, accuracy-micro: 0.7569902539253235, accuracy-macro: 0.0037000000011176\n",
      "step:    1828, loss: 0.1702754050493240, accuracy-micro: 0.7570837736129761, accuracy-macro: 0.0037000000011176\n",
      "step:    1829, loss: 0.1702785640954971, accuracy-micro: 0.7569450139999390, accuracy-macro: 0.0037000000011176\n",
      "step:    1830, loss: 0.1702836602926254, accuracy-micro: 0.7571164965629578, accuracy-macro: 0.0037000000011176\n",
      "step:    1831, loss: 0.1702888756990433, accuracy-micro: 0.7569174766540527, accuracy-macro: 0.0037000000011176\n",
      "step:    1832, loss: 0.1702966541051865, accuracy-micro: 0.7571284770965576, accuracy-macro: 0.0037000000011176\n",
      "step:    1833, loss: 0.1703051030635834, accuracy-micro: 0.7568857669830322, accuracy-macro: 0.0037000000011176\n",
      "step:    1834, loss: 0.1703210622072220, accuracy-micro: 0.7571082711219788, accuracy-macro: 0.0037000000011176\n",
      "step:    1835, loss: 0.1703311800956726, accuracy-micro: 0.7568389773368835, accuracy-macro: 0.0037000000011176\n",
      "step:    1836, loss: 0.1703384220600128, accuracy-micro: 0.7570919990539551, accuracy-macro: 0.0037000000011176\n",
      "step:    1837, loss: 0.1703239977359772, accuracy-micro: 0.7568845152854919, accuracy-macro: 0.0037000000011176\n",
      "step:    1838, loss: 0.1703017354011536, accuracy-micro: 0.7571399807929993, accuracy-macro: 0.0037000000011176\n",
      "step:    1839, loss: 0.1702674329280853, accuracy-micro: 0.7569584846496582, accuracy-macro: 0.0037000000011176\n",
      "step:    1840, loss: 0.1702390760183334, accuracy-micro: 0.7571719884872437, accuracy-macro: 0.0037000000011176\n",
      "step:    1841, loss: 0.1702213436365128, accuracy-micro: 0.7570932507514954, accuracy-macro: 0.0037000000011176\n",
      "step:    1842, loss: 0.1702178716659546, accuracy-micro: 0.7571062445640564, accuracy-macro: 0.0037000000011176\n",
      "step:    1843, loss: 0.1702250242233276, accuracy-micro: 0.7571777701377869, accuracy-macro: 0.0037000000011176\n",
      "step:    1844, loss: 0.1702373325824738, accuracy-micro: 0.7570242285728455, accuracy-macro: 0.0037000000011176\n",
      "step:    1845, loss: 0.1702484041452408, accuracy-micro: 0.7571857571601868, accuracy-macro: 0.0037000000011176\n",
      "step:    1846, loss: 0.1702474057674408, accuracy-micro: 0.7570040225982666, accuracy-macro: 0.0037000000011176\n",
      "step:    1847, loss: 0.1702383458614349, accuracy-micro: 0.7572000026702881, accuracy-macro: 0.0037000000011176\n",
      "step:    1848, loss: 0.1702220886945724, accuracy-micro: 0.7570729851722717, accuracy-macro: 0.0037000000011176\n",
      "step:    1849, loss: 0.1702051907777786, accuracy-micro: 0.7572209835052490, accuracy-macro: 0.0037000000011176\n",
      "step:    1850, loss: 0.1701956242322922, accuracy-micro: 0.7571784853935242, accuracy-macro: 0.0037000000011176\n",
      "step:    1851, loss: 0.1701938211917877, accuracy-micro: 0.7571697235107422, accuracy-macro: 0.0037000000011176\n",
      "step:    1852, loss: 0.1701980978250504, accuracy-micro: 0.7572437524795532, accuracy-macro: 0.0037000000011176\n",
      "step:    1853, loss: 0.1702026575803757, accuracy-micro: 0.7571114897727966, accuracy-macro: 0.0037000000011176\n",
      "step:    1854, loss: 0.1702010333538055, accuracy-micro: 0.7572642564773560, accuracy-macro: 0.0037000000011176\n",
      "step:    1855, loss: 0.1701954901218414, accuracy-micro: 0.7571147680282593, accuracy-macro: 0.0037000000011176\n",
      "step:    1856, loss: 0.1701884418725967, accuracy-micro: 0.7572624683380127, accuracy-macro: 0.0037000000011176\n",
      "step:    1857, loss: 0.1701810657978058, accuracy-micro: 0.7571445107460022, accuracy-macro: 0.0037000000011176\n",
      "step:    1858, loss: 0.1701739132404327, accuracy-micro: 0.7572427392005920, accuracy-macro: 0.0037000000011176\n",
      "step:    1859, loss: 0.1701709032058716, accuracy-micro: 0.7572397589683533, accuracy-macro: 0.0037000000011176\n",
      "step:    1860, loss: 0.1701703965663910, accuracy-micro: 0.7572017312049866, accuracy-macro: 0.0037000000011176\n",
      "step:    1861, loss: 0.1701735407114029, accuracy-micro: 0.7572965025901794, accuracy-macro: 0.0037000000011176\n",
      "step:    1862, loss: 0.1701762676239014, accuracy-micro: 0.7571455240249634, accuracy-macro: 0.0037000000011176\n",
      "step:    1863, loss: 0.1701782792806625, accuracy-micro: 0.7573304772377014, accuracy-macro: 0.0037000000011176\n",
      "step:    1864, loss: 0.1701750904321671, accuracy-micro: 0.7571445107460022, accuracy-macro: 0.0037000000011176\n",
      "step:    1865, loss: 0.1701682060956955, accuracy-micro: 0.7573300004005432, accuracy-macro: 0.0037000000011176\n",
      "step:    1866, loss: 0.1701585054397583, accuracy-micro: 0.7572107315063477, accuracy-macro: 0.0037000000011176\n",
      "step:    1867, loss: 0.1701508760452271, accuracy-micro: 0.7572832703590393, accuracy-macro: 0.0037000000011176\n",
      "step:    1868, loss: 0.1701466143131256, accuracy-micro: 0.7572680115699768, accuracy-macro: 0.0037000000011176\n",
      "step:    1869, loss: 0.1701461523771286, accuracy-micro: 0.7572417259216309, accuracy-macro: 0.0037000000011176\n",
      "step:    1870, loss: 0.1701479554176331, accuracy-micro: 0.7573459744453430, accuracy-macro: 0.0037000000011176\n",
      "step:    1871, loss: 0.1701492518186569, accuracy-micro: 0.7572014927864075, accuracy-macro: 0.0037000000011176\n",
      "step:    1872, loss: 0.1701495051383972, accuracy-micro: 0.7573404908180237, accuracy-macro: 0.0037000000011176\n",
      "step:    1873, loss: 0.1701479703187943, accuracy-micro: 0.7571922540664673, accuracy-macro: 0.0037000000011176\n",
      "step:    1874, loss: 0.1701434403657913, accuracy-micro: 0.7573544979095459, accuracy-macro: 0.0037000000011176\n",
      "step:    1875, loss: 0.1701358109712601, accuracy-micro: 0.7572337388992310, accuracy-macro: 0.0037000000011176\n",
      "step:    1876, loss: 0.1701291054487228, accuracy-micro: 0.7573377490043640, accuracy-macro: 0.0037000000011176\n",
      "step:    1877, loss: 0.1701236665248871, accuracy-micro: 0.7572892308235168, accuracy-macro: 0.0037000000011176\n",
      "step:    1878, loss: 0.1701197773218155, accuracy-micro: 0.7573057413101196, accuracy-macro: 0.0037000000011176\n",
      "step:    1879, loss: 0.1701184958219528, accuracy-micro: 0.7573595046997070, accuracy-macro: 0.0037000000011176\n",
      "step:    1880, loss: 0.1701183021068573, accuracy-micro: 0.7572730183601379, accuracy-macro: 0.0037000000011176\n",
      "step:    1881, loss: 0.1701203137636185, accuracy-micro: 0.7574074864387512, accuracy-macro: 0.0037000000011176\n",
      "step:    1882, loss: 0.1701214611530304, accuracy-micro: 0.7572504878044128, accuracy-macro: 0.0037000000011176\n",
      "step:    1883, loss: 0.1701202988624573, accuracy-micro: 0.7573932409286499, accuracy-macro: 0.0037000000011176\n",
      "step:    1884, loss: 0.1701150536537170, accuracy-micro: 0.7572742700576782, accuracy-macro: 0.0037000000011176\n",
      "step:    1885, loss: 0.1701093316078186, accuracy-micro: 0.7574172616004944, accuracy-macro: 0.0037000000011176\n",
      "step:    1886, loss: 0.1701034307479858, accuracy-micro: 0.7573205232620239, accuracy-macro: 0.0037000000011176\n",
      "step:    1887, loss: 0.1700985133647919, accuracy-micro: 0.7573900222778320, accuracy-macro: 0.0037000000011176\n",
      "step:    1888, loss: 0.1700939834117889, accuracy-micro: 0.7573432326316833, accuracy-macro: 0.0037000000011176\n",
      "step:    1889, loss: 0.1700912117958069, accuracy-micro: 0.7573362588882446, accuracy-macro: 0.0037000000011176\n",
      "step:    1890, loss: 0.1700903326272964, accuracy-micro: 0.7574107646942139, accuracy-macro: 0.0037000000011176\n",
      "step:    1891, loss: 0.1700904071331024, accuracy-micro: 0.7573317289352417, accuracy-macro: 0.0037000000011176\n",
      "step:    1892, loss: 0.1700914055109024, accuracy-micro: 0.7574574947357178, accuracy-macro: 0.0037000000011176\n",
      "step:    1893, loss: 0.1700908690690994, accuracy-micro: 0.7573237419128418, accuracy-macro: 0.0037000000011176\n",
      "step:    1894, loss: 0.1700868159532547, accuracy-micro: 0.7574577331542969, accuracy-macro: 0.0037000000011176\n",
      "step:    1895, loss: 0.1700814962387085, accuracy-micro: 0.7573497295379639, accuracy-macro: 0.0037000000011176\n",
      "step:    1896, loss: 0.1700760573148727, accuracy-micro: 0.7574549913406372, accuracy-macro: 0.0037000000011176\n",
      "step:    1897, loss: 0.1700709313154221, accuracy-micro: 0.7574024796485901, accuracy-macro: 0.0037000000011176\n",
      "step:    1898, loss: 0.1700673103332520, accuracy-micro: 0.7574127316474915, accuracy-macro: 0.0037000000011176\n",
      "step:    1899, loss: 0.1700655370950699, accuracy-micro: 0.7574462294578552, accuracy-macro: 0.0037000000011176\n",
      "step:    1900, loss: 0.1700641214847565, accuracy-micro: 0.7573984861373901, accuracy-macro: 0.0037000000011176\n",
      "step:    1901, loss: 0.1700635403394699, accuracy-micro: 0.7574874758720398, accuracy-macro: 0.0037000000011176\n",
      "step:    1902, loss: 0.1700620651245117, accuracy-micro: 0.7573949694633484, accuracy-macro: 0.0037000000011176\n",
      "step:    1903, loss: 0.1700608283281326, accuracy-micro: 0.7574754953384399, accuracy-macro: 0.0037000000011176\n",
      "step:    1904, loss: 0.1700576096773148, accuracy-micro: 0.7574067711830139, accuracy-macro: 0.0037000000011176\n",
      "step:    1905, loss: 0.1700547039508820, accuracy-micro: 0.7575017213821411, accuracy-macro: 0.0037000000011176\n",
      "step:    1906, loss: 0.1700508445501328, accuracy-micro: 0.7574362754821777, accuracy-macro: 0.0037000000011176\n",
      "step:    1907, loss: 0.1700470298528671, accuracy-micro: 0.7575144767761230, accuracy-macro: 0.0037000000011176\n",
      "step:    1908, loss: 0.1700434833765030, accuracy-micro: 0.7574327588081360, accuracy-macro: 0.0037000000011176\n",
      "step:    1909, loss: 0.1700398772954941, accuracy-micro: 0.7574995160102844, accuracy-macro: 0.0037000000011176\n",
      "step:    1910, loss: 0.1700362265110016, accuracy-micro: 0.7574704885482788, accuracy-macro: 0.0037000000011176\n",
      "step:    1911, loss: 0.1700339615345001, accuracy-micro: 0.7574779987335205, accuracy-macro: 0.0037000000011176\n",
      "step:    1912, loss: 0.1700315922498703, accuracy-micro: 0.7574712634086609, accuracy-macro: 0.0037000000011176\n",
      "step:    1913, loss: 0.1700286567211151, accuracy-micro: 0.7574812769889832, accuracy-macro: 0.0037000000011176\n",
      "step:    1914, loss: 0.1700262427330017, accuracy-micro: 0.7575004696846008, accuracy-macro: 0.0037000000011176\n",
      "step:    1915, loss: 0.1700236201286316, accuracy-micro: 0.7575017213821411, accuracy-macro: 0.0037000000011176\n",
      "step:    1916, loss: 0.1700209379196167, accuracy-micro: 0.7574862241744995, accuracy-macro: 0.0037000000011176\n",
      "step:    1917, loss: 0.1700192689895630, accuracy-micro: 0.7575445175170898, accuracy-macro: 0.0037000000011176\n",
      "step:    1918, loss: 0.1700173616409302, accuracy-micro: 0.7575102448463440, accuracy-macro: 0.0037000000011176\n",
      "step:    1919, loss: 0.1700152605772018, accuracy-micro: 0.7575587630271912, accuracy-macro: 0.0037000000011176\n",
      "step:    1920, loss: 0.1700125336647034, accuracy-micro: 0.7575160264968872, accuracy-macro: 0.0037000000011176\n",
      "step:    1921, loss: 0.1700098961591721, accuracy-micro: 0.7575667500495911, accuracy-macro: 0.0037000000011176\n",
      "step:    1922, loss: 0.1700066328048706, accuracy-micro: 0.7575322389602661, accuracy-macro: 0.0037000000011176\n",
      "step:    1923, loss: 0.1700041741132736, accuracy-micro: 0.7575765252113342, accuracy-macro: 0.0037000000011176\n",
      "step:    1924, loss: 0.1700014024972916, accuracy-micro: 0.7575477361679077, accuracy-macro: 0.0037000000011176\n",
      "step:    1925, loss: 0.1699987053871155, accuracy-micro: 0.7575650215148926, accuracy-macro: 0.0037000000011176\n",
      "step:    1926, loss: 0.1699959635734558, accuracy-micro: 0.7575629949569702, accuracy-macro: 0.0037000000011176\n",
      "step:    1927, loss: 0.1699929237365723, accuracy-micro: 0.7575914859771729, accuracy-macro: 0.0037000000011176\n",
      "step:    1928, loss: 0.1699905395507812, accuracy-micro: 0.7575694918632507, accuracy-macro: 0.0037000000011176\n",
      "step:    1929, loss: 0.1699876934289932, accuracy-micro: 0.7576012611389160, accuracy-macro: 0.0037000000011176\n",
      "step:    1930, loss: 0.1699849963188171, accuracy-micro: 0.7575954794883728, accuracy-macro: 0.0037000000011176\n",
      "step:    1931, loss: 0.1699831038713455, accuracy-micro: 0.7576112747192383, accuracy-macro: 0.0037000000011176\n",
      "step:    1932, loss: 0.1699804365634918, accuracy-micro: 0.7576289772987366, accuracy-macro: 0.0037000000011176\n",
      "step:    1933, loss: 0.1699774563312531, accuracy-micro: 0.7576239705085754, accuracy-macro: 0.0037000000011176\n",
      "step:    1934, loss: 0.1699752807617188, accuracy-micro: 0.7576387524604797, accuracy-macro: 0.0037000000011176\n",
      "step:    1935, loss: 0.1699728816747665, accuracy-micro: 0.7576270103454590, accuracy-macro: 0.0037000000011176\n",
      "step:    1936, loss: 0.1699707359075546, accuracy-micro: 0.7576370239257812, accuracy-macro: 0.0037000000011176\n",
      "step:    1937, loss: 0.1699680685997009, accuracy-micro: 0.7576425075531006, accuracy-macro: 0.0037000000011176\n",
      "step:    1938, loss: 0.1699657738208771, accuracy-micro: 0.7576582431793213, accuracy-macro: 0.0037000000011176\n",
      "step:    1939, loss: 0.1699632406234741, accuracy-micro: 0.7576465010643005, accuracy-macro: 0.0037000000011176\n",
      "step:    1940, loss: 0.1699609011411667, accuracy-micro: 0.7576612234115601, accuracy-macro: 0.0037000000011176\n",
      "step:    1941, loss: 0.1699584424495697, accuracy-micro: 0.7576582431793213, accuracy-macro: 0.0037000000011176\n",
      "step:    1942, loss: 0.1699560433626175, accuracy-micro: 0.7576632499694824, accuracy-macro: 0.0037000000011176\n",
      "step:    1943, loss: 0.1699536144733429, accuracy-micro: 0.7576699852943420, accuracy-macro: 0.0037000000011176\n",
      "step:    1944, loss: 0.1699507385492325, accuracy-micro: 0.7576835155487061, accuracy-macro: 0.0037000000011176\n",
      "step:    1945, loss: 0.1699485033750534, accuracy-micro: 0.7576887607574463, accuracy-macro: 0.0037000000011176\n",
      "step:    1946, loss: 0.1699452847242355, accuracy-micro: 0.7577049732208252, accuracy-macro: 0.0037000000011176\n",
      "step:    1947, loss: 0.1699433773756027, accuracy-micro: 0.7576720118522644, accuracy-macro: 0.0037000000011176\n",
      "step:    1948, loss: 0.1699420809745789, accuracy-micro: 0.7577097415924072, accuracy-macro: 0.0037000000011176\n",
      "step:    1949, loss: 0.1699399650096893, accuracy-micro: 0.7576887607574463, accuracy-macro: 0.0037000000011176\n",
      "step:    1950, loss: 0.1699369996786118, accuracy-micro: 0.7576950192451477, accuracy-macro: 0.0037000000011176\n",
      "step:    1951, loss: 0.1699347943067551, accuracy-micro: 0.7576977610588074, accuracy-macro: 0.0037000000011176\n",
      "step:    1952, loss: 0.1699316352605820, accuracy-micro: 0.7577222585678101, accuracy-macro: 0.0037000000011176\n",
      "step:    1953, loss: 0.1699279099702835, accuracy-micro: 0.7577145099639893, accuracy-macro: 0.0037000000011176\n",
      "step:    1954, loss: 0.1699251830577850, accuracy-micro: 0.7577400207519531, accuracy-macro: 0.0037000000011176\n",
      "step:    1955, loss: 0.1699216514825821, accuracy-micro: 0.7577310204505920, accuracy-macro: 0.0037000000011176\n",
      "step:    1956, loss: 0.1699203103780746, accuracy-micro: 0.7577177286148071, accuracy-macro: 0.0037000000011176\n",
      "step:    1957, loss: 0.1699194461107254, accuracy-micro: 0.7577704787254333, accuracy-macro: 0.0037000000011176\n",
      "step:    1958, loss: 0.1699186861515045, accuracy-micro: 0.7577122449874878, accuracy-macro: 0.0037000000011176\n",
      "step:    1959, loss: 0.1699184924364090, accuracy-micro: 0.7577542662620544, accuracy-macro: 0.0037000000011176\n",
      "step:    1960, loss: 0.1699176877737045, accuracy-micro: 0.7576977610588074, accuracy-macro: 0.0037000000011176\n",
      "step:    1961, loss: 0.1699176579713821, accuracy-micro: 0.7577880024909973, accuracy-macro: 0.0037000000011176\n",
      "step:    1962, loss: 0.1699177473783493, accuracy-micro: 0.7576992511749268, accuracy-macro: 0.0037000000011176\n",
      "step:    1963, loss: 0.1699169576168060, accuracy-micro: 0.7577894926071167, accuracy-macro: 0.0037000000011176\n",
      "step:    1964, loss: 0.1699163466691971, accuracy-micro: 0.7576732635498047, accuracy-macro: 0.0037000000011176\n",
      "step:    1965, loss: 0.1699165999889374, accuracy-micro: 0.7577822208404541, accuracy-macro: 0.0037000000011176\n",
      "step:    1966, loss: 0.1699172109365463, accuracy-micro: 0.7576844692230225, accuracy-macro: 0.0037000000011176\n",
      "step:    1967, loss: 0.1699184328317642, accuracy-micro: 0.7578142285346985, accuracy-macro: 0.0037000000011176\n",
      "step:    1968, loss: 0.1699184924364090, accuracy-micro: 0.7576737403869629, accuracy-macro: 0.0037000000011176\n",
      "step:    1969, loss: 0.1699188202619553, accuracy-micro: 0.7577957510948181, accuracy-macro: 0.0037000000011176\n",
      "step:    1970, loss: 0.1699155420064926, accuracy-micro: 0.7576842308044434, accuracy-macro: 0.0037000000011176\n",
      "step:    1971, loss: 0.1699106842279434, accuracy-micro: 0.7578262686729431, accuracy-macro: 0.0037000000011176\n",
      "step:    1972, loss: 0.1699012219905853, accuracy-micro: 0.7577245235443115, accuracy-macro: 0.0037000000011176\n",
      "step:    1973, loss: 0.1698917746543884, accuracy-micro: 0.7578222751617432, accuracy-macro: 0.0037000000011176\n",
      "step:    1974, loss: 0.1698825061321259, accuracy-micro: 0.7577919960021973, accuracy-macro: 0.0037000000011176\n",
      "step:    1975, loss: 0.1698756814002991, accuracy-micro: 0.7578480243682861, accuracy-macro: 0.0037000000011176\n",
      "step:    1976, loss: 0.1698704659938812, accuracy-micro: 0.7578052282333374, accuracy-macro: 0.0037000000011176\n",
      "step:    1977, loss: 0.1698665618896484, accuracy-micro: 0.7578300237655640, accuracy-macro: 0.0037000000011176\n",
      "step:    1978, loss: 0.1698653101921082, accuracy-micro: 0.7578537464141846, accuracy-macro: 0.0037000000011176\n",
      "step:    1979, loss: 0.1698640286922455, accuracy-micro: 0.7578129768371582, accuracy-macro: 0.0037000000011176\n",
      "step:    1980, loss: 0.1698648631572723, accuracy-micro: 0.7578817605972290, accuracy-macro: 0.0037000000011176\n",
      "step:    1981, loss: 0.1698669344186783, accuracy-micro: 0.7578055262565613, accuracy-macro: 0.0037000000011176\n",
      "step:    1982, loss: 0.1698693037033081, accuracy-micro: 0.7578647732734680, accuracy-macro: 0.0037000000011176\n",
      "step:    1983, loss: 0.1698692739009857, accuracy-micro: 0.7577924728393555, accuracy-macro: 0.0037000000011176\n",
      "step:    1984, loss: 0.1698670238256454, accuracy-micro: 0.7578889727592468, accuracy-macro: 0.0037000000011176\n",
      "step:    1985, loss: 0.1698614358901978, accuracy-micro: 0.7578012347221375, accuracy-macro: 0.0037000000011176\n",
      "step:    1986, loss: 0.1698534190654755, accuracy-micro: 0.7579190135002136, accuracy-macro: 0.0037000000011176\n",
      "step:    1987, loss: 0.1698468774557114, accuracy-micro: 0.7578864693641663, accuracy-macro: 0.0037000000011176\n",
      "step:    1988, loss: 0.1698419153690338, accuracy-micro: 0.7579054832458496, accuracy-macro: 0.0037000000011176\n",
      "step:    1989, loss: 0.1698383688926697, accuracy-micro: 0.7578527331352234, accuracy-macro: 0.0037000000011176\n",
      "step:    1990, loss: 0.1698350608348846, accuracy-micro: 0.7578897476196289, accuracy-macro: 0.0037000000011176\n",
      "step:    1991, loss: 0.1698324084281921, accuracy-micro: 0.7578954696655273, accuracy-macro: 0.0037000000011176\n",
      "step:    1992, loss: 0.1698307991027832, accuracy-micro: 0.7578837275505066, accuracy-macro: 0.0037000000011176\n",
      "step:    1993, loss: 0.1698299944400787, accuracy-micro: 0.7579184770584106, accuracy-macro: 0.0037000000011176\n",
      "step:    1994, loss: 0.1698292940855026, accuracy-micro: 0.7578999996185303, accuracy-macro: 0.0037000000011176\n",
      "step:    1995, loss: 0.1698290556669235, accuracy-micro: 0.7579642534255981, accuracy-macro: 0.0037000000011176\n",
      "step:    1996, loss: 0.1698291152715683, accuracy-micro: 0.7579025030136108, accuracy-macro: 0.0037000000011176\n",
      "step:    1997, loss: 0.1698274463415146, accuracy-micro: 0.7579502463340759, accuracy-macro: 0.0037000000011176\n",
      "step:    1998, loss: 0.1698260456323624, accuracy-micro: 0.7578937411308289, accuracy-macro: 0.0037000000011176\n",
      "step:    1999, loss: 0.1698246896266937, accuracy-micro: 0.7579544782638550, accuracy-macro: 0.0037000000011176\n",
      "step:    2000, loss: 0.1698207557201385, accuracy-micro: 0.7579154968261719, accuracy-macro: 0.0037000000011176\n",
      "step:    2001, loss: 0.1698154062032700, accuracy-micro: 0.7579969763755798, accuracy-macro: 0.0037000000011176\n",
      "step:    2002, loss: 0.1698102205991745, accuracy-micro: 0.7579537630081177, accuracy-macro: 0.0037000000011176\n",
      "step:    2003, loss: 0.1698053777217865, accuracy-micro: 0.7579665184020996, accuracy-macro: 0.0037000000011176\n",
      "step:    2004, loss: 0.1698018610477448, accuracy-micro: 0.7579367756843567, accuracy-macro: 0.0037000000011176\n",
      "step:    2005, loss: 0.1697989404201508, accuracy-micro: 0.7579627633094788, accuracy-macro: 0.0037000000011176\n",
      "step:    2006, loss: 0.1697956025600433, accuracy-micro: 0.7579782605171204, accuracy-macro: 0.0037000000011176\n",
      "step:    2007, loss: 0.1697940081357956, accuracy-micro: 0.7579470276832581, accuracy-macro: 0.0037000000011176\n",
      "step:    2008, loss: 0.1697935312986374, accuracy-micro: 0.7579780220985413, accuracy-macro: 0.0037000000011176\n",
      "step:    2009, loss: 0.1697935909032822, accuracy-micro: 0.7579642534255981, accuracy-macro: 0.0037000000011176\n",
      "step:    2010, loss: 0.1697925031185150, accuracy-micro: 0.7580435276031494, accuracy-macro: 0.0037000000011176\n",
      "step:    2011, loss: 0.1697909384965897, accuracy-micro: 0.7579739689826965, accuracy-macro: 0.0037000000011176\n",
      "step:    2012, loss: 0.1697887033224106, accuracy-micro: 0.7580572366714478, accuracy-macro: 0.0037000000011176\n",
      "step:    2013, loss: 0.1697849929332733, accuracy-micro: 0.7579817771911621, accuracy-macro: 0.0037000000011176\n",
      "step:    2014, loss: 0.1697818487882614, accuracy-micro: 0.7580502629280090, accuracy-macro: 0.0037000000011176\n",
      "step:    2015, loss: 0.1697791069746017, accuracy-micro: 0.7579967379570007, accuracy-macro: 0.0037000000011176\n",
      "step:    2016, loss: 0.1697763204574585, accuracy-micro: 0.7580402493476868, accuracy-macro: 0.0037000000011176\n",
      "step:    2017, loss: 0.1697728037834167, accuracy-micro: 0.7579712271690369, accuracy-macro: 0.0037000000011176\n",
      "step:    2018, loss: 0.1697702109813690, accuracy-micro: 0.7580342292785645, accuracy-macro: 0.0037000000011176\n",
      "step:    2019, loss: 0.1697682142257690, accuracy-micro: 0.7580052614212036, accuracy-macro: 0.0037000000011176\n",
      "step:    2020, loss: 0.1697656512260437, accuracy-micro: 0.7580547332763672, accuracy-macro: 0.0037000000011176\n",
      "step:    2021, loss: 0.1697635054588318, accuracy-micro: 0.7580007314682007, accuracy-macro: 0.0037000000011176\n",
      "step:    2022, loss: 0.1697604060173035, accuracy-micro: 0.7580429911613464, accuracy-macro: 0.0037000000011176\n",
      "step:    2023, loss: 0.1697575151920319, accuracy-micro: 0.7580257654190063, accuracy-macro: 0.0037000000011176\n",
      "step:    2024, loss: 0.1697554439306259, accuracy-micro: 0.7580647468566895, accuracy-macro: 0.0037000000011176\n",
      "step:    2025, loss: 0.1697530150413513, accuracy-micro: 0.7580494880676270, accuracy-macro: 0.0037000000011176\n",
      "step:    2026, loss: 0.1697505414485931, accuracy-micro: 0.7580627202987671, accuracy-macro: 0.0037000000011176\n",
      "step:    2027, loss: 0.1697491854429245, accuracy-micro: 0.7580552697181702, accuracy-macro: 0.0037000000011176\n",
      "step:    2028, loss: 0.1697469800710678, accuracy-micro: 0.7580732703208923, accuracy-macro: 0.0037000000011176\n",
      "step:    2029, loss: 0.1697433143854141, accuracy-micro: 0.7580667734146118, accuracy-macro: 0.0037000000011176\n",
      "step:    2030, loss: 0.1697409301996231, accuracy-micro: 0.7580860257148743, accuracy-macro: 0.0037000000011176\n",
      "step:    2031, loss: 0.1697381436824799, accuracy-micro: 0.7580547332763672, accuracy-macro: 0.0037000000011176\n",
      "step:    2032, loss: 0.1697357743978500, accuracy-micro: 0.7580757737159729, accuracy-macro: 0.0037000000011176\n",
      "step:    2033, loss: 0.1697329729795456, accuracy-micro: 0.7580770254135132, accuracy-macro: 0.0037000000011176\n",
      "step:    2034, loss: 0.1697307974100113, accuracy-micro: 0.7580865025520325, accuracy-macro: 0.0037000000011176\n",
      "step:    2035, loss: 0.1697283089160919, accuracy-micro: 0.7580902576446533, accuracy-macro: 0.0037000000011176\n",
      "step:    2036, loss: 0.1697258800268173, accuracy-micro: 0.7581145167350769, accuracy-macro: 0.0037000000011176\n",
      "step:    2037, loss: 0.1697241514921188, accuracy-micro: 0.7580974698066711, accuracy-macro: 0.0037000000011176\n",
      "step:    2038, loss: 0.1697220802307129, accuracy-micro: 0.7581142187118530, accuracy-macro: 0.0037000000011176\n",
      "step:    2039, loss: 0.1697201430797577, accuracy-micro: 0.7580737471580505, accuracy-macro: 0.0037000000011176\n",
      "step:    2040, loss: 0.1697180718183517, accuracy-micro: 0.7581312656402588, accuracy-macro: 0.0037000000011176\n",
      "step:    2041, loss: 0.1697156578302383, accuracy-micro: 0.7580999732017517, accuracy-macro: 0.0037000000011176\n",
      "step:    2042, loss: 0.1697127521038055, accuracy-micro: 0.7581179738044739, accuracy-macro: 0.0037000000011176\n",
      "step:    2043, loss: 0.1697096824645996, accuracy-micro: 0.7581114768981934, accuracy-macro: 0.0037000000011176\n",
      "step:    2044, loss: 0.1697064638137817, accuracy-micro: 0.7581070065498352, accuracy-macro: 0.0037000000011176\n",
      "step:    2045, loss: 0.1697027534246445, accuracy-micro: 0.7581400275230408, accuracy-macro: 0.0037000000011176\n",
      "step:    2046, loss: 0.1697007566690445, accuracy-micro: 0.7581392526626587, accuracy-macro: 0.0037000000011176\n",
      "step:    2047, loss: 0.1696989685297012, accuracy-micro: 0.7581382393836975, accuracy-macro: 0.0037000000011176\n",
      "step:    2048, loss: 0.1696966886520386, accuracy-micro: 0.7581422328948975, accuracy-macro: 0.0037000000011176\n",
      "step:    2049, loss: 0.1696963608264923, accuracy-micro: 0.7581530213356018, accuracy-macro: 0.0037000000011176\n",
      "step:    2050, loss: 0.1696962714195251, accuracy-micro: 0.7581222653388977, accuracy-macro: 0.0037000000011176\n",
      "step:    2051, loss: 0.1696968972682953, accuracy-micro: 0.7581537365913391, accuracy-macro: 0.0037000000011176\n",
      "step:    2052, loss: 0.1696987897157669, accuracy-micro: 0.7581160068511963, accuracy-macro: 0.0037000000011176\n",
      "step:    2053, loss: 0.1697007715702057, accuracy-micro: 0.7581689953804016, accuracy-macro: 0.0037000000011176\n",
      "step:    2054, loss: 0.1697023361921310, accuracy-micro: 0.7580974698066711, accuracy-macro: 0.0037000000011176\n",
      "step:    2055, loss: 0.1697069108486176, accuracy-micro: 0.7581627368927002, accuracy-macro: 0.0037000000011176\n",
      "step:    2056, loss: 0.1697125583887100, accuracy-micro: 0.7580394744873047, accuracy-macro: 0.0037000000011176\n",
      "step:    2057, loss: 0.1697203963994980, accuracy-micro: 0.7581552267074585, accuracy-macro: 0.0037000000011176\n",
      "step:    2058, loss: 0.1697230637073517, accuracy-micro: 0.7580099701881409, accuracy-macro: 0.0037000000011176\n",
      "step:    2059, loss: 0.1697252243757248, accuracy-micro: 0.7581599950790405, accuracy-macro: 0.0037000000011176\n",
      "step:    2060, loss: 0.1697193682193756, accuracy-micro: 0.7580052614212036, accuracy-macro: 0.0037000000011176\n",
      "step:    2061, loss: 0.1697114109992981, accuracy-micro: 0.7581689953804016, accuracy-macro: 0.0037000000011176\n",
      "step:    2062, loss: 0.1696955561637878, accuracy-micro: 0.7580980062484741, accuracy-macro: 0.0037000000011176\n",
      "step:    2063, loss: 0.1696780025959015, accuracy-micro: 0.7581909894943237, accuracy-macro: 0.0037000000011176\n",
      "step:    2064, loss: 0.1696636825799942, accuracy-micro: 0.7581712603569031, accuracy-macro: 0.0037000000011176\n",
      "step:    2065, loss: 0.1696560680866241, accuracy-micro: 0.7582172751426697, accuracy-macro: 0.0037000000011176\n",
      "step:    2066, loss: 0.1696563810110092, accuracy-micro: 0.7582242488861084, accuracy-macro: 0.0037000000011176\n",
      "step:    2067, loss: 0.1696615666151047, accuracy-micro: 0.7581702470779419, accuracy-macro: 0.0037000000011176\n",
      "step:    2068, loss: 0.1696668416261673, accuracy-micro: 0.7582162618637085, accuracy-macro: 0.0037000000011176\n",
      "step:    2069, loss: 0.1696702241897583, accuracy-micro: 0.7581562399864197, accuracy-macro: 0.0037000000011176\n",
      "step:    2070, loss: 0.1696711033582687, accuracy-micro: 0.7582232356071472, accuracy-macro: 0.0037000000011176\n",
      "step:    2071, loss: 0.1696692705154419, accuracy-micro: 0.7581534981727600, accuracy-macro: 0.0037000000011176\n",
      "step:    2072, loss: 0.1696649640798569, accuracy-micro: 0.7582497596740723, accuracy-macro: 0.0037000000011176\n",
      "step:    2073, loss: 0.1696565449237823, accuracy-micro: 0.7581862211227417, accuracy-macro: 0.0037000000011176\n",
      "step:    2074, loss: 0.1696494966745377, accuracy-micro: 0.7582682371139526, accuracy-macro: 0.0037000000011176\n",
      "step:    2075, loss: 0.1696429848670959, accuracy-micro: 0.7581997513771057, accuracy-macro: 0.0037000000011176\n",
      "step:    2076, loss: 0.1696376055479050, accuracy-micro: 0.7582622766494751, accuracy-macro: 0.0037000000011176\n",
      "step:    2077, loss: 0.1696319580078125, accuracy-micro: 0.7582079768180847, accuracy-macro: 0.0037000000011176\n",
      "step:    2078, loss: 0.1696273833513260, accuracy-micro: 0.7582724690437317, accuracy-macro: 0.0037000000011176\n",
      "step:    2079, loss: 0.1696250736713409, accuracy-micro: 0.7582715153694153, accuracy-macro: 0.0037000000011176\n",
      "step:    2080, loss: 0.1696258485317230, accuracy-micro: 0.7582002282142639, accuracy-macro: 0.0037000000011176\n",
      "step:    2081, loss: 0.1696281880140305, accuracy-micro: 0.7582765221595764, accuracy-macro: 0.0037000000011176\n",
      "step:    2082, loss: 0.1696301549673080, accuracy-micro: 0.7582302689552307, accuracy-macro: 0.0037000000011176\n",
      "step:    2083, loss: 0.1696301102638245, accuracy-micro: 0.7582957744598389, accuracy-macro: 0.0037000000011176\n",
      "step:    2084, loss: 0.1696272790431976, accuracy-micro: 0.7582417726516724, accuracy-macro: 0.0037000000011176\n",
      "step:    2085, loss: 0.1696221083402634, accuracy-micro: 0.7583044767379761, accuracy-macro: 0.0037000000011176\n",
      "step:    2086, loss: 0.1696147918701172, accuracy-micro: 0.7582464814186096, accuracy-macro: 0.0037000000011176\n",
      "step:    2087, loss: 0.1696086823940277, accuracy-micro: 0.7583052515983582, accuracy-macro: 0.0037000000011176\n",
      "step:    2088, loss: 0.1696047633886337, accuracy-micro: 0.7583077549934387, accuracy-macro: 0.0037000000011176\n",
      "step:    2089, loss: 0.1696030050516129, accuracy-micro: 0.7582939863204956, accuracy-macro: 0.0037000000011176\n",
      "step:    2090, loss: 0.1696015298366547, accuracy-micro: 0.7583029866218567, accuracy-macro: 0.0037000000011176\n",
      "step:    2091, loss: 0.1696007996797562, accuracy-micro: 0.7582604885101318, accuracy-macro: 0.0037000000011176\n",
      "step:    2092, loss: 0.1695989072322845, accuracy-micro: 0.7583249807357788, accuracy-macro: 0.0037000000011176\n",
      "step:    2093, loss: 0.1695975661277771, accuracy-micro: 0.7582920193672180, accuracy-macro: 0.0037000000011176\n",
      "step:    2094, loss: 0.1695945113897324, accuracy-micro: 0.7583442330360413, accuracy-macro: 0.0037000000011176\n",
      "step:    2095, loss: 0.1695910096168518, accuracy-micro: 0.7582902312278748, accuracy-macro: 0.0037000000011176\n",
      "step:    2096, loss: 0.1695872843265533, accuracy-micro: 0.7583220005035400, accuracy-macro: 0.0037000000011176\n",
      "step:    2097, loss: 0.1695847362279892, accuracy-micro: 0.7583182454109192, accuracy-macro: 0.0037000000011176\n",
      "step:    2098, loss: 0.1695825159549713, accuracy-micro: 0.7583352327346802, accuracy-macro: 0.0037000000011176\n",
      "step:    2099, loss: 0.1695804595947266, accuracy-micro: 0.7583314776420593, accuracy-macro: 0.0037000000011176\n",
      "step:    2100, loss: 0.1695782244205475, accuracy-micro: 0.7583159804344177, accuracy-macro: 0.0037000000011176\n",
      "step:    2101, loss: 0.1695767492055893, accuracy-micro: 0.7583387494087219, accuracy-macro: 0.0037000000011176\n",
      "step:    2102, loss: 0.1695754677057266, accuracy-micro: 0.7583237290382385, accuracy-macro: 0.0037000000011176\n",
      "step:    2103, loss: 0.1695734858512878, accuracy-micro: 0.7583707571029663, accuracy-macro: 0.0037000000011176\n",
      "step:    2104, loss: 0.1695712804794312, accuracy-micro: 0.7583377361297607, accuracy-macro: 0.0037000000011176\n",
      "step:    2105, loss: 0.1695687919855118, accuracy-micro: 0.7583797574043274, accuracy-macro: 0.0037000000011176\n",
      "step:    2106, loss: 0.1695655882358551, accuracy-micro: 0.7583410143852234, accuracy-macro: 0.0037000000011176\n",
      "step:    2107, loss: 0.1695631444454193, accuracy-micro: 0.7583527565002441, accuracy-macro: 0.0037000000011176\n",
      "step:    2108, loss: 0.1695603132247925, accuracy-micro: 0.7583562731742859, accuracy-macro: 0.0037000000011176\n",
      "step:    2109, loss: 0.1695588082075119, accuracy-micro: 0.7583655118942261, accuracy-macro: 0.0037000000011176\n",
      "step:    2110, loss: 0.1695578992366791, accuracy-micro: 0.7583787441253662, accuracy-macro: 0.0037000000011176\n",
      "step:    2111, loss: 0.1695569008588791, accuracy-micro: 0.7583297491073608, accuracy-macro: 0.0037000000011176\n",
      "step:    2112, loss: 0.1695563644170761, accuracy-micro: 0.7583727240562439, accuracy-macro: 0.0037000000011176\n",
      "step:    2113, loss: 0.1695550382137299, accuracy-micro: 0.7583649754524231, accuracy-macro: 0.0037000000011176\n",
      "step:    2114, loss: 0.1695528477430344, accuracy-micro: 0.7584170103073120, accuracy-macro: 0.0037000000011176\n",
      "step:    2115, loss: 0.1695500910282135, accuracy-micro: 0.7583749890327454, accuracy-macro: 0.0037000000011176\n",
      "step:    2116, loss: 0.1695464402437210, accuracy-micro: 0.7584087252616882, accuracy-macro: 0.0037000000011176\n",
      "step:    2117, loss: 0.1695429682731628, accuracy-micro: 0.7583655118942261, accuracy-macro: 0.0037000000011176\n",
      "step:    2118, loss: 0.1695396751165390, accuracy-micro: 0.7584092617034912, accuracy-macro: 0.0037000000011176\n",
      "step:    2119, loss: 0.1695359051227570, accuracy-micro: 0.7584012746810913, accuracy-macro: 0.0037000000011176\n",
      "step:    2120, loss: 0.1695343703031540, accuracy-micro: 0.7583990097045898, accuracy-macro: 0.0037000000011176\n",
      "step:    2121, loss: 0.1695328503847122, accuracy-micro: 0.7584120035171509, accuracy-macro: 0.0037000000011176\n",
      "step:    2122, loss: 0.1695320457220078, accuracy-micro: 0.7583824992179871, accuracy-macro: 0.0037000000011176\n",
      "step:    2123, loss: 0.1695320010185242, accuracy-micro: 0.7584237456321716, accuracy-macro: 0.0037000000011176\n",
      "step:    2124, loss: 0.1695321053266525, accuracy-micro: 0.7583892345428467, accuracy-macro: 0.0037000000011176\n",
      "step:    2125, loss: 0.1695325225591660, accuracy-micro: 0.7584829926490784, accuracy-macro: 0.0037000000011176\n",
      "step:    2126, loss: 0.1695336848497391, accuracy-micro: 0.7584049701690674, accuracy-macro: 0.0037000000011176\n",
      "step:    2127, loss: 0.1695348769426346, accuracy-micro: 0.7584727406501770, accuracy-macro: 0.0037000000011176\n",
      "step:    2128, loss: 0.1695338785648346, accuracy-micro: 0.7583994865417480, accuracy-macro: 0.0037000000011176\n",
      "step:    2129, loss: 0.1695315241813660, accuracy-micro: 0.7584924697875977, accuracy-macro: 0.0037000000011176\n",
      "step:    2130, loss: 0.1695284098386765, accuracy-micro: 0.7584210038185120, accuracy-macro: 0.0037000000011176\n",
      "step:    2131, loss: 0.1695251315832138, accuracy-micro: 0.7584912776947021, accuracy-macro: 0.0037000000011176\n",
      "step:    2132, loss: 0.1695214658975601, accuracy-micro: 0.7584402561187744, accuracy-macro: 0.0037000000011176\n",
      "step:    2133, loss: 0.1695173084735870, accuracy-micro: 0.7585082650184631, accuracy-macro: 0.0037000000011176\n",
      "step:    2134, loss: 0.1695132255554199, accuracy-micro: 0.7584387660026550, accuracy-macro: 0.0037000000011176\n",
      "step:    2135, loss: 0.1695103049278259, accuracy-micro: 0.7585039734840393, accuracy-macro: 0.0037000000011176\n",
      "step:    2136, loss: 0.1695066839456558, accuracy-micro: 0.7584402561187744, accuracy-macro: 0.0037000000011176\n",
      "step:    2137, loss: 0.1695025861263275, accuracy-micro: 0.7584812641143799, accuracy-macro: 0.0037000000011176\n",
      "step:    2138, loss: 0.1694975495338440, accuracy-micro: 0.7584467530250549, accuracy-macro: 0.0037000000011176\n",
      "step:    2139, loss: 0.1694931387901306, accuracy-micro: 0.7584695219993591, accuracy-macro: 0.0037000000011176\n",
      "step:    2140, loss: 0.1694907248020172, accuracy-micro: 0.7584664821624756, accuracy-macro: 0.0037000000011176\n",
      "step:    2141, loss: 0.1694894880056381, accuracy-micro: 0.7584542632102966, accuracy-macro: 0.0037000000011176\n",
      "step:    2142, loss: 0.1694908887147903, accuracy-micro: 0.7585185170173645, accuracy-macro: 0.0037000000011176\n",
      "step:    2143, loss: 0.1694936305284500, accuracy-micro: 0.7584877610206604, accuracy-macro: 0.0037000000011176\n",
      "step:    2144, loss: 0.1694980263710022, accuracy-micro: 0.7585269808769226, accuracy-macro: 0.0037000000011176\n",
      "step:    2145, loss: 0.1695023477077484, accuracy-micro: 0.7584459781646729, accuracy-macro: 0.0037000000011176\n",
      "step:    2146, loss: 0.1695059984922409, accuracy-micro: 0.7585505247116089, accuracy-macro: 0.0037000000011176\n",
      "step:    2147, loss: 0.1695038229227066, accuracy-micro: 0.7584062218666077, accuracy-macro: 0.0037000000011176\n",
      "step:    2148, loss: 0.1694999933242798, accuracy-micro: 0.7585535049438477, accuracy-macro: 0.0037000000011176\n",
      "step:    2149, loss: 0.1694944202899933, accuracy-micro: 0.7584484815597534, accuracy-macro: 0.0037000000011176\n",
      "step:    2150, loss: 0.1694903522729874, accuracy-micro: 0.7585322260856628, accuracy-macro: 0.0037000000011176\n",
      "step:    2151, loss: 0.1694856882095337, accuracy-micro: 0.7584792375564575, accuracy-macro: 0.0037000000011176\n",
      "step:    2152, loss: 0.1694803088903427, accuracy-micro: 0.7585537433624268, accuracy-macro: 0.0037000000011176\n",
      "step:    2153, loss: 0.1694750636816025, accuracy-micro: 0.7585467696189880, accuracy-macro: 0.0037000000011176\n",
      "step:    2154, loss: 0.1694678813219070, accuracy-micro: 0.7585794925689697, accuracy-macro: 0.0037000000011176\n",
      "step:    2155, loss: 0.1694618761539459, accuracy-micro: 0.7585362195968628, accuracy-macro: 0.0037000000011176\n",
      "step:    2156, loss: 0.1694572716951370, accuracy-micro: 0.7585432529449463, accuracy-macro: 0.0037000000011176\n",
      "step:    2157, loss: 0.1694530546665192, accuracy-micro: 0.7585219740867615, accuracy-macro: 0.0037000000011176\n",
      "step:    2158, loss: 0.1694517135620117, accuracy-micro: 0.7585330009460449, accuracy-macro: 0.0037000000011176\n",
      "step:    2159, loss: 0.1694508492946625, accuracy-micro: 0.7585694789886475, accuracy-macro: 0.0037000000011176\n",
      "step:    2160, loss: 0.1694518476724625, accuracy-micro: 0.7585482597351074, accuracy-macro: 0.0037000000011176\n",
      "step:    2161, loss: 0.1694511920213699, accuracy-micro: 0.7585977315902710, accuracy-macro: 0.0037000000011176\n",
      "step:    2162, loss: 0.1694501489400864, accuracy-micro: 0.7585384845733643, accuracy-macro: 0.0037000000011176\n",
      "step:    2163, loss: 0.1694467812776566, accuracy-micro: 0.7585997581481934, accuracy-macro: 0.0037000000011176\n",
      "step:    2164, loss: 0.1694423854351044, accuracy-micro: 0.7585622668266296, accuracy-macro: 0.0037000000011176\n",
      "step:    2165, loss: 0.1694378703832626, accuracy-micro: 0.7585914731025696, accuracy-macro: 0.0037000000011176\n",
      "step:    2166, loss: 0.1694343686103821, accuracy-micro: 0.7585704922676086, accuracy-macro: 0.0037000000011176\n",
      "step:    2167, loss: 0.1694317758083344, accuracy-micro: 0.7585805058479309, accuracy-macro: 0.0037000000011176\n",
      "step:    2168, loss: 0.1694304049015045, accuracy-micro: 0.7585849761962891, accuracy-macro: 0.0037000000011176\n",
      "step:    2169, loss: 0.1694282144308090, accuracy-micro: 0.7585832476615906, accuracy-macro: 0.0037000000011176\n",
      "step:    2170, loss: 0.1694275587797165, accuracy-micro: 0.7586332559585571, accuracy-macro: 0.0037000000011176\n",
      "step:    2171, loss: 0.1694279313087463, accuracy-micro: 0.7585799694061279, accuracy-macro: 0.0037000000011176\n",
      "step:    2172, loss: 0.1694292128086090, accuracy-micro: 0.7586577534675598, accuracy-macro: 0.0037000000011176\n",
      "step:    2173, loss: 0.1694303452968597, accuracy-micro: 0.7585589885711670, accuracy-macro: 0.0037000000011176\n",
      "step:    2174, loss: 0.1694305241107941, accuracy-micro: 0.7586452364921570, accuracy-macro: 0.0037000000011176\n",
      "step:    2175, loss: 0.1694283336400986, accuracy-micro: 0.7585677504539490, accuracy-macro: 0.0037000000011176\n",
      "step:    2176, loss: 0.1694254428148270, accuracy-micro: 0.7586780190467834, accuracy-macro: 0.0037000000011176\n",
      "step:    2177, loss: 0.1694201380014420, accuracy-micro: 0.7585934996604919, accuracy-macro: 0.0037000000011176\n",
      "step:    2178, loss: 0.1694150567054749, accuracy-micro: 0.7586740255355835, accuracy-macro: 0.0037000000011176\n",
      "step:    2179, loss: 0.1694101244211197, accuracy-micro: 0.7586057186126709, accuracy-macro: 0.0037000000011176\n",
      "step:    2180, loss: 0.1694057881832123, accuracy-micro: 0.7586492300033569, accuracy-macro: 0.0037000000011176\n",
      "step:    2181, loss: 0.1694022119045258, accuracy-micro: 0.7586212754249573, accuracy-macro: 0.0037000000011176\n",
      "step:    2182, loss: 0.1693996340036392, accuracy-micro: 0.7586269974708557, accuracy-macro: 0.0037000000011176\n",
      "step:    2183, loss: 0.1693975925445557, accuracy-micro: 0.7586259841918945, accuracy-macro: 0.0037000000011176\n",
      "step:    2184, loss: 0.1693951189517975, accuracy-micro: 0.7586389780044556, accuracy-macro: 0.0037000000011176\n",
      "step:    2185, loss: 0.1693933457136154, accuracy-micro: 0.7586525082588196, accuracy-macro: 0.0037000000011176\n",
      "step:    2186, loss: 0.1693909913301468, accuracy-micro: 0.7586460113525391, accuracy-macro: 0.0037000000011176\n",
      "step:    2187, loss: 0.1693885028362274, accuracy-micro: 0.7586489915847778, accuracy-macro: 0.0037000000011176\n",
      "step:    2188, loss: 0.1693869382143021, accuracy-micro: 0.7586690187454224, accuracy-macro: 0.0037000000011176\n",
      "step:    2189, loss: 0.1693842858076096, accuracy-micro: 0.7586669921875000, accuracy-macro: 0.0037000000011176\n",
      "step:    2190, loss: 0.1693825125694275, accuracy-micro: 0.7586677670478821, accuracy-macro: 0.0037000000011176\n",
      "step:    2191, loss: 0.1693804115056992, accuracy-micro: 0.7586587667465210, accuracy-macro: 0.0037000000011176\n",
      "step:    2192, loss: 0.1693778932094574, accuracy-micro: 0.7586557269096375, accuracy-macro: 0.0037000000011176\n",
      "step:    2193, loss: 0.1693759709596634, accuracy-micro: 0.7586560249328613, accuracy-macro: 0.0037000000011176\n",
      "step:    2194, loss: 0.1693742871284485, accuracy-micro: 0.7586812376976013, accuracy-macro: 0.0037000000011176\n",
      "step:    2195, loss: 0.1693727225065231, accuracy-micro: 0.7586852312088013, accuracy-macro: 0.0037000000011176\n",
      "step:    2196, loss: 0.1693715900182724, accuracy-micro: 0.7587124705314636, accuracy-macro: 0.0037000000011176\n",
      "step:    2197, loss: 0.1693686544895172, accuracy-micro: 0.7586997747421265, accuracy-macro: 0.0037000000011176\n",
      "step:    2198, loss: 0.1693661510944366, accuracy-micro: 0.7586807608604431, accuracy-macro: 0.0037000000011176\n",
      "step:    2199, loss: 0.1693633049726486, accuracy-micro: 0.7586989998817444, accuracy-macro: 0.0037000000011176\n",
      "step:    2200, loss: 0.1693610250949860, accuracy-micro: 0.7587034702301025, accuracy-macro: 0.0037000000011176\n",
      "step:    2201, loss: 0.1693594753742218, accuracy-micro: 0.7586952447891235, accuracy-macro: 0.0037000000011176\n",
      "step:    2202, loss: 0.1693573743104935, accuracy-micro: 0.7587124705314636, accuracy-macro: 0.0037000000011176\n",
      "step:    2203, loss: 0.1693557500839233, accuracy-micro: 0.7587209939956665, accuracy-macro: 0.0037000000011176\n",
      "step:    2204, loss: 0.1693537533283234, accuracy-micro: 0.7587050199508667, accuracy-macro: 0.0037000000011176\n",
      "step:    2205, loss: 0.1693518310785294, accuracy-micro: 0.7587312459945679, accuracy-macro: 0.0037000000011176\n",
      "step:    2206, loss: 0.1693507432937622, accuracy-micro: 0.7587130069732666, accuracy-macro: 0.0037000000011176\n",
      "step:    2207, loss: 0.1693497449159622, accuracy-micro: 0.7587429881095886, accuracy-macro: 0.0037000000011176\n",
      "step:    2208, loss: 0.1693487763404846, accuracy-micro: 0.7587170004844666, accuracy-macro: 0.0037000000011176\n",
      "step:    2209, loss: 0.1693489402532578, accuracy-micro: 0.7587882280349731, accuracy-macro: 0.0037000000011176\n",
      "step:    2210, loss: 0.1693479716777802, accuracy-micro: 0.7587040066719055, accuracy-macro: 0.0037000000011176\n",
      "step:    2211, loss: 0.1693460196256638, accuracy-micro: 0.7587980031967163, accuracy-macro: 0.0037000000011176\n",
      "step:    2212, loss: 0.1693441569805145, accuracy-micro: 0.7587270140647888, accuracy-macro: 0.0037000000011176\n",
      "step:    2213, loss: 0.1693415343761444, accuracy-micro: 0.7588192224502563, accuracy-macro: 0.0037000000011176\n",
      "step:    2214, loss: 0.1693387776613235, accuracy-micro: 0.7587327361106873, accuracy-macro: 0.0037000000011176\n",
      "step:    2215, loss: 0.1693353801965714, accuracy-micro: 0.7588082551956177, accuracy-macro: 0.0037000000011176\n",
      "step:    2216, loss: 0.1693312078714371, accuracy-micro: 0.7587729692459106, accuracy-macro: 0.0037000000011176\n",
      "step:    2217, loss: 0.1693277955055237, accuracy-micro: 0.7587795257568359, accuracy-macro: 0.0037000000011176\n",
      "step:    2218, loss: 0.1693248450756073, accuracy-micro: 0.7587787508964539, accuracy-macro: 0.0037000000011176\n",
      "step:    2219, loss: 0.1693226546049118, accuracy-micro: 0.7587534785270691, accuracy-macro: 0.0037000000011176\n",
      "step:    2220, loss: 0.1693197786808014, accuracy-micro: 0.7587599754333496, accuracy-macro: 0.0037000000011176\n",
      "step:    2221, loss: 0.1693172901868820, accuracy-micro: 0.7587812542915344, accuracy-macro: 0.0037000000011176\n",
      "step:    2222, loss: 0.1693155914545059, accuracy-micro: 0.7587797641754150, accuracy-macro: 0.0037000000011176\n",
      "step:    2223, loss: 0.1693134009838104, accuracy-micro: 0.7587812542915344, accuracy-macro: 0.0037000000011176\n",
      "step:    2224, loss: 0.1693109571933746, accuracy-micro: 0.7587714791297913, accuracy-macro: 0.0037000000011176\n",
      "step:    2225, loss: 0.1693087518215179, accuracy-micro: 0.7587822675704956, accuracy-macro: 0.0037000000011176\n",
      "step:    2226, loss: 0.1693075001239777, accuracy-micro: 0.7587977647781372, accuracy-macro: 0.0037000000011176\n",
      "step:    2227, loss: 0.1693054735660553, accuracy-micro: 0.7588095068931580, accuracy-macro: 0.0037000000011176\n",
      "step:    2228, loss: 0.1693032234907150, accuracy-micro: 0.7588032484054565, accuracy-macro: 0.0037000000011176\n",
      "step:    2229, loss: 0.1693007200956345, accuracy-micro: 0.7588030099868774, accuracy-macro: 0.0037000000011176\n",
      "step:    2230, loss: 0.1692985296249390, accuracy-micro: 0.7587869763374329, accuracy-macro: 0.0037000000011176\n",
      "step:    2231, loss: 0.1692961901426315, accuracy-micro: 0.7588032484054565, accuracy-macro: 0.0037000000011176\n",
      "step:    2232, loss: 0.1692947894334793, accuracy-micro: 0.7588287591934204, accuracy-macro: 0.0037000000011176\n",
      "step:    2233, loss: 0.1692930310964584, accuracy-micro: 0.7588095068931580, accuracy-macro: 0.0037000000011176\n",
      "step:    2234, loss: 0.1692908704280853, accuracy-micro: 0.7588107585906982, accuracy-macro: 0.0037000000011176\n",
      "step:    2235, loss: 0.1692900061607361, accuracy-micro: 0.7588124871253967, accuracy-macro: 0.0037000000011176\n",
      "step:    2236, loss: 0.1692880690097809, accuracy-micro: 0.7588390111923218, accuracy-macro: 0.0037000000011176\n",
      "step:    2237, loss: 0.1692869216203690, accuracy-micro: 0.7588377594947815, accuracy-macro: 0.0037000000011176\n",
      "step:    2238, loss: 0.1692855656147003, accuracy-micro: 0.7588507533073425, accuracy-macro: 0.0037000000011176\n",
      "step:    2239, loss: 0.1692854017019272, accuracy-micro: 0.7588254809379578, accuracy-macro: 0.0037000000011176\n",
      "step:    2240, loss: 0.1692852824926376, accuracy-micro: 0.7588739991188049, accuracy-macro: 0.0037000000011176\n",
      "step:    2241, loss: 0.1692859232425690, accuracy-micro: 0.7587999701499939, accuracy-macro: 0.0037000000011176\n",
      "step:    2242, loss: 0.1692867428064346, accuracy-micro: 0.7588930130004883, accuracy-macro: 0.0037000000011176\n",
      "step:    2243, loss: 0.1692887842655182, accuracy-micro: 0.7587584853172302, accuracy-macro: 0.0037000000011176\n",
      "step:    2244, loss: 0.1692930608987808, accuracy-micro: 0.7588815093040466, accuracy-macro: 0.0037000000011176\n",
      "step:    2245, loss: 0.1692947894334793, accuracy-micro: 0.7587404847145081, accuracy-macro: 0.0037000000011176\n",
      "step:    2246, loss: 0.1692956835031509, accuracy-micro: 0.7588685154914856, accuracy-macro: 0.0037000000011176\n",
      "step:    2247, loss: 0.1692949086427689, accuracy-micro: 0.7587335109710693, accuracy-macro: 0.0037000000011176\n",
      "step:    2248, loss: 0.1692928075790405, accuracy-micro: 0.7588775157928467, accuracy-macro: 0.0037000000011176\n",
      "step:    2249, loss: 0.1692900359630585, accuracy-micro: 0.7587552666664124, accuracy-macro: 0.0037000000011176\n",
      "step:    2250, loss: 0.1692891269922256, accuracy-micro: 0.7588934898376465, accuracy-macro: 0.0037000000011176\n",
      "step:    2251, loss: 0.1692865937948227, accuracy-micro: 0.7587592601776123, accuracy-macro: 0.0037000000011176\n",
      "step:    2252, loss: 0.1692841798067093, accuracy-micro: 0.7588867545127869, accuracy-macro: 0.0037000000011176\n",
      "step:    2253, loss: 0.1692777425050735, accuracy-micro: 0.7587710022926331, accuracy-macro: 0.0037000000011176\n",
      "step:    2254, loss: 0.1692673563957214, accuracy-micro: 0.7589280009269714, accuracy-macro: 0.0037000000011176\n",
      "step:    2255, loss: 0.1692554056644440, accuracy-micro: 0.7588432431221008, accuracy-macro: 0.0037000000011176\n",
      "step:    2256, loss: 0.1692470908164978, accuracy-micro: 0.7589122653007507, accuracy-macro: 0.0037000000011176\n",
      "step:    2257, loss: 0.1692429780960083, accuracy-micro: 0.7589077353477478, accuracy-macro: 0.0037000000011176\n",
      "step:    2258, loss: 0.1692429929971695, accuracy-micro: 0.7588855028152466, accuracy-macro: 0.0037000000011176\n",
      "step:    2259, loss: 0.1692448109388351, accuracy-micro: 0.7589225172996521, accuracy-macro: 0.0037000000011176\n",
      "step:    2260, loss: 0.1692464649677277, accuracy-micro: 0.7588415145874023, accuracy-macro: 0.0037000000011176\n",
      "step:    2261, loss: 0.1692481935024261, accuracy-micro: 0.7589564919471741, accuracy-macro: 0.0037000000011176\n",
      "step:    2262, loss: 0.1692490428686142, accuracy-micro: 0.7588130235671997, accuracy-macro: 0.0037000000011176\n",
      "step:    2263, loss: 0.1692476272583008, accuracy-micro: 0.7589562535285950, accuracy-macro: 0.0037000000011176\n",
      "step:    2264, loss: 0.1692442148923874, accuracy-micro: 0.7588145136833191, accuracy-macro: 0.0037000000011176\n",
      "step:    2265, loss: 0.1692395210266113, accuracy-micro: 0.7589715123176575, accuracy-macro: 0.0037000000011176\n",
      "step:    2266, loss: 0.1692347973585129, accuracy-micro: 0.7588642239570618, accuracy-macro: 0.0037000000011176\n",
      "step:    2267, loss: 0.1692303270101547, accuracy-micro: 0.7589734792709351, accuracy-macro: 0.0037000000011176\n",
      "step:    2268, loss: 0.1692248135805130, accuracy-micro: 0.7589037418365479, accuracy-macro: 0.0037000000011176\n",
      "step:    2269, loss: 0.1692204028367996, accuracy-micro: 0.7589622735977173, accuracy-macro: 0.0037000000011176\n",
      "step:    2270, loss: 0.1692176312208176, accuracy-micro: 0.7589380145072937, accuracy-macro: 0.0037000000011176\n",
      "step:    2271, loss: 0.1692153811454773, accuracy-micro: 0.7589432597160339, accuracy-macro: 0.0037000000011176\n",
      "step:    2272, loss: 0.1692136824131012, accuracy-micro: 0.7589402198791504, accuracy-macro: 0.0037000000011176\n",
      "step:    2273, loss: 0.1692124009132385, accuracy-micro: 0.7589267492294312, accuracy-macro: 0.0037000000011176\n",
      "step:    2274, loss: 0.1692115664482117, accuracy-micro: 0.7589839696884155, accuracy-macro: 0.0037000000011176\n",
      "step:    2275, loss: 0.1692100316286087, accuracy-micro: 0.7589150071144104, accuracy-macro: 0.0037000000011176\n",
      "step:    2276, loss: 0.1692079007625580, accuracy-micro: 0.7589737772941589, accuracy-macro: 0.0037000000011176\n",
      "step:    2277, loss: 0.1692051142454147, accuracy-micro: 0.7589207291603088, accuracy-macro: 0.0037000000011176\n",
      "step:    2278, loss: 0.1692038029432297, accuracy-micro: 0.7589852213859558, accuracy-macro: 0.0037000000011176\n",
      "step:    2279, loss: 0.1692025363445282, accuracy-micro: 0.7589262723922729, accuracy-macro: 0.0037000000011176\n",
      "step:    2280, loss: 0.1692010909318924, accuracy-micro: 0.7590307593345642, accuracy-macro: 0.0037000000011176\n",
      "step:    2281, loss: 0.1692001819610596, accuracy-micro: 0.7589102387428284, accuracy-macro: 0.0037000000011176\n",
      "step:    2282, loss: 0.1692000627517700, accuracy-micro: 0.7590115070343018, accuracy-macro: 0.0037000000011176\n",
      "step:    2283, loss: 0.1691990345716476, accuracy-micro: 0.7589305043220520, accuracy-macro: 0.0037000000011176\n",
      "step:    2284, loss: 0.1691978424787521, accuracy-micro: 0.7590255141258240, accuracy-macro: 0.0037000000011176\n",
      "step:    2285, loss: 0.1691971570253372, accuracy-micro: 0.7589269876480103, accuracy-macro: 0.0037000000011176\n",
      "step:    2286, loss: 0.1691942512989044, accuracy-micro: 0.7590270042419434, accuracy-macro: 0.0037000000011176\n",
      "step:    2287, loss: 0.1691911667585373, accuracy-micro: 0.7589372396469116, accuracy-macro: 0.0037000000011176\n",
      "step:    2288, loss: 0.1691889464855194, accuracy-micro: 0.7590159773826599, accuracy-macro: 0.0037000000011176\n",
      "step:    2289, loss: 0.1691861897706985, accuracy-micro: 0.7589297294616699, accuracy-macro: 0.0037000000011176\n",
      "step:    2290, loss: 0.1691833883523941, accuracy-micro: 0.7590184807777405, accuracy-macro: 0.0037000000011176\n",
      "step:    2291, loss: 0.1691812723875046, accuracy-micro: 0.7589397430419922, accuracy-macro: 0.0037000000011176\n",
      "step:    2292, loss: 0.1691791713237762, accuracy-micro: 0.7590387463569641, accuracy-macro: 0.0037000000011176\n",
      "step:    2293, loss: 0.1691769212484360, accuracy-micro: 0.7589499950408936, accuracy-macro: 0.0037000000011176\n",
      "step:    2294, loss: 0.1691738069057465, accuracy-micro: 0.7590339779853821, accuracy-macro: 0.0037000000011176\n",
      "step:    2295, loss: 0.1691701859235764, accuracy-micro: 0.7589937448501587, accuracy-macro: 0.0037000000011176\n",
      "step:    2296, loss: 0.1691673547029495, accuracy-micro: 0.7590500116348267, accuracy-macro: 0.0037000000011176\n",
      "step:    2297, loss: 0.1691641807556152, accuracy-micro: 0.7590284943580627, accuracy-macro: 0.0037000000011176\n",
      "step:    2298, loss: 0.1691612899303436, accuracy-micro: 0.7590299844741821, accuracy-macro: 0.0037000000011176\n",
      "step:    2299, loss: 0.1691594719886780, accuracy-micro: 0.7590387463569641, accuracy-macro: 0.0037000000011176\n",
      "step:    2300, loss: 0.1691583245992661, accuracy-micro: 0.7590119838714600, accuracy-macro: 0.0037000000011176\n",
      "step:    2301, loss: 0.1691566407680511, accuracy-micro: 0.7590517401695251, accuracy-macro: 0.0037000000011176\n",
      "step:    2302, loss: 0.1691564768552780, accuracy-micro: 0.7589997649192810, accuracy-macro: 0.0037000000011176\n",
      "step:    2303, loss: 0.1691569089889526, accuracy-micro: 0.7590569853782654, accuracy-macro: 0.0037000000011176\n",
      "step:    2304, loss: 0.1691574752330780, accuracy-micro: 0.7589805126190186, accuracy-macro: 0.0037000000011176\n",
      "step:    2305, loss: 0.1691595315933228, accuracy-micro: 0.7590742707252502, accuracy-macro: 0.0037000000011176\n",
      "step:    2306, loss: 0.1691606193780899, accuracy-micro: 0.7589809894561768, accuracy-macro: 0.0037000000011176\n",
      "step:    2307, loss: 0.1691619902849197, accuracy-micro: 0.7591189742088318, accuracy-macro: 0.0037000000011176\n",
      "step:    2308, loss: 0.1691614389419556, accuracy-micro: 0.7589899897575378, accuracy-macro: 0.0037000000011176\n",
      "step:    2309, loss: 0.1691583245992661, accuracy-micro: 0.7591025233268738, accuracy-macro: 0.0037000000011176\n",
      "step:    2310, loss: 0.1691527217626572, accuracy-micro: 0.7589945197105408, accuracy-macro: 0.0037000000011176\n",
      "step:    2311, loss: 0.1691485196352005, accuracy-micro: 0.7591062188148499, accuracy-macro: 0.0037000000011176\n",
      "step:    2312, loss: 0.1691445410251617, accuracy-micro: 0.7590012550354004, accuracy-macro: 0.0037000000011176\n",
      "step:    2313, loss: 0.1691409349441528, accuracy-micro: 0.7591094970703125, accuracy-macro: 0.0037000000011176\n",
      "step:    2314, loss: 0.1691358536481857, accuracy-micro: 0.7590457201004028, accuracy-macro: 0.0037000000011176\n",
      "step:    2315, loss: 0.1691320538520813, accuracy-micro: 0.7591052651405334, accuracy-macro: 0.0037000000011176\n",
      "step:    2316, loss: 0.1691292226314545, accuracy-micro: 0.7590332627296448, accuracy-macro: 0.0037000000011176\n",
      "step:    2317, loss: 0.1691277027130127, accuracy-micro: 0.7591004967689514, accuracy-macro: 0.0037000000011176\n",
      "step:    2318, loss: 0.1691264659166336, accuracy-micro: 0.7590737342834473, accuracy-macro: 0.0037000000011176\n",
      "step:    2319, loss: 0.1691258847713470, accuracy-micro: 0.7591279745101929, accuracy-macro: 0.0037000000011176\n",
      "step:    2320, loss: 0.1691250652074814, accuracy-micro: 0.7590619921684265, accuracy-macro: 0.0037000000011176\n",
      "step:    2321, loss: 0.1691233962774277, accuracy-micro: 0.7591272592544556, accuracy-macro: 0.0037000000011176\n",
      "step:    2322, loss: 0.1691222339868546, accuracy-micro: 0.7590284943580627, accuracy-macro: 0.0037000000011176\n",
      "step:    2323, loss: 0.1691203117370605, accuracy-micro: 0.7591317296028137, accuracy-macro: 0.0037000000011176\n",
      "step:    2324, loss: 0.1691184341907501, accuracy-micro: 0.7590652704238892, accuracy-macro: 0.0037000000011176\n",
      "step:    2325, loss: 0.1691164672374725, accuracy-micro: 0.7591335177421570, accuracy-macro: 0.0037000000011176\n",
      "step:    2326, loss: 0.1691146939992905, accuracy-micro: 0.7590519785881042, accuracy-macro: 0.0037000000011176\n",
      "step:    2327, loss: 0.1691130101680756, accuracy-micro: 0.7591447234153748, accuracy-macro: 0.0037000000011176\n",
      "step:    2328, loss: 0.1691097319126129, accuracy-micro: 0.7590757608413696, accuracy-macro: 0.0037000000011176\n",
      "step:    2329, loss: 0.1691062748432159, accuracy-micro: 0.7591499686241150, accuracy-macro: 0.0037000000011176\n",
      "step:    2330, loss: 0.1691024750471115, accuracy-micro: 0.7591149806976318, accuracy-macro: 0.0037000000011176\n",
      "step:    2331, loss: 0.1690981835126877, accuracy-micro: 0.7591357231140137, accuracy-macro: 0.0037000000011176\n",
      "step:    2332, loss: 0.1690960973501205, accuracy-micro: 0.7591292262077332, accuracy-macro: 0.0037000000011176\n",
      "step:    2333, loss: 0.1690929979085922, accuracy-micro: 0.7591310143470764, accuracy-macro: 0.0037000000011176\n",
      "step:    2334, loss: 0.1690915971994400, accuracy-micro: 0.7591544985771179, accuracy-macro: 0.0037000000011176\n",
      "step:    2335, loss: 0.1690903156995773, accuracy-micro: 0.7591434717178345, accuracy-macro: 0.0037000000011176\n",
      "step:    2336, loss: 0.1690890341997147, accuracy-micro: 0.7591664791107178, accuracy-macro: 0.0037000000011176\n",
      "step:    2337, loss: 0.1690868735313416, accuracy-micro: 0.7591369748115540, accuracy-macro: 0.0037000000011176\n",
      "step:    2338, loss: 0.1690856516361237, accuracy-micro: 0.7591702342033386, accuracy-macro: 0.0037000000011176\n",
      "step:    2339, loss: 0.1690830886363983, accuracy-micro: 0.7591595053672791, accuracy-macro: 0.0037000000011176\n",
      "step:    2340, loss: 0.1690810918807983, accuracy-micro: 0.7591999769210815, accuracy-macro: 0.0037000000011176\n",
      "step:    2341, loss: 0.1690788120031357, accuracy-micro: 0.7591404914855957, accuracy-macro: 0.0037000000011176\n",
      "step:    2342, loss: 0.1690769344568253, accuracy-micro: 0.7591517567634583, accuracy-macro: 0.0037000000011176\n",
      "step:    2343, loss: 0.1690751612186432, accuracy-micro: 0.7591835260391235, accuracy-macro: 0.0037000000011176\n",
      "step:    2344, loss: 0.1690743118524551, accuracy-micro: 0.7591532468795776, accuracy-macro: 0.0037000000011176\n",
      "step:    2345, loss: 0.1690737903118134, accuracy-micro: 0.7591904997825623, accuracy-macro: 0.0037000000011176\n",
      "step:    2346, loss: 0.1690736413002014, accuracy-micro: 0.7591487765312195, accuracy-macro: 0.0037000000011176\n",
      "step:    2347, loss: 0.1690745055675507, accuracy-micro: 0.7592052221298218, accuracy-macro: 0.0037000000011176\n",
      "step:    2348, loss: 0.1690760850906372, accuracy-micro: 0.7591397762298584, accuracy-macro: 0.0037000000011176\n",
      "step:    2349, loss: 0.1690790951251984, accuracy-micro: 0.7592332363128662, accuracy-macro: 0.0037000000011176\n",
      "step:    2350, loss: 0.1690840870141983, accuracy-micro: 0.7591199874877930, accuracy-macro: 0.0037000000011176\n",
      "step:    2351, loss: 0.1690920889377594, accuracy-micro: 0.7592610120773315, accuracy-macro: 0.0037000000011176\n",
      "step:    2352, loss: 0.1690988391637802, accuracy-micro: 0.7590552568435669, accuracy-macro: 0.0037000000011176\n",
      "step:    2353, loss: 0.1691049039363861, accuracy-micro: 0.7592392563819885, accuracy-macro: 0.0037000000011176\n",
      "step:    2354, loss: 0.1691058278083801, accuracy-micro: 0.7590407729148865, accuracy-macro: 0.0037000000011176\n",
      "step:    2355, loss: 0.1691061854362488, accuracy-micro: 0.7592612504959106, accuracy-macro: 0.0037000000011176\n",
      "step:    2356, loss: 0.1690993905067444, accuracy-micro: 0.7590617537498474, accuracy-macro: 0.0037000000011176\n",
      "step:    2357, loss: 0.1690883785486221, accuracy-micro: 0.7592579722404480, accuracy-macro: 0.0037000000011176\n",
      "step:    2358, loss: 0.1690728068351746, accuracy-micro: 0.7591274976730347, accuracy-macro: 0.0037000000011176\n",
      "step:    2359, loss: 0.1690586805343628, accuracy-micro: 0.7592700123786926, accuracy-macro: 0.0037000000011176\n",
      "step:    2360, loss: 0.1690485477447510, accuracy-micro: 0.7591992616653442, accuracy-macro: 0.0037000000011176\n",
      "step:    2361, loss: 0.1690419316291809, accuracy-micro: 0.7592637538909912, accuracy-macro: 0.0037000000011176\n",
      "step:    2362, loss: 0.1690393686294556, accuracy-micro: 0.7592462301254272, accuracy-macro: 0.0037000000011176\n",
      "step:    2363, loss: 0.1690399348735809, accuracy-micro: 0.7592369914054871, accuracy-macro: 0.0037000000011176\n",
      "step:    2364, loss: 0.1690427809953690, accuracy-micro: 0.7592779994010925, accuracy-macro: 0.0037000000011176\n",
      "step:    2365, loss: 0.1690447926521301, accuracy-micro: 0.7591955065727234, accuracy-macro: 0.0037000000011176\n",
      "step:    2366, loss: 0.1690477877855301, accuracy-micro: 0.7592752575874329, accuracy-macro: 0.0037000000011176\n",
      "step:    2367, loss: 0.1690475344657898, accuracy-micro: 0.7591782212257385, accuracy-macro: 0.0037000000011176\n",
      "step:    2368, loss: 0.1690446883440018, accuracy-micro: 0.7593137621879578, accuracy-macro: 0.0037000000011176\n",
      "step:    2369, loss: 0.1690379083156586, accuracy-micro: 0.7592262625694275, accuracy-macro: 0.0037000000011176\n",
      "step:    2370, loss: 0.1690313220024109, accuracy-micro: 0.7593114972114563, accuracy-macro: 0.0037000000011176\n",
      "step:    2371, loss: 0.1690257042646408, accuracy-micro: 0.7592437267303467, accuracy-macro: 0.0037000000011176\n",
      "step:    2372, loss: 0.1690217852592468, accuracy-micro: 0.7593029737472534, accuracy-macro: 0.0037000000011176\n",
      "step:    2373, loss: 0.1690193116664886, accuracy-micro: 0.7592865228652954, accuracy-macro: 0.0037000000011176\n",
      "step:    2374, loss: 0.1690175682306290, accuracy-micro: 0.7592834830284119, accuracy-macro: 0.0037000000011176\n",
      "step:    2375, loss: 0.1690164655447006, accuracy-micro: 0.7593107223510742, accuracy-macro: 0.0037000000011176\n",
      "step:    2376, loss: 0.1690150946378708, accuracy-micro: 0.7592672705650330, accuracy-macro: 0.0037000000011176\n",
      "step:    2377, loss: 0.1690124422311783, accuracy-micro: 0.7593215107917786, accuracy-macro: 0.0037000000011176\n",
      "step:    2378, loss: 0.1690106242895126, accuracy-micro: 0.7592830061912537, accuracy-macro: 0.0037000000011176\n",
      "step:    2379, loss: 0.1690091192722321, accuracy-micro: 0.7593414783477783, accuracy-macro: 0.0037000000011176\n",
      "step:    2380, loss: 0.1690063476562500, accuracy-micro: 0.7593075037002563, accuracy-macro: 0.0037000000011176\n",
      "step:    2381, loss: 0.1690050363540649, accuracy-micro: 0.7593194842338562, accuracy-macro: 0.0037000000011176\n",
      "step:    2382, loss: 0.1690029948949814, accuracy-micro: 0.7593052387237549, accuracy-macro: 0.0037000000011176\n",
      "step:    2383, loss: 0.1690006256103516, accuracy-micro: 0.7593094706535339, accuracy-macro: 0.0037000000011176\n",
      "step:    2384, loss: 0.1689996868371964, accuracy-micro: 0.7593237757682800, accuracy-macro: 0.0037000000011176\n",
      "step:    2385, loss: 0.1689987778663635, accuracy-micro: 0.7592980265617371, accuracy-macro: 0.0037000000011176\n",
      "step:    2386, loss: 0.1689980179071426, accuracy-micro: 0.7593512535095215, accuracy-macro: 0.0037000000011176\n",
      "step:    2387, loss: 0.1689969748258591, accuracy-micro: 0.7592747211456299, accuracy-macro: 0.0037000000011176\n",
      "step:    2388, loss: 0.1689963489770889, accuracy-micro: 0.7593587636947632, accuracy-macro: 0.0037000000011176\n",
      "step:    2389, loss: 0.1689950376749039, accuracy-micro: 0.7592882513999939, accuracy-macro: 0.0037000000011176\n",
      "step:    2390, loss: 0.1689935922622681, accuracy-micro: 0.7593777775764465, accuracy-macro: 0.0037000000011176\n",
      "step:    2391, loss: 0.1689923703670502, accuracy-micro: 0.7593012452125549, accuracy-macro: 0.0037000000011176\n",
      "step:    2392, loss: 0.1689896881580353, accuracy-micro: 0.7593887448310852, accuracy-macro: 0.0037000000011176\n",
      "step:    2393, loss: 0.1689861863851547, accuracy-micro: 0.7593050003051758, accuracy-macro: 0.0037000000011176\n",
      "step:    2394, loss: 0.1689836680889130, accuracy-micro: 0.7593485116958618, accuracy-macro: 0.0037000000011176\n",
      "step:    2395, loss: 0.1689807325601578, accuracy-micro: 0.7593167424201965, accuracy-macro: 0.0037000000011176\n",
      "step:    2396, loss: 0.1689782291650772, accuracy-micro: 0.7593650221824646, accuracy-macro: 0.0037000000011176\n",
      "step:    2397, loss: 0.1689760088920593, accuracy-micro: 0.7593604922294617, accuracy-macro: 0.0037000000011176\n",
      "step:    2398, loss: 0.1689735203981400, accuracy-micro: 0.7593542337417603, accuracy-macro: 0.0037000000011176\n",
      "step:    2399, loss: 0.1689720302820206, accuracy-micro: 0.7593715190887451, accuracy-macro: 0.0037000000011176\n",
      "step:    2400, loss: 0.1689701974391937, accuracy-micro: 0.7593680024147034, accuracy-macro: 0.0037000000011176\n",
      "step:    2401, loss: 0.1689675301313400, accuracy-micro: 0.7593585252761841, accuracy-macro: 0.0037000000011176\n",
      "step:    2402, loss: 0.1689665019512177, accuracy-micro: 0.7593755125999451, accuracy-macro: 0.0037000000011176\n",
      "step:    2403, loss: 0.1689644902944565, accuracy-micro: 0.7593814730644226, accuracy-macro: 0.0037000000011176\n",
      "step:    2404, loss: 0.1689628809690475, accuracy-micro: 0.7593862414360046, accuracy-macro: 0.0037000000011176\n",
      "step:    2405, loss: 0.1689615398645401, accuracy-micro: 0.7593852281570435, accuracy-macro: 0.0037000000011176\n",
      "step:    2406, loss: 0.1689598858356476, accuracy-micro: 0.7593920230865479, accuracy-macro: 0.0037000000011176\n",
      "step:    2407, loss: 0.1689584106206894, accuracy-micro: 0.7593734860420227, accuracy-macro: 0.0037000000011176\n",
      "step:    2408, loss: 0.1689567863941193, accuracy-micro: 0.7593770027160645, accuracy-macro: 0.0037000000011176\n",
      "step:    2409, loss: 0.1689556539058685, accuracy-micro: 0.7593847513198853, accuracy-macro: 0.0037000000011176\n",
      "step:    2410, loss: 0.1689540743827820, accuracy-micro: 0.7593657374382019, accuracy-macro: 0.0037000000011176\n",
      "step:    2411, loss: 0.1689521223306656, accuracy-micro: 0.7593957185745239, accuracy-macro: 0.0037000000011176\n",
      "step:    2412, loss: 0.1689503788948059, accuracy-micro: 0.7593757510185242, accuracy-macro: 0.0037000000011176\n",
      "step:    2413, loss: 0.1689481884241104, accuracy-micro: 0.7594059705734253, accuracy-macro: 0.0037000000011176\n",
      "step:    2414, loss: 0.1689466238021851, accuracy-micro: 0.7593862414360046, accuracy-macro: 0.0037000000011176\n",
      "step:    2415, loss: 0.1689443737268448, accuracy-micro: 0.7594337463378906, accuracy-macro: 0.0037000000011176\n",
      "step:    2416, loss: 0.1689427196979523, accuracy-micro: 0.7593897581100464, accuracy-macro: 0.0037000000011176\n",
      "step:    2417, loss: 0.1689406335353851, accuracy-micro: 0.7594307661056519, accuracy-macro: 0.0037000000011176\n",
      "step:    2418, loss: 0.1689387112855911, accuracy-micro: 0.7594122290611267, accuracy-macro: 0.0037000000011176\n",
      "step:    2419, loss: 0.1689362823963165, accuracy-micro: 0.7594305276870728, accuracy-macro: 0.0037000000011176\n",
      "step:    2420, loss: 0.1689350605010986, accuracy-micro: 0.7594192624092102, accuracy-macro: 0.0037000000011176\n",
      "step:    2421, loss: 0.1689331978559494, accuracy-micro: 0.7594504952430725, accuracy-macro: 0.0037000000011176\n",
      "step:    2422, loss: 0.1689316779375076, accuracy-micro: 0.7594220042228699, accuracy-macro: 0.0037000000011176\n",
      "step:    2423, loss: 0.1689303815364838, accuracy-micro: 0.7594457268714905, accuracy-macro: 0.0037000000011176\n",
      "step:    2424, loss: 0.1689281314611435, accuracy-micro: 0.7594157457351685, accuracy-macro: 0.0037000000011176\n",
      "step:    2425, loss: 0.1689263135194778, accuracy-micro: 0.7594670057296753, accuracy-macro: 0.0037000000011176\n",
      "step:    2426, loss: 0.1689245551824570, accuracy-micro: 0.7594397664070129, accuracy-macro: 0.0037000000011176\n",
      "step:    2427, loss: 0.1689220368862152, accuracy-micro: 0.7594342231750488, accuracy-macro: 0.0037000000011176\n",
      "step:    2428, loss: 0.1689209342002869, accuracy-micro: 0.7594615221023560, accuracy-macro: 0.0037000000011176\n",
      "step:    2429, loss: 0.1689201444387436, accuracy-micro: 0.7594370245933533, accuracy-macro: 0.0037000000011176\n",
      "step:    2430, loss: 0.1689185053110123, accuracy-micro: 0.7594640254974365, accuracy-macro: 0.0037000000011176\n",
      "step:    2431, loss: 0.1689182519912720, accuracy-micro: 0.7594252228736877, accuracy-macro: 0.0037000000011176\n",
      "step:    2432, loss: 0.1689184010028839, accuracy-micro: 0.7594915032386780, accuracy-macro: 0.0037000000011176\n",
      "step:    2433, loss: 0.1689206063747406, accuracy-micro: 0.7594054937362671, accuracy-macro: 0.0037000000011176\n",
      "step:    2434, loss: 0.1689246892929077, accuracy-micro: 0.7595359683036804, accuracy-macro: 0.0037000000011176\n",
      "step:    2435, loss: 0.1689313501119614, accuracy-micro: 0.7593892216682434, accuracy-macro: 0.0037000000011176\n",
      "step:    2436, loss: 0.1689397543668747, accuracy-micro: 0.7595934867858887, accuracy-macro: 0.0037000000011176\n",
      "step:    2437, loss: 0.1689451038837433, accuracy-micro: 0.7594092488288879, accuracy-macro: 0.0037000000011176\n",
      "step:    2438, loss: 0.1689491569995880, accuracy-micro: 0.7595539689064026, accuracy-macro: 0.0037000000011176\n",
      "step:    2439, loss: 0.1689480245113373, accuracy-micro: 0.7593799829483032, accuracy-macro: 0.0037000000011176\n",
      "step:    2440, loss: 0.1689442545175552, accuracy-micro: 0.7595574855804443, accuracy-macro: 0.0037000000011176\n",
      "step:    2441, loss: 0.1689337491989136, accuracy-micro: 0.7594172358512878, accuracy-macro: 0.0037000000011176\n",
      "step:    2442, loss: 0.1689224094152451, accuracy-micro: 0.7595857381820679, accuracy-macro: 0.0037000000011176\n",
      "step:    2443, loss: 0.1689086258411407, accuracy-micro: 0.7594132423400879, accuracy-macro: 0.0037000000011176\n",
      "step:    2444, loss: 0.1688975840806961, accuracy-micro: 0.7595517635345459, accuracy-macro: 0.0037000000011176\n",
      "step:    2445, loss: 0.1688914895057678, accuracy-micro: 0.7594947218894958, accuracy-macro: 0.0037000000011176\n",
      "step:    2446, loss: 0.1688881218433380, accuracy-micro: 0.7595270276069641, accuracy-macro: 0.0037000000011176\n",
      "step:    2447, loss: 0.1688885688781738, accuracy-micro: 0.7595390081405640, accuracy-macro: 0.0037000000011176\n",
      "step:    2448, loss: 0.1688906252384186, accuracy-micro: 0.7594785094261169, accuracy-macro: 0.0037000000011176\n",
      "step:    2449, loss: 0.1688921898603439, accuracy-micro: 0.7595832347869873, accuracy-macro: 0.0037000000011176\n",
      "step:    2450, loss: 0.1688914000988007, accuracy-micro: 0.7594727277755737, accuracy-macro: 0.0037000000011176\n",
      "step:    2451, loss: 0.1688890606164932, accuracy-micro: 0.7595934867858887, accuracy-macro: 0.0037000000011176\n",
      "step:    2452, loss: 0.1688847243785858, accuracy-micro: 0.7595002651214600, accuracy-macro: 0.0037000000011176\n",
      "step:    2453, loss: 0.1688799113035202, accuracy-micro: 0.7595842480659485, accuracy-macro: 0.0037000000011176\n",
      "step:    2454, loss: 0.1688756346702576, accuracy-micro: 0.7595239877700806, accuracy-macro: 0.0037000000011176\n",
      "step:    2455, loss: 0.1688738018274307, accuracy-micro: 0.7595654726028442, accuracy-macro: 0.0037000000011176\n",
      "step:    2456, loss: 0.1688712537288666, accuracy-micro: 0.7595722675323486, accuracy-macro: 0.0037000000011176\n",
      "step:    2457, loss: 0.1688700616359711, accuracy-micro: 0.7595469951629639, accuracy-macro: 0.0037000000011176\n",
      "step:    2458, loss: 0.1688695400953293, accuracy-micro: 0.7595974802970886, accuracy-macro: 0.0037000000011176\n",
      "step:    2459, loss: 0.1688684970140457, accuracy-micro: 0.7595425248146057, accuracy-macro: 0.0037000000011176\n",
      "step:    2460, loss: 0.1688667684793472, accuracy-micro: 0.7595967650413513, accuracy-macro: 0.0037000000011176\n",
      "step:    2461, loss: 0.1688663065433502, accuracy-micro: 0.7595300078392029, accuracy-macro: 0.0037000000011176\n",
      "step:    2462, loss: 0.1688660681247711, accuracy-micro: 0.7596210241317749, accuracy-macro: 0.0037000000011176\n",
      "step:    2463, loss: 0.1688651144504547, accuracy-micro: 0.7595352530479431, accuracy-macro: 0.0037000000011176\n",
      "step:    2464, loss: 0.1688641309738159, accuracy-micro: 0.7596355080604553, accuracy-macro: 0.0037000000011176\n",
      "step:    2465, loss: 0.1688628792762756, accuracy-micro: 0.7595312595367432, accuracy-macro: 0.0037000000011176\n",
      "step:    2466, loss: 0.1688616871833801, accuracy-micro: 0.7596399784088135, accuracy-macro: 0.0037000000011176\n",
      "step:    2467, loss: 0.1688594073057175, accuracy-micro: 0.7595425248146057, accuracy-macro: 0.0037000000011176\n",
      "step:    2468, loss: 0.1688574254512787, accuracy-micro: 0.7596529722213745, accuracy-macro: 0.0037000000011176\n",
      "step:    2469, loss: 0.1688542813062668, accuracy-micro: 0.7595632672309875, accuracy-macro: 0.0037000000011176\n",
      "step:    2470, loss: 0.1688515990972519, accuracy-micro: 0.7596539855003357, accuracy-macro: 0.0037000000011176\n",
      "step:    2471, loss: 0.1688491255044937, accuracy-micro: 0.7595744729042053, accuracy-macro: 0.0037000000011176\n",
      "step:    2472, loss: 0.1688461601734161, accuracy-micro: 0.7596405148506165, accuracy-macro: 0.0037000000011176\n",
      "step:    2473, loss: 0.1688435822725296, accuracy-micro: 0.7596142292022705, accuracy-macro: 0.0037000000011176\n",
      "step:    2474, loss: 0.1688411235809326, accuracy-micro: 0.7596390247344971, accuracy-macro: 0.0037000000011176\n",
      "step:    2475, loss: 0.1688390970230103, accuracy-micro: 0.7596340179443359, accuracy-macro: 0.0037000000011176\n",
      "step:    2476, loss: 0.1688366830348969, accuracy-micro: 0.7596430182456970, accuracy-macro: 0.0037000000011176\n",
      "step:    2477, loss: 0.1688353717327118, accuracy-micro: 0.7596322298049927, accuracy-macro: 0.0037000000011176\n",
      "step:    2478, loss: 0.1688331961631775, accuracy-micro: 0.7596625089645386, accuracy-macro: 0.0037000000011176\n",
      "step:    2479, loss: 0.1688315421342850, accuracy-micro: 0.7596575021743774, accuracy-macro: 0.0037000000011176\n",
      "step:    2480, loss: 0.1688291728496552, accuracy-micro: 0.7596502304077148, accuracy-macro: 0.0037000000011176\n",
      "step:    2481, loss: 0.1688280850648880, accuracy-micro: 0.7596477270126343, accuracy-macro: 0.0037000000011176\n",
      "step:    2482, loss: 0.1688265949487686, accuracy-micro: 0.7596662640571594, accuracy-macro: 0.0037000000011176\n",
      "step:    2483, loss: 0.1688254475593567, accuracy-micro: 0.7596524953842163, accuracy-macro: 0.0037000000011176\n",
      "step:    2484, loss: 0.1688235998153687, accuracy-micro: 0.7596687674522400, accuracy-macro: 0.0037000000011176\n",
      "step:    2485, loss: 0.1688216626644135, accuracy-micro: 0.7596587538719177, accuracy-macro: 0.0037000000011176\n",
      "step:    2486, loss: 0.1688203662633896, accuracy-micro: 0.7596917748451233, accuracy-macro: 0.0037000000011176\n",
      "step:    2487, loss: 0.1688189208507538, accuracy-micro: 0.7596755027770996, accuracy-macro: 0.0037000000011176\n",
      "step:    2488, loss: 0.1688171923160553, accuracy-micro: 0.7596972584724426, accuracy-macro: 0.0037000000011176\n",
      "step:    2489, loss: 0.1688161641359329, accuracy-micro: 0.7596780061721802, accuracy-macro: 0.0037000000011176\n",
      "step:    2490, loss: 0.1688137948513031, accuracy-micro: 0.7597085237503052, accuracy-macro: 0.0037000000011176\n",
      "step:    2491, loss: 0.1688124388456345, accuracy-micro: 0.7596697211265564, accuracy-macro: 0.0037000000011176\n",
      "step:    2492, loss: 0.1688106507062912, accuracy-micro: 0.7597290277481079, accuracy-macro: 0.0037000000011176\n",
      "step:    2493, loss: 0.1688099950551987, accuracy-micro: 0.7596474885940552, accuracy-macro: 0.0037000000011176\n",
      "step:    2494, loss: 0.1688088625669479, accuracy-micro: 0.7597442269325256, accuracy-macro: 0.0037000000011176\n",
      "step:    2495, loss: 0.1688079684972763, accuracy-micro: 0.7596650123596191, accuracy-macro: 0.0037000000011176\n",
      "step:    2496, loss: 0.1688076555728912, accuracy-micro: 0.7597367763519287, accuracy-macro: 0.0037000000011176\n",
      "step:    2497, loss: 0.1688083708286285, accuracy-micro: 0.7596462368965149, accuracy-macro: 0.0037000000011176\n",
      "step:    2498, loss: 0.1688087582588196, accuracy-micro: 0.7597514986991882, accuracy-macro: 0.0037000000011176\n",
      "step:    2499, loss: 0.1688098758459091, accuracy-micro: 0.7596252560615540, accuracy-macro: 0.0037000000011176\n",
      "step:    2500, loss: 0.1688133478164673, accuracy-micro: 0.7597712278366089, accuracy-macro: 0.0037000000011176\n",
      "step:    2501, loss: 0.1688175499439240, accuracy-micro: 0.7595872282981873, accuracy-macro: 0.0037000000011176\n",
      "step:    2502, loss: 0.1688232123851776, accuracy-micro: 0.7597612738609314, accuracy-macro: 0.0037000000011176\n",
      "step:    2503, loss: 0.1688273400068283, accuracy-micro: 0.7595557570457458, accuracy-macro: 0.0037000000011176\n",
      "step:    2504, loss: 0.1688281148672104, accuracy-micro: 0.7597342729568481, accuracy-macro: 0.0037000000011176\n",
      "step:    2505, loss: 0.1688214987516403, accuracy-micro: 0.7595737576484680, accuracy-macro: 0.0037000000011176\n",
      "step:    2506, loss: 0.1688116937875748, accuracy-micro: 0.7597590088844299, accuracy-macro: 0.0037000000011176\n",
      "step:    2507, loss: 0.1688005328178406, accuracy-micro: 0.7596352696418762, accuracy-macro: 0.0037000000011176\n",
      "step:    2508, loss: 0.1687925159931183, accuracy-micro: 0.7597879767417908, accuracy-macro: 0.0037000000011176\n",
      "step:    2509, loss: 0.1687858104705811, accuracy-micro: 0.7597232460975647, accuracy-macro: 0.0037000000011176\n",
      "step:    2510, loss: 0.1687809377908707, accuracy-micro: 0.7597854733467102, accuracy-macro: 0.0037000000011176\n",
      "step:    2511, loss: 0.1687782108783722, accuracy-micro: 0.7597640156745911, accuracy-macro: 0.0037000000011176\n",
      "step:    2512, loss: 0.1687760949134827, accuracy-micro: 0.7597702741622925, accuracy-macro: 0.0037000000011176\n",
      "step:    2513, loss: 0.1687754839658737, accuracy-micro: 0.7597939968109131, accuracy-macro: 0.0037000000011176\n",
      "step:    2514, loss: 0.1687758117914200, accuracy-micro: 0.7597450017929077, accuracy-macro: 0.0037000000011176\n",
      "step:    2515, loss: 0.1687766313552856, accuracy-micro: 0.7597952485084534, accuracy-macro: 0.0037000000011176\n",
      "step:    2516, loss: 0.1687753796577454, accuracy-micro: 0.7597277760505676, accuracy-macro: 0.0037000000011176\n",
      "step:    2517, loss: 0.1687730252742767, accuracy-micro: 0.7597960233688354, accuracy-macro: 0.0037000000011176\n",
      "step:    2518, loss: 0.1687695235013962, accuracy-micro: 0.7597674727439880, accuracy-macro: 0.0037000000011176\n",
      "step:    2519, loss: 0.1687661558389664, accuracy-micro: 0.7598044872283936, accuracy-macro: 0.0037000000011176\n",
      "step:    2520, loss: 0.1687635928392410, accuracy-micro: 0.7597914934158325, accuracy-macro: 0.0037000000011176\n",
      "step:    2521, loss: 0.1687612384557724, accuracy-micro: 0.7597952485084534, accuracy-macro: 0.0037000000011176\n",
      "step:    2522, loss: 0.1687592118978500, accuracy-micro: 0.7598140239715576, accuracy-macro: 0.0037000000011176\n",
      "step:    2523, loss: 0.1687582433223724, accuracy-micro: 0.7598180174827576, accuracy-macro: 0.0037000000011176\n",
      "step:    2524, loss: 0.1687563359737396, accuracy-micro: 0.7598127722740173, accuracy-macro: 0.0037000000011176\n",
      "step:    2525, loss: 0.1687556058168411, accuracy-micro: 0.7597935199737549, accuracy-macro: 0.0037000000011176\n",
      "step:    2526, loss: 0.1687553375959396, accuracy-micro: 0.7598232626914978, accuracy-macro: 0.0037000000011176\n",
      "step:    2527, loss: 0.1687546223402023, accuracy-micro: 0.7597799897193909, accuracy-macro: 0.0037000000011176\n",
      "step:    2528, loss: 0.1687544882297516, accuracy-micro: 0.7598425149917603, accuracy-macro: 0.0037000000011176\n",
      "step:    2529, loss: 0.1687559336423874, accuracy-micro: 0.7597604990005493, accuracy-macro: 0.0037000000011176\n",
      "step:    2530, loss: 0.1687557548284531, accuracy-micro: 0.7598595023155212, accuracy-macro: 0.0037000000011176\n",
      "step:    2531, loss: 0.1687560826539993, accuracy-micro: 0.7597297430038452, accuracy-macro: 0.0037000000011176\n",
      "step:    2532, loss: 0.1687556803226471, accuracy-micro: 0.7598717212677002, accuracy-macro: 0.0037000000011176\n",
      "step:    2533, loss: 0.1687536388635635, accuracy-micro: 0.7597410082817078, accuracy-macro: 0.0037000000011176\n",
      "step:    2534, loss: 0.1687500178813934, accuracy-micro: 0.7598475217819214, accuracy-macro: 0.0037000000011176\n",
      "step:    2535, loss: 0.1687452197074890, accuracy-micro: 0.7597690224647522, accuracy-macro: 0.0037000000011176\n",
      "step:    2536, loss: 0.1687415093183517, accuracy-micro: 0.7598557472229004, accuracy-macro: 0.0037000000011176\n",
      "step:    2537, loss: 0.1687377095222473, accuracy-micro: 0.7598057389259338, accuracy-macro: 0.0037000000011176\n",
      "step:    2538, loss: 0.1687354743480682, accuracy-micro: 0.7598559856414795, accuracy-macro: 0.0037000000011176\n",
      "step:    2539, loss: 0.1687326282262802, accuracy-micro: 0.7598492503166199, accuracy-macro: 0.0037000000011176\n",
      "step:    2540, loss: 0.1687307506799698, accuracy-micro: 0.7598429918289185, accuracy-macro: 0.0037000000011176\n",
      "step:    2541, loss: 0.1687288433313370, accuracy-micro: 0.7598634958267212, accuracy-macro: 0.0037000000011176\n",
      "step:    2542, loss: 0.1687268465757370, accuracy-micro: 0.7598670125007629, accuracy-macro: 0.0037000000011176\n",
      "step:    2543, loss: 0.1687254756689072, accuracy-micro: 0.7598670125007629, accuracy-macro: 0.0037000000011176\n",
      "step:    2544, loss: 0.1687249392271042, accuracy-micro: 0.7598812580108643, accuracy-macro: 0.0037000000011176\n",
      "step:    2545, loss: 0.1687241196632385, accuracy-micro: 0.7598339915275574, accuracy-macro: 0.0037000000011176\n",
      "step:    2546, loss: 0.1687239110469818, accuracy-micro: 0.7598930001258850, accuracy-macro: 0.0037000000011176\n",
      "step:    2547, loss: 0.1687239855527878, accuracy-micro: 0.7598177194595337, accuracy-macro: 0.0037000000011176\n",
      "step:    2548, loss: 0.1687234044075012, accuracy-micro: 0.7598982453346252, accuracy-macro: 0.0037000000011176\n",
      "step:    2549, loss: 0.1687218844890594, accuracy-micro: 0.7597900032997131, accuracy-macro: 0.0037000000011176\n",
      "step:    2550, loss: 0.1687216460704803, accuracy-micro: 0.7599042654037476, accuracy-macro: 0.0037000000011176\n",
      "step:    2551, loss: 0.1687209308147430, accuracy-micro: 0.7598082423210144, accuracy-macro: 0.0037000000011176\n",
      "step:    2552, loss: 0.1687190830707550, accuracy-micro: 0.7599122524261475, accuracy-macro: 0.0037000000011176\n",
      "step:    2553, loss: 0.1687171310186386, accuracy-micro: 0.7598255276679993, accuracy-macro: 0.0037000000011176\n",
      "step:    2554, loss: 0.1687144637107849, accuracy-micro: 0.7599214911460876, accuracy-macro: 0.0037000000011176\n",
      "step:    2555, loss: 0.1687112450599670, accuracy-micro: 0.7598162293434143, accuracy-macro: 0.0037000000011176\n",
      "step:    2556, loss: 0.1687072515487671, accuracy-micro: 0.7599127292633057, accuracy-macro: 0.0037000000011176\n",
      "step:    2557, loss: 0.1687043160200119, accuracy-micro: 0.7598662376403809, accuracy-macro: 0.0037000000011176\n",
      "step:    2558, loss: 0.1687008738517761, accuracy-micro: 0.7599045038223267, accuracy-macro: 0.0037000000011176\n",
      "step:    2559, loss: 0.1686987131834030, accuracy-micro: 0.7599302530288696, accuracy-macro: 0.0037000000011176\n",
      "step:    2560, loss: 0.1686969101428986, accuracy-micro: 0.7599172592163086, accuracy-macro: 0.0037000000011176\n",
      "step:    2561, loss: 0.1686972528696060, accuracy-micro: 0.7599307298660278, accuracy-macro: 0.0037000000011176\n",
      "step:    2562, loss: 0.1686993986368179, accuracy-micro: 0.7598555088043213, accuracy-macro: 0.0037000000011176\n",
      "step:    2563, loss: 0.1687030643224716, accuracy-micro: 0.7599669694900513, accuracy-macro: 0.0037000000011176\n",
      "step:    2564, loss: 0.1687071919441223, accuracy-micro: 0.7598222494125366, accuracy-macro: 0.0037000000011176\n",
      "step:    2565, loss: 0.1687138378620148, accuracy-micro: 0.7599455118179321, accuracy-macro: 0.0037000000011176\n",
      "step:    2566, loss: 0.1687207370996475, accuracy-micro: 0.7597795128822327, accuracy-macro: 0.0037000000011176\n",
      "step:    2567, loss: 0.1687282770872116, accuracy-micro: 0.7599210143089294, accuracy-macro: 0.0037000000011176\n",
      "step:    2568, loss: 0.1687338203191757, accuracy-micro: 0.7597607374191284, accuracy-macro: 0.0037000000011176\n",
      "step:    2569, loss: 0.1687394678592682, accuracy-micro: 0.7598729729652405, accuracy-macro: 0.0037000000011176\n",
      "step:    2570, loss: 0.1687384843826294, accuracy-micro: 0.7597205042839050, accuracy-macro: 0.0037000000011176\n",
      "step:    2571, loss: 0.1687339842319489, accuracy-micro: 0.7598852515220642, accuracy-macro: 0.0037000000011176\n",
      "step:    2572, loss: 0.1687222868204117, accuracy-micro: 0.7597732543945312, accuracy-macro: 0.0037000000011176\n",
      "step:    2573, loss: 0.1687096804380417, accuracy-micro: 0.7599499821662903, accuracy-macro: 0.0037000000011176\n",
      "step:    2574, loss: 0.1686924546957016, accuracy-micro: 0.7598609924316406, accuracy-macro: 0.0037000000011176\n",
      "step:    2575, loss: 0.1686778068542480, accuracy-micro: 0.7599694728851318, accuracy-macro: 0.0037000000011176\n",
      "step:    2576, loss: 0.1686713099479675, accuracy-micro: 0.7599484920501709, accuracy-macro: 0.0037000000011176\n",
      "step:    2577, loss: 0.1686724275350571, accuracy-micro: 0.7599084973335266, accuracy-macro: 0.0037000000011176\n",
      "step:    2578, loss: 0.1686769276857376, accuracy-micro: 0.7599924802780151, accuracy-macro: 0.0037000000011176\n",
      "step:    2579, loss: 0.1686828434467316, accuracy-micro: 0.7598789930343628, accuracy-macro: 0.0037000000011176\n",
      "step:    2580, loss: 0.1686876267194748, accuracy-micro: 0.7599742412567139, accuracy-macro: 0.0037000000011176\n",
      "step:    2581, loss: 0.1686859726905823, accuracy-micro: 0.7598760128021240, accuracy-macro: 0.0037000000011176\n",
      "step:    2582, loss: 0.1686783432960510, accuracy-micro: 0.7600014805793762, accuracy-macro: 0.0037000000011176\n",
      "step:    2583, loss: 0.1686681061983109, accuracy-micro: 0.7598787546157837, accuracy-macro: 0.0037000000011176\n",
      "step:    2584, loss: 0.1686599552631378, accuracy-micro: 0.7599767446517944, accuracy-macro: 0.0037000000011176\n",
      "step:    2585, loss: 0.1686574369668961, accuracy-micro: 0.7599599957466125, accuracy-macro: 0.0037000000011176\n",
      "step:    2586, loss: 0.1686592996120453, accuracy-micro: 0.7599342465400696, accuracy-macro: 0.0037000000011176\n",
      "step:    2587, loss: 0.1686628609895706, accuracy-micro: 0.7600194811820984, accuracy-macro: 0.0037000000011176\n",
      "step:    2588, loss: 0.1686644256114960, accuracy-micro: 0.7599030137062073, accuracy-macro: 0.0037000000011176\n",
      "step:    2589, loss: 0.1686632931232452, accuracy-micro: 0.7600194811820984, accuracy-macro: 0.0037000000011176\n",
      "step:    2590, loss: 0.1686586588621140, accuracy-micro: 0.7599122524261475, accuracy-macro: 0.0037000000011176\n",
      "step:    2591, loss: 0.1686529070138931, accuracy-micro: 0.7600179910659790, accuracy-macro: 0.0037000000011176\n",
      "step:    2592, loss: 0.1686486601829529, accuracy-micro: 0.7599455118179321, accuracy-macro: 0.0037000000011176\n",
      "step:    2593, loss: 0.1686452776193619, accuracy-micro: 0.7599947452545166, accuracy-macro: 0.0037000000011176\n",
      "step:    2594, loss: 0.1686432808637619, accuracy-micro: 0.7599614858627319, accuracy-macro: 0.0037000000011176\n",
      "step:    2595, loss: 0.1686412990093231, accuracy-micro: 0.7599769830703735, accuracy-macro: 0.0037000000011176\n",
      "step:    2596, loss: 0.1686401218175888, accuracy-micro: 0.7600007653236389, accuracy-macro: 0.0037000000011176\n",
      "step:    2597, loss: 0.1686391383409500, accuracy-micro: 0.7599700093269348, accuracy-macro: 0.0037000000011176\n",
      "step:    2598, loss: 0.1686379015445709, accuracy-micro: 0.7599967718124390, accuracy-macro: 0.0037000000011176\n",
      "step:    2599, loss: 0.1686360687017441, accuracy-micro: 0.7599782347679138, accuracy-macro: 0.0037000000011176\n",
      "step:    2600, loss: 0.1686342805624008, accuracy-micro: 0.7600054740905762, accuracy-macro: 0.0037000000011176\n",
      "step:    2601, loss: 0.1686323732137680, accuracy-micro: 0.7599874734878540, accuracy-macro: 0.0037000000011176\n",
      "step:    2602, loss: 0.1686307936906815, accuracy-micro: 0.7599822282791138, accuracy-macro: 0.0037000000011176\n",
      "step:    2603, loss: 0.1686290204524994, accuracy-micro: 0.7600217461585999, accuracy-macro: 0.0037000000011176\n",
      "step:    2604, loss: 0.1686284840106964, accuracy-micro: 0.7599804997444153, accuracy-macro: 0.0037000000011176\n",
      "step:    2605, loss: 0.1686277687549591, accuracy-micro: 0.7600192427635193, accuracy-macro: 0.0037000000011176\n",
      "step:    2606, loss: 0.1686259955167770, accuracy-micro: 0.7599669694900513, accuracy-macro: 0.0037000000011176\n",
      "step:    2607, loss: 0.1686246246099472, accuracy-micro: 0.7600265145301819, accuracy-macro: 0.0037000000011176\n",
      "step:    2608, loss: 0.1686227470636368, accuracy-micro: 0.7599737644195557, accuracy-macro: 0.0037000000011176\n",
      "step:    2609, loss: 0.1686223149299622, accuracy-micro: 0.7600409984588623, accuracy-macro: 0.0037000000011176\n",
      "step:    2610, loss: 0.1686212122440338, accuracy-micro: 0.7599812746047974, accuracy-macro: 0.0037000000011176\n",
      "step:    2611, loss: 0.1686204224824905, accuracy-micro: 0.7600489854812622, accuracy-macro: 0.0037000000011176\n",
      "step:    2612, loss: 0.1686195433139801, accuracy-micro: 0.7599832415580750, accuracy-macro: 0.0037000000011176\n",
      "step:    2613, loss: 0.1686179339885712, accuracy-micro: 0.7600707411766052, accuracy-macro: 0.0037000000011176\n",
      "step:    2614, loss: 0.1686160564422607, accuracy-micro: 0.7599952220916748, accuracy-macro: 0.0037000000011176\n",
      "step:    2615, loss: 0.1686138808727264, accuracy-micro: 0.7600780129432678, accuracy-macro: 0.0037000000011176\n",
      "step:    2616, loss: 0.1686115562915802, accuracy-micro: 0.7599892616271973, accuracy-macro: 0.0037000000011176\n",
      "step:    2617, loss: 0.1686095595359802, accuracy-micro: 0.7600529789924622, accuracy-macro: 0.0037000000011176\n",
      "step:    2618, loss: 0.1686074733734131, accuracy-micro: 0.7600012421607971, accuracy-macro: 0.0037000000011176\n",
      "step:    2619, loss: 0.1686056852340698, accuracy-micro: 0.7600647211074829, accuracy-macro: 0.0037000000011176\n",
      "step:    2620, loss: 0.1686036288738251, accuracy-micro: 0.7600330114364624, accuracy-macro: 0.0037000000011176\n",
      "step:    2621, loss: 0.1686018705368042, accuracy-micro: 0.7600439786911011, accuracy-macro: 0.0037000000011176\n",
      "step:    2622, loss: 0.1686003059148788, accuracy-micro: 0.7600330114364624, accuracy-macro: 0.0037000000011176\n",
      "step:    2623, loss: 0.1685986965894699, accuracy-micro: 0.7600324749946594, accuracy-macro: 0.0037000000011176\n",
      "step:    2624, loss: 0.1685974001884460, accuracy-micro: 0.7600520253181458, accuracy-macro: 0.0037000000011176\n",
      "step:    2625, loss: 0.1685958057641983, accuracy-micro: 0.7600602507591248, accuracy-macro: 0.0037000000011176\n",
      "step:    2626, loss: 0.1685949414968491, accuracy-micro: 0.7600315213203430, accuracy-macro: 0.0037000000011176\n",
      "step:    2627, loss: 0.1685940921306610, accuracy-micro: 0.7600769996643066, accuracy-macro: 0.0037000000011176\n",
      "step:    2628, loss: 0.1685924977064133, accuracy-micro: 0.7600427269935608, accuracy-macro: 0.0037000000011176\n",
      "step:    2629, loss: 0.1685911267995834, accuracy-micro: 0.7601047754287720, accuracy-macro: 0.0037000000011176\n",
      "step:    2630, loss: 0.1685897856950760, accuracy-micro: 0.7600427269935608, accuracy-macro: 0.0037000000011176\n",
      "step:    2631, loss: 0.1685881316661835, accuracy-micro: 0.7600952386856079, accuracy-macro: 0.0037000000011176\n",
      "step:    2632, loss: 0.1685875058174133, accuracy-micro: 0.7600392699241638, accuracy-macro: 0.0037000000011176\n",
      "step:    2633, loss: 0.1685869246721268, accuracy-micro: 0.7601247429847717, accuracy-macro: 0.0037000000011176\n",
      "step:    2634, loss: 0.1685865372419357, accuracy-micro: 0.7600557208061218, accuracy-macro: 0.0037000000011176\n",
      "step:    2635, loss: 0.1685865968465805, accuracy-micro: 0.7601479887962341, accuracy-macro: 0.0037000000011176\n",
      "step:    2636, loss: 0.1685854047536850, accuracy-micro: 0.7600537538528442, accuracy-macro: 0.0037000000011176\n",
      "step:    2637, loss: 0.1685824245214462, accuracy-micro: 0.7601364850997925, accuracy-macro: 0.0037000000011176\n",
      "step:    2638, loss: 0.1685793995857239, accuracy-micro: 0.7600552439689636, accuracy-macro: 0.0037000000011176\n",
      "step:    2639, loss: 0.1685760617256165, accuracy-micro: 0.7600997686386108, accuracy-macro: 0.0037000000011176\n",
      "step:    2640, loss: 0.1685737520456314, accuracy-micro: 0.7600730061531067, accuracy-macro: 0.0037000000011176\n",
      "step:    2641, loss: 0.1685717403888702, accuracy-micro: 0.7601069808006287, accuracy-macro: 0.0037000000011176\n",
      "step:    2642, loss: 0.1685698479413986, accuracy-micro: 0.7600954771041870, accuracy-macro: 0.0037000000011176\n",
      "step:    2643, loss: 0.1685695797204971, accuracy-micro: 0.7600755095481873, accuracy-macro: 0.0037000000011176\n",
      "step:    2644, loss: 0.1685681343078613, accuracy-micro: 0.7601084709167480, accuracy-macro: 0.0037000000011176\n",
      "step:    2645, loss: 0.1685675084590912, accuracy-micro: 0.7600809931755066, accuracy-macro: 0.0037000000011176\n",
      "step:    2646, loss: 0.1685662567615509, accuracy-micro: 0.7601232528686523, accuracy-macro: 0.0037000000011176\n",
      "step:    2647, loss: 0.1685635894536972, accuracy-micro: 0.7600867748260498, accuracy-macro: 0.0037000000011176\n",
      "step:    2648, loss: 0.1685625761747360, accuracy-micro: 0.7601287364959717, accuracy-macro: 0.0037000000011176\n",
      "step:    2649, loss: 0.1685603857040405, accuracy-micro: 0.7600945234298706, accuracy-macro: 0.0037000000011176\n",
      "step:    2650, loss: 0.1685589402914047, accuracy-micro: 0.7601342201232910, accuracy-macro: 0.0037000000011176\n",
      "step:    2651, loss: 0.1685572564601898, accuracy-micro: 0.7601165175437927, accuracy-macro: 0.0037000000011176\n",
      "step:    2652, loss: 0.1685554981231689, accuracy-micro: 0.7601187229156494, accuracy-macro: 0.0037000000011176\n",
      "step:    2653, loss: 0.1685541570186615, accuracy-micro: 0.7601182460784912, accuracy-macro: 0.0037000000011176\n",
      "step:    2654, loss: 0.1685530692338943, accuracy-micro: 0.7601382732391357, accuracy-macro: 0.0037000000011176\n",
      "step:    2655, loss: 0.1685519814491272, accuracy-micro: 0.7601069808006287, accuracy-macro: 0.0037000000011176\n",
      "step:    2656, loss: 0.1685507446527481, accuracy-micro: 0.7601597309112549, accuracy-macro: 0.0037000000011176\n",
      "step:    2657, loss: 0.1685501933097839, accuracy-micro: 0.7600982189178467, accuracy-macro: 0.0037000000011176\n",
      "step:    2658, loss: 0.1685490459203720, accuracy-micro: 0.7601804733276367, accuracy-macro: 0.0037000000011176\n",
      "step:    2659, loss: 0.1685491800308228, accuracy-micro: 0.7601037621498108, accuracy-macro: 0.0037000000011176\n",
      "step:    2660, loss: 0.1685495674610138, accuracy-micro: 0.7601774930953979, accuracy-macro: 0.0037000000011176\n",
      "step:    2661, loss: 0.1685507297515869, accuracy-micro: 0.7600985169410706, accuracy-macro: 0.0037000000011176\n",
      "step:    2662, loss: 0.1685514897108078, accuracy-micro: 0.7601702213287354, accuracy-macro: 0.0037000000011176\n",
      "step:    2663, loss: 0.1685522794723511, accuracy-micro: 0.7600992321968079, accuracy-macro: 0.0037000000011176\n",
      "step:    2664, loss: 0.1685528457164764, accuracy-micro: 0.7601900100708008, accuracy-macro: 0.0037000000011176\n",
      "step:    2665, loss: 0.1685531884431839, accuracy-micro: 0.7600650191307068, accuracy-macro: 0.0037000000011176\n",
      "step:    2666, loss: 0.1685545593500137, accuracy-micro: 0.7601944804191589, accuracy-macro: 0.0037000000011176\n",
      "step:    2667, loss: 0.1685571223497391, accuracy-micro: 0.7600610256195068, accuracy-macro: 0.0037000000011176\n",
      "step:    2668, loss: 0.1685614436864853, accuracy-micro: 0.7601687312126160, accuracy-macro: 0.0037000000011176\n",
      "step:    2669, loss: 0.1685648411512375, accuracy-micro: 0.7600347399711609, accuracy-macro: 0.0037000000011176\n",
      "step:    2670, loss: 0.1685670614242554, accuracy-micro: 0.7601642608642578, accuracy-macro: 0.0037000000011176\n",
      "step:    2671, loss: 0.1685647815465927, accuracy-micro: 0.7600422501564026, accuracy-macro: 0.0037000000011176\n",
      "step:    2672, loss: 0.1685618460178375, accuracy-micro: 0.7601772546768188, accuracy-macro: 0.0037000000011176\n",
      "step:    2673, loss: 0.1685544401407242, accuracy-micro: 0.7600554823875427, accuracy-macro: 0.0037000000011176\n",
      "step:    2674, loss: 0.1685452312231064, accuracy-micro: 0.7602005004882812, accuracy-macro: 0.0037000000011176\n",
      "step:    2675, loss: 0.1685337126255035, accuracy-micro: 0.7601177692413330, accuracy-macro: 0.0037000000011176\n",
      "step:    2676, loss: 0.1685242950916290, accuracy-micro: 0.7602322697639465, accuracy-macro: 0.0037000000011176\n",
      "step:    2677, loss: 0.1685197502374649, accuracy-micro: 0.7601910233497620, accuracy-macro: 0.0037000000011176\n",
      "step:    2678, loss: 0.1685184389352798, accuracy-micro: 0.7601860165596008, accuracy-macro: 0.0037000000011176\n",
      "step:    2679, loss: 0.1685202568769455, accuracy-micro: 0.7602379918098450, accuracy-macro: 0.0037000000011176\n",
      "step:    2680, loss: 0.1685224175453186, accuracy-micro: 0.7601342201232910, accuracy-macro: 0.0037000000011176\n",
      "step:    2681, loss: 0.1685251444578171, accuracy-micro: 0.7602400183677673, accuracy-macro: 0.0037000000011176\n",
      "step:    2682, loss: 0.1685271710157394, accuracy-micro: 0.7601297497749329, accuracy-macro: 0.0037000000011176\n",
      "step:    2683, loss: 0.1685280352830887, accuracy-micro: 0.7602214813232422, accuracy-macro: 0.0037000000011176\n",
      "step:    2684, loss: 0.1685238778591156, accuracy-micro: 0.7601349949836731, accuracy-macro: 0.0037000000011176\n",
      "step:    2685, loss: 0.1685187071561813, accuracy-micro: 0.7602365016937256, accuracy-macro: 0.0037000000011176\n",
      "step:    2686, loss: 0.1685127168893814, accuracy-micro: 0.7601752281188965, accuracy-macro: 0.0037000000011176\n",
      "step:    2687, loss: 0.1685074269771576, accuracy-micro: 0.7602282762527466, accuracy-macro: 0.0037000000011176\n",
      "step:    2688, loss: 0.1685039699077606, accuracy-micro: 0.7602105140686035, accuracy-macro: 0.0037000000011176\n",
      "step:    2689, loss: 0.1685028374195099, accuracy-micro: 0.7602222561836243, accuracy-macro: 0.0037000000011176\n",
      "step:    2690, loss: 0.1685020774602890, accuracy-micro: 0.7602347731590271, accuracy-macro: 0.0037000000011176\n",
      "step:    2691, loss: 0.1685018390417099, accuracy-micro: 0.7602037191390991, accuracy-macro: 0.0037000000011176\n",
      "step:    2692, loss: 0.1685013771057129, accuracy-micro: 0.7602455019950867, accuracy-macro: 0.0037000000011176\n",
      "step:    2693, loss: 0.1685003489255905, accuracy-micro: 0.7601952552795410, accuracy-macro: 0.0037000000011176\n",
      "step:    2694, loss: 0.1684992611408234, accuracy-micro: 0.7602457404136658, accuracy-macro: 0.0037000000011176\n",
      "step:    2695, loss: 0.1684972196817398, accuracy-micro: 0.7602047324180603, accuracy-macro: 0.0037000000011176\n",
      "step:    2696, loss: 0.1684949398040771, accuracy-micro: 0.7602394819259644, accuracy-macro: 0.0037000000011176\n",
      "step:    2697, loss: 0.1684921830892563, accuracy-micro: 0.7602202296257019, accuracy-macro: 0.0037000000011176\n",
      "step:    2698, loss: 0.1684900969266891, accuracy-micro: 0.7602409720420837, accuracy-macro: 0.0037000000011176\n",
      "step:    2699, loss: 0.1684885919094086, accuracy-micro: 0.7602474689483643, accuracy-macro: 0.0037000000011176\n",
      "step:    2700, loss: 0.1684875637292862, accuracy-micro: 0.7602564692497253, accuracy-macro: 0.0037000000011176\n",
      "step:    2701, loss: 0.1684887856245041, accuracy-micro: 0.7602714896202087, accuracy-macro: 0.0037000000011176\n",
      "step:    2702, loss: 0.1684895604848862, accuracy-micro: 0.7602117657661438, accuracy-macro: 0.0037000000011176\n",
      "step:    2703, loss: 0.1684893518686295, accuracy-micro: 0.7602729797363281, accuracy-macro: 0.0037000000011176\n",
      "step:    2704, loss: 0.1684882193803787, accuracy-micro: 0.7602090239524841, accuracy-macro: 0.0037000000011176\n",
      "step:    2705, loss: 0.1684870123863220, accuracy-micro: 0.7602672576904297, accuracy-macro: 0.0037000000011176\n",
      "step:    2706, loss: 0.1684839725494385, accuracy-micro: 0.7602109909057617, accuracy-macro: 0.0037000000011176\n",
      "step:    2707, loss: 0.1684819012880325, accuracy-micro: 0.7602725028991699, accuracy-macro: 0.0037000000011176\n",
      "step:    2708, loss: 0.1684799492359161, accuracy-micro: 0.7602312564849854, accuracy-macro: 0.0037000000011176\n",
      "step:    2709, loss: 0.1684784740209579, accuracy-micro: 0.7602827548980713, accuracy-macro: 0.0037000000011176\n",
      "step:    2710, loss: 0.1684769988059998, accuracy-micro: 0.7602587342262268, accuracy-macro: 0.0037000000011176\n",
      "step:    2711, loss: 0.1684764623641968, accuracy-micro: 0.7602999806404114, accuracy-macro: 0.0037000000011176\n",
      "step:    2712, loss: 0.1684760302305222, accuracy-micro: 0.7602434754371643, accuracy-macro: 0.0037000000011176\n",
      "step:    2713, loss: 0.1684740632772446, accuracy-micro: 0.7602750062942505, accuracy-macro: 0.0037000000011176\n",
      "step:    2714, loss: 0.1684709042310715, accuracy-micro: 0.7602692246437073, accuracy-macro: 0.0037000000011176\n",
      "step:    2715, loss: 0.1684682369232178, accuracy-micro: 0.7602865099906921, accuracy-macro: 0.0037000000011176\n",
      "step:    2716, loss: 0.1684657037258148, accuracy-micro: 0.7602685093879700, accuracy-macro: 0.0037000000011176\n",
      "step:    2717, loss: 0.1684638708829880, accuracy-micro: 0.7602930068969727, accuracy-macro: 0.0037000000011176\n",
      "step:    2718, loss: 0.1684622466564178, accuracy-micro: 0.7602817416191101, accuracy-macro: 0.0037000000011176\n",
      "step:    2719, loss: 0.1684600859880447, accuracy-micro: 0.7602812647819519, accuracy-macro: 0.0037000000011176\n",
      "step:    2720, loss: 0.1684586554765701, accuracy-micro: 0.7602999806404114, accuracy-macro: 0.0037000000011176\n",
      "step:    2721, loss: 0.1684579104185104, accuracy-micro: 0.7602840065956116, accuracy-macro: 0.0037000000011176\n",
      "step:    2722, loss: 0.1684573292732239, accuracy-micro: 0.7603009939193726, accuracy-macro: 0.0037000000011176\n",
      "step:    2723, loss: 0.1684558093547821, accuracy-micro: 0.7602867484092712, accuracy-macro: 0.0037000000011176\n",
      "step:    2724, loss: 0.1684533059597015, accuracy-micro: 0.7603030204772949, accuracy-macro: 0.0037000000011176\n",
      "step:    2725, loss: 0.1684523075819016, accuracy-micro: 0.7603070139884949, accuracy-macro: 0.0037000000011176\n",
      "step:    2726, loss: 0.1684513390064240, accuracy-micro: 0.7603315114974976, accuracy-macro: 0.0037000000011176\n",
      "step:    2727, loss: 0.1684499979019165, accuracy-micro: 0.7602934837341309, accuracy-macro: 0.0037000000011176\n",
      "step:    2728, loss: 0.1684498339891434, accuracy-micro: 0.7603157758712769, accuracy-macro: 0.0037000000011176\n",
      "step:    2729, loss: 0.1684482842683792, accuracy-micro: 0.7603110074996948, accuracy-macro: 0.0037000000011176\n",
      "step:    2730, loss: 0.1684471666812897, accuracy-micro: 0.7603359818458557, accuracy-macro: 0.0037000000011176\n",
      "step:    2731, loss: 0.1684454679489136, accuracy-micro: 0.7602997422218323, accuracy-macro: 0.0037000000011176\n",
      "step:    2732, loss: 0.1684429794549942, accuracy-micro: 0.7603432536125183, accuracy-macro: 0.0037000000011176\n",
      "step:    2733, loss: 0.1684405207633972, accuracy-micro: 0.7603110074996948, accuracy-macro: 0.0037000000011176\n",
      "step:    2734, loss: 0.1684391498565674, accuracy-micro: 0.7603319883346558, accuracy-macro: 0.0037000000011176\n",
      "step:    2735, loss: 0.1684379130601883, accuracy-micro: 0.7603229880332947, accuracy-macro: 0.0037000000011176\n",
      "step:    2736, loss: 0.1684366911649704, accuracy-micro: 0.7603409886360168, accuracy-macro: 0.0037000000011176\n",
      "step:    2737, loss: 0.1684347689151764, accuracy-micro: 0.7603625059127808, accuracy-macro: 0.0037000000011176\n",
      "step:    2738, loss: 0.1684335768222809, accuracy-micro: 0.7603677511215210, accuracy-macro: 0.0037000000011176\n",
      "step:    2739, loss: 0.1684321016073227, accuracy-micro: 0.7603595256805420, accuracy-macro: 0.0037000000011176\n",
      "step:    2740, loss: 0.1684308499097824, accuracy-micro: 0.7603535056114197, accuracy-macro: 0.0037000000011176\n",
      "step:    2741, loss: 0.1684291511774063, accuracy-micro: 0.7603562474250793, accuracy-macro: 0.0037000000011176\n",
      "step:    2742, loss: 0.1684282124042511, accuracy-micro: 0.7603707313537598, accuracy-macro: 0.0037000000011176\n",
      "step:    2743, loss: 0.1684266924858093, accuracy-micro: 0.7603489756584167, accuracy-macro: 0.0037000000011176\n",
      "step:    2744, loss: 0.1684255897998810, accuracy-micro: 0.7603449821472168, accuracy-macro: 0.0037000000011176\n",
      "step:    2745, loss: 0.1684244722127914, accuracy-micro: 0.7603489756584167, accuracy-macro: 0.0037000000011176\n",
      "step:    2746, loss: 0.1684234142303467, accuracy-micro: 0.7603775262832642, accuracy-macro: 0.0037000000011176\n",
      "step:    2747, loss: 0.1684220284223557, accuracy-micro: 0.7603767514228821, accuracy-macro: 0.0037000000011176\n",
      "step:    2748, loss: 0.1684206575155258, accuracy-micro: 0.7603797316551208, accuracy-macro: 0.0037000000011176\n",
      "step:    2749, loss: 0.1684194505214691, accuracy-micro: 0.7603742480278015, accuracy-macro: 0.0037000000011176\n",
      "step:    2750, loss: 0.1684189438819885, accuracy-micro: 0.7603635191917419, accuracy-macro: 0.0037000000011176\n",
      "step:    2751, loss: 0.1684186458587646, accuracy-micro: 0.7603612542152405, accuracy-macro: 0.0037000000011176\n",
      "step:    2752, loss: 0.1684166342020035, accuracy-micro: 0.7603859901428223, accuracy-macro: 0.0037000000011176\n",
      "step:    2753, loss: 0.1684157997369766, accuracy-micro: 0.7603690028190613, accuracy-macro: 0.0037000000011176\n",
      "step:    2754, loss: 0.1684153378009796, accuracy-micro: 0.7603754997253418, accuracy-macro: 0.0037000000011176\n",
      "step:    2755, loss: 0.1684162765741348, accuracy-micro: 0.7603987455368042, accuracy-macro: 0.0037000000011176\n",
      "step:    2756, loss: 0.1684169024229050, accuracy-micro: 0.7603572607040405, accuracy-macro: 0.0037000000011176\n",
      "step:    2757, loss: 0.1684172749519348, accuracy-micro: 0.7604052424430847, accuracy-macro: 0.0037000000011176\n",
      "step:    2758, loss: 0.1684172004461288, accuracy-micro: 0.7603522539138794, accuracy-macro: 0.0037000000011176\n",
      "step:    2759, loss: 0.1684184670448303, accuracy-micro: 0.7604069709777832, accuracy-macro: 0.0037000000011176\n",
      "step:    2760, loss: 0.1684200912714005, accuracy-micro: 0.7603537440299988, accuracy-macro: 0.0037000000011176\n",
      "step:    2761, loss: 0.1684225350618362, accuracy-micro: 0.7603889703750610, accuracy-macro: 0.0037000000011176\n",
      "step:    2762, loss: 0.1684234142303467, accuracy-micro: 0.7603332400321960, accuracy-macro: 0.0037000000011176\n",
      "step:    2763, loss: 0.1684235632419586, accuracy-micro: 0.7603895068168640, accuracy-macro: 0.0037000000011176\n",
      "step:    2764, loss: 0.1684209108352661, accuracy-micro: 0.7603182196617126, accuracy-macro: 0.0037000000011176\n",
      "step:    2765, loss: 0.1684170067310333, accuracy-micro: 0.7603942751884460, accuracy-macro: 0.0037000000011176\n",
      "step:    2766, loss: 0.1684109121561050, accuracy-micro: 0.7603507637977600, accuracy-macro: 0.0037000000011176\n",
      "step:    2767, loss: 0.1684047132730484, accuracy-micro: 0.7604277729988098, accuracy-macro: 0.0037000000011176\n",
      "step:    2768, loss: 0.1683995872735977, accuracy-micro: 0.7604190111160278, accuracy-macro: 0.0037000000011176\n",
      "step:    2769, loss: 0.1683952212333679, accuracy-micro: 0.7604147195816040, accuracy-macro: 0.0037000000011176\n",
      "step:    2770, loss: 0.1683909744024277, accuracy-micro: 0.7604187726974487, accuracy-macro: 0.0037000000011176\n",
      "step:    2771, loss: 0.1683885604143143, accuracy-micro: 0.7604377269744873, accuracy-macro: 0.0037000000011176\n",
      "step:    2772, loss: 0.1683865338563919, accuracy-micro: 0.7604445219039917, accuracy-macro: 0.0037000000011176\n",
      "step:    2773, loss: 0.1683860272169113, accuracy-micro: 0.7604604959487915, accuracy-macro: 0.0037000000011176\n",
      "step:    2774, loss: 0.1683860570192337, accuracy-micro: 0.7604244947433472, accuracy-macro: 0.0037000000011176\n",
      "step:    2775, loss: 0.1683864444494247, accuracy-micro: 0.7604202628135681, accuracy-macro: 0.0037000000011176\n",
      "step:    2776, loss: 0.1683859378099442, accuracy-micro: 0.7604277729988098, accuracy-macro: 0.0037000000011176\n",
      "step:    2777, loss: 0.1683854162693024, accuracy-micro: 0.7604412436485291, accuracy-macro: 0.0037000000011176\n",
      "step:    2778, loss: 0.1683858782052994, accuracy-micro: 0.7604380249977112, accuracy-macro: 0.0037000000011176\n",
      "step:    2779, loss: 0.1683875173330307, accuracy-micro: 0.7604100108146667, accuracy-macro: 0.0037000000011176\n",
      "step:    2780, loss: 0.1683918237686157, accuracy-micro: 0.7604414820671082, accuracy-macro: 0.0037000000011176\n",
      "step:    2781, loss: 0.1683956086635590, accuracy-micro: 0.7603632211685181, accuracy-macro: 0.0037000000011176\n",
      "step:    2782, loss: 0.1684003025293350, accuracy-micro: 0.7604437470436096, accuracy-macro: 0.0037000000011176\n",
      "step:    2783, loss: 0.1684015840291977, accuracy-micro: 0.7603797316551208, accuracy-macro: 0.0037000000011176\n",
      "step:    2784, loss: 0.1684001833200455, accuracy-micro: 0.7604579925537109, accuracy-macro: 0.0037000000011176\n",
      "step:    2785, loss: 0.1683951616287231, accuracy-micro: 0.7603660225868225, accuracy-macro: 0.0037000000011176\n",
      "step:    2786, loss: 0.1683890968561172, accuracy-micro: 0.7604357600212097, accuracy-macro: 0.0037000000011176\n",
      "step:    2787, loss: 0.1683806627988815, accuracy-micro: 0.7604002356529236, accuracy-macro: 0.0037000000011176\n",
      "step:    2788, loss: 0.1683736592531204, accuracy-micro: 0.7604634761810303, accuracy-macro: 0.0037000000011176\n",
      "step:    2789, loss: 0.1683671474456787, accuracy-micro: 0.7604550123214722, accuracy-macro: 0.0037000000011176\n",
      "step:    2790, loss: 0.1683637201786041, accuracy-micro: 0.7604954838752747, accuracy-macro: 0.0037000000011176\n",
      "step:    2791, loss: 0.1683615595102310, accuracy-micro: 0.7604932188987732, accuracy-macro: 0.0037000000011176\n",
      "step:    2792, loss: 0.1683596819639206, accuracy-micro: 0.7604952454566956, accuracy-macro: 0.0037000000011176\n",
      "step:    2793, loss: 0.1683614403009415, accuracy-micro: 0.7604927420616150, accuracy-macro: 0.0037000000011176\n",
      "step:    2794, loss: 0.1683643013238907, accuracy-micro: 0.7604619860649109, accuracy-macro: 0.0037000000011176\n",
      "step:    2795, loss: 0.1683701723814011, accuracy-micro: 0.7604952454566956, accuracy-macro: 0.0037000000011176\n",
      "step:    2796, loss: 0.1683775037527084, accuracy-micro: 0.7604132294654846, accuracy-macro: 0.0037000000011176\n",
      "step:    2797, loss: 0.1683849692344666, accuracy-micro: 0.7604674696922302, accuracy-macro: 0.0037000000011176\n",
      "step:    2798, loss: 0.1683883070945740, accuracy-micro: 0.7603619694709778, accuracy-macro: 0.0037000000011176\n",
      "step:    2799, loss: 0.1683863699436188, accuracy-micro: 0.7604847550392151, accuracy-macro: 0.0037000000011176\n",
      "step:    2800, loss: 0.1683776825666428, accuracy-micro: 0.7604027390480042, accuracy-macro: 0.0037000000011176\n",
      "step:    2801, loss: 0.1683666706085205, accuracy-micro: 0.7604877352714539, accuracy-macro: 0.0037000000011176\n",
      "step:    2802, loss: 0.1683552861213684, accuracy-micro: 0.7604737281799316, accuracy-macro: 0.0037000000011176\n",
      "step:    2803, loss: 0.1683475375175476, accuracy-micro: 0.7605190277099609, accuracy-macro: 0.0037000000011176\n",
      "step:    2804, loss: 0.1683441698551178, accuracy-micro: 0.7605105042457581, accuracy-macro: 0.0037000000011176\n",
      "step:    2805, loss: 0.1683429777622223, accuracy-micro: 0.7605172395706177, accuracy-macro: 0.0037000000011176\n",
      "step:    2806, loss: 0.1683441549539566, accuracy-micro: 0.7605322599411011, accuracy-macro: 0.0037000000011176\n",
      "step:    2807, loss: 0.1683450341224670, accuracy-micro: 0.7604892253875732, accuracy-macro: 0.0037000000011176\n",
      "step:    2808, loss: 0.1683458834886551, accuracy-micro: 0.7605444788932800, accuracy-macro: 0.0037000000011176\n",
      "step:    2809, loss: 0.1683474928140640, accuracy-micro: 0.7604715228080750, accuracy-macro: 0.0037000000011176\n",
      "step:    2810, loss: 0.1683479100465775, accuracy-micro: 0.7605274915695190, accuracy-macro: 0.0037000000011176\n",
      "step:    2811, loss: 0.1683463901281357, accuracy-micro: 0.7604892253875732, accuracy-macro: 0.0037000000011176\n",
      "step:    2812, loss: 0.1683436632156372, accuracy-micro: 0.7605542540550232, accuracy-macro: 0.0037000000011176\n",
      "step:    2813, loss: 0.1683399379253387, accuracy-micro: 0.7604960203170776, accuracy-macro: 0.0037000000011176\n",
      "step:    2814, loss: 0.1683363765478134, accuracy-micro: 0.7605452537536621, accuracy-macro: 0.0037000000011176\n",
      "step:    2815, loss: 0.1683323234319687, accuracy-micro: 0.7604979872703552, accuracy-macro: 0.0037000000011176\n",
      "step:    2816, loss: 0.1683289408683777, accuracy-micro: 0.7605504989624023, accuracy-macro: 0.0037000000011176\n",
      "step:    2817, loss: 0.1683270633220673, accuracy-micro: 0.7605657577514648, accuracy-macro: 0.0037000000011176\n",
      "step:    2818, loss: 0.1683271825313568, accuracy-micro: 0.7605412602424622, accuracy-macro: 0.0037000000011176\n",
      "step:    2819, loss: 0.1683277785778046, accuracy-micro: 0.7605695128440857, accuracy-macro: 0.0037000000011176\n",
      "step:    2820, loss: 0.1683284938335419, accuracy-micro: 0.7604852318763733, accuracy-macro: 0.0037000000011176\n",
      "step:    2821, loss: 0.1683284938335419, accuracy-micro: 0.7605674862861633, accuracy-macro: 0.0037000000011176\n",
      "step:    2822, loss: 0.1683269590139389, accuracy-micro: 0.7605015039443970, accuracy-macro: 0.0037000000011176\n",
      "step:    2823, loss: 0.1683256179094315, accuracy-micro: 0.7605774998664856, accuracy-macro: 0.0037000000011176\n",
      "step:    2824, loss: 0.1683250367641449, accuracy-micro: 0.7605022192001343, accuracy-macro: 0.0037000000011176\n",
      "step:    2825, loss: 0.1683252751827240, accuracy-micro: 0.7605599761009216, accuracy-macro: 0.0037000000011176\n",
      "step:    2826, loss: 0.1683247536420822, accuracy-micro: 0.7605007290840149, accuracy-macro: 0.0037000000011176\n",
      "step:    2827, loss: 0.1683247238397598, accuracy-micro: 0.7605692744255066, accuracy-macro: 0.0037000000011176\n",
      "step:    2828, loss: 0.1683260351419449, accuracy-micro: 0.7605017423629761, accuracy-macro: 0.0037000000011176\n",
      "step:    2829, loss: 0.1683257818222046, accuracy-micro: 0.7605515122413635, accuracy-macro: 0.0037000000011176\n",
      "step:    2830, loss: 0.1683217138051987, accuracy-micro: 0.7605130076408386, accuracy-macro: 0.0037000000011176\n",
      "step:    2831, loss: 0.1683172285556793, accuracy-micro: 0.7605902552604675, accuracy-macro: 0.0037000000011176\n",
      "step:    2832, loss: 0.1683110445737839, accuracy-micro: 0.7605247497558594, accuracy-macro: 0.0037000000011176\n",
      "step:    2833, loss: 0.1683071553707123, accuracy-micro: 0.7605714797973633, accuracy-macro: 0.0037000000011176\n",
      "step:    2834, loss: 0.1683047860860825, accuracy-micro: 0.7605727314949036, accuracy-macro: 0.0037000000011176\n",
      "step:    2835, loss: 0.1683049052953720, accuracy-micro: 0.7605552673339844, accuracy-macro: 0.0037000000011176\n",
      "step:    2836, loss: 0.1683055609464645, accuracy-micro: 0.7605842351913452, accuracy-macro: 0.0037000000011176\n",
      "step:    2837, loss: 0.1683081239461899, accuracy-micro: 0.7605402469635010, accuracy-macro: 0.0037000000011176\n",
      "step:    2838, loss: 0.1683116108179092, accuracy-micro: 0.7605872750282288, accuracy-macro: 0.0037000000011176\n",
      "step:    2839, loss: 0.1683130711317062, accuracy-micro: 0.7605417370796204, accuracy-macro: 0.0037000000011176\n",
      "step:    2840, loss: 0.1683104932308197, accuracy-micro: 0.7605767250061035, accuracy-macro: 0.0037000000011176\n",
      "step:    2841, loss: 0.1683058440685272, accuracy-micro: 0.7605462670326233, accuracy-macro: 0.0037000000011176\n",
      "step:    2842, loss: 0.1683014333248138, accuracy-micro: 0.7605835199356079, accuracy-macro: 0.0037000000011176\n",
      "step:    2843, loss: 0.1682980060577393, accuracy-micro: 0.7605590224266052, accuracy-macro: 0.0037000000011176\n",
      "step:    2844, loss: 0.1682948470115662, accuracy-micro: 0.7606135010719299, accuracy-macro: 0.0037000000011176\n",
      "step:    2845, loss: 0.1682924032211304, accuracy-micro: 0.7605720162391663, accuracy-macro: 0.0037000000011176\n",
      "step:    2846, loss: 0.1682903170585632, accuracy-micro: 0.7605912685394287, accuracy-macro: 0.0037000000011176\n",
      "step:    2847, loss: 0.1682884395122528, accuracy-micro: 0.7605819702148438, accuracy-macro: 0.0037000000011176\n",
      "step:    2848, loss: 0.1682876944541931, accuracy-micro: 0.7605774998664856, accuracy-macro: 0.0037000000011176\n",
      "step:    2849, loss: 0.1682872474193573, accuracy-micro: 0.7606112360954285, accuracy-macro: 0.0037000000011176\n",
      "step:    2850, loss: 0.1682867407798767, accuracy-micro: 0.7605972290039062, accuracy-macro: 0.0037000000011176\n",
      "step:    2851, loss: 0.1682857125997543, accuracy-micro: 0.7606272697448730, accuracy-macro: 0.0037000000011176\n",
      "step:    2852, loss: 0.1682847142219543, accuracy-micro: 0.7605634927749634, accuracy-macro: 0.0037000000011176\n",
      "step:    2853, loss: 0.1682840287685394, accuracy-micro: 0.7606089711189270, accuracy-macro: 0.0037000000011176\n",
      "step:    2854, loss: 0.1682837903499603, accuracy-micro: 0.7605885267257690, accuracy-macro: 0.0037000000011176\n",
      "step:    2855, loss: 0.1682834327220917, accuracy-micro: 0.7606227397918701, accuracy-macro: 0.0037000000011176\n",
      "step:    2856, loss: 0.1682820767164230, accuracy-micro: 0.7605987191200256, accuracy-macro: 0.0037000000011176\n",
      "step:    2857, loss: 0.1682815253734589, accuracy-micro: 0.7606300115585327, accuracy-macro: 0.0037000000011176\n",
      "step:    2858, loss: 0.1682792454957962, accuracy-micro: 0.7605990171432495, accuracy-macro: 0.0037000000011176\n",
      "step:    2859, loss: 0.1682766228914261, accuracy-micro: 0.7606257200241089, accuracy-macro: 0.0037000000011176\n",
      "step:    2860, loss: 0.1682741194963455, accuracy-micro: 0.7606195211410522, accuracy-macro: 0.0037000000011176\n",
      "step:    2861, loss: 0.1682724356651306, accuracy-micro: 0.7606344819068909, accuracy-macro: 0.0037000000011176\n",
      "step:    2862, loss: 0.1682703047990799, accuracy-micro: 0.7605992555618286, accuracy-macro: 0.0037000000011176\n",
      "step:    2863, loss: 0.1682687997817993, accuracy-micro: 0.7606332302093506, accuracy-macro: 0.0037000000011176\n",
      "step:    2864, loss: 0.1682673990726471, accuracy-micro: 0.7606067657470703, accuracy-macro: 0.0037000000011176\n",
      "step:    2865, loss: 0.1682663708925247, accuracy-micro: 0.7606212496757507, accuracy-macro: 0.0037000000011176\n",
      "step:    2866, loss: 0.1682648062705994, accuracy-micro: 0.7606367468833923, accuracy-macro: 0.0037000000011176\n",
      "step:    2867, loss: 0.1682639122009277, accuracy-micro: 0.7606202363967896, accuracy-macro: 0.0037000000011176\n",
      "step:    2868, loss: 0.1682637482881546, accuracy-micro: 0.7606532573699951, accuracy-macro: 0.0037000000011176\n",
      "step:    2869, loss: 0.1682642400264740, accuracy-micro: 0.7606277465820312, accuracy-macro: 0.0037000000011176\n",
      "step:    2870, loss: 0.1682650148868561, accuracy-micro: 0.7606660127639771, accuracy-macro: 0.0037000000011176\n",
      "step:    2871, loss: 0.1682673841714859, accuracy-micro: 0.7606032490730286, accuracy-macro: 0.0037000000011176\n",
      "step:    2872, loss: 0.1682686209678650, accuracy-micro: 0.7606867551803589, accuracy-macro: 0.0037000000011176\n",
      "step:    2873, loss: 0.1682679653167725, accuracy-micro: 0.7605867385864258, accuracy-macro: 0.0037000000011176\n",
      "step:    2874, loss: 0.1682677865028381, accuracy-micro: 0.7606850266456604, accuracy-macro: 0.0037000000011176\n",
      "step:    2875, loss: 0.1682654023170471, accuracy-micro: 0.7605839967727661, accuracy-macro: 0.0037000000011176\n",
      "step:    2876, loss: 0.1682648658752441, accuracy-micro: 0.7606995105743408, accuracy-macro: 0.0037000000011176\n",
      "step:    2877, loss: 0.1682656556367874, accuracy-micro: 0.7605827450752258, accuracy-macro: 0.0037000000011176\n",
      "step:    2878, loss: 0.1682707816362381, accuracy-micro: 0.7607079744338989, accuracy-macro: 0.0037000000011176\n",
      "step:    2879, loss: 0.1682810038328171, accuracy-micro: 0.7605317234992981, accuracy-macro: 0.0037000000011176\n",
      "step:    2880, loss: 0.1682944744825363, accuracy-micro: 0.7606649994850159, accuracy-macro: 0.0037000000011176\n",
      "step:    2881, loss: 0.1683004498481750, accuracy-micro: 0.7605214715003967, accuracy-macro: 0.0037000000011176\n",
      "step:    2882, loss: 0.1682996004819870, accuracy-micro: 0.7607107758522034, accuracy-macro: 0.0037000000011176\n",
      "step:    2883, loss: 0.1682861596345901, accuracy-micro: 0.7605279684066772, accuracy-macro: 0.0037000000011176\n",
      "step:    2884, loss: 0.1682670861482620, accuracy-micro: 0.7606800198554993, accuracy-macro: 0.0037000000011176\n",
      "step:    2885, loss: 0.1682474315166473, accuracy-micro: 0.7606357336044312, accuracy-macro: 0.0037000000011176\n",
      "step:    2886, loss: 0.1682399809360504, accuracy-micro: 0.7606857419013977, accuracy-macro: 0.0037000000011176\n",
      "step:    2887, loss: 0.1682449281215668, accuracy-micro: 0.7607414722442627, accuracy-macro: 0.0037000000011176\n",
      "step:    2888, loss: 0.1682572811841965, accuracy-micro: 0.7605997323989868, accuracy-macro: 0.0037000000011176\n",
      "step:    2889, loss: 0.1682710349559784, accuracy-micro: 0.7607112526893616, accuracy-macro: 0.0037000000011176\n",
      "step:    2890, loss: 0.1682773679494858, accuracy-micro: 0.7605357766151428, accuracy-macro: 0.0037000000011176\n",
      "step:    2891, loss: 0.1682799011468887, accuracy-micro: 0.7607102394104004, accuracy-macro: 0.0037000000011176\n",
      "step:    2892, loss: 0.1682741492986679, accuracy-micro: 0.7605507373809814, accuracy-macro: 0.0037000000011176\n",
      "step:    2893, loss: 0.1682642400264740, accuracy-micro: 0.7607079744338989, accuracy-macro: 0.0037000000011176\n",
      "step:    2894, loss: 0.1682501584291458, accuracy-micro: 0.7605929970741272, accuracy-macro: 0.0037000000011176\n",
      "step:    2895, loss: 0.1682377457618713, accuracy-micro: 0.7607377767562866, accuracy-macro: 0.0037000000011176\n",
      "step:    2896, loss: 0.1682294756174088, accuracy-micro: 0.7606639862060547, accuracy-macro: 0.0037000000011176\n",
      "step:    2897, loss: 0.1682257503271103, accuracy-micro: 0.7607367634773254, accuracy-macro: 0.0037000000011176\n",
      "step:    2898, loss: 0.1682266741991043, accuracy-micro: 0.7607485055923462, accuracy-macro: 0.0037000000011176\n",
      "step:    2899, loss: 0.1682283729314804, accuracy-micro: 0.7606465220451355, accuracy-macro: 0.0037000000011176\n",
      "step:    2900, loss: 0.1682308763265610, accuracy-micro: 0.7607652544975281, accuracy-macro: 0.0037000000011176\n",
      "step:    2901, loss: 0.1682298183441162, accuracy-micro: 0.7606505155563354, accuracy-macro: 0.0037000000011176\n",
      "step:    2902, loss: 0.1682271808385849, accuracy-micro: 0.7607627511024475, accuracy-macro: 0.0037000000011176\n",
      "step:    2903, loss: 0.1682230532169342, accuracy-micro: 0.7606549859046936, accuracy-macro: 0.0037000000011176\n",
      "step:    2904, loss: 0.1682190746068954, accuracy-micro: 0.7607357501983643, accuracy-macro: 0.0037000000011176\n",
      "step:    2905, loss: 0.1682158410549164, accuracy-micro: 0.7607294917106628, accuracy-macro: 0.0037000000011176\n",
      "step:    2906, loss: 0.1682160347700119, accuracy-micro: 0.7607114911079407, accuracy-macro: 0.0037000000011176\n",
      "step:    2907, loss: 0.1682168692350388, accuracy-micro: 0.7607587575912476, accuracy-macro: 0.0037000000011176\n",
      "step:    2908, loss: 0.1682177037000656, accuracy-micro: 0.7606555223464966, accuracy-macro: 0.0037000000011176\n",
      "step:    2909, loss: 0.1682189553976059, accuracy-micro: 0.7607907652854919, accuracy-macro: 0.0037000000011176\n",
      "step:    2910, loss: 0.1682190895080566, accuracy-micro: 0.7606744766235352, accuracy-macro: 0.0037000000011176\n",
      "step:    2911, loss: 0.1682170778512955, accuracy-micro: 0.7607970237731934, accuracy-macro: 0.0037000000011176\n",
      "step:    2912, loss: 0.1682145297527313, accuracy-micro: 0.7606432437896729, accuracy-macro: 0.0037000000011176\n",
      "step:    2913, loss: 0.1682110428810120, accuracy-micro: 0.7607702612876892, accuracy-macro: 0.0037000000011176\n",
      "step:    2914, loss: 0.1682077199220657, accuracy-micro: 0.7607027292251587, accuracy-macro: 0.0037000000011176\n",
      "step:    2915, loss: 0.1682043671607971, accuracy-micro: 0.7607769966125488, accuracy-macro: 0.0037000000011176\n",
      "step:    2916, loss: 0.1682028770446777, accuracy-micro: 0.7607504725456238, accuracy-macro: 0.0037000000011176\n",
      "step:    2917, loss: 0.1682017743587494, accuracy-micro: 0.7607389688491821, accuracy-macro: 0.0037000000011176\n",
      "step:    2918, loss: 0.1682025343179703, accuracy-micro: 0.7607737183570862, accuracy-macro: 0.0037000000011176\n",
      "step:    2919, loss: 0.1682040244340897, accuracy-micro: 0.7607005238533020, accuracy-macro: 0.0037000000011176\n",
      "step:    2920, loss: 0.1682070642709732, accuracy-micro: 0.7608267664909363, accuracy-macro: 0.0037000000011176\n",
      "step:    2921, loss: 0.1682074368000031, accuracy-micro: 0.7607062458992004, accuracy-macro: 0.0037000000011176\n",
      "step:    2922, loss: 0.1682054400444031, accuracy-micro: 0.7607960104942322, accuracy-macro: 0.0037000000011176\n",
      "step:    2923, loss: 0.1681998223066330, accuracy-micro: 0.7606980204582214, accuracy-macro: 0.0037000000011176\n",
      "step:    2924, loss: 0.1681945323944092, accuracy-micro: 0.7607882618904114, accuracy-macro: 0.0037000000011176\n",
      "step:    2925, loss: 0.1681913733482361, accuracy-micro: 0.7607677578926086, accuracy-macro: 0.0037000000011176\n",
      "step:    2926, loss: 0.1681900322437286, accuracy-micro: 0.7607807517051697, accuracy-macro: 0.0037000000011176\n",
      "step:    2927, loss: 0.1681906282901764, accuracy-micro: 0.7607997655868530, accuracy-macro: 0.0037000000011176\n",
      "step:    2928, loss: 0.1681917458772659, accuracy-micro: 0.7607222199440002, accuracy-macro: 0.0037000000011176\n",
      "step:    2929, loss: 0.1681934297084808, accuracy-micro: 0.7608332633972168, accuracy-macro: 0.0037000000011176\n",
      "step:    2930, loss: 0.1681938171386719, accuracy-micro: 0.7607204914093018, accuracy-macro: 0.0037000000011176\n",
      "step:    2931, loss: 0.1681950241327286, accuracy-micro: 0.7608199715614319, accuracy-macro: 0.0037000000011176\n",
      "step:    2932, loss: 0.1681955158710480, accuracy-micro: 0.7607147693634033, accuracy-macro: 0.0037000000011176\n",
      "step:    2933, loss: 0.1681957691907883, accuracy-micro: 0.7607882618904114, accuracy-macro: 0.0037000000011176\n",
      "step:    2934, loss: 0.1681927144527435, accuracy-micro: 0.7607002258300781, accuracy-macro: 0.0037000000011176\n",
      "step:    2935, loss: 0.1681886017322540, accuracy-micro: 0.7608500123023987, accuracy-macro: 0.0037000000011176\n",
      "step:    2936, loss: 0.1681835353374481, accuracy-micro: 0.7607384920120239, accuracy-macro: 0.0037000000011176\n",
      "step:    2937, loss: 0.1681792140007019, accuracy-micro: 0.7608374953269958, accuracy-macro: 0.0037000000011176\n",
      "step:    2938, loss: 0.1681757569313049, accuracy-micro: 0.7607539892196655, accuracy-macro: 0.0037000000011176\n",
      "step:    2939, loss: 0.1681739240884781, accuracy-micro: 0.7607809901237488, accuracy-macro: 0.0037000000011176\n",
      "step:    2940, loss: 0.1681733727455139, accuracy-micro: 0.7608302235603333, accuracy-macro: 0.0037000000011176\n",
      "step:    2941, loss: 0.1681738942861557, accuracy-micro: 0.7607539892196655, accuracy-macro: 0.0037000000011176\n",
      "step:    2942, loss: 0.1681752204895020, accuracy-micro: 0.7608489990234375, accuracy-macro: 0.0037000000011176\n",
      "step:    2943, loss: 0.1681765168905258, accuracy-micro: 0.7607554793357849, accuracy-macro: 0.0037000000011176\n",
      "step:    2944, loss: 0.1681752949953079, accuracy-micro: 0.7608667612075806, accuracy-macro: 0.0037000000011176\n",
      "step:    2945, loss: 0.1681728810071945, accuracy-micro: 0.7607562541961670, accuracy-macro: 0.0037000000011176\n",
      "step:    2946, loss: 0.1681691408157349, accuracy-micro: 0.7608667612075806, accuracy-macro: 0.0037000000011176\n",
      "step:    2947, loss: 0.1681659966707230, accuracy-micro: 0.7607752680778503, accuracy-macro: 0.0037000000011176\n",
      "step:    2948, loss: 0.1681634485721588, accuracy-micro: 0.7608349919319153, accuracy-macro: 0.0037000000011176\n",
      "step:    2949, loss: 0.1681618094444275, accuracy-micro: 0.7608042359352112, accuracy-macro: 0.0037000000011176\n",
      "step:    2950, loss: 0.1681623756885529, accuracy-micro: 0.7607822418212891, accuracy-macro: 0.0037000000011176\n",
      "step:    2951, loss: 0.1681619435548782, accuracy-micro: 0.7608709931373596, accuracy-macro: 0.0037000000011176\n",
      "step:    2952, loss: 0.1681618988513947, accuracy-micro: 0.7607547640800476, accuracy-macro: 0.0037000000011176\n",
      "step:    2953, loss: 0.1681608706712723, accuracy-micro: 0.7608672380447388, accuracy-macro: 0.0037000000011176\n",
      "step:    2954, loss: 0.1681589633226395, accuracy-micro: 0.7607792615890503, accuracy-macro: 0.0037000000011176\n",
      "step:    2955, loss: 0.1681559681892395, accuracy-micro: 0.7608652710914612, accuracy-macro: 0.0037000000011176\n",
      "step:    2956, loss: 0.1681539416313171, accuracy-micro: 0.7607759833335876, accuracy-macro: 0.0037000000011176\n",
      "step:    2957, loss: 0.1681524217128754, accuracy-micro: 0.7608377337455750, accuracy-macro: 0.0037000000011176\n",
      "step:    2958, loss: 0.1681504845619202, accuracy-micro: 0.7608249783515930, accuracy-macro: 0.0037000000011176\n",
      "step:    2959, loss: 0.1681496500968933, accuracy-micro: 0.7608104944229126, accuracy-macro: 0.0037000000011176\n",
      "step:    2960, loss: 0.1681485921144485, accuracy-micro: 0.7608472704887390, accuracy-macro: 0.0037000000011176\n",
      "step:    2961, loss: 0.1681480109691620, accuracy-micro: 0.7607995271682739, accuracy-macro: 0.0037000000011176\n",
      "step:    2962, loss: 0.1681468635797501, accuracy-micro: 0.7608467340469360, accuracy-macro: 0.0037000000011176\n",
      "step:    2963, loss: 0.1681454032659531, accuracy-micro: 0.7608119845390320, accuracy-macro: 0.0037000000011176\n",
      "step:    2964, loss: 0.1681454777717590, accuracy-micro: 0.7608702182769775, accuracy-macro: 0.0037000000011176\n",
      "step:    2965, loss: 0.1681434810161591, accuracy-micro: 0.7608144879341125, accuracy-macro: 0.0037000000011176\n",
      "step:    2966, loss: 0.1681421101093292, accuracy-micro: 0.7608529925346375, accuracy-macro: 0.0037000000011176\n",
      "step:    2967, loss: 0.1681406199932098, accuracy-micro: 0.7608299851417542, accuracy-macro: 0.0037000000011176\n",
      "step:    2968, loss: 0.1681387871503830, accuracy-micro: 0.7608807682991028, accuracy-macro: 0.0037000000011176\n",
      "step:    2969, loss: 0.1681374311447144, accuracy-micro: 0.7608255147933960, accuracy-macro: 0.0037000000011176\n",
      "step:    2970, loss: 0.1681360304355621, accuracy-micro: 0.7608659863471985, accuracy-macro: 0.0037000000011176\n",
      "step:    2971, loss: 0.1681352406740189, accuracy-micro: 0.7608262300491333, accuracy-macro: 0.0037000000011176\n",
      "step:    2972, loss: 0.1681337505578995, accuracy-micro: 0.7608724832534790, accuracy-macro: 0.0037000000011176\n",
      "step:    2973, loss: 0.1681321114301682, accuracy-micro: 0.7608382701873779, accuracy-macro: 0.0037000000011176\n",
      "step:    2974, loss: 0.1681312322616577, accuracy-micro: 0.7608690261840820, accuracy-macro: 0.0037000000011176\n",
      "step:    2975, loss: 0.1681298166513443, accuracy-micro: 0.7608389854431152, accuracy-macro: 0.0037000000011176\n",
      "step:    2976, loss: 0.1681290566921234, accuracy-micro: 0.7608512639999390, accuracy-macro: 0.0037000000011176\n",
      "step:    2977, loss: 0.1681271493434906, accuracy-micro: 0.7608492374420166, accuracy-macro: 0.0037000000011176\n",
      "step:    2978, loss: 0.1681268811225891, accuracy-micro: 0.7608697414398193, accuracy-macro: 0.0037000000011176\n",
      "step:    2979, loss: 0.1681258678436279, accuracy-micro: 0.7608960270881653, accuracy-macro: 0.0037000000011176\n",
      "step:    2980, loss: 0.1681257486343384, accuracy-micro: 0.7608554959297180, accuracy-macro: 0.0037000000011176\n",
      "step:    2981, loss: 0.1681259274482727, accuracy-micro: 0.7608947753906250, accuracy-macro: 0.0037000000011176\n",
      "step:    2982, loss: 0.1681251823902130, accuracy-micro: 0.7608472704887390, accuracy-macro: 0.0037000000011176\n",
      "step:    2983, loss: 0.1681250482797623, accuracy-micro: 0.7609272599220276, accuracy-macro: 0.0037000000011176\n",
      "step:    2984, loss: 0.1681244075298309, accuracy-micro: 0.7608479857444763, accuracy-macro: 0.0037000000011176\n",
      "step:    2985, loss: 0.1681227087974548, accuracy-micro: 0.7609210014343262, accuracy-macro: 0.0037000000011176\n",
      "step:    2986, loss: 0.1681219339370728, accuracy-micro: 0.7608557343482971, accuracy-macro: 0.0037000000011176\n",
      "step:    2987, loss: 0.1681205630302429, accuracy-micro: 0.7609300017356873, accuracy-macro: 0.0037000000011176\n",
      "step:    2988, loss: 0.1681196540594101, accuracy-micro: 0.7608547210693359, accuracy-macro: 0.0037000000011176\n",
      "step:    2989, loss: 0.1681183427572250, accuracy-micro: 0.7609367370605469, accuracy-macro: 0.0037000000011176\n",
      "step:    2990, loss: 0.1681173592805862, accuracy-micro: 0.7608542442321777, accuracy-macro: 0.0037000000011176\n",
      "step:    2991, loss: 0.1681170910596848, accuracy-micro: 0.7609274983406067, accuracy-macro: 0.0037000000011176\n",
      "step:    2992, loss: 0.1681157499551773, accuracy-micro: 0.7608579993247986, accuracy-macro: 0.0037000000011176\n",
      "step:    2993, loss: 0.1681140661239624, accuracy-micro: 0.7609442472457886, accuracy-macro: 0.0037000000011176\n",
      "step:    2994, loss: 0.1681115627288818, accuracy-micro: 0.7608727216720581, accuracy-macro: 0.0037000000011176\n",
      "step:    2995, loss: 0.1681089997291565, accuracy-micro: 0.7609242200851440, accuracy-macro: 0.0037000000011176\n",
      "step:    2996, loss: 0.1681070327758789, accuracy-micro: 0.7608914971351624, accuracy-macro: 0.0037000000011176\n",
      "step:    2997, loss: 0.1681059598922729, accuracy-micro: 0.7609122395515442, accuracy-macro: 0.0037000000011176\n",
      "step:    2998, loss: 0.1681053191423416, accuracy-micro: 0.7608812451362610, accuracy-macro: 0.0037000000011176\n",
      "step:    2999, loss: 0.1681039333343506, accuracy-micro: 0.7609469890594482, accuracy-macro: 0.0037000000011176\n",
      "step:    3000, loss: 0.1681026816368103, accuracy-micro: 0.7608894705772400, accuracy-macro: 0.0037000000011176\n",
      "step:    3001, loss: 0.1681000590324402, accuracy-micro: 0.7609304785728455, accuracy-macro: 0.0037000000011176\n",
      "step:    3002, loss: 0.1680982857942581, accuracy-micro: 0.7608975172042847, accuracy-macro: 0.0037000000011176\n",
      "step:    3003, loss: 0.1680970042943954, accuracy-micro: 0.7609107494354248, accuracy-macro: 0.0037000000011176\n",
      "step:    3004, loss: 0.1680952906608582, accuracy-micro: 0.7609180212020874, accuracy-macro: 0.0037000000011176\n",
      "step:    3005, loss: 0.1680946648120880, accuracy-micro: 0.7609107494354248, accuracy-macro: 0.0037000000011176\n",
      "step:    3006, loss: 0.1680945307016373, accuracy-micro: 0.7609549760818481, accuracy-macro: 0.0037000000011176\n",
      "step:    3007, loss: 0.1680941283702850, accuracy-micro: 0.7609247565269470, accuracy-macro: 0.0037000000011176\n",
      "step:    3008, loss: 0.1680933535099030, accuracy-micro: 0.7609337568283081, accuracy-macro: 0.0037000000011176\n",
      "step:    3009, loss: 0.1680925041437149, accuracy-micro: 0.7609352469444275, accuracy-macro: 0.0037000000011176\n",
      "step:    3010, loss: 0.1680909693241119, accuracy-micro: 0.7609745264053345, accuracy-macro: 0.0037000000011176\n",
      "step:    3011, loss: 0.1680894345045090, accuracy-micro: 0.7609319686889648, accuracy-macro: 0.0037000000011176\n",
      "step:    3012, loss: 0.1680880337953568, accuracy-micro: 0.7609534859657288, accuracy-macro: 0.0037000000011176\n",
      "step:    3013, loss: 0.1680874377489090, accuracy-micro: 0.7609379887580872, accuracy-macro: 0.0037000000011176\n",
      "step:    3014, loss: 0.1680860668420792, accuracy-micro: 0.7609645128250122, accuracy-macro: 0.0037000000011176\n",
      "step:    3015, loss: 0.1680853813886642, accuracy-micro: 0.7609459757804871, accuracy-macro: 0.0037000000011176\n",
      "step:    3016, loss: 0.1680831760168076, accuracy-micro: 0.7609632611274719, accuracy-macro: 0.0037000000011176\n",
      "step:    3017, loss: 0.1680810898542404, accuracy-micro: 0.7609552741050720, accuracy-macro: 0.0037000000011176\n",
      "step:    3018, loss: 0.1680790930986404, accuracy-micro: 0.7609522342681885, accuracy-macro: 0.0037000000011176\n",
      "step:    3019, loss: 0.1680778861045837, accuracy-micro: 0.7609602212905884, accuracy-macro: 0.0037000000011176\n",
      "step:    3020, loss: 0.1680765748023987, accuracy-micro: 0.7609672546386719, accuracy-macro: 0.0037000000011176\n",
      "step:    3021, loss: 0.1680749952793121, accuracy-micro: 0.7609767317771912, accuracy-macro: 0.0037000000011176\n",
      "step:    3022, loss: 0.1680745631456375, accuracy-micro: 0.7609519958496094, accuracy-macro: 0.0037000000011176\n",
      "step:    3023, loss: 0.1680741906166077, accuracy-micro: 0.7609607577323914, accuracy-macro: 0.0037000000011176\n",
      "step:    3024, loss: 0.1680740118026733, accuracy-micro: 0.7609737515449524, accuracy-macro: 0.0037000000011176\n",
      "step:    3025, loss: 0.1680749058723450, accuracy-micro: 0.7609704732894897, accuracy-macro: 0.0037000000011176\n",
      "step:    3026, loss: 0.1680778563022614, accuracy-micro: 0.7609890103340149, accuracy-macro: 0.0037000000011176\n",
      "step:    3027, loss: 0.1680812537670135, accuracy-micro: 0.7609015107154846, accuracy-macro: 0.0037000000011176\n",
      "step:    3028, loss: 0.1680863946676254, accuracy-micro: 0.7610229849815369, accuracy-macro: 0.0037000000011176\n",
      "step:    3029, loss: 0.1680908501148224, accuracy-micro: 0.7608755230903625, accuracy-macro: 0.0037000000011176\n",
      "step:    3030, loss: 0.1680969595909119, accuracy-micro: 0.7610217332839966, accuracy-macro: 0.0037000000011176\n",
      "step:    3031, loss: 0.1681004166603088, accuracy-micro: 0.7608785033226013, accuracy-macro: 0.0037000000011176\n",
      "step:    3032, loss: 0.1681029200553894, accuracy-micro: 0.7610085010528564, accuracy-macro: 0.0037000000011176\n",
      "step:    3033, loss: 0.1681004911661148, accuracy-micro: 0.7608692646026611, accuracy-macro: 0.0037000000011176\n",
      "step:    3034, loss: 0.1680937409400940, accuracy-micro: 0.7610194683074951, accuracy-macro: 0.0037000000011176\n",
      "step:    3035, loss: 0.1680822223424911, accuracy-micro: 0.7609040141105652, accuracy-macro: 0.0037000000011176\n",
      "step:    3036, loss: 0.1680713444948196, accuracy-micro: 0.7610252499580383, accuracy-macro: 0.0037000000011176\n",
      "step:    3037, loss: 0.1680628657341003, accuracy-micro: 0.7609685063362122, accuracy-macro: 0.0037000000011176\n",
      "step:    3038, loss: 0.1680575609207153, accuracy-micro: 0.7609829902648926, accuracy-macro: 0.0037000000011176\n",
      "step:    3039, loss: 0.1680547297000885, accuracy-micro: 0.7609977722167969, accuracy-macro: 0.0037000000011176\n",
      "step:    3040, loss: 0.1680544018745422, accuracy-micro: 0.7610034942626953, accuracy-macro: 0.0037000000011176\n",
      "step:    3041, loss: 0.1680564880371094, accuracy-micro: 0.7610242366790771, accuracy-macro: 0.0037000000011176\n",
      "step:    3042, loss: 0.1680607497692108, accuracy-micro: 0.7609714865684509, accuracy-macro: 0.0037000000011176\n",
      "step:    3043, loss: 0.1680669784545898, accuracy-micro: 0.7610329985618591, accuracy-macro: 0.0037000000011176\n",
      "step:    3044, loss: 0.1680741906166077, accuracy-micro: 0.7609122395515442, accuracy-macro: 0.0037000000011176\n",
      "step:    3045, loss: 0.1680788397789001, accuracy-micro: 0.7610502243041992, accuracy-macro: 0.0037000000011176\n",
      "step:    3046, loss: 0.1680787503719330, accuracy-micro: 0.7609207630157471, accuracy-macro: 0.0037000000011176\n",
      "step:    3047, loss: 0.1680734306573868, accuracy-micro: 0.7610572576522827, accuracy-macro: 0.0037000000011176\n",
      "step:    3048, loss: 0.1680635064840317, accuracy-micro: 0.7609595060348511, accuracy-macro: 0.0037000000011176\n",
      "step:    3049, loss: 0.1680543273687363, accuracy-micro: 0.7610222697257996, accuracy-macro: 0.0037000000011176\n",
      "step:    3050, loss: 0.1680455356836319, accuracy-micro: 0.7609990239143372, accuracy-macro: 0.0037000000011176\n",
      "step:    3051, loss: 0.1680406183004379, accuracy-micro: 0.7610340118408203, accuracy-macro: 0.0037000000011176\n",
      "step:    3052, loss: 0.1680399924516678, accuracy-micro: 0.7610365152359009, accuracy-macro: 0.0037000000011176\n",
      "step:    3053, loss: 0.1680410057306290, accuracy-micro: 0.7610072493553162, accuracy-macro: 0.0037000000011176\n",
      "step:    3054, loss: 0.1680428385734558, accuracy-micro: 0.7610442638397217, accuracy-macro: 0.0037000000011176\n",
      "step:    3055, loss: 0.1680433750152588, accuracy-micro: 0.7610179781913757, accuracy-macro: 0.0037000000011176\n",
      "step:    3056, loss: 0.1680429428815842, accuracy-micro: 0.7610419988632202, accuracy-macro: 0.0037000000011176\n",
      "step:    3057, loss: 0.1680406033992767, accuracy-micro: 0.7610110044479370, accuracy-macro: 0.0037000000011176\n",
      "step:    3058, loss: 0.1680368930101395, accuracy-micro: 0.7610700130462646, accuracy-macro: 0.0037000000011176\n",
      "step:    3059, loss: 0.1680336892604828, accuracy-micro: 0.7610200047492981, accuracy-macro: 0.0037000000011176\n",
      "step:    3060, loss: 0.1680304408073425, accuracy-micro: 0.7610617280006409, accuracy-macro: 0.0037000000011176\n",
      "step:    3061, loss: 0.1680292189121246, accuracy-micro: 0.7610509991645813, accuracy-macro: 0.0037000000011176\n",
      "step:    3062, loss: 0.1680284887552261, accuracy-micro: 0.7610222697257996, accuracy-macro: 0.0037000000011176\n",
      "step:    3063, loss: 0.1680282205343246, accuracy-micro: 0.7610837221145630, accuracy-macro: 0.0037000000011176\n",
      "step:    3064, loss: 0.1680282801389694, accuracy-micro: 0.7610227465629578, accuracy-macro: 0.0037000000011176\n",
      "step:    3065, loss: 0.1680275350809097, accuracy-micro: 0.7610759735107422, accuracy-macro: 0.0037000000011176\n",
      "step:    3066, loss: 0.1680269241333008, accuracy-micro: 0.7610350251197815, accuracy-macro: 0.0037000000011176\n",
      "step:    3067, loss: 0.1680252254009247, accuracy-micro: 0.7610767483711243, accuracy-macro: 0.0037000000011176\n",
      "step:    3068, loss: 0.1680233776569366, accuracy-micro: 0.7610275149345398, accuracy-macro: 0.0037000000011176\n",
      "step:    3069, loss: 0.1680212765932083, accuracy-micro: 0.7610989809036255, accuracy-macro: 0.0037000000011176\n",
      "step:    3070, loss: 0.1680192798376083, accuracy-micro: 0.7610307335853577, accuracy-macro: 0.0037000000011176\n",
      "step:    3071, loss: 0.1680172234773636, accuracy-micro: 0.7610610127449036, accuracy-macro: 0.0037000000011176\n",
      "step:    3072, loss: 0.1680165678262711, accuracy-micro: 0.7610960006713867, accuracy-macro: 0.0037000000011176\n",
      "step:    3073, loss: 0.1680178344249725, accuracy-micro: 0.7610452771186829, accuracy-macro: 0.0037000000011176\n",
      "step:    3074, loss: 0.1680180430412292, accuracy-micro: 0.7611010074615479, accuracy-macro: 0.0037000000011176\n",
      "step:    3075, loss: 0.1680178195238113, accuracy-micro: 0.7610480189323425, accuracy-macro: 0.0037000000011176\n",
      "step:    3076, loss: 0.1680173873901367, accuracy-micro: 0.7610842585563660, accuracy-macro: 0.0037000000011176\n",
      "step:    3077, loss: 0.1680161803960800, accuracy-micro: 0.7610654830932617, accuracy-macro: 0.0037000000011176\n",
      "step:    3078, loss: 0.1680145114660263, accuracy-micro: 0.7611097693443298, accuracy-macro: 0.0037000000011176\n",
      "step:    3079, loss: 0.1680125147104263, accuracy-micro: 0.7610562443733215, accuracy-macro: 0.0037000000011176\n",
      "step:    3080, loss: 0.1680108308792114, accuracy-micro: 0.7611064910888672, accuracy-macro: 0.0037000000011176\n",
      "step:    3081, loss: 0.1680088192224503, accuracy-micro: 0.7610537409782410, accuracy-macro: 0.0037000000011176\n",
      "step:    3082, loss: 0.1680070906877518, accuracy-micro: 0.7611184716224670, accuracy-macro: 0.0037000000011176\n",
      "step:    3083, loss: 0.1680050939321518, accuracy-micro: 0.7610729932785034, accuracy-macro: 0.0037000000011176\n",
      "step:    3084, loss: 0.1680036783218384, accuracy-micro: 0.7611020207405090, accuracy-macro: 0.0037000000011176\n",
      "step:    3085, loss: 0.1680023968219757, accuracy-micro: 0.7611092329025269, accuracy-macro: 0.0037000000011176\n",
      "step:    3086, loss: 0.1680004298686981, accuracy-micro: 0.7611259818077087, accuracy-macro: 0.0037000000011176\n",
      "step:    3087, loss: 0.1680000871419907, accuracy-micro: 0.7611097693443298, accuracy-macro: 0.0037000000011176\n",
      "step:    3088, loss: 0.1679991632699966, accuracy-micro: 0.7610970139503479, accuracy-macro: 0.0037000000011176\n",
      "step:    3089, loss: 0.1679977476596832, accuracy-micro: 0.7611420154571533, accuracy-macro: 0.0037000000011176\n",
      "step:    3090, loss: 0.1679979115724564, accuracy-micro: 0.7611004710197449, accuracy-macro: 0.0037000000011176\n",
      "step:    3091, loss: 0.1679980903863907, accuracy-micro: 0.7611257433891296, accuracy-macro: 0.0037000000011176\n",
      "step:    3092, loss: 0.1679982990026474, accuracy-micro: 0.7610732316970825, accuracy-macro: 0.0037000000011176\n",
      "step:    3093, loss: 0.1679978221654892, accuracy-micro: 0.7611142396926880, accuracy-macro: 0.0037000000011176\n",
      "step:    3094, loss: 0.1679974943399429, accuracy-micro: 0.7610862255096436, accuracy-macro: 0.0037000000011176\n",
      "step:    3095, loss: 0.1679957807064056, accuracy-micro: 0.7611242532730103, accuracy-macro: 0.0037000000011176\n",
      "step:    3096, loss: 0.1679933965206146, accuracy-micro: 0.7610917687416077, accuracy-macro: 0.0037000000011176\n",
      "step:    3097, loss: 0.1679916083812714, accuracy-micro: 0.7611249685287476, accuracy-macro: 0.0037000000011176\n",
      "step:    3098, loss: 0.1679900735616684, accuracy-micro: 0.7611014842987061, accuracy-macro: 0.0037000000011176\n",
      "step:    3099, loss: 0.1679893285036087, accuracy-micro: 0.7611142396926880, accuracy-macro: 0.0037000000011176\n",
      "step:    3100, loss: 0.1679883599281311, accuracy-micro: 0.7611150145530701, accuracy-macro: 0.0037000000011176\n",
      "step:    3101, loss: 0.1679866611957550, accuracy-micro: 0.7611232399940491, accuracy-macro: 0.0037000000011176\n",
      "step:    3102, loss: 0.1679858118295670, accuracy-micro: 0.7611290216445923, accuracy-macro: 0.0037000000011176\n",
      "step:    3103, loss: 0.1679857224225998, accuracy-micro: 0.7611317634582520, accuracy-macro: 0.0037000000011176\n",
      "step:    3104, loss: 0.1679857224225998, accuracy-micro: 0.7611160278320312, accuracy-macro: 0.0037000000011176\n",
      "step:    3105, loss: 0.1679880023002625, accuracy-micro: 0.7611407637596130, accuracy-macro: 0.0037000000011176\n",
      "step:    3106, loss: 0.1679910123348236, accuracy-micro: 0.7610962390899658, accuracy-macro: 0.0037000000011176\n",
      "step:    3107, loss: 0.1679939627647400, accuracy-micro: 0.7611364722251892, accuracy-macro: 0.0037000000011176\n",
      "step:    3108, loss: 0.1679970622062683, accuracy-micro: 0.7610757350921631, accuracy-macro: 0.0037000000011176\n",
      "step:    3109, loss: 0.1679992228746414, accuracy-micro: 0.7611330151557922, accuracy-macro: 0.0037000000011176\n",
      "step:    3110, loss: 0.1679975837469101, accuracy-micro: 0.7610632777214050, accuracy-macro: 0.0037000000011176\n",
      "step:    3111, loss: 0.1679953187704086, accuracy-micro: 0.7611477375030518, accuracy-macro: 0.0037000000011176\n",
      "step:    3112, loss: 0.1679894030094147, accuracy-micro: 0.7611082196235657, accuracy-macro: 0.0037000000011176\n",
      "step:    3113, loss: 0.1679834425449371, accuracy-micro: 0.7611577510833740, accuracy-macro: 0.0037000000011176\n",
      "step:    3114, loss: 0.1679772287607193, accuracy-micro: 0.7611249685287476, accuracy-macro: 0.0037000000011176\n",
      "step:    3115, loss: 0.1679713129997253, accuracy-micro: 0.7611439824104309, accuracy-macro: 0.0037000000011176\n",
      "step:    3116, loss: 0.1679682433605194, accuracy-micro: 0.7611812353134155, accuracy-macro: 0.0037000000011176\n",
      "step:    3117, loss: 0.1679664105176926, accuracy-micro: 0.7611734867095947, accuracy-macro: 0.0037000000011176\n",
      "step:    3118, loss: 0.1679652631282806, accuracy-micro: 0.7611682415008545, accuracy-macro: 0.0037000000011176\n",
      "step:    3119, loss: 0.1679638326168060, accuracy-micro: 0.7611682415008545, accuracy-macro: 0.0037000000011176\n",
      "step:    3120, loss: 0.1679624319076538, accuracy-micro: 0.7611642479896545, accuracy-macro: 0.0037000000011176\n",
      "step:    3121, loss: 0.1679621189832687, accuracy-micro: 0.7611857652664185, accuracy-macro: 0.0037000000011176\n",
      "step:    3122, loss: 0.1679616868495941, accuracy-micro: 0.7611557245254517, accuracy-macro: 0.0037000000011176\n",
      "step:    3123, loss: 0.1679606288671494, accuracy-micro: 0.7611709833145142, accuracy-macro: 0.0037000000011176\n",
      "step:    3124, loss: 0.1679613739252090, accuracy-micro: 0.7611692547798157, accuracy-macro: 0.0037000000011176\n",
      "step:    3125, loss: 0.1679617762565613, accuracy-micro: 0.7611737251281738, accuracy-macro: 0.0037000000011176\n",
      "step:    3126, loss: 0.1679625064134598, accuracy-micro: 0.7611615061759949, accuracy-macro: 0.0037000000011176\n",
      "step:    3127, loss: 0.1679627150297165, accuracy-micro: 0.7611675262451172, accuracy-macro: 0.0037000000011176\n",
      "step:    3128, loss: 0.1679615974426270, accuracy-micro: 0.7611682415008545, accuracy-macro: 0.0037000000011176\n",
      "step:    3129, loss: 0.1679582595825195, accuracy-micro: 0.7611647248268127, accuracy-macro: 0.0037000000011176\n",
      "step:    3130, loss: 0.1679551750421524, accuracy-micro: 0.7611640095710754, accuracy-macro: 0.0037000000011176\n",
      "step:    3131, loss: 0.1679516583681107, accuracy-micro: 0.7611832618713379, accuracy-macro: 0.0037000000011176\n",
      "step:    3132, loss: 0.1679491847753525, accuracy-micro: 0.7611962556838989, accuracy-macro: 0.0037000000011176\n",
      "step:    3133, loss: 0.1679482311010361, accuracy-micro: 0.7611957192420959, accuracy-macro: 0.0037000000011176\n",
      "step:    3134, loss: 0.1679481565952301, accuracy-micro: 0.7612152695655823, accuracy-macro: 0.0037000000011176\n",
      "step:    3135, loss: 0.1679498404264450, accuracy-micro: 0.7611960172653198, accuracy-macro: 0.0037000000011176\n",
      "step:    3136, loss: 0.1679513901472092, accuracy-micro: 0.7611789703369141, accuracy-macro: 0.0037000000011176\n",
      "step:    3137, loss: 0.1679547876119614, accuracy-micro: 0.7611762285232544, accuracy-macro: 0.0037000000011176\n",
      "step:    3138, loss: 0.1679608076810837, accuracy-micro: 0.7611330151557922, accuracy-macro: 0.0037000000011176\n",
      "step:    3139, loss: 0.1679750233888626, accuracy-micro: 0.7612167596817017, accuracy-macro: 0.0037000000011176\n",
      "step:    3140, loss: 0.1679909974336624, accuracy-micro: 0.7610654830932617, accuracy-macro: 0.0037000000011176\n",
      "step:    3141, loss: 0.1680091768503189, accuracy-micro: 0.7612025141716003, accuracy-macro: 0.0037000000011176\n",
      "step:    3142, loss: 0.1680173873901367, accuracy-micro: 0.7610625028610229, accuracy-macro: 0.0037000000011176\n",
      "step:    3143, loss: 0.1680182814598083, accuracy-micro: 0.7612149715423584, accuracy-macro: 0.0037000000011176\n",
      "step:    3144, loss: 0.1680022180080414, accuracy-micro: 0.7610677480697632, accuracy-macro: 0.0037000000011176\n",
      "step:    3145, loss: 0.1679804623126984, accuracy-micro: 0.7612287402153015, accuracy-macro: 0.0037000000011176\n",
      "step:    3146, loss: 0.1679562777280807, accuracy-micro: 0.7611539959907532, accuracy-macro: 0.0037000000011176\n",
      "step:    3147, loss: 0.1679383367300034, accuracy-micro: 0.7612047195434570, accuracy-macro: 0.0037000000011176\n",
      "step:    3148, loss: 0.1679322868585587, accuracy-micro: 0.7612112760543823, accuracy-macro: 0.0037000000011176\n",
      "step:    3149, loss: 0.1679344624280930, accuracy-micro: 0.7612037658691406, accuracy-macro: 0.0037000000011176\n",
      "step:    3150, loss: 0.1679412275552750, accuracy-micro: 0.7612090110778809, accuracy-macro: 0.0037000000011176\n",
      "step:    3151, loss: 0.1679469943046570, accuracy-micro: 0.7611662745475769, accuracy-macro: 0.0037000000011176\n",
      "step:    3152, loss: 0.1679491549730301, accuracy-micro: 0.7612172365188599, accuracy-macro: 0.0037000000011176\n",
      "step:    3153, loss: 0.1679442822933197, accuracy-micro: 0.7611864805221558, accuracy-macro: 0.0037000000011176\n",
      "step:    3154, loss: 0.1679343134164810, accuracy-micro: 0.7612010240554810, accuracy-macro: 0.0037000000011176\n",
      "step:    3155, loss: 0.1679257452487946, accuracy-micro: 0.7612515091896057, accuracy-macro: 0.0037000000011176\n",
      "step:    3156, loss: 0.1679234355688095, accuracy-micro: 0.7612747550010681, accuracy-macro: 0.0037000000011176\n",
      "step:    3157, loss: 0.1679279208183289, accuracy-micro: 0.7612417340278625, accuracy-macro: 0.0037000000011176\n",
      "step:    3158, loss: 0.1679363101720810, accuracy-micro: 0.7612172365188599, accuracy-macro: 0.0037000000011176\n",
      "step:    3159, loss: 0.1679425686597824, accuracy-micro: 0.7612372636795044, accuracy-macro: 0.0037000000011176\n",
      "step:    3160, loss: 0.1679414659738541, accuracy-micro: 0.7611797451972961, accuracy-macro: 0.0037000000011176\n",
      "step:    3161, loss: 0.1679354906082153, accuracy-micro: 0.7612397670745850, accuracy-macro: 0.0037000000011176\n",
      "step:    3162, loss: 0.1679250895977020, accuracy-micro: 0.7612232565879822, accuracy-macro: 0.0037000000011176\n",
      "step:    3163, loss: 0.1679173111915588, accuracy-micro: 0.7612320184707642, accuracy-macro: 0.0037000000011176\n",
      "step:    3164, loss: 0.1679146885871887, accuracy-micro: 0.7612469792366028, accuracy-macro: 0.0037000000011176\n",
      "step:    3165, loss: 0.1679183393716812, accuracy-micro: 0.7612400054931641, accuracy-macro: 0.0037000000011176\n",
      "step:    3166, loss: 0.1679263412952423, accuracy-micro: 0.7612429857254028, accuracy-macro: 0.0037000000011176\n",
      "step:    3167, loss: 0.1679330617189407, accuracy-micro: 0.7612372636795044, accuracy-macro: 0.0037000000011176\n",
      "step:    3168, loss: 0.1679339706897736, accuracy-micro: 0.7612705230712891, accuracy-macro: 0.0037000000011176\n",
      "step:    3169, loss: 0.1679289937019348, accuracy-micro: 0.7612237334251404, accuracy-macro: 0.0037000000011176\n",
      "step:    3170, loss: 0.1679217815399170, accuracy-micro: 0.7612302303314209, accuracy-macro: 0.0037000000011176\n",
      "step:    3171, loss: 0.1679137200117111, accuracy-micro: 0.7612385153770447, accuracy-macro: 0.0037000000011176\n",
      "step:    3172, loss: 0.1679078191518784, accuracy-micro: 0.7612512707710266, accuracy-macro: 0.0037000000011176\n",
      "step:    3173, loss: 0.1679044663906097, accuracy-micro: 0.7612442374229431, accuracy-macro: 0.0037000000011176\n",
      "step:    3174, loss: 0.1679044514894485, accuracy-micro: 0.7612594962120056, accuracy-macro: 0.0037000000011176\n",
      "step:    3175, loss: 0.1679066717624664, accuracy-micro: 0.7612829804420471, accuracy-macro: 0.0037000000011176\n",
      "step:    3176, loss: 0.1679086834192276, accuracy-micro: 0.7612507343292236, accuracy-macro: 0.0037000000011176\n",
      "step:    3177, loss: 0.1679098308086395, accuracy-micro: 0.7612762451171875, accuracy-macro: 0.0037000000011176\n",
      "step:    3178, loss: 0.1679087877273560, accuracy-micro: 0.7612642645835876, accuracy-macro: 0.0037000000011176\n",
      "step:    3179, loss: 0.1679061502218246, accuracy-micro: 0.7612847685813904, accuracy-macro: 0.0037000000011176\n",
      "step:    3180, loss: 0.1679021120071411, accuracy-micro: 0.7612544894218445, accuracy-macro: 0.0037000000011176\n",
      "step:    3181, loss: 0.1678976565599442, accuracy-micro: 0.7612854838371277, accuracy-macro: 0.0037000000011176\n",
      "step:    3182, loss: 0.1678954511880875, accuracy-micro: 0.7612947225570679, accuracy-macro: 0.0037000000011176\n",
      "step:    3183, loss: 0.1678947508335114, accuracy-micro: 0.7612642645835876, accuracy-macro: 0.0037000000011176\n",
      "step:    3184, loss: 0.1678968816995621, accuracy-micro: 0.7613007426261902, accuracy-macro: 0.0037000000011176\n",
      "step:    3185, loss: 0.1678992509841919, accuracy-micro: 0.7612555027008057, accuracy-macro: 0.0037000000011176\n",
      "step:    3186, loss: 0.1678992062807083, accuracy-micro: 0.7613164782524109, accuracy-macro: 0.0037000000011176\n",
      "step:    3187, loss: 0.1678974926471710, accuracy-micro: 0.7612777352333069, accuracy-macro: 0.0037000000011176\n",
      "step:    3188, loss: 0.1678938567638397, accuracy-micro: 0.7613030076026917, accuracy-macro: 0.0037000000011176\n",
      "step:    3189, loss: 0.1678900569677353, accuracy-micro: 0.7612850069999695, accuracy-macro: 0.0037000000011176\n",
      "step:    3190, loss: 0.1678869277238846, accuracy-micro: 0.7613059878349304, accuracy-macro: 0.0037000000011176\n",
      "step:    3191, loss: 0.1678856611251831, accuracy-micro: 0.7613217234611511, accuracy-macro: 0.0037000000011176\n",
      "step:    3192, loss: 0.1678873449563980, accuracy-micro: 0.7612934708595276, accuracy-macro: 0.0037000000011176\n",
      "step:    3193, loss: 0.1678900271654129, accuracy-micro: 0.7613204717636108, accuracy-macro: 0.0037000000011176\n",
      "step:    3194, loss: 0.1678947210311890, accuracy-micro: 0.7613017559051514, accuracy-macro: 0.0037000000011176\n",
      "step:    3195, loss: 0.1678974479436874, accuracy-micro: 0.7612919807434082, accuracy-macro: 0.0037000000011176\n",
      "step:    3196, loss: 0.1678957045078278, accuracy-micro: 0.7613067626953125, accuracy-macro: 0.0037000000011176\n",
      "step:    3197, loss: 0.1678907424211502, accuracy-micro: 0.7613222599029541, accuracy-macro: 0.0037000000011176\n",
      "step:    3198, loss: 0.1678832769393921, accuracy-micro: 0.7612912654876709, accuracy-macro: 0.0037000000011176\n",
      "step:    3199, loss: 0.1678782403469086, accuracy-micro: 0.7613319754600525, accuracy-macro: 0.0037000000011176\n",
      "step:    3200, loss: 0.1678767949342728, accuracy-micro: 0.7613185048103333, accuracy-macro: 0.0037000000011176\n",
      "step:    3201, loss: 0.1678776443004608, accuracy-micro: 0.7613097429275513, accuracy-macro: 0.0037000000011176\n",
      "step:    3202, loss: 0.1678806543350220, accuracy-micro: 0.7613447308540344, accuracy-macro: 0.0037000000011176\n",
      "step:    3203, loss: 0.1678827255964279, accuracy-micro: 0.7613107562065125, accuracy-macro: 0.0037000000011176\n",
      "step:    3204, loss: 0.1678834110498428, accuracy-micro: 0.7613282203674316, accuracy-macro: 0.0037000000011176\n",
      "step:    3205, loss: 0.1678840368986130, accuracy-micro: 0.7613142728805542, accuracy-macro: 0.0037000000011176\n",
      "step:    3206, loss: 0.1678831875324249, accuracy-micro: 0.7613362669944763, accuracy-macro: 0.0037000000011176\n",
      "step:    3207, loss: 0.1678791642189026, accuracy-micro: 0.7613027691841125, accuracy-macro: 0.0037000000011176\n",
      "step:    3208, loss: 0.1678745299577713, accuracy-micro: 0.7613584995269775, accuracy-macro: 0.0037000000011176\n",
      "step:    3209, loss: 0.1678699702024460, accuracy-micro: 0.7613307237625122, accuracy-macro: 0.0037000000011176\n",
      "step:    3210, loss: 0.1678663492202759, accuracy-micro: 0.7613552212715149, accuracy-macro: 0.0037000000011176\n",
      "step:    3211, loss: 0.1678642332553864, accuracy-micro: 0.7613289952278137, accuracy-macro: 0.0037000000011176\n",
      "step:    3212, loss: 0.1678630411624908, accuracy-micro: 0.7613685131072998, accuracy-macro: 0.0037000000011176\n",
      "step:    3213, loss: 0.1678627431392670, accuracy-micro: 0.7613637447357178, accuracy-macro: 0.0037000000011176\n",
      "step:    3214, loss: 0.1678617149591446, accuracy-micro: 0.7613350152969360, accuracy-macro: 0.0037000000011176\n",
      "step:    3215, loss: 0.1678609400987625, accuracy-micro: 0.7613645195960999, accuracy-macro: 0.0037000000011176\n",
      "step:    3216, loss: 0.1678596436977386, accuracy-micro: 0.7613492608070374, accuracy-macro: 0.0037000000011176\n",
      "step:    3217, loss: 0.1678586602210999, accuracy-micro: 0.7613829970359802, accuracy-macro: 0.0037000000011176\n",
      "step:    3218, loss: 0.1678580641746521, accuracy-micro: 0.7613384723663330, accuracy-macro: 0.0037000000011176\n",
      "step:    3219, loss: 0.1678571254014969, accuracy-micro: 0.7613722681999207, accuracy-macro: 0.0037000000011176\n",
      "step:    3220, loss: 0.1678563505411148, accuracy-micro: 0.7613412737846375, accuracy-macro: 0.0037000000011176\n",
      "step:    3221, loss: 0.1678555905818939, accuracy-micro: 0.7613815069198608, accuracy-macro: 0.0037000000011176\n",
      "step:    3222, loss: 0.1678545922040939, accuracy-micro: 0.7613549828529358, accuracy-macro: 0.0037000000011176\n",
      "step:    3223, loss: 0.1678549945354462, accuracy-micro: 0.7613897323608398, accuracy-macro: 0.0037000000011176\n",
      "step:    3224, loss: 0.1678549945354462, accuracy-micro: 0.7613527774810791, accuracy-macro: 0.0037000000011176\n",
      "step:    3225, loss: 0.1678551584482193, accuracy-micro: 0.7613792419433594, accuracy-macro: 0.0037000000011176\n",
      "step:    3226, loss: 0.1678557693958282, accuracy-micro: 0.7613392472267151, accuracy-macro: 0.0037000000011176\n",
      "step:    3227, loss: 0.1678538173437119, accuracy-micro: 0.7613775134086609, accuracy-macro: 0.0037000000011176\n",
      "step:    3228, loss: 0.1678508967161179, accuracy-micro: 0.7613484859466553, accuracy-macro: 0.0037000000011176\n",
      "step:    3229, loss: 0.1678480654954910, accuracy-micro: 0.7614102363586426, accuracy-macro: 0.0037000000011176\n",
      "step:    3230, loss: 0.1678453683853149, accuracy-micro: 0.7613642215728760, accuracy-macro: 0.0037000000011176\n",
      "step:    3231, loss: 0.1678433567285538, accuracy-micro: 0.7613884806632996, accuracy-macro: 0.0037000000011176\n",
      "step:    3232, loss: 0.1678424030542374, accuracy-micro: 0.7614110112190247, accuracy-macro: 0.0037000000011176\n",
      "step:    3233, loss: 0.1678429543972015, accuracy-micro: 0.7613742351531982, accuracy-macro: 0.0037000000011176\n",
      "step:    3234, loss: 0.1678436845541000, accuracy-micro: 0.7613880038261414, accuracy-macro: 0.0037000000011176\n",
      "step:    3235, loss: 0.1678446829319000, accuracy-micro: 0.7613515257835388, accuracy-macro: 0.0037000000011176\n",
      "step:    3236, loss: 0.1678434312343597, accuracy-micro: 0.7613982558250427, accuracy-macro: 0.0037000000011176\n",
      "step:    3237, loss: 0.1678438186645508, accuracy-micro: 0.7613622546195984, accuracy-macro: 0.0037000000011176\n",
      "step:    3238, loss: 0.1678429096937180, accuracy-micro: 0.7614002227783203, accuracy-macro: 0.0037000000011176\n",
      "step:    3239, loss: 0.1678397804498672, accuracy-micro: 0.7613670229911804, accuracy-macro: 0.0037000000011176\n",
      "step:    3240, loss: 0.1678369045257568, accuracy-micro: 0.7614309787750244, accuracy-macro: 0.0037000000011176\n",
      "step:    3241, loss: 0.1678338944911957, accuracy-micro: 0.7613842487335205, accuracy-macro: 0.0037000000011176\n",
      "step:    3242, loss: 0.1678321659564972, accuracy-micro: 0.7614234685897827, accuracy-macro: 0.0037000000011176\n",
      "step:    3243, loss: 0.1678314059972763, accuracy-micro: 0.7613912224769592, accuracy-macro: 0.0037000000011176\n",
      "step:    3244, loss: 0.1678303778171539, accuracy-micro: 0.7614234685897827, accuracy-macro: 0.0037000000011176\n",
      "step:    3245, loss: 0.1678290367126465, accuracy-micro: 0.7613905072212219, accuracy-macro: 0.0037000000011176\n",
      "step:    3246, loss: 0.1678291112184525, accuracy-micro: 0.7614340186119080, accuracy-macro: 0.0037000000011176\n",
      "step:    3247, loss: 0.1678286343812943, accuracy-micro: 0.7613869905471802, accuracy-macro: 0.0037000000011176\n",
      "step:    3248, loss: 0.1678272932767868, accuracy-micro: 0.7614392638206482, accuracy-macro: 0.0037000000011176\n",
      "step:    3249, loss: 0.1678266078233719, accuracy-micro: 0.7613965272903442, accuracy-macro: 0.0037000000011176\n",
      "step:    3250, loss: 0.1678255349397659, accuracy-micro: 0.7614632248878479, accuracy-macro: 0.0037000000011176\n",
      "step:    3251, loss: 0.1678234934806824, accuracy-micro: 0.7613937258720398, accuracy-macro: 0.0037000000011176\n",
      "step:    3252, loss: 0.1678216904401779, accuracy-micro: 0.7614447474479675, accuracy-macro: 0.0037000000011176\n",
      "step:    3253, loss: 0.1678209900856018, accuracy-micro: 0.7614204883575439, accuracy-macro: 0.0037000000011176\n",
      "step:    3254, loss: 0.1678191721439362, accuracy-micro: 0.7614297270774841, accuracy-macro: 0.0037000000011176\n",
      "step:    3255, loss: 0.1678179651498795, accuracy-micro: 0.7614077329635620, accuracy-macro: 0.0037000000011176\n",
      "step:    3256, loss: 0.1678165942430496, accuracy-micro: 0.7614470124244690, accuracy-macro: 0.0037000000011176\n",
      "step:    3257, loss: 0.1678154468536377, accuracy-micro: 0.7614275217056274, accuracy-macro: 0.0037000000011176\n",
      "step:    3258, loss: 0.1678142547607422, accuracy-micro: 0.7614427208900452, accuracy-macro: 0.0037000000011176\n",
      "step:    3259, loss: 0.1678142547607422, accuracy-micro: 0.7614412307739258, accuracy-macro: 0.0037000000011176\n",
      "step:    3260, loss: 0.1678126901388168, accuracy-micro: 0.7614437341690063, accuracy-macro: 0.0037000000011176\n",
      "step:    3261, loss: 0.1678122133016586, accuracy-micro: 0.7614397406578064, accuracy-macro: 0.0037000000011176\n",
      "step:    3262, loss: 0.1678114831447601, accuracy-micro: 0.7614639997482300, accuracy-macro: 0.0037000000011176\n",
      "step:    3263, loss: 0.1678096354007721, accuracy-micro: 0.7614412307739258, accuracy-macro: 0.0037000000011176\n",
      "step:    3264, loss: 0.1678092330694199, accuracy-micro: 0.7614387273788452, accuracy-macro: 0.0037000000011176\n",
      "step:    3265, loss: 0.1678072810173035, accuracy-micro: 0.7614604830741882, accuracy-macro: 0.0037000000011176\n",
      "step:    3266, loss: 0.1678078025579453, accuracy-micro: 0.7614309787750244, accuracy-macro: 0.0037000000011176\n",
      "step:    3267, loss: 0.1678080707788467, accuracy-micro: 0.7614762187004089, accuracy-macro: 0.0037000000011176\n",
      "step:    3268, loss: 0.1678073704242706, accuracy-micro: 0.7614244818687439, accuracy-macro: 0.0037000000011176\n",
      "step:    3269, loss: 0.1678081899881363, accuracy-micro: 0.7615050077438354, accuracy-macro: 0.0037000000011176\n",
      "step:    3270, loss: 0.1678085178136826, accuracy-micro: 0.7614227533340454, accuracy-macro: 0.0037000000011176\n",
      "step:    3271, loss: 0.1678088158369064, accuracy-micro: 0.7614905238151550, accuracy-macro: 0.0037000000011176\n",
      "step:    3272, loss: 0.1678089350461960, accuracy-micro: 0.7614177465438843, accuracy-macro: 0.0037000000011176\n",
      "step:    3273, loss: 0.1678085327148438, accuracy-micro: 0.7615000009536743, accuracy-macro: 0.0037000000011176\n",
      "step:    3274, loss: 0.1678070574998856, accuracy-micro: 0.7614037394523621, accuracy-macro: 0.0037000000011176\n",
      "step:    3275, loss: 0.1678043901920319, accuracy-micro: 0.7614977359771729, accuracy-macro: 0.0037000000011176\n",
      "step:    3276, loss: 0.1678021848201752, accuracy-micro: 0.7614269852638245, accuracy-macro: 0.0037000000011176\n",
      "step:    3277, loss: 0.1677992790937424, accuracy-micro: 0.7615067362785339, accuracy-macro: 0.0037000000011176\n",
      "step:    3278, loss: 0.1677963733673096, accuracy-micro: 0.7614537477493286, accuracy-macro: 0.0037000000011176\n",
      "step:    3279, loss: 0.1677937358617783, accuracy-micro: 0.7614982724189758, accuracy-macro: 0.0037000000011176\n",
      "step:    3280, loss: 0.1677919030189514, accuracy-micro: 0.7614862322807312, accuracy-macro: 0.0037000000011176\n",
      "step:    3281, loss: 0.1677915006875992, accuracy-micro: 0.7614594697952271, accuracy-macro: 0.0037000000011176\n",
      "step:    3282, loss: 0.1677907854318619, accuracy-micro: 0.7615180015563965, accuracy-macro: 0.0037000000011176\n",
      "step:    3283, loss: 0.1677909046411514, accuracy-micro: 0.7614784836769104, accuracy-macro: 0.0037000000011176\n",
      "step:    3284, loss: 0.1677896827459335, accuracy-micro: 0.7615242600440979, accuracy-macro: 0.0037000000011176\n",
      "step:    3285, loss: 0.1677893102169037, accuracy-micro: 0.7614657282829285, accuracy-macro: 0.0037000000011176\n",
      "step:    3286, loss: 0.1677875369787216, accuracy-micro: 0.7615317702293396, accuracy-macro: 0.0037000000011176\n",
      "step:    3287, loss: 0.1677854210138321, accuracy-micro: 0.7614837288856506, accuracy-macro: 0.0037000000011176\n",
      "step:    3288, loss: 0.1677834391593933, accuracy-micro: 0.7615280151367188, accuracy-macro: 0.0037000000011176\n",
      "step:    3289, loss: 0.1677822023630142, accuracy-micro: 0.7614877223968506, accuracy-macro: 0.0037000000011176\n",
      "step:    3290, loss: 0.1677815765142441, accuracy-micro: 0.7614964842796326, accuracy-macro: 0.0037000000011176\n",
      "step:    3291, loss: 0.1677803397178650, accuracy-micro: 0.7614987492561340, accuracy-macro: 0.0037000000011176\n",
      "step:    3292, loss: 0.1677789390087128, accuracy-micro: 0.7614827752113342, accuracy-macro: 0.0037000000011176\n",
      "step:    3293, loss: 0.1677787750959396, accuracy-micro: 0.7615307569503784, accuracy-macro: 0.0037000000011176\n",
      "step:    3294, loss: 0.1677780598402023, accuracy-micro: 0.7614962458610535, accuracy-macro: 0.0037000000011176\n",
      "step:    3295, loss: 0.1677765995264053, accuracy-micro: 0.7615182399749756, accuracy-macro: 0.0037000000011176\n",
      "step:    3296, loss: 0.1677755862474442, accuracy-micro: 0.7614974975585938, accuracy-macro: 0.0037000000011176\n",
      "step:    3297, loss: 0.1677743345499039, accuracy-micro: 0.7615205049514771, accuracy-macro: 0.0037000000011176\n",
      "step:    3298, loss: 0.1677731424570084, accuracy-micro: 0.7614995241165161, accuracy-macro: 0.0037000000011176\n",
      "step:    3299, loss: 0.1677723526954651, accuracy-micro: 0.7615397572517395, accuracy-macro: 0.0037000000011176\n",
      "step:    3300, loss: 0.1677718311548233, accuracy-micro: 0.7615284919738770, accuracy-macro: 0.0037000000011176\n",
      "step:    3301, loss: 0.1677719205617905, accuracy-micro: 0.7615604996681213, accuracy-macro: 0.0037000000011176\n",
      "step:    3302, loss: 0.1677716076374054, accuracy-micro: 0.7615125179290771, accuracy-macro: 0.0037000000011176\n",
      "step:    3303, loss: 0.1677718162536621, accuracy-micro: 0.7615517377853394, accuracy-macro: 0.0037000000011176\n",
      "step:    3304, loss: 0.1677719354629517, accuracy-micro: 0.7614992260932922, accuracy-macro: 0.0037000000011176\n",
      "step:    3305, loss: 0.1677725017070770, accuracy-micro: 0.7615870237350464, accuracy-macro: 0.0037000000011176\n",
      "step:    3306, loss: 0.1677712351083755, accuracy-micro: 0.7614849805831909, accuracy-macro: 0.0037000000011176\n",
      "step:    3307, loss: 0.1677698343992233, accuracy-micro: 0.7615827322006226, accuracy-macro: 0.0037000000011176\n",
      "step:    3308, loss: 0.1677701920270920, accuracy-micro: 0.7614917755126953, accuracy-macro: 0.0037000000011176\n",
      "step:    3309, loss: 0.1677699387073517, accuracy-micro: 0.7615942358970642, accuracy-macro: 0.0037000000011176\n",
      "step:    3310, loss: 0.1677696257829666, accuracy-micro: 0.7614817619323730, accuracy-macro: 0.0037000000011176\n",
      "step:    3311, loss: 0.1677690595388412, accuracy-micro: 0.7616047263145447, accuracy-macro: 0.0037000000011176\n",
      "step:    3312, loss: 0.1677689105272293, accuracy-micro: 0.7614849805831909, accuracy-macro: 0.0037000000011176\n",
      "step:    3313, loss: 0.1677687466144562, accuracy-micro: 0.7616065144538879, accuracy-macro: 0.0037000000011176\n",
      "step:    3314, loss: 0.1677678376436234, accuracy-micro: 0.7614762187004089, accuracy-macro: 0.0037000000011176\n",
      "step:    3315, loss: 0.1677651256322861, accuracy-micro: 0.7616087198257446, accuracy-macro: 0.0037000000011176\n",
      "step:    3316, loss: 0.1677627861499786, accuracy-micro: 0.7615075111389160, accuracy-macro: 0.0037000000011176\n",
      "step:    3317, loss: 0.1677580624818802, accuracy-micro: 0.7615944743156433, accuracy-macro: 0.0037000000011176\n",
      "step:    3318, loss: 0.1677546501159668, accuracy-micro: 0.7615067362785339, accuracy-macro: 0.0037000000011176\n",
      "step:    3319, loss: 0.1677518486976624, accuracy-micro: 0.7615885138511658, accuracy-macro: 0.0037000000011176\n",
      "step:    3320, loss: 0.1677498370409012, accuracy-micro: 0.7615655064582825, accuracy-macro: 0.0037000000011176\n",
      "step:    3321, loss: 0.1677490174770355, accuracy-micro: 0.7615797519683838, accuracy-macro: 0.0037000000011176\n",
      "step:    3322, loss: 0.1677485704421997, accuracy-micro: 0.7615985274314880, accuracy-macro: 0.0037000000011176\n",
      "step:    3323, loss: 0.1677486300468445, accuracy-micro: 0.7615364789962769, accuracy-macro: 0.0037000000011176\n",
      "step:    3324, loss: 0.1677471995353699, accuracy-micro: 0.7616149783134460, accuracy-macro: 0.0037000000011176\n",
      "step:    3325, loss: 0.1677469164133072, accuracy-micro: 0.7615399956703186, accuracy-macro: 0.0037000000011176\n",
      "step:    3326, loss: 0.1677466630935669, accuracy-micro: 0.7616195082664490, accuracy-macro: 0.0037000000011176\n",
      "step:    3327, loss: 0.1677453964948654, accuracy-micro: 0.7615417242050171, accuracy-macro: 0.0037000000011176\n",
      "step:    3328, loss: 0.1677439659833908, accuracy-micro: 0.7616270184516907, accuracy-macro: 0.0037000000011176\n",
      "step:    3329, loss: 0.1677427440881729, accuracy-micro: 0.7615510225296021, accuracy-macro: 0.0037000000011176\n",
      "step:    3330, loss: 0.1677423119544983, accuracy-micro: 0.7616252303123474, accuracy-macro: 0.0037000000011176\n",
      "step:    3331, loss: 0.1677417159080505, accuracy-micro: 0.7615485191345215, accuracy-macro: 0.0037000000011176\n",
      "step:    3332, loss: 0.1677427142858505, accuracy-micro: 0.7616287469863892, accuracy-macro: 0.0037000000011176\n",
      "step:    3333, loss: 0.1677449047565460, accuracy-micro: 0.7614987492561340, accuracy-macro: 0.0037000000011176\n",
      "step:    3334, loss: 0.1677489727735519, accuracy-micro: 0.7616112232208252, accuracy-macro: 0.0037000000011176\n",
      "step:    3335, loss: 0.1677527278661728, accuracy-micro: 0.7615119814872742, accuracy-macro: 0.0037000000011176\n",
      "step:    3336, loss: 0.1677556186914444, accuracy-micro: 0.7616479992866516, accuracy-macro: 0.0037000000011176\n",
      "step:    3337, loss: 0.1677569001913071, accuracy-micro: 0.7614887356758118, accuracy-macro: 0.0037000000011176\n",
      "step:    3338, loss: 0.1677567362785339, accuracy-micro: 0.7616672515869141, accuracy-macro: 0.0037000000011176\n",
      "step:    3339, loss: 0.1677525639533997, accuracy-micro: 0.7615090012550354, accuracy-macro: 0.0037000000011176\n",
      "step:    3340, loss: 0.1677472591400146, accuracy-micro: 0.7616402506828308, accuracy-macro: 0.0037000000011176\n",
      "step:    3341, loss: 0.1677388250827789, accuracy-micro: 0.7615289688110352, accuracy-macro: 0.0037000000011176\n",
      "step:    3342, loss: 0.1677326261997223, accuracy-micro: 0.7616415023803711, accuracy-macro: 0.0037000000011176\n",
      "step:    3343, loss: 0.1677273064851761, accuracy-micro: 0.7615759968757629, accuracy-macro: 0.0037000000011176\n",
      "step:    3344, loss: 0.1677252948284149, accuracy-micro: 0.7616339921951294, accuracy-macro: 0.0037000000011176\n",
      "step:    3345, loss: 0.1677237749099731, accuracy-micro: 0.7616440057754517, accuracy-macro: 0.0037000000011176\n",
      "step:    3346, loss: 0.1677229851484299, accuracy-micro: 0.7616015076637268, accuracy-macro: 0.0037000000011176\n",
      "step:    3347, loss: 0.1677234470844269, accuracy-micro: 0.7616540193557739, accuracy-macro: 0.0037000000011176\n",
      "step:    3348, loss: 0.1677231341600418, accuracy-micro: 0.7615939974784851, accuracy-macro: 0.0037000000011176\n",
      "step:    3349, loss: 0.1677226275205612, accuracy-micro: 0.7616622447967529, accuracy-macro: 0.0037000000011176\n",
      "step:    3350, loss: 0.1677214056253433, accuracy-micro: 0.7615780234336853, accuracy-macro: 0.0037000000011176\n",
      "step:    3351, loss: 0.1677213460206985, accuracy-micro: 0.7616775035858154, accuracy-macro: 0.0037000000011176\n",
      "step:    3352, loss: 0.1677211672067642, accuracy-micro: 0.7615824937820435, accuracy-macro: 0.0037000000011176\n",
      "step:    3353, loss: 0.1677200943231583, accuracy-micro: 0.7616947293281555, accuracy-macro: 0.0037000000011176\n",
      "step:    3354, loss: 0.1677188128232956, accuracy-micro: 0.7615882754325867, accuracy-macro: 0.0037000000011176\n",
      "step:    3355, loss: 0.1677170693874359, accuracy-micro: 0.7616850137710571, accuracy-macro: 0.0037000000011176\n",
      "step:    3356, loss: 0.1677152812480927, accuracy-micro: 0.7616090178489685, accuracy-macro: 0.0037000000011176\n",
      "step:    3357, loss: 0.1677132248878479, accuracy-micro: 0.7616692185401917, accuracy-macro: 0.0037000000011176\n",
      "step:    3358, loss: 0.1677116006612778, accuracy-micro: 0.7616184949874878, accuracy-macro: 0.0037000000011176\n",
      "step:    3359, loss: 0.1677104979753494, accuracy-micro: 0.7616655230522156, accuracy-macro: 0.0037000000011176\n",
      "step:    3360, loss: 0.1677090674638748, accuracy-micro: 0.7616214752197266, accuracy-macro: 0.0037000000011176\n",
      "step:    3361, loss: 0.1677087843418121, accuracy-micro: 0.7616770267486572, accuracy-macro: 0.0037000000011176\n",
      "step:    3362, loss: 0.1677088141441345, accuracy-micro: 0.7616214752197266, accuracy-macro: 0.0037000000011176\n",
      "step:    3363, loss: 0.1677083373069763, accuracy-micro: 0.7616950273513794, accuracy-macro: 0.0037000000011176\n",
      "step:    3364, loss: 0.1677085906267166, accuracy-micro: 0.7616170048713684, accuracy-macro: 0.0037000000011176\n",
      "step:    3365, loss: 0.1677076518535614, accuracy-micro: 0.7617007493972778, accuracy-macro: 0.0037000000011176\n",
      "step:    3366, loss: 0.1677054911851883, accuracy-micro: 0.7616105079650879, accuracy-macro: 0.0037000000011176\n",
      "step:    3367, loss: 0.1677043437957764, accuracy-micro: 0.7617024779319763, accuracy-macro: 0.0037000000011176\n",
      "step:    3368, loss: 0.1677021235227585, accuracy-micro: 0.7616242766380310, accuracy-macro: 0.0037000000011176\n",
      "step:    3369, loss: 0.1677021980285645, accuracy-micro: 0.7617002725601196, accuracy-macro: 0.0037000000011176\n",
      "step:    3370, loss: 0.1677004098892212, accuracy-micro: 0.7616412639617920, accuracy-macro: 0.0037000000011176\n",
      "step:    3371, loss: 0.1677007824182510, accuracy-micro: 0.7617182731628418, accuracy-macro: 0.0037000000011176\n",
      "step:    3372, loss: 0.1677016913890839, accuracy-micro: 0.7616214752197266, accuracy-macro: 0.0037000000011176\n",
      "step:    3373, loss: 0.1677043139934540, accuracy-micro: 0.7617267370223999, accuracy-macro: 0.0037000000011176\n",
      "step:    3374, loss: 0.1677081137895584, accuracy-micro: 0.7616117596626282, accuracy-macro: 0.0037000000011176\n",
      "step:    3375, loss: 0.1677104383707047, accuracy-micro: 0.7617357373237610, accuracy-macro: 0.0037000000011176\n",
      "step:    3376, loss: 0.1677096337080002, accuracy-micro: 0.7615990042686462, accuracy-macro: 0.0037000000011176\n",
      "step:    3377, loss: 0.1677076816558838, accuracy-micro: 0.7617434859275818, accuracy-macro: 0.0037000000011176\n",
      "step:    3378, loss: 0.1677031964063644, accuracy-micro: 0.7615942358970642, accuracy-macro: 0.0037000000011176\n",
      "step:    3379, loss: 0.1676988452672958, accuracy-micro: 0.7617392539978027, accuracy-macro: 0.0037000000011176\n",
      "step:    3380, loss: 0.1676919013261795, accuracy-micro: 0.7616595029830933, accuracy-macro: 0.0037000000011176\n",
      "step:    3381, loss: 0.1676875352859497, accuracy-micro: 0.7617132663726807, accuracy-macro: 0.0037000000011176\n",
      "step:    3382, loss: 0.1676856577396393, accuracy-micro: 0.7616882324218750, accuracy-macro: 0.0037000000011176\n",
      "step:    3383, loss: 0.1676863729953766, accuracy-micro: 0.7616907358169556, accuracy-macro: 0.0037000000011176\n",
      "step:    3384, loss: 0.1676874309778214, accuracy-micro: 0.7617437243461609, accuracy-macro: 0.0037000000011176\n",
      "step:    3385, loss: 0.1676889061927795, accuracy-micro: 0.7616614699363708, accuracy-macro: 0.0037000000011176\n",
      "step:    3386, loss: 0.1676896810531616, accuracy-micro: 0.7617562413215637, accuracy-macro: 0.0037000000011176\n",
      "step:    3387, loss: 0.1676919460296631, accuracy-micro: 0.7616249918937683, accuracy-macro: 0.0037000000011176\n",
      "step:    3388, loss: 0.1676964163780212, accuracy-micro: 0.7617642283439636, accuracy-macro: 0.0037000000011176\n",
      "step:    3389, loss: 0.1677054613828659, accuracy-micro: 0.7615739703178406, accuracy-macro: 0.0037000000011176\n",
      "step:    3390, loss: 0.1677213013172150, accuracy-micro: 0.7617629766464233, accuracy-macro: 0.0037000000011176\n",
      "step:    3391, loss: 0.1677393764257431, accuracy-micro: 0.7615355253219604, accuracy-macro: 0.0037000000011176\n",
      "step:    3392, loss: 0.1677590161561966, accuracy-micro: 0.7617174983024597, accuracy-macro: 0.0037000000011176\n",
      "step:    3393, loss: 0.1677663177251816, accuracy-micro: 0.7615125179290771, accuracy-macro: 0.0037000000011176\n",
      "step:    3394, loss: 0.1677594184875488, accuracy-micro: 0.7616955041885376, accuracy-macro: 0.0037000000011176\n",
      "step:    3395, loss: 0.1677308380603790, accuracy-micro: 0.7615420222282410, accuracy-macro: 0.0037000000011176\n",
      "step:    3396, loss: 0.1677013784646988, accuracy-micro: 0.7617980241775513, accuracy-macro: 0.0037000000011176\n",
      "step:    3397, loss: 0.1676794439554214, accuracy-micro: 0.7616599798202515, accuracy-macro: 0.0037000000011176\n",
      "step:    3398, loss: 0.1676703989505768, accuracy-micro: 0.7617285251617432, accuracy-macro: 0.0037000000011176\n",
      "step:    3399, loss: 0.1676725894212723, accuracy-micro: 0.7617570161819458, accuracy-macro: 0.0037000000011176\n",
      "step:    3400, loss: 0.1676818728446960, accuracy-micro: 0.7616484761238098, accuracy-macro: 0.0037000000011176\n",
      "step:    3401, loss: 0.1676927655935287, accuracy-micro: 0.7617927193641663, accuracy-macro: 0.0037000000011176\n",
      "step:    3402, loss: 0.1676989048719406, accuracy-micro: 0.7616212368011475, accuracy-macro: 0.0037000000011176\n",
      "step:    3403, loss: 0.1676984578371048, accuracy-micro: 0.7617827653884888, accuracy-macro: 0.0037000000011176\n",
      "step:    3404, loss: 0.1676908433437347, accuracy-micro: 0.7616582512855530, accuracy-macro: 0.0037000000011176\n",
      "step:    3405, loss: 0.1676785647869110, accuracy-micro: 0.7618150115013123, accuracy-macro: 0.0037000000011176\n",
      "step:    3406, loss: 0.1676678657531738, accuracy-micro: 0.7617262601852417, accuracy-macro: 0.0037000000011176\n",
      "step:    3407, loss: 0.1676613092422485, accuracy-micro: 0.7617784738540649, accuracy-macro: 0.0037000000011176\n",
      "step:    3408, loss: 0.1676620244979858, accuracy-micro: 0.7617675065994263, accuracy-macro: 0.0037000000011176\n",
      "step:    3409, loss: 0.1676640659570694, accuracy-micro: 0.7617047429084778, accuracy-macro: 0.0037000000011176\n",
      "step:    3410, loss: 0.1676685959100723, accuracy-micro: 0.7618162631988525, accuracy-macro: 0.0037000000011176\n",
      "step:    3411, loss: 0.1676715761423111, accuracy-micro: 0.7616597414016724, accuracy-macro: 0.0037000000011176\n",
      "step:    3412, loss: 0.1676740348339081, accuracy-micro: 0.7618035078048706, accuracy-macro: 0.0037000000011176\n",
      "step:    3413, loss: 0.1676722764968872, accuracy-micro: 0.7616454958915710, accuracy-macro: 0.0037000000011176\n",
      "step:    3414, loss: 0.1676660627126694, accuracy-micro: 0.7618299722671509, accuracy-macro: 0.0037000000011176\n",
      "step:    3415, loss: 0.1676578819751740, accuracy-micro: 0.7617472410202026, accuracy-macro: 0.0037000000011176\n",
      "step:    3416, loss: 0.1676530689001083, accuracy-micro: 0.7617939710617065, accuracy-macro: 0.0037000000011176\n",
      "step:    3417, loss: 0.1676529645919800, accuracy-micro: 0.7617995142936707, accuracy-macro: 0.0037000000011176\n",
      "step:    3418, loss: 0.1676568686962128, accuracy-micro: 0.7617232203483582, accuracy-macro: 0.0037000000011176\n",
      "step:    3419, loss: 0.1676625311374664, accuracy-micro: 0.7618100047111511, accuracy-macro: 0.0037000000011176\n",
      "step:    3420, loss: 0.1676673293113708, accuracy-micro: 0.7616557478904724, accuracy-macro: 0.0037000000011176\n",
      "step:    3421, loss: 0.1676681935787201, accuracy-micro: 0.7618192434310913, accuracy-macro: 0.0037000000011176\n",
      "step:    3422, loss: 0.1676640957593918, accuracy-micro: 0.7616800069808960, accuracy-macro: 0.0037000000011176\n",
      "step:    3423, loss: 0.1676565706729889, accuracy-micro: 0.7618165016174316, accuracy-macro: 0.0037000000011176\n",
      "step:    3424, loss: 0.1676488816738129, accuracy-micro: 0.7617334723472595, accuracy-macro: 0.0037000000011176\n",
      "step:    3425, loss: 0.1676436066627502, accuracy-micro: 0.7618104815483093, accuracy-macro: 0.0037000000011176\n",
      "step:    3426, loss: 0.1676435768604279, accuracy-micro: 0.7618144750595093, accuracy-macro: 0.0037000000011176\n",
      "step:    3427, loss: 0.1676472872495651, accuracy-micro: 0.7617564797401428, accuracy-macro: 0.0037000000011176\n",
      "step:    3428, loss: 0.1676488369703293, accuracy-micro: 0.7618225216865540, accuracy-macro: 0.0037000000011176\n",
      "step:    3429, loss: 0.1676473468542099, accuracy-micro: 0.7617452740669250, accuracy-macro: 0.0037000000011176\n",
      "step:    3430, loss: 0.1676430851221085, accuracy-micro: 0.7618160247802734, accuracy-macro: 0.0037000000011176\n",
      "step:    3431, loss: 0.1676394641399384, accuracy-micro: 0.7617807388305664, accuracy-macro: 0.0037000000011176\n",
      "step:    3432, loss: 0.1676370948553085, accuracy-micro: 0.7618087530136108, accuracy-macro: 0.0037000000011176\n",
      "step:    3433, loss: 0.1676367223262787, accuracy-micro: 0.7618232369422913, accuracy-macro: 0.0037000000011176\n",
      "step:    3434, loss: 0.1676389127969742, accuracy-micro: 0.7617689967155457, accuracy-macro: 0.0037000000011176\n",
      "step:    3435, loss: 0.1676417440176010, accuracy-micro: 0.7618330121040344, accuracy-macro: 0.0037000000011176\n",
      "step:    3436, loss: 0.1676429212093353, accuracy-micro: 0.7617407441139221, accuracy-macro: 0.0037000000011176\n",
      "step:    3437, loss: 0.1676415354013443, accuracy-micro: 0.7618487477302551, accuracy-macro: 0.0037000000011176\n",
      "step:    3438, loss: 0.1676391810178757, accuracy-micro: 0.7617614865303040, accuracy-macro: 0.0037000000011176\n",
      "step:    3439, loss: 0.1676365286111832, accuracy-micro: 0.7618340253829956, accuracy-macro: 0.0037000000011176\n",
      "step:    3440, loss: 0.1676338464021683, accuracy-micro: 0.7617650032043457, accuracy-macro: 0.0037000000011176\n",
      "step:    3441, loss: 0.1676305979490280, accuracy-micro: 0.7618280053138733, accuracy-macro: 0.0037000000011176\n",
      "step:    3442, loss: 0.1676290482282639, accuracy-micro: 0.7618064880371094, accuracy-macro: 0.0037000000011176\n",
      "step:    3443, loss: 0.1676265895366669, accuracy-micro: 0.7618259787559509, accuracy-macro: 0.0037000000011176\n",
      "step:    3444, loss: 0.1676258295774460, accuracy-micro: 0.7618287205696106, accuracy-macro: 0.0037000000011176\n",
      "step:    3445, loss: 0.1676252037286758, accuracy-micro: 0.7618252635002136, accuracy-macro: 0.0037000000011176\n",
      "step:    3446, loss: 0.1676240414381027, accuracy-micro: 0.7618342638015747, accuracy-macro: 0.0037000000011176\n",
      "step:    3447, loss: 0.1676228344440460, accuracy-micro: 0.7618259787559509, accuracy-macro: 0.0037000000011176\n",
      "step:    3448, loss: 0.1676222383975983, accuracy-micro: 0.7618492245674133, accuracy-macro: 0.0037000000011176\n",
      "step:    3449, loss: 0.1676208674907684, accuracy-micro: 0.7618372440338135, accuracy-macro: 0.0037000000011176\n",
      "step:    3450, loss: 0.1676197499036789, accuracy-micro: 0.7618284821510315, accuracy-macro: 0.0037000000011176\n",
      "step:    3451, loss: 0.1676195263862610, accuracy-micro: 0.7618319988250732, accuracy-macro: 0.0037000000011176\n",
      "step:    3452, loss: 0.1676188111305237, accuracy-micro: 0.7618397474288940, accuracy-macro: 0.0037000000011176\n",
      "step:    3453, loss: 0.1676185280084610, accuracy-micro: 0.7618600130081177, accuracy-macro: 0.0037000000011176\n",
      "step:    3454, loss: 0.1676175594329834, accuracy-micro: 0.7618327736854553, accuracy-macro: 0.0037000000011176\n",
      "step:    3455, loss: 0.1676168441772461, accuracy-micro: 0.7618457674980164, accuracy-macro: 0.0037000000011176\n",
      "step:    3456, loss: 0.1676149368286133, accuracy-micro: 0.7618417739868164, accuracy-macro: 0.0037000000011176\n",
      "step:    3457, loss: 0.1676139682531357, accuracy-micro: 0.7618445158004761, accuracy-macro: 0.0037000000011176\n",
      "step:    3458, loss: 0.1676125824451447, accuracy-micro: 0.7618632316589355, accuracy-macro: 0.0037000000011176\n",
      "step:    3459, loss: 0.1676118373870850, accuracy-micro: 0.7618567347526550, accuracy-macro: 0.0037000000011176\n",
      "step:    3460, loss: 0.1676124334335327, accuracy-micro: 0.7618550062179565, accuracy-macro: 0.0037000000011176\n",
      "step:    3461, loss: 0.1676122248172760, accuracy-micro: 0.7618152499198914, accuracy-macro: 0.0037000000011176\n",
      "step:    3462, loss: 0.1676138788461685, accuracy-micro: 0.7618885040283203, accuracy-macro: 0.0037000000011176\n",
      "step:    3463, loss: 0.1676147133111954, accuracy-micro: 0.7618062496185303, accuracy-macro: 0.0037000000011176\n",
      "step:    3464, loss: 0.1676153242588043, accuracy-micro: 0.7619119882583618, accuracy-macro: 0.0037000000011176\n",
      "step:    3465, loss: 0.1676152199506760, accuracy-micro: 0.7617830038070679, accuracy-macro: 0.0037000000011176\n",
      "step:    3466, loss: 0.1676129400730133, accuracy-micro: 0.7618937492370605, accuracy-macro: 0.0037000000011176\n",
      "step:    3467, loss: 0.1676098406314850, accuracy-micro: 0.7618190050125122, accuracy-macro: 0.0037000000011176\n",
      "step:    3468, loss: 0.1676061600446701, accuracy-micro: 0.7618802189826965, accuracy-macro: 0.0037000000011176\n",
      "step:    3469, loss: 0.1676028072834015, accuracy-micro: 0.7618809938430786, accuracy-macro: 0.0037000000011176\n",
      "step:    3470, loss: 0.1676014363765717, accuracy-micro: 0.7618870139122009, accuracy-macro: 0.0037000000011176\n",
      "step:    3471, loss: 0.1676011681556702, accuracy-micro: 0.7618652582168579, accuracy-macro: 0.0037000000011176\n",
      "step:    3472, loss: 0.1676031500101089, accuracy-micro: 0.7618297338485718, accuracy-macro: 0.0037000000011176\n",
      "step:    3473, loss: 0.1676049381494522, accuracy-micro: 0.7619054913520813, accuracy-macro: 0.0037000000011176\n",
      "step:    3474, loss: 0.1676058173179626, accuracy-micro: 0.7618222236633301, accuracy-macro: 0.0037000000011176\n",
      "step:    3475, loss: 0.1676049977540970, accuracy-micro: 0.7619202733039856, accuracy-macro: 0.0037000000011176\n",
      "step:    3476, loss: 0.1676027327775955, accuracy-micro: 0.7618345022201538, accuracy-macro: 0.0037000000011176\n",
      "step:    3477, loss: 0.1675996184349060, accuracy-micro: 0.7619112730026245, accuracy-macro: 0.0037000000011176\n",
      "step:    3478, loss: 0.1675957292318344, accuracy-micro: 0.7618737220764160, accuracy-macro: 0.0037000000011176\n",
      "step:    3479, loss: 0.1675933152437210, accuracy-micro: 0.7619152665138245, accuracy-macro: 0.0037000000011176\n",
      "step:    3480, loss: 0.1675912141799927, accuracy-micro: 0.7619079947471619, accuracy-macro: 0.0037000000011176\n",
      "step:    3481, loss: 0.1675917208194733, accuracy-micro: 0.7618874907493591, accuracy-macro: 0.0037000000011176\n",
      "step:    3482, loss: 0.1675926893949509, accuracy-micro: 0.7618964910507202, accuracy-macro: 0.0037000000011176\n",
      "step:    3483, loss: 0.1675934940576553, accuracy-micro: 0.7618489861488342, accuracy-macro: 0.0037000000011176\n",
      "step:    3484, loss: 0.1675952076911926, accuracy-micro: 0.7619194984436035, accuracy-macro: 0.0037000000011176\n",
      "step:    3485, loss: 0.1675971150398254, accuracy-micro: 0.7618432641029358, accuracy-macro: 0.0037000000011176\n",
      "step:    3486, loss: 0.1675981879234314, accuracy-micro: 0.7619277238845825, accuracy-macro: 0.0037000000011176\n",
      "step:    3487, loss: 0.1675961911678314, accuracy-micro: 0.7618569731712341, accuracy-macro: 0.0037000000011176\n",
      "step:    3488, loss: 0.1675920188426971, accuracy-micro: 0.7619464993476868, accuracy-macro: 0.0037000000011176\n",
      "step:    3489, loss: 0.1675871312618256, accuracy-micro: 0.7618852257728577, accuracy-macro: 0.0037000000011176\n",
      "step:    3490, loss: 0.1675837188959122, accuracy-micro: 0.7619372606277466, accuracy-macro: 0.0037000000011176\n",
      "step:    3491, loss: 0.1675814688205719, accuracy-micro: 0.7618952393531799, accuracy-macro: 0.0037000000011176\n",
      "step:    3492, loss: 0.1675803065299988, accuracy-micro: 0.7619057297706604, accuracy-macro: 0.0037000000011176\n",
      "step:    3493, loss: 0.1675808131694794, accuracy-micro: 0.7619262337684631, accuracy-macro: 0.0037000000011176\n",
      "step:    3494, loss: 0.1675822734832764, accuracy-micro: 0.7618929743766785, accuracy-macro: 0.0037000000011176\n",
      "step:    3495, loss: 0.1675831377506256, accuracy-micro: 0.7619354724884033, accuracy-macro: 0.0037000000011176\n",
      "step:    3496, loss: 0.1675837039947510, accuracy-micro: 0.7618715167045593, accuracy-macro: 0.0037000000011176\n",
      "step:    3497, loss: 0.1675830632448196, accuracy-micro: 0.7619454860687256, accuracy-macro: 0.0037000000011176\n",
      "step:    3498, loss: 0.1675807833671570, accuracy-micro: 0.7619142532348633, accuracy-macro: 0.0037000000011176\n",
      "step:    3499, loss: 0.1675767749547958, accuracy-micro: 0.7619612216949463, accuracy-macro: 0.0037000000011176\n",
      "step:    3500, loss: 0.1675740927457809, accuracy-micro: 0.7619314789772034, accuracy-macro: 0.0037000000011176\n",
      "step:    3501, loss: 0.1675727069377899, accuracy-micro: 0.7619444727897644, accuracy-macro: 0.0037000000011176\n",
      "step:    3502, loss: 0.1675717383623123, accuracy-micro: 0.7619207501411438, accuracy-macro: 0.0037000000011176\n",
      "step:    3503, loss: 0.1675708889961243, accuracy-micro: 0.7619305253028870, accuracy-macro: 0.0037000000011176\n",
      "step:    3504, loss: 0.1675695031881332, accuracy-micro: 0.7619282603263855, accuracy-macro: 0.0037000000011176\n",
      "step:    3505, loss: 0.1675683110952377, accuracy-micro: 0.7619090080261230, accuracy-macro: 0.0037000000011176\n",
      "step:    3506, loss: 0.1675680875778198, accuracy-micro: 0.7619259953498840, accuracy-macro: 0.0037000000011176\n",
      "step:    3507, loss: 0.1675669550895691, accuracy-micro: 0.7619435191154480, accuracy-macro: 0.0037000000011176\n",
      "step:    3508, loss: 0.1675675064325333, accuracy-micro: 0.7619735002517700, accuracy-macro: 0.0037000000011176\n",
      "step:    3509, loss: 0.1675677448511124, accuracy-micro: 0.7619407773017883, accuracy-macro: 0.0037000000011176\n",
      "step:    3510, loss: 0.1675693392753601, accuracy-micro: 0.7619745135307312, accuracy-macro: 0.0037000000011176\n",
      "step:    3511, loss: 0.1675700098276138, accuracy-micro: 0.7619152665138245, accuracy-macro: 0.0037000000011176\n",
      "step:    3512, loss: 0.1675682365894318, accuracy-micro: 0.7619777321815491, accuracy-macro: 0.0037000000011176\n",
      "step:    3513, loss: 0.1675666868686676, accuracy-micro: 0.7619272470474243, accuracy-macro: 0.0037000000011176\n",
      "step:    3514, loss: 0.1675629019737244, accuracy-micro: 0.7619584798812866, accuracy-macro: 0.0037000000011176\n",
      "step:    3515, loss: 0.1675599813461304, accuracy-micro: 0.7619787454605103, accuracy-macro: 0.0037000000011176\n",
      "step:    3516, loss: 0.1675583422183990, accuracy-micro: 0.7619612216949463, accuracy-macro: 0.0037000000011176\n",
      "step:    3517, loss: 0.1675574034452438, accuracy-micro: 0.7619454860687256, accuracy-macro: 0.0037000000011176\n",
      "step:    3518, loss: 0.1675573587417603, accuracy-micro: 0.7619672417640686, accuracy-macro: 0.0037000000011176\n",
      "step:    3519, loss: 0.1675567030906677, accuracy-micro: 0.7619622349739075, accuracy-macro: 0.0037000000011176\n",
      "step:    3520, loss: 0.1675556153059006, accuracy-micro: 0.7619932293891907, accuracy-macro: 0.0037000000011176\n",
      "step:    3521, loss: 0.1675539463758469, accuracy-micro: 0.7619602680206299, accuracy-macro: 0.0037000000011176\n",
      "step:    3522, loss: 0.1675531119108200, accuracy-micro: 0.7619624733924866, accuracy-macro: 0.0037000000011176\n",
      "step:    3523, loss: 0.1675523519515991, accuracy-micro: 0.7619680166244507, accuracy-macro: 0.0037000000011176\n",
      "step:    3524, loss: 0.1675510257482529, accuracy-micro: 0.7619845271110535, accuracy-macro: 0.0037000000011176\n",
      "step:    3525, loss: 0.1675493270158768, accuracy-micro: 0.7619529962539673, accuracy-macro: 0.0037000000011176\n",
      "step:    3526, loss: 0.1675490289926529, accuracy-micro: 0.7619817256927490, accuracy-macro: 0.0037000000011176\n",
      "step:    3527, loss: 0.1675481349229813, accuracy-micro: 0.7619640231132507, accuracy-macro: 0.0037000000011176\n",
      "step:    3528, loss: 0.1675463616847992, accuracy-micro: 0.7619770169258118, accuracy-macro: 0.0037000000011176\n",
      "step:    3529, loss: 0.1675455868244171, accuracy-micro: 0.7619917392730713, accuracy-macro: 0.0037000000011176\n",
      "step:    3530, loss: 0.1675459742546082, accuracy-micro: 0.7620040178298950, accuracy-macro: 0.0037000000011176\n",
      "step:    3531, loss: 0.1675456613302231, accuracy-micro: 0.7619764804840088, accuracy-macro: 0.0037000000011176\n",
      "step:    3532, loss: 0.1675458997488022, accuracy-micro: 0.7620152235031128, accuracy-macro: 0.0037000000011176\n",
      "step:    3533, loss: 0.1675460487604141, accuracy-micro: 0.7619709968566895, accuracy-macro: 0.0037000000011176\n",
      "step:    3534, loss: 0.1675467938184738, accuracy-micro: 0.7620077729225159, accuracy-macro: 0.0037000000011176\n",
      "step:    3535, loss: 0.1675491929054260, accuracy-micro: 0.7619722485542297, accuracy-macro: 0.0037000000011176\n",
      "step:    3536, loss: 0.1675506085157394, accuracy-micro: 0.7620122432708740, accuracy-macro: 0.0037000000011176\n",
      "step:    3537, loss: 0.1675514727830887, accuracy-micro: 0.7619670033454895, accuracy-macro: 0.0037000000011176\n",
      "step:    3538, loss: 0.1675531566143036, accuracy-micro: 0.7620077729225159, accuracy-macro: 0.0037000000011176\n",
      "step:    3539, loss: 0.1675542145967484, accuracy-micro: 0.7619525194168091, accuracy-macro: 0.0037000000011176\n",
      "step:    3540, loss: 0.1675564348697662, accuracy-micro: 0.7620310187339783, accuracy-macro: 0.0037000000011176\n",
      "step:    3541, loss: 0.1675567477941513, accuracy-micro: 0.7619494795799255, accuracy-macro: 0.0037000000011176\n",
      "step:    3542, loss: 0.1675551533699036, accuracy-micro: 0.7620369791984558, accuracy-macro: 0.0037000000011176\n",
      "step:    3543, loss: 0.1675500422716141, accuracy-micro: 0.7619569897651672, accuracy-macro: 0.0037000000011176\n",
      "step:    3544, loss: 0.1675438731908798, accuracy-micro: 0.7620319724082947, accuracy-macro: 0.0037000000011176\n",
      "step:    3545, loss: 0.1675364971160889, accuracy-micro: 0.7619935274124146, accuracy-macro: 0.0037000000011176\n",
      "step:    3546, loss: 0.1675316542387009, accuracy-micro: 0.7620415091514587, accuracy-macro: 0.0037000000011176\n",
      "step:    3547, loss: 0.1675290614366531, accuracy-micro: 0.7620419859886169, accuracy-macro: 0.0037000000011176\n",
      "step:    3548, loss: 0.1675296872854233, accuracy-micro: 0.7619979977607727, accuracy-macro: 0.0037000000011176\n",
      "step:    3549, loss: 0.1675311923027039, accuracy-micro: 0.7620482444763184, accuracy-macro: 0.0037000000011176\n",
      "step:    3550, loss: 0.1675332188606262, accuracy-micro: 0.7620047330856323, accuracy-macro: 0.0037000000011176\n",
      "step:    3551, loss: 0.1675325930118561, accuracy-micro: 0.7620570063591003, accuracy-macro: 0.0037000000011176\n",
      "step:    3552, loss: 0.1675292253494263, accuracy-micro: 0.7620077729225159, accuracy-macro: 0.0037000000011176\n",
      "step:    3553, loss: 0.1675262153148651, accuracy-micro: 0.7620682716369629, accuracy-macro: 0.0037000000011176\n",
      "step:    3554, loss: 0.1675231754779816, accuracy-micro: 0.7620202302932739, accuracy-macro: 0.0037000000011176\n",
      "step:    3555, loss: 0.1675214022397995, accuracy-micro: 0.7620455026626587, accuracy-macro: 0.0037000000011176\n",
      "step:    3556, loss: 0.1675205677747726, accuracy-micro: 0.7620354890823364, accuracy-macro: 0.0037000000011176\n",
      "step:    3557, loss: 0.1675192117691040, accuracy-micro: 0.7620204687118530, accuracy-macro: 0.0037000000011176\n",
      "step:    3558, loss: 0.1675195246934891, accuracy-micro: 0.7620532512664795, accuracy-macro: 0.0037000000011176\n",
      "step:    3559, loss: 0.1675193458795547, accuracy-micro: 0.7620282769203186, accuracy-macro: 0.0037000000011176\n",
      "step:    3560, loss: 0.1675184071063995, accuracy-micro: 0.7620722651481628, accuracy-macro: 0.0037000000011176\n",
      "step:    3561, loss: 0.1675177216529846, accuracy-micro: 0.7620417475700378, accuracy-macro: 0.0037000000011176\n",
      "step:    3562, loss: 0.1675160974264145, accuracy-micro: 0.7620777487754822, accuracy-macro: 0.0037000000011176\n",
      "step:    3563, loss: 0.1675152778625488, accuracy-micro: 0.7620390057563782, accuracy-macro: 0.0037000000011176\n",
      "step:    3564, loss: 0.1675137877464294, accuracy-micro: 0.7620744705200195, accuracy-macro: 0.0037000000011176\n",
      "step:    3565, loss: 0.1675137132406235, accuracy-micro: 0.7620319724082947, accuracy-macro: 0.0037000000011176\n",
      "step:    3566, loss: 0.1675123125314713, accuracy-micro: 0.7620764970779419, accuracy-macro: 0.0037000000011176\n",
      "step:    3567, loss: 0.1675112992525101, accuracy-micro: 0.7620279788970947, accuracy-macro: 0.0037000000011176\n",
      "step:    3568, loss: 0.1675111204385757, accuracy-micro: 0.7620990276336670, accuracy-macro: 0.0037000000011176\n",
      "step:    3569, loss: 0.1675107628107071, accuracy-micro: 0.7620367407798767, accuracy-macro: 0.0037000000011176\n",
      "step:    3570, loss: 0.1675104051828384, accuracy-micro: 0.7620972394943237, accuracy-macro: 0.0037000000011176\n",
      "step:    3571, loss: 0.1675118803977966, accuracy-micro: 0.7620472311973572, accuracy-macro: 0.0037000000011176\n",
      "step:    3572, loss: 0.1675112992525101, accuracy-micro: 0.7621042728424072, accuracy-macro: 0.0037000000011176\n",
      "step:    3573, loss: 0.1675123423337936, accuracy-micro: 0.7620310187339783, accuracy-macro: 0.0037000000011176\n",
      "step:    3574, loss: 0.1675118952989578, accuracy-micro: 0.7621060013771057, accuracy-macro: 0.0037000000011176\n",
      "step:    3575, loss: 0.1675133109092712, accuracy-micro: 0.7620502710342407, accuracy-macro: 0.0037000000011176\n",
      "step:    3576, loss: 0.1675160825252533, accuracy-micro: 0.7621120214462280, accuracy-macro: 0.0037000000011176\n",
      "step:    3577, loss: 0.1675201207399368, accuracy-micro: 0.7620462775230408, accuracy-macro: 0.0037000000011176\n",
      "step:    3578, loss: 0.1675274521112442, accuracy-micro: 0.7621142268180847, accuracy-macro: 0.0037000000011176\n",
      "step:    3579, loss: 0.1675358861684799, accuracy-micro: 0.7620017528533936, accuracy-macro: 0.0037000000011176\n",
      "step:    3580, loss: 0.1675447225570679, accuracy-micro: 0.7620949745178223, accuracy-macro: 0.0037000000011176\n",
      "step:    3581, loss: 0.1675467193126678, accuracy-micro: 0.7619910240173340, accuracy-macro: 0.0037000000011176\n",
      "step:    3582, loss: 0.1675446033477783, accuracy-micro: 0.7621027231216431, accuracy-macro: 0.0037000000011176\n",
      "step:    3583, loss: 0.1675312966108322, accuracy-micro: 0.7620199918746948, accuracy-macro: 0.0037000000011176\n",
      "step:    3584, loss: 0.1675150692462921, accuracy-micro: 0.7621240019798279, accuracy-macro: 0.0037000000011176\n",
      "step:    3585, loss: 0.1675011664628983, accuracy-micro: 0.7620524764060974, accuracy-macro: 0.0037000000011176\n",
      "step:    3586, loss: 0.1674938648939133, accuracy-micro: 0.7621070146560669, accuracy-macro: 0.0037000000011176\n",
      "step:    3587, loss: 0.1674930155277252, accuracy-micro: 0.7621309757232666, accuracy-macro: 0.0037000000011176\n",
      "step:    3588, loss: 0.1674988567829132, accuracy-micro: 0.7620562314987183, accuracy-macro: 0.0037000000011176\n",
      "step:    3589, loss: 0.1675073504447937, accuracy-micro: 0.7621492743492126, accuracy-macro: 0.0037000000011176\n",
      "step:    3590, loss: 0.1675129085779190, accuracy-micro: 0.7620530128479004, accuracy-macro: 0.0037000000011176\n",
      "step:    3591, loss: 0.1675139367580414, accuracy-micro: 0.7621369957923889, accuracy-macro: 0.0037000000011176\n",
      "step:    3592, loss: 0.1675084680318832, accuracy-micro: 0.7620682716369629, accuracy-macro: 0.0037000000011176\n",
      "step:    3593, loss: 0.1675013452768326, accuracy-micro: 0.7621510028839111, accuracy-macro: 0.0037000000011176\n",
      "step:    3594, loss: 0.1674945801496506, accuracy-micro: 0.7620649933815002, accuracy-macro: 0.0037000000011176\n",
      "step:    3595, loss: 0.1674888432025909, accuracy-micro: 0.7621602416038513, accuracy-macro: 0.0037000000011176\n",
      "step:    3596, loss: 0.1674847155809402, accuracy-micro: 0.7621024847030640, accuracy-macro: 0.0037000000011176\n",
      "step:    3597, loss: 0.1674839407205582, accuracy-micro: 0.7620917558670044, accuracy-macro: 0.0037000000011176\n",
      "step:    3598, loss: 0.1674860864877701, accuracy-micro: 0.7621722221374512, accuracy-macro: 0.0037000000011176\n",
      "step:    3599, loss: 0.1674916595220566, accuracy-micro: 0.7620595097541809, accuracy-macro: 0.0037000000011176\n",
      "step:    3600, loss: 0.1674959361553192, accuracy-micro: 0.7621702551841736, accuracy-macro: 0.0037000000011176\n",
      "step:    3601, loss: 0.1674982458353043, accuracy-micro: 0.7620777487754822, accuracy-macro: 0.0037000000011176\n",
      "step:    3602, loss: 0.1674979031085968, accuracy-micro: 0.7621759772300720, accuracy-macro: 0.0037000000011176\n",
      "step:    3603, loss: 0.1674934327602386, accuracy-micro: 0.7620735168457031, accuracy-macro: 0.0037000000011176\n",
      "step:    3604, loss: 0.1674881875514984, accuracy-micro: 0.7621682286262512, accuracy-macro: 0.0037000000011176\n",
      "step:    3605, loss: 0.1674823164939880, accuracy-micro: 0.7620704770088196, accuracy-macro: 0.0037000000011176\n",
      "step:    3606, loss: 0.1674780249595642, accuracy-micro: 0.7621704936027527, accuracy-macro: 0.0037000000011176\n",
      "step:    3607, loss: 0.1674751043319702, accuracy-micro: 0.7621110081672668, accuracy-macro: 0.0037000000011176\n",
      "step:    3608, loss: 0.1674736887216568, accuracy-micro: 0.7621277570724487, accuracy-macro: 0.0037000000011176\n",
      "step:    3609, loss: 0.1674732565879822, accuracy-micro: 0.7621432542800903, accuracy-macro: 0.0037000000011176\n",
      "step:    3610, loss: 0.1674735993146896, accuracy-micro: 0.7621127367019653, accuracy-macro: 0.0037000000011176\n",
      "step:    3611, loss: 0.1674736589193344, accuracy-micro: 0.7621842622756958, accuracy-macro: 0.0037000000011176\n",
      "step:    3612, loss: 0.1674732267856598, accuracy-micro: 0.7620982527732849, accuracy-macro: 0.0037000000011176\n",
      "step:    3613, loss: 0.1674728244543076, accuracy-micro: 0.7621842622756958, accuracy-macro: 0.0037000000011176\n",
      "step:    3614, loss: 0.1674718111753464, accuracy-micro: 0.7621045112609863, accuracy-macro: 0.0037000000011176\n",
      "step:    3615, loss: 0.1674716472625732, accuracy-micro: 0.7621827721595764, accuracy-macro: 0.0037000000011176\n",
      "step:    3616, loss: 0.1674696058034897, accuracy-micro: 0.7620997428894043, accuracy-macro: 0.0037000000011176\n",
      "step:    3617, loss: 0.1674676388502121, accuracy-micro: 0.7621617317199707, accuracy-macro: 0.0037000000011176\n",
      "step:    3618, loss: 0.1674655973911285, accuracy-micro: 0.7621177434921265, accuracy-macro: 0.0037000000011176\n",
      "step:    3619, loss: 0.1674636900424957, accuracy-micro: 0.7621432542800903, accuracy-macro: 0.0037000000011176\n",
      "step:    3620, loss: 0.1674637794494629, accuracy-micro: 0.7621424794197083, accuracy-macro: 0.0037000000011176\n",
      "step:    3621, loss: 0.1674629002809525, accuracy-micro: 0.7621222734451294, accuracy-macro: 0.0037000000011176\n",
      "step:    3622, loss: 0.1674623787403107, accuracy-micro: 0.7621734738349915, accuracy-macro: 0.0037000000011176\n",
      "step:    3623, loss: 0.1674614399671555, accuracy-micro: 0.7621312737464905, accuracy-macro: 0.0037000000011176\n",
      "step:    3624, loss: 0.1674611121416092, accuracy-micro: 0.7621690034866333, accuracy-macro: 0.0037000000011176\n",
      "step:    3625, loss: 0.1674595773220062, accuracy-micro: 0.7621472477912903, accuracy-macro: 0.0037000000011176\n",
      "step:    3626, loss: 0.1674585640430450, accuracy-micro: 0.7621362209320068, accuracy-macro: 0.0037000000011176\n",
      "step:    3627, loss: 0.1674574613571167, accuracy-micro: 0.7621302604675293, accuracy-macro: 0.0037000000011176\n",
      "step:    3628, loss: 0.1674562990665436, accuracy-micro: 0.7621424794197083, accuracy-macro: 0.0037000000011176\n",
      "step:    3629, loss: 0.1674556881189346, accuracy-micro: 0.7621302604675293, accuracy-macro: 0.0037000000011176\n",
      "step:    3630, loss: 0.1674548834562302, accuracy-micro: 0.7621415257453918, accuracy-macro: 0.0037000000011176\n",
      "step:    3631, loss: 0.1674537807703018, accuracy-micro: 0.7621514797210693, accuracy-macro: 0.0037000000011176\n",
      "step:    3632, loss: 0.1674526184797287, accuracy-micro: 0.7621362209320068, accuracy-macro: 0.0037000000011176\n",
      "step:    3633, loss: 0.1674516052007675, accuracy-micro: 0.7621472477912903, accuracy-macro: 0.0037000000011176\n",
      "step:    3634, loss: 0.1674510687589645, accuracy-micro: 0.7621520161628723, accuracy-macro: 0.0037000000011176\n",
      "step:    3635, loss: 0.1674506962299347, accuracy-micro: 0.7621607184410095, accuracy-macro: 0.0037000000011176\n",
      "step:    3636, loss: 0.1674493849277496, accuracy-micro: 0.7621412277221680, accuracy-macro: 0.0037000000011176\n",
      "step:    3637, loss: 0.1674492210149765, accuracy-micro: 0.7621685266494751, accuracy-macro: 0.0037000000011176\n",
      "step:    3638, loss: 0.1674481630325317, accuracy-micro: 0.7621430158615112, accuracy-macro: 0.0037000000011176\n",
      "step:    3639, loss: 0.1674474477767944, accuracy-micro: 0.7621809840202332, accuracy-macro: 0.0037000000011176\n",
      "step:    3640, loss: 0.1674471497535706, accuracy-micro: 0.7621399760246277, accuracy-macro: 0.0037000000011176\n",
      "step:    3641, loss: 0.1674473434686661, accuracy-micro: 0.7622287273406982, accuracy-macro: 0.0037000000011176\n",
      "step:    3642, loss: 0.1674466133117676, accuracy-micro: 0.7621430158615112, accuracy-macro: 0.0037000000011176\n",
      "step:    3643, loss: 0.1674459874629974, accuracy-micro: 0.7622150182723999, accuracy-macro: 0.0037000000011176\n",
      "step:    3644, loss: 0.1674441844224930, accuracy-micro: 0.7621517777442932, accuracy-macro: 0.0037000000011176\n",
      "step:    3645, loss: 0.1674420535564423, accuracy-micro: 0.7621799707412720, accuracy-macro: 0.0037000000011176\n",
      "step:    3646, loss: 0.1674406379461288, accuracy-micro: 0.7621687650680542, accuracy-macro: 0.0037000000011176\n",
      "step:    3647, loss: 0.1674398481845856, accuracy-micro: 0.7621529698371887, accuracy-macro: 0.0037000000011176\n",
      "step:    3648, loss: 0.1674384623765945, accuracy-micro: 0.7621784806251526, accuracy-macro: 0.0037000000011176\n",
      "step:    3649, loss: 0.1674404442310333, accuracy-micro: 0.7621772289276123, accuracy-macro: 0.0037000000011176\n",
      "step:    3650, loss: 0.1674445718526840, accuracy-micro: 0.7622579932212830, accuracy-macro: 0.0037000000011176\n",
      "step:    3651, loss: 0.1674498766660690, accuracy-micro: 0.7621347308158875, accuracy-macro: 0.0037000000011176\n",
      "step:    3652, loss: 0.1674567162990570, accuracy-micro: 0.7622427344322205, accuracy-macro: 0.0037000000011176\n",
      "step:    3653, loss: 0.1674641519784927, accuracy-micro: 0.7621037364006042, accuracy-macro: 0.0037000000011176\n",
      "step:    3654, loss: 0.1674753427505493, accuracy-micro: 0.7622417211532593, accuracy-macro: 0.0037000000011176\n",
      "step:    3655, loss: 0.1674830019474030, accuracy-micro: 0.7621062397956848, accuracy-macro: 0.0037000000011176\n",
      "step:    3656, loss: 0.1674854159355164, accuracy-micro: 0.7622359991073608, accuracy-macro: 0.0037000000011176\n",
      "step:    3657, loss: 0.1674753725528717, accuracy-micro: 0.7620972394943237, accuracy-macro: 0.0037000000011176\n",
      "step:    3658, loss: 0.1674623340368271, accuracy-micro: 0.7622687220573425, accuracy-macro: 0.0037000000011176\n",
      "step:    3659, loss: 0.1674481630325317, accuracy-micro: 0.7621512413024902, accuracy-macro: 0.0037000000011176\n",
      "step:    3660, loss: 0.1674361526966095, accuracy-micro: 0.7622557282447815, accuracy-macro: 0.0037000000011176\n",
      "step:    3661, loss: 0.1674288362264633, accuracy-micro: 0.7621744871139526, accuracy-macro: 0.0037000000011176\n",
      "step:    3662, loss: 0.1674265712499619, accuracy-micro: 0.7621939778327942, accuracy-macro: 0.0037000000011176\n",
      "step:    3663, loss: 0.1674272119998932, accuracy-micro: 0.7622252702713013, accuracy-macro: 0.0037000000011176\n",
      "step:    3664, loss: 0.1674281507730484, accuracy-micro: 0.7621960043907166, accuracy-macro: 0.0037000000011176\n",
      "step:    3665, loss: 0.1674302071332932, accuracy-micro: 0.7622772455215454, accuracy-macro: 0.0037000000011176\n",
      "step:    3666, loss: 0.1674300581216812, accuracy-micro: 0.7621912360191345, accuracy-macro: 0.0037000000011176\n",
      "step:    3667, loss: 0.1674281060695648, accuracy-micro: 0.7622810006141663, accuracy-macro: 0.0037000000011176\n",
      "step:    3668, loss: 0.1674250364303589, accuracy-micro: 0.7622122764587402, accuracy-macro: 0.0037000000011176\n",
      "step:    3669, loss: 0.1674209237098694, accuracy-micro: 0.7622277736663818, accuracy-macro: 0.0037000000011176\n",
      "step:    3670, loss: 0.1674192547798157, accuracy-micro: 0.7622069716453552, accuracy-macro: 0.0037000000011176\n",
      "step:    3671, loss: 0.1674183756113052, accuracy-micro: 0.7622202634811401, accuracy-macro: 0.0037000000011176\n",
      "step:    3672, loss: 0.1674176305532455, accuracy-micro: 0.7622244954109192, accuracy-macro: 0.0037000000011176\n",
      "step:    3673, loss: 0.1674172133207321, accuracy-micro: 0.7622134685516357, accuracy-macro: 0.0037000000011176\n",
      "step:    3674, loss: 0.1674169301986694, accuracy-micro: 0.7622417211532593, accuracy-macro: 0.0037000000011176\n",
      "step:    3675, loss: 0.1674170941114426, accuracy-micro: 0.7622077465057373, accuracy-macro: 0.0037000000011176\n",
      "step:    3676, loss: 0.1674161851406097, accuracy-micro: 0.7622625231742859, accuracy-macro: 0.0037000000011176\n",
      "step:    3677, loss: 0.1674149334430695, accuracy-micro: 0.7622282505035400, accuracy-macro: 0.0037000000011176\n",
      "step:    3678, loss: 0.1674149930477142, accuracy-micro: 0.7622644901275635, accuracy-macro: 0.0037000000011176\n",
      "step:    3679, loss: 0.1674149185419083, accuracy-micro: 0.7622127532958984, accuracy-macro: 0.0037000000011176\n",
      "step:    3680, loss: 0.1674154251813889, accuracy-micro: 0.7622755169868469, accuracy-macro: 0.0037000000011176\n",
      "step:    3681, loss: 0.1674166470766068, accuracy-micro: 0.7621970176696777, accuracy-macro: 0.0037000000011176\n",
      "step:    3682, loss: 0.1674179732799530, accuracy-micro: 0.7622657418251038, accuracy-macro: 0.0037000000011176\n",
      "step:    3683, loss: 0.1674187332391739, accuracy-micro: 0.7621979713439941, accuracy-macro: 0.0037000000011176\n",
      "step:    3684, loss: 0.1674184054136276, accuracy-micro: 0.7622697353363037, accuracy-macro: 0.0037000000011176\n",
      "step:    3685, loss: 0.1674153208732605, accuracy-micro: 0.7622029781341553, accuracy-macro: 0.0037000000011176\n",
      "step:    3686, loss: 0.1674132645130157, accuracy-micro: 0.7622797489166260, accuracy-macro: 0.0037000000011176\n",
      "step:    3687, loss: 0.1674115508794785, accuracy-micro: 0.7622082233428955, accuracy-macro: 0.0037000000011176\n",
      "step:    3688, loss: 0.1674092859029770, accuracy-micro: 0.7622762322425842, accuracy-macro: 0.0037000000011176\n",
      "step:    3689, loss: 0.1674069464206696, accuracy-micro: 0.7622200250625610, accuracy-macro: 0.0037000000011176\n",
      "step:    3690, loss: 0.1674046069383621, accuracy-micro: 0.7622870206832886, accuracy-macro: 0.0037000000011176\n",
      "step:    3691, loss: 0.1674023717641830, accuracy-micro: 0.7622579932212830, accuracy-macro: 0.0037000000011176\n",
      "step:    3692, loss: 0.1674001812934875, accuracy-micro: 0.7622740268707275, accuracy-macro: 0.0037000000011176\n",
      "step:    3693, loss: 0.1673992872238159, accuracy-micro: 0.7622770071029663, accuracy-macro: 0.0037000000011176\n",
      "step:    3694, loss: 0.1673993468284607, accuracy-micro: 0.7622627615928650, accuracy-macro: 0.0037000000011176\n",
      "step:    3695, loss: 0.1673997491598129, accuracy-micro: 0.7622770071029663, accuracy-macro: 0.0037000000011176\n",
      "step:    3696, loss: 0.1674010604619980, accuracy-micro: 0.7622332572937012, accuracy-macro: 0.0037000000011176\n",
      "step:    3697, loss: 0.1674011498689651, accuracy-micro: 0.7622904777526855, accuracy-macro: 0.0037000000011176\n",
      "step:    3698, loss: 0.1674007028341293, accuracy-micro: 0.7622457742691040, accuracy-macro: 0.0037000000011176\n",
      "step:    3699, loss: 0.1673997193574905, accuracy-micro: 0.7622874975204468, accuracy-macro: 0.0037000000011176\n",
      "step:    3700, loss: 0.1673970818519592, accuracy-micro: 0.7622349858283997, accuracy-macro: 0.0037000000011176\n",
      "step:    3701, loss: 0.1673960089683533, accuracy-micro: 0.7622979879379272, accuracy-macro: 0.0037000000011176\n",
      "step:    3702, loss: 0.1673935353755951, accuracy-micro: 0.7622672319412231, accuracy-macro: 0.0037000000011176\n",
      "step:    3703, loss: 0.1673922240734100, accuracy-micro: 0.7623007297515869, accuracy-macro: 0.0037000000011176\n",
      "step:    3704, loss: 0.1673904955387115, accuracy-micro: 0.7622952461242676, accuracy-macro: 0.0037000000011176\n",
      "step:    3705, loss: 0.1673890799283981, accuracy-micro: 0.7622780203819275, accuracy-macro: 0.0037000000011176\n",
      "step:    3706, loss: 0.1673888415098190, accuracy-micro: 0.7622682452201843, accuracy-macro: 0.0037000000011176\n",
      "step:    3707, loss: 0.1673882007598877, accuracy-micro: 0.7622732520103455, accuracy-macro: 0.0037000000011176\n",
      "step:    3708, loss: 0.1673888117074966, accuracy-micro: 0.7622960209846497, accuracy-macro: 0.0037000000011176\n",
      "step:    3709, loss: 0.1673895567655563, accuracy-micro: 0.7622550129890442, accuracy-macro: 0.0037000000011176\n",
      "step:    3710, loss: 0.1673897802829742, accuracy-micro: 0.7623224854469299, accuracy-macro: 0.0037000000011176\n",
      "step:    3711, loss: 0.1673907488584518, accuracy-micro: 0.7622579932212830, accuracy-macro: 0.0037000000011176\n",
      "step:    3712, loss: 0.1673908531665802, accuracy-micro: 0.7623209953308105, accuracy-macro: 0.0037000000011176\n",
      "step:    3713, loss: 0.1673894673585892, accuracy-micro: 0.7622609734535217, accuracy-macro: 0.0037000000011176\n",
      "step:    3714, loss: 0.1673878580331802, accuracy-micro: 0.7623335123062134, accuracy-macro: 0.0037000000011176\n",
      "step:    3715, loss: 0.1673849076032639, accuracy-micro: 0.7622659802436829, accuracy-macro: 0.0037000000011176\n",
      "step:    3716, loss: 0.1673821061849594, accuracy-micro: 0.7623122334480286, accuracy-macro: 0.0037000000011176\n",
      "step:    3717, loss: 0.1673799008131027, accuracy-micro: 0.7622907757759094, accuracy-macro: 0.0037000000011176\n",
      "step:    3718, loss: 0.1673777848482132, accuracy-micro: 0.7622960209846497, accuracy-macro: 0.0037000000011176\n",
      "step:    3719, loss: 0.1673764437437057, accuracy-micro: 0.7623010277748108, accuracy-macro: 0.0037000000011176\n",
      "step:    3720, loss: 0.1673763543367386, accuracy-micro: 0.7622997760772705, accuracy-macro: 0.0037000000011176\n",
      "step:    3721, loss: 0.1673765927553177, accuracy-micro: 0.7623264789581299, accuracy-macro: 0.0037000000011176\n",
      "step:    3722, loss: 0.1673768162727356, accuracy-micro: 0.7622922658920288, accuracy-macro: 0.0037000000011176\n",
      "step:    3723, loss: 0.1673766225576401, accuracy-micro: 0.7623402476310730, accuracy-macro: 0.0037000000011176\n",
      "step:    3724, loss: 0.1673761159181595, accuracy-micro: 0.7622697353363037, accuracy-macro: 0.0037000000011176\n",
      "step:    3725, loss: 0.1673749685287476, accuracy-micro: 0.7623352408409119, accuracy-macro: 0.0037000000011176\n",
      "step:    3726, loss: 0.1673743128776550, accuracy-micro: 0.7622912526130676, accuracy-macro: 0.0037000000011176\n",
      "step:    3727, loss: 0.1673754900693893, accuracy-micro: 0.7623507380485535, accuracy-macro: 0.0037000000011176\n",
      "step:    3728, loss: 0.1673780679702759, accuracy-micro: 0.7622622251510620, accuracy-macro: 0.0037000000011176\n",
      "step:    3729, loss: 0.1673824489116669, accuracy-micro: 0.7623180150985718, accuracy-macro: 0.0037000000011176\n",
      "step:    3730, loss: 0.1673869490623474, accuracy-micro: 0.7622767686843872, accuracy-macro: 0.0037000000011176\n",
      "step:    3731, loss: 0.1673866361379623, accuracy-micro: 0.7623347640037537, accuracy-macro: 0.0037000000011176\n",
      "step:    3732, loss: 0.1673828363418579, accuracy-micro: 0.7622732520103455, accuracy-macro: 0.0037000000011176\n",
      "step:    3733, loss: 0.1673769950866699, accuracy-micro: 0.7623360157012939, accuracy-macro: 0.0037000000011176\n",
      "step:    3734, loss: 0.1673709005117416, accuracy-micro: 0.7622987627983093, accuracy-macro: 0.0037000000011176\n",
      "step:    3735, loss: 0.1673651188611984, accuracy-micro: 0.7623659968376160, accuracy-macro: 0.0037000000011176\n",
      "step:    3736, loss: 0.1673626601696014, accuracy-micro: 0.7623320221900940, accuracy-macro: 0.0037000000011176\n",
      "step:    3737, loss: 0.1673620492219925, accuracy-micro: 0.7623279690742493, accuracy-macro: 0.0037000000011176\n",
      "step:    3738, loss: 0.1673635095357895, accuracy-micro: 0.7623659968376160, accuracy-macro: 0.0037000000011176\n",
      "step:    3739, loss: 0.1673644483089447, accuracy-micro: 0.7623105049133301, accuracy-macro: 0.0037000000011176\n",
      "step:    3740, loss: 0.1673659086227417, accuracy-micro: 0.7623289823532104, accuracy-macro: 0.0037000000011176\n",
      "step:    3741, loss: 0.1673655360937119, accuracy-micro: 0.7623072266578674, accuracy-macro: 0.0037000000011176\n",
      "step:    3742, loss: 0.1673633605241776, accuracy-micro: 0.7623519897460938, accuracy-macro: 0.0037000000011176\n",
      "step:    3743, loss: 0.1673612147569656, accuracy-micro: 0.7623192667961121, accuracy-macro: 0.0037000000011176\n",
      "step:    3744, loss: 0.1673596650362015, accuracy-micro: 0.7623712420463562, accuracy-macro: 0.0037000000011176\n",
      "step:    3745, loss: 0.1673583090305328, accuracy-micro: 0.7623342275619507, accuracy-macro: 0.0037000000011176\n",
      "step:    3746, loss: 0.1673575341701508, accuracy-micro: 0.7623670101165771, accuracy-macro: 0.0037000000011176\n",
      "step:    3747, loss: 0.1673555523157120, accuracy-micro: 0.7623189687728882, accuracy-macro: 0.0037000000011176\n",
      "step:    3748, loss: 0.1673541218042374, accuracy-micro: 0.7624030113220215, accuracy-macro: 0.0037000000011176\n",
      "step:    3749, loss: 0.1673528701066971, accuracy-micro: 0.7623477578163147, accuracy-macro: 0.0037000000011176\n",
      "step:    3750, loss: 0.1673513799905777, accuracy-micro: 0.7623950242996216, accuracy-macro: 0.0037000000011176\n",
      "step:    3751, loss: 0.1673501580953598, accuracy-micro: 0.7623584866523743, accuracy-macro: 0.0037000000011176\n",
      "step:    3752, loss: 0.1673487126827240, accuracy-micro: 0.7623624801635742, accuracy-macro: 0.0037000000011176\n",
      "step:    3753, loss: 0.1673476547002792, accuracy-micro: 0.7623527646064758, accuracy-macro: 0.0037000000011176\n",
      "step:    3754, loss: 0.1673463135957718, accuracy-micro: 0.7623632550239563, accuracy-macro: 0.0037000000011176\n",
      "step:    3755, loss: 0.1673460602760315, accuracy-micro: 0.7623620033264160, accuracy-macro: 0.0037000000011176\n",
      "step:    3756, loss: 0.1673445552587509, accuracy-micro: 0.7623617649078369, accuracy-macro: 0.0037000000011176\n",
      "step:    3757, loss: 0.1673443168401718, accuracy-micro: 0.7623637318611145, accuracy-macro: 0.0037000000011176\n",
      "step:    3758, loss: 0.1673432141542435, accuracy-micro: 0.7623835206031799, accuracy-macro: 0.0037000000011176\n",
      "step:    3759, loss: 0.1673427373170853, accuracy-micro: 0.7623757719993591, accuracy-macro: 0.0037000000011176\n",
      "step:    3760, loss: 0.1673418134450912, accuracy-micro: 0.7623847723007202, accuracy-macro: 0.0037000000011176\n",
      "step:    3761, loss: 0.1673410981893539, accuracy-micro: 0.7623902559280396, accuracy-macro: 0.0037000000011176\n",
      "step:    3762, loss: 0.1673400998115540, accuracy-micro: 0.7623737454414368, accuracy-macro: 0.0037000000011176\n",
      "step:    3763, loss: 0.1673395335674286, accuracy-micro: 0.7623902559280396, accuracy-macro: 0.0037000000011176\n",
      "step:    3764, loss: 0.1673381626605988, accuracy-micro: 0.7623737454414368, accuracy-macro: 0.0037000000011176\n",
      "step:    3765, loss: 0.1673373281955719, accuracy-micro: 0.7623944878578186, accuracy-macro: 0.0037000000011176\n",
      "step:    3766, loss: 0.1673366129398346, accuracy-micro: 0.7623702287673950, accuracy-macro: 0.0037000000011176\n",
      "step:    3767, loss: 0.1673360913991928, accuracy-micro: 0.7624024748802185, accuracy-macro: 0.0037000000011176\n",
      "step:    3768, loss: 0.1673351675271988, accuracy-micro: 0.7623869776725769, accuracy-macro: 0.0037000000011176\n",
      "step:    3769, loss: 0.1673334687948227, accuracy-micro: 0.7624052762985229, accuracy-macro: 0.0037000000011176\n",
      "step:    3770, loss: 0.1673332750797272, accuracy-micro: 0.7623962759971619, accuracy-macro: 0.0037000000011176\n",
      "step:    3771, loss: 0.1673320978879929, accuracy-micro: 0.7623942494392395, accuracy-macro: 0.0037000000011176\n",
      "step:    3772, loss: 0.1673312783241272, accuracy-micro: 0.7624099850654602, accuracy-macro: 0.0037000000011176\n",
      "step:    3773, loss: 0.1673308163881302, accuracy-micro: 0.7623892426490784, accuracy-macro: 0.0037000000011176\n",
      "step:    3774, loss: 0.1673297435045242, accuracy-micro: 0.7623812556266785, accuracy-macro: 0.0037000000011176\n",
      "step:    3775, loss: 0.1673290729522705, accuracy-micro: 0.7623992562294006, accuracy-macro: 0.0037000000011176\n",
      "step:    3776, loss: 0.1673277467489243, accuracy-micro: 0.7624067664146423, accuracy-macro: 0.0037000000011176\n",
      "step:    3777, loss: 0.1673273891210556, accuracy-micro: 0.7624099850654602, accuracy-macro: 0.0037000000011176\n",
      "step:    3778, loss: 0.1673267781734467, accuracy-micro: 0.7624250054359436, accuracy-macro: 0.0037000000011176\n",
      "step:    3779, loss: 0.1673278957605362, accuracy-micro: 0.7624082565307617, accuracy-macro: 0.0037000000011176\n",
      "step:    3780, loss: 0.1673305779695511, accuracy-micro: 0.7623927593231201, accuracy-macro: 0.0037000000011176\n",
      "step:    3781, loss: 0.1673349738121033, accuracy-micro: 0.7624267339706421, accuracy-macro: 0.0037000000011176\n",
      "step:    3782, loss: 0.1673397123813629, accuracy-micro: 0.7623549699783325, accuracy-macro: 0.0037000000011176\n",
      "step:    3783, loss: 0.1673435270786285, accuracy-micro: 0.7623940110206604, accuracy-macro: 0.0037000000011176\n",
      "step:    3784, loss: 0.1673451066017151, accuracy-micro: 0.7623202204704285, accuracy-macro: 0.0037000000011176\n",
      "step:    3785, loss: 0.1673456877470016, accuracy-micro: 0.7624017596244812, accuracy-macro: 0.0037000000011176\n",
      "step:    3786, loss: 0.1673444956541061, accuracy-micro: 0.7623239755630493, accuracy-macro: 0.0037000000011176\n",
      "step:    3787, loss: 0.1673425585031509, accuracy-micro: 0.7624024748802185, accuracy-macro: 0.0037000000011176\n",
      "step:    3788, loss: 0.1673404574394226, accuracy-micro: 0.7623469829559326, accuracy-macro: 0.0037000000011176\n",
      "step:    3789, loss: 0.1673375070095062, accuracy-micro: 0.7624077200889587, accuracy-macro: 0.0037000000011176\n",
      "step:    3790, loss: 0.1673335433006287, accuracy-micro: 0.7623624801635742, accuracy-macro: 0.0037000000011176\n",
      "step:    3791, loss: 0.1673295944929123, accuracy-micro: 0.7624362707138062, accuracy-macro: 0.0037000000011176\n",
      "step:    3792, loss: 0.1673249304294586, accuracy-micro: 0.7623862624168396, accuracy-macro: 0.0037000000011176\n",
      "step:    3793, loss: 0.1673220843076706, accuracy-micro: 0.7624482512474060, accuracy-macro: 0.0037000000011176\n",
      "step:    3794, loss: 0.1673185378313065, accuracy-micro: 0.7624227404594421, accuracy-macro: 0.0037000000011176\n",
      "step:    3795, loss: 0.1673155277967453, accuracy-micro: 0.7624377608299255, accuracy-macro: 0.0037000000011176\n",
      "step:    3796, loss: 0.1673130095005035, accuracy-micro: 0.7624310255050659, accuracy-macro: 0.0037000000011176\n",
      "step:    3797, loss: 0.1673099100589752, accuracy-micro: 0.7624694705009460, accuracy-macro: 0.0037000000011176\n",
      "step:    3798, loss: 0.1673086583614349, accuracy-micro: 0.7624559998512268, accuracy-macro: 0.0037000000011176\n",
      "step:    3799, loss: 0.1673083305358887, accuracy-micro: 0.7624532580375671, accuracy-macro: 0.0037000000011176\n",
      "step:    3800, loss: 0.1673075407743454, accuracy-micro: 0.7624534964561462, accuracy-macro: 0.0037000000011176\n",
      "step:    3801, loss: 0.1673068255186081, accuracy-micro: 0.7624390125274658, accuracy-macro: 0.0037000000011176\n",
      "step:    3802, loss: 0.1673066020011902, accuracy-micro: 0.7624474763870239, accuracy-macro: 0.0037000000011176\n",
      "step:    3803, loss: 0.1673067212104797, accuracy-micro: 0.7624262571334839, accuracy-macro: 0.0037000000011176\n",
      "step:    3804, loss: 0.1673054099082947, accuracy-micro: 0.7624627351760864, accuracy-macro: 0.0037000000011176\n",
      "step:    3805, loss: 0.1673058420419693, accuracy-micro: 0.7624392509460449, accuracy-macro: 0.0037000000011176\n",
      "step:    3806, loss: 0.1673049032688141, accuracy-micro: 0.7624677419662476, accuracy-macro: 0.0037000000011176\n",
      "step:    3807, loss: 0.1673053503036499, accuracy-micro: 0.7624392509460449, accuracy-macro: 0.0037000000011176\n",
      "step:    3808, loss: 0.1673060059547424, accuracy-micro: 0.7624635100364685, accuracy-macro: 0.0037000000011176\n",
      "step:    3809, loss: 0.1673066914081573, accuracy-micro: 0.7624147534370422, accuracy-macro: 0.0037000000011176\n",
      "step:    3810, loss: 0.1673084497451782, accuracy-micro: 0.7624887228012085, accuracy-macro: 0.0037000000011176\n",
      "step:    3811, loss: 0.1673086136579514, accuracy-micro: 0.7624117732048035, accuracy-macro: 0.0037000000011176\n",
      "step:    3812, loss: 0.1673089265823364, accuracy-micro: 0.7624757289886475, accuracy-macro: 0.0037000000011176\n",
      "step:    3813, loss: 0.1673078984022141, accuracy-micro: 0.7624182701110840, accuracy-macro: 0.0037000000011176\n",
      "step:    3814, loss: 0.1673065572977066, accuracy-micro: 0.7624934911727905, accuracy-macro: 0.0037000000011176\n",
      "step:    3815, loss: 0.1673042476177216, accuracy-micro: 0.7624367475509644, accuracy-macro: 0.0037000000011176\n",
      "step:    3816, loss: 0.1673019379377365, accuracy-micro: 0.7625002264976501, accuracy-macro: 0.0037000000011176\n",
      "step:    3817, loss: 0.1672995835542679, accuracy-micro: 0.7624507546424866, accuracy-macro: 0.0037000000011176\n",
      "step:    3818, loss: 0.1672964841127396, accuracy-micro: 0.7624794840812683, accuracy-macro: 0.0037000000011176\n",
      "step:    3819, loss: 0.1672935336828232, accuracy-micro: 0.7624599933624268, accuracy-macro: 0.0037000000011176\n",
      "step:    3820, loss: 0.1672916114330292, accuracy-micro: 0.7624915242195129, accuracy-macro: 0.0037000000011176\n",
      "step:    3821, loss: 0.1672898232936859, accuracy-micro: 0.7624682188034058, accuracy-macro: 0.0037000000011176\n",
      "step:    3822, loss: 0.1672885864973068, accuracy-micro: 0.7624992728233337, accuracy-macro: 0.0037000000011176\n",
      "step:    3823, loss: 0.1672877818346024, accuracy-micro: 0.7624952197074890, accuracy-macro: 0.0037000000011176\n",
      "step:    3824, loss: 0.1672867983579636, accuracy-micro: 0.7624869942665100, accuracy-macro: 0.0037000000011176\n",
      "step:    3825, loss: 0.1672864854335785, accuracy-micro: 0.7625017762184143, accuracy-macro: 0.0037000000011176\n",
      "step:    3826, loss: 0.1672854721546173, accuracy-micro: 0.7625104784965515, accuracy-macro: 0.0037000000011176\n",
      "step:    3827, loss: 0.1672843843698502, accuracy-micro: 0.7625052332878113, accuracy-macro: 0.0037000000011176\n",
      "step:    3828, loss: 0.1672841310501099, accuracy-micro: 0.7624917626380920, accuracy-macro: 0.0037000000011176\n",
      "step:    3829, loss: 0.1672830432653427, accuracy-micro: 0.7624987363815308, accuracy-macro: 0.0037000000011176\n",
      "step:    3830, loss: 0.1672820895910263, accuracy-micro: 0.7625127434730530, accuracy-macro: 0.0037000000011176\n",
      "step:    3831, loss: 0.1672810167074203, accuracy-micro: 0.7625107765197754, accuracy-macro: 0.0037000000011176\n",
      "step:    3832, loss: 0.1672807782888412, accuracy-micro: 0.7625085115432739, accuracy-macro: 0.0037000000011176\n",
      "step:    3833, loss: 0.1672798991203308, accuracy-micro: 0.7625167369842529, accuracy-macro: 0.0037000000011176\n",
      "step:    3834, loss: 0.1672794967889786, accuracy-micro: 0.7625062465667725, accuracy-macro: 0.0037000000011176\n",
      "step:    3835, loss: 0.1672789901494980, accuracy-micro: 0.7625125050544739, accuracy-macro: 0.0037000000011176\n",
      "step:    3836, loss: 0.1672782748937607, accuracy-micro: 0.7624977231025696, accuracy-macro: 0.0037000000011176\n",
      "step:    3837, loss: 0.1672779321670532, accuracy-micro: 0.7624984979629517, accuracy-macro: 0.0037000000011176\n",
      "step:    3838, loss: 0.1672773063182831, accuracy-micro: 0.7625037431716919, accuracy-macro: 0.0037000000011176\n",
      "step:    3839, loss: 0.1672770977020264, accuracy-micro: 0.7625062465667725, accuracy-macro: 0.0037000000011176\n",
      "step:    3840, loss: 0.1672779023647308, accuracy-micro: 0.7625157237052917, accuracy-macro: 0.0037000000011176\n",
      "step:    3841, loss: 0.1672772467136383, accuracy-micro: 0.7624817490577698, accuracy-macro: 0.0037000000011176\n",
      "step:    3842, loss: 0.1672784537076950, accuracy-micro: 0.7625215053558350, accuracy-macro: 0.0037000000011176\n",
      "step:    3843, loss: 0.1672788709402084, accuracy-micro: 0.7624682188034058, accuracy-macro: 0.0037000000011176\n",
      "step:    3844, loss: 0.1672798097133636, accuracy-micro: 0.7625197768211365, accuracy-macro: 0.0037000000011176\n",
      "step:    3845, loss: 0.1672805547714233, accuracy-micro: 0.7624577283859253, accuracy-macro: 0.0037000000011176\n",
      "step:    3846, loss: 0.1672818064689636, accuracy-micro: 0.7624949812889099, accuracy-macro: 0.0037000000011176\n",
      "step:    3847, loss: 0.1672848314046860, accuracy-micro: 0.7624647617340088, accuracy-macro: 0.0037000000011176\n",
      "step:    3848, loss: 0.1672874689102173, accuracy-micro: 0.7624792456626892, accuracy-macro: 0.0037000000011176\n",
      "step:    3849, loss: 0.1672896295785904, accuracy-micro: 0.7624225020408630, accuracy-macro: 0.0037000000011176\n",
      "step:    3850, loss: 0.1672923415899277, accuracy-micro: 0.7624617218971252, accuracy-macro: 0.0037000000011176\n",
      "step:    3851, loss: 0.1672946661710739, accuracy-micro: 0.7623854875564575, accuracy-macro: 0.0037000000011176\n",
      "step:    3852, loss: 0.1672973781824112, accuracy-micro: 0.7624872326850891, accuracy-macro: 0.0037000000011176\n",
      "step:    3853, loss: 0.1672980338335037, accuracy-micro: 0.7623865008354187, accuracy-macro: 0.0037000000011176\n",
      "step:    3854, loss: 0.1672983169555664, accuracy-micro: 0.7624664902687073, accuracy-macro: 0.0037000000011176\n",
      "step:    3855, loss: 0.1672945618629456, accuracy-micro: 0.7623894810676575, accuracy-macro: 0.0037000000011176\n",
      "step:    3856, loss: 0.1672900617122650, accuracy-micro: 0.7624530196189880, accuracy-macro: 0.0037000000011176\n",
      "step:    3857, loss: 0.1672822833061218, accuracy-micro: 0.7624514698982239, accuracy-macro: 0.0037000000011176\n",
      "step:    3858, loss: 0.1672748923301697, accuracy-micro: 0.7625035047531128, accuracy-macro: 0.0037000000011176\n",
      "step:    3859, loss: 0.1672675609588623, accuracy-micro: 0.7624819874763489, accuracy-macro: 0.0037000000011176\n",
      "step:    3860, loss: 0.1672611236572266, accuracy-micro: 0.7625237703323364, accuracy-macro: 0.0037000000011176\n",
      "step:    3861, loss: 0.1672574430704117, accuracy-micro: 0.7625629901885986, accuracy-macro: 0.0037000000011176\n",
      "step:    3862, loss: 0.1672544628381729, accuracy-micro: 0.7625550031661987, accuracy-macro: 0.0037000000011176\n",
      "step:    3863, loss: 0.1672549098730087, accuracy-micro: 0.7625485062599182, accuracy-macro: 0.0037000000011176\n",
      "step:    3864, loss: 0.1672583818435669, accuracy-micro: 0.7625187635421753, accuracy-macro: 0.0037000000011176\n",
      "step:    3865, loss: 0.1672639250755310, accuracy-micro: 0.7625242471694946, accuracy-macro: 0.0037000000011176\n",
      "step:    3866, loss: 0.1672729402780533, accuracy-micro: 0.7624702453613281, accuracy-macro: 0.0037000000011176\n",
      "step:    3867, loss: 0.1672808676958084, accuracy-micro: 0.7624884843826294, accuracy-macro: 0.0037000000011176\n",
      "step:    3868, loss: 0.1672853529453278, accuracy-micro: 0.7624172568321228, accuracy-macro: 0.0037000000011176\n",
      "step:    3869, loss: 0.1672889441251755, accuracy-micro: 0.7624842524528503, accuracy-macro: 0.0037000000011176\n",
      "step:    3870, loss: 0.1672881245613098, accuracy-micro: 0.7623987197875977, accuracy-macro: 0.0037000000011176\n",
      "step:    3871, loss: 0.1672825664281845, accuracy-micro: 0.7624947428703308, accuracy-macro: 0.0037000000011176\n",
      "step:    3872, loss: 0.1672721505165100, accuracy-micro: 0.7624490261077881, accuracy-macro: 0.0037000000011176\n",
      "step:    3873, loss: 0.1672612428665161, accuracy-micro: 0.7625135183334351, accuracy-macro: 0.0037000000011176\n",
      "step:    3874, loss: 0.1672530621290207, accuracy-micro: 0.7625032663345337, accuracy-macro: 0.0037000000011176\n",
      "step:    3875, loss: 0.1672468483448029, accuracy-micro: 0.7625635266304016, accuracy-macro: 0.0037000000011176\n",
      "step:    3876, loss: 0.1672431379556656, accuracy-micro: 0.7625737190246582, accuracy-macro: 0.0037000000011176\n",
      "step:    3877, loss: 0.1672416627407074, accuracy-micro: 0.7625700235366821, accuracy-macro: 0.0037000000011176\n",
      "step:    3878, loss: 0.1672420948743820, accuracy-micro: 0.7625847458839417, accuracy-macro: 0.0037000000011176\n",
      "step:    3879, loss: 0.1672445982694626, accuracy-micro: 0.7625552415847778, accuracy-macro: 0.0037000000011176\n",
      "step:    3880, loss: 0.1672470271587372, accuracy-micro: 0.7625445127487183, accuracy-macro: 0.0037000000011176\n",
      "step:    3881, loss: 0.1672497540712357, accuracy-micro: 0.7624830007553101, accuracy-macro: 0.0037000000011176\n",
      "step:    3882, loss: 0.1672496497631073, accuracy-micro: 0.7625322341918945, accuracy-macro: 0.0037000000011176\n",
      "step:    3883, loss: 0.1672491580247879, accuracy-micro: 0.7624902725219727, accuracy-macro: 0.0037000000011176\n",
      "step:    3884, loss: 0.1672462075948715, accuracy-micro: 0.7625457644462585, accuracy-macro: 0.0037000000011176\n",
      "step:    3885, loss: 0.1672404706478119, accuracy-micro: 0.7625460028648376, accuracy-macro: 0.0037000000011176\n",
      "step:    3886, loss: 0.1672355234622955, accuracy-micro: 0.7625827193260193, accuracy-macro: 0.0037000000011176\n",
      "step:    3887, loss: 0.1672327220439911, accuracy-micro: 0.7625859975814819, accuracy-macro: 0.0037000000011176\n",
      "step:    3888, loss: 0.1672343164682388, accuracy-micro: 0.7625855207443237, accuracy-macro: 0.0037000000011176\n",
      "step:    3889, loss: 0.1672366261482239, accuracy-micro: 0.7625700235366821, accuracy-macro: 0.0037000000011176\n",
      "step:    3890, loss: 0.1672387570142746, accuracy-micro: 0.7625147700309753, accuracy-macro: 0.0037000000011176\n",
      "step:    3891, loss: 0.1672412157058716, accuracy-micro: 0.7625554800033569, accuracy-macro: 0.0037000000011176\n",
      "step:    3892, loss: 0.1672403812408447, accuracy-micro: 0.7624957561492920, accuracy-macro: 0.0037000000011176\n",
      "step:    3893, loss: 0.1672388166189194, accuracy-micro: 0.7625642418861389, accuracy-macro: 0.0037000000011176\n",
      "step:    3894, loss: 0.1672340035438538, accuracy-micro: 0.7625430226325989, accuracy-macro: 0.0037000000011176\n",
      "step:    3895, loss: 0.1672301143407822, accuracy-micro: 0.7625790238380432, accuracy-macro: 0.0037000000011176\n",
      "step:    3896, loss: 0.1672262847423553, accuracy-micro: 0.7625817656517029, accuracy-macro: 0.0037000000011176\n",
      "step:    3897, loss: 0.1672248691320419, accuracy-micro: 0.7626190185546875, accuracy-macro: 0.0037000000011176\n",
      "step:    3898, loss: 0.1672257781028748, accuracy-micro: 0.7626209855079651, accuracy-macro: 0.0037000000011176\n",
      "step:    3899, loss: 0.1672272682189941, accuracy-micro: 0.7625682353973389, accuracy-macro: 0.0037000000011176\n",
      "step:    3900, loss: 0.1672298610210419, accuracy-micro: 0.7625700235366821, accuracy-macro: 0.0037000000011176\n",
      "step:    3901, loss: 0.1672339439392090, accuracy-micro: 0.7625252604484558, accuracy-macro: 0.0037000000011176\n",
      "step:    3902, loss: 0.1672372519969940, accuracy-micro: 0.7625587582588196, accuracy-macro: 0.0037000000011176\n",
      "step:    3903, loss: 0.1672378480434418, accuracy-micro: 0.7625117301940918, accuracy-macro: 0.0037000000011176\n",
      "step:    3904, loss: 0.1672342866659164, accuracy-micro: 0.7625507712364197, accuracy-macro: 0.0037000000011176\n",
      "step:    3905, loss: 0.1672283709049225, accuracy-micro: 0.7625407576560974, accuracy-macro: 0.0037000000011176\n",
      "step:    3906, loss: 0.1672222614288330, accuracy-micro: 0.7626060247421265, accuracy-macro: 0.0037000000011176\n",
      "step:    3907, loss: 0.1672169715166092, accuracy-micro: 0.7626109719276428, accuracy-macro: 0.0037000000011176\n",
      "step:    3908, loss: 0.1672165989875793, accuracy-micro: 0.7626224756240845, accuracy-macro: 0.0037000000011176\n",
      "step:    3909, loss: 0.1672168374061584, accuracy-micro: 0.7626150250434875, accuracy-macro: 0.0037000000011176\n",
      "step:    3910, loss: 0.1672170609235764, accuracy-micro: 0.7625690102577209, accuracy-macro: 0.0037000000011176\n",
      "step:    3911, loss: 0.1672162562608719, accuracy-micro: 0.7626227736473083, accuracy-macro: 0.0037000000011176\n",
      "step:    3912, loss: 0.1672151237726212, accuracy-micro: 0.7625857591629028, accuracy-macro: 0.0037000000011176\n",
      "step:    3913, loss: 0.1672147810459137, accuracy-micro: 0.7626320123672485, accuracy-macro: 0.0037000000011176\n",
      "step:    3914, loss: 0.1672129631042480, accuracy-micro: 0.7625972628593445, accuracy-macro: 0.0037000000011176\n",
      "step:    3915, loss: 0.1672120690345764, accuracy-micro: 0.7626385092735291, accuracy-macro: 0.0037000000011176\n",
      "step:    3916, loss: 0.1672108471393585, accuracy-micro: 0.7626027464866638, accuracy-macro: 0.0037000000011176\n",
      "step:    3917, loss: 0.1672095954418182, accuracy-micro: 0.7626372575759888, accuracy-macro: 0.0037000000011176\n",
      "step:    3918, loss: 0.1672080308198929, accuracy-micro: 0.7626219987869263, accuracy-macro: 0.0037000000011176\n",
      "step:    3919, loss: 0.1672065556049347, accuracy-micro: 0.7626202702522278, accuracy-macro: 0.0037000000011176\n",
      "step:    3920, loss: 0.1672066301107407, accuracy-micro: 0.7626299858093262, accuracy-macro: 0.0037000000011176\n",
      "step:    3921, loss: 0.1672058701515198, accuracy-micro: 0.7626217603683472, accuracy-macro: 0.0037000000011176\n",
      "step:    3922, loss: 0.1672064065933228, accuracy-micro: 0.7626534700393677, accuracy-macro: 0.0037000000011176\n",
      "step:    3923, loss: 0.1672071069478989, accuracy-micro: 0.7626180052757263, accuracy-macro: 0.0037000000011176\n",
      "step:    3924, loss: 0.1672076284885406, accuracy-micro: 0.7626372575759888, accuracy-macro: 0.0037000000011176\n",
      "step:    3925, loss: 0.1672084182500839, accuracy-micro: 0.7625820040702820, accuracy-macro: 0.0037000000011176\n",
      "step:    3926, loss: 0.1672086864709854, accuracy-micro: 0.7626202702522278, accuracy-macro: 0.0037000000011176\n",
      "step:    3927, loss: 0.1672074049711227, accuracy-micro: 0.7625702619552612, accuracy-macro: 0.0037000000011176\n",
      "step:    3928, loss: 0.1672053784132004, accuracy-micro: 0.7626129984855652, accuracy-macro: 0.0037000000011176\n",
      "step:    3929, loss: 0.1672025322914124, accuracy-micro: 0.7626069784164429, accuracy-macro: 0.0037000000011176\n",
      "step:    3930, loss: 0.1672001928091049, accuracy-micro: 0.7626277208328247, accuracy-macro: 0.0037000000011176\n",
      "step:    3931, loss: 0.1671983450651169, accuracy-micro: 0.7626150250434875, accuracy-macro: 0.0037000000011176\n",
      "step:    3932, loss: 0.1671968549489975, accuracy-micro: 0.7626454830169678, accuracy-macro: 0.0037000000011176\n",
      "step:    3933, loss: 0.1671953350305557, accuracy-micro: 0.7626320123672485, accuracy-macro: 0.0037000000011176\n",
      "step:    3934, loss: 0.1671948134899139, accuracy-micro: 0.7626469731330872, accuracy-macro: 0.0037000000011176\n",
      "step:    3935, loss: 0.1671945005655289, accuracy-micro: 0.7626469731330872, accuracy-macro: 0.0037000000011176\n",
      "step:    3936, loss: 0.1671937555074692, accuracy-micro: 0.7626302242279053, accuracy-macro: 0.0037000000011176\n",
      "step:    3937, loss: 0.1671926081180573, accuracy-micro: 0.7626712322235107, accuracy-macro: 0.0037000000011176\n",
      "step:    3938, loss: 0.1671916395425797, accuracy-micro: 0.7626284956932068, accuracy-macro: 0.0037000000011176\n",
      "step:    3939, loss: 0.1671908050775528, accuracy-micro: 0.7626579999923706, accuracy-macro: 0.0037000000011176\n",
      "step:    3940, loss: 0.1671898365020752, accuracy-micro: 0.7626317739486694, accuracy-macro: 0.0037000000011176\n",
      "step:    3941, loss: 0.1671886295080185, accuracy-micro: 0.7626485228538513, accuracy-macro: 0.0037000000011176\n",
      "step:    3942, loss: 0.1671875864267349, accuracy-micro: 0.7626695036888123, accuracy-macro: 0.0037000000011176\n",
      "step:    3943, loss: 0.1671873629093170, accuracy-micro: 0.7626432776451111, accuracy-macro: 0.0037000000011176\n",
      "step:    3944, loss: 0.1671866923570633, accuracy-micro: 0.7626517415046692, accuracy-macro: 0.0037000000011176\n",
      "step:    3945, loss: 0.1671857833862305, accuracy-micro: 0.7626454830169678, accuracy-macro: 0.0037000000011176\n",
      "step:    3946, loss: 0.1671859472990036, accuracy-micro: 0.7626747488975525, accuracy-macro: 0.0037000000011176\n",
      "step:    3947, loss: 0.1671856939792633, accuracy-micro: 0.7626489996910095, accuracy-macro: 0.0037000000011176\n",
      "step:    3948, loss: 0.1671867519617081, accuracy-micro: 0.7626584768295288, accuracy-macro: 0.0037000000011176\n",
      "step:    3949, loss: 0.1671878099441528, accuracy-micro: 0.7626217603683472, accuracy-macro: 0.0037000000011176\n",
      "step:    3950, loss: 0.1671893000602722, accuracy-micro: 0.7626670002937317, accuracy-macro: 0.0037000000011176\n",
      "step:    3951, loss: 0.1671906411647797, accuracy-micro: 0.7625929713249207, accuracy-macro: 0.0037000000011176\n",
      "step:    3952, loss: 0.1671919971704483, accuracy-micro: 0.7626347541809082, accuracy-macro: 0.0037000000011176\n",
      "step:    3953, loss: 0.1671912074089050, accuracy-micro: 0.7625870108604431, accuracy-macro: 0.0037000000011176\n",
      "step:    3954, loss: 0.1671870946884155, accuracy-micro: 0.7626447677612305, accuracy-macro: 0.0037000000011176\n",
      "step:    3955, loss: 0.1671832203865051, accuracy-micro: 0.7626307606697083, accuracy-macro: 0.0037000000011176\n",
      "step:    3956, loss: 0.1671797186136246, accuracy-micro: 0.7626755237579346, accuracy-macro: 0.0037000000011176\n",
      "step:    3957, loss: 0.1671758741140366, accuracy-micro: 0.7626720070838928, accuracy-macro: 0.0037000000011176\n",
      "step:    3958, loss: 0.1671749949455261, accuracy-micro: 0.7626829743385315, accuracy-macro: 0.0037000000011176\n",
      "step:    3959, loss: 0.1671743690967560, accuracy-micro: 0.7626997232437134, accuracy-macro: 0.0037000000011176\n",
      "step:    3960, loss: 0.1671757847070694, accuracy-micro: 0.7626714706420898, accuracy-macro: 0.0037000000011176\n",
      "step:    3961, loss: 0.1671774387359619, accuracy-micro: 0.7626745104789734, accuracy-macro: 0.0037000000011176\n",
      "step:    3962, loss: 0.1671791225671768, accuracy-micro: 0.7626302242279053, accuracy-macro: 0.0037000000011176\n",
      "step:    3963, loss: 0.1671796292066574, accuracy-micro: 0.7626462578773499, accuracy-macro: 0.0037000000011176\n",
      "step:    3964, loss: 0.1671800017356873, accuracy-micro: 0.7626029849052429, accuracy-macro: 0.0037000000011176\n",
      "step:    3965, loss: 0.1671798676252365, accuracy-micro: 0.7626422643661499, accuracy-macro: 0.0037000000011176\n",
      "step:    3966, loss: 0.1671785712242126, accuracy-micro: 0.7626222372055054, accuracy-macro: 0.0037000000011176\n",
      "step:    3967, loss: 0.1671754717826843, accuracy-micro: 0.7626732587814331, accuracy-macro: 0.0037000000011176\n",
      "step:    3968, loss: 0.1671717613935471, accuracy-micro: 0.7626632452011108, accuracy-macro: 0.0037000000011176\n",
      "step:    3969, loss: 0.1671690791845322, accuracy-micro: 0.7626885175704956, accuracy-macro: 0.0037000000011176\n",
      "step:    3970, loss: 0.1671666055917740, accuracy-micro: 0.7626770138740540, accuracy-macro: 0.0037000000011176\n",
      "step:    3971, loss: 0.1671648770570755, accuracy-micro: 0.7627124786376953, accuracy-macro: 0.0037000000011176\n",
      "step:    3972, loss: 0.1671633273363113, accuracy-micro: 0.7626792192459106, accuracy-macro: 0.0037000000011176\n",
      "step:    3973, loss: 0.1671627163887024, accuracy-micro: 0.7626705169677734, accuracy-macro: 0.0037000000011176\n",
      "step:    3974, loss: 0.1671624928712845, accuracy-micro: 0.7627037763595581, accuracy-macro: 0.0037000000011176\n",
      "step:    3975, loss: 0.1671623438596725, accuracy-micro: 0.7626910209655762, accuracy-macro: 0.0037000000011176\n",
      "step:    3976, loss: 0.1671613603830338, accuracy-micro: 0.7627157568931580, accuracy-macro: 0.0037000000011176\n",
      "step:    3977, loss: 0.1671619117259979, accuracy-micro: 0.7626682519912720, accuracy-macro: 0.0037000000011176\n",
      "step:    3978, loss: 0.1671637147665024, accuracy-micro: 0.7626917362213135, accuracy-macro: 0.0037000000011176\n",
      "step:    3979, loss: 0.1671653091907501, accuracy-micro: 0.7626600265502930, accuracy-macro: 0.0037000000011176\n",
      "step:    3980, loss: 0.1671671122312546, accuracy-micro: 0.7626557350158691, accuracy-macro: 0.0037000000011176\n",
      "step:    3981, loss: 0.1671659052371979, accuracy-micro: 0.7626437544822693, accuracy-macro: 0.0037000000011176\n",
      "step:    3982, loss: 0.1671636849641800, accuracy-micro: 0.7626397609710693, accuracy-macro: 0.0037000000011176\n",
      "step:    3983, loss: 0.1671606004238129, accuracy-micro: 0.7626562714576721, accuracy-macro: 0.0037000000011176\n",
      "step:    3984, loss: 0.1671578139066696, accuracy-micro: 0.7626984715461731, accuracy-macro: 0.0037000000011176\n",
      "step:    3985, loss: 0.1671557873487473, accuracy-micro: 0.7626777291297913, accuracy-macro: 0.0037000000011176\n",
      "step:    3986, loss: 0.1671548634767532, accuracy-micro: 0.7626847624778748, accuracy-macro: 0.0037000000011176\n",
      "step:    3987, loss: 0.1671529114246368, accuracy-micro: 0.7626889944076538, accuracy-macro: 0.0037000000011176\n",
      "step:    3988, loss: 0.1671512722969055, accuracy-micro: 0.7627245187759399, accuracy-macro: 0.0037000000011176\n",
      "step:    3989, loss: 0.1671501994132996, accuracy-micro: 0.7626972198486328, accuracy-macro: 0.0037000000011176\n",
      "step:    3990, loss: 0.1671494394540787, accuracy-micro: 0.7627087235450745, accuracy-macro: 0.0037000000011176\n",
      "step:    3991, loss: 0.1671487987041473, accuracy-micro: 0.7627082467079163, accuracy-macro: 0.0037000000011176\n",
      "step:    3992, loss: 0.1671481430530548, accuracy-micro: 0.7626957297325134, accuracy-macro: 0.0037000000011176\n",
      "step:    3993, loss: 0.1671476364135742, accuracy-micro: 0.7627184987068176, accuracy-macro: 0.0037000000011176\n",
      "step:    3994, loss: 0.1671475619077682, accuracy-micro: 0.7626797556877136, accuracy-macro: 0.0037000000011176\n",
      "step:    3995, loss: 0.1671474575996399, accuracy-micro: 0.7626992464065552, accuracy-macro: 0.0037000000011176\n",
      "step:    3996, loss: 0.1671469062566757, accuracy-micro: 0.7627017498016357, accuracy-macro: 0.0037000000011176\n",
      "step:    3997, loss: 0.1671471148729324, accuracy-micro: 0.7627037763595581, accuracy-macro: 0.0037000000011176\n",
      "step:    3998, loss: 0.1671477109193802, accuracy-micro: 0.7626929879188538, accuracy-macro: 0.0037000000011176\n",
      "step:    3999, loss: 0.1671503931283951, accuracy-micro: 0.7626900076866150, accuracy-macro: 0.0037000000011176\n",
      "step:    4000, loss: 0.1671538501977921, accuracy-micro: 0.7626695036888123, accuracy-macro: 0.0037000000011176\n",
      "step:    4001, loss: 0.1671571582555771, accuracy-micro: 0.7626565098762512, accuracy-macro: 0.0037000000011176\n",
      "step:    4002, loss: 0.1671601980924606, accuracy-micro: 0.7626435160636902, accuracy-macro: 0.0037000000011176\n",
      "step:    4003, loss: 0.1671598106622696, accuracy-micro: 0.7626515030860901, accuracy-macro: 0.0037000000011176\n",
      "step:    4004, loss: 0.1671566218137741, accuracy-micro: 0.7626672387123108, accuracy-macro: 0.0037000000011176\n",
      "step:    4005, loss: 0.1671518683433533, accuracy-micro: 0.7626682519912720, accuracy-macro: 0.0037000000011176\n",
      "step:    4006, loss: 0.1671471595764160, accuracy-micro: 0.7627090215682983, accuracy-macro: 0.0037000000011176\n",
      "step:    4007, loss: 0.1671420633792877, accuracy-micro: 0.7626885175704956, accuracy-macro: 0.0037000000011176\n",
      "step:    4008, loss: 0.1671385020017624, accuracy-micro: 0.7627285122871399, accuracy-macro: 0.0037000000011176\n",
      "step:    4009, loss: 0.1671354025602341, accuracy-micro: 0.7627524733543396, accuracy-macro: 0.0037000000011176\n",
      "step:    4010, loss: 0.1671329736709595, accuracy-micro: 0.7627242207527161, accuracy-macro: 0.0037000000011176\n",
      "step:    4011, loss: 0.1671328693628311, accuracy-micro: 0.7627347707748413, accuracy-macro: 0.0037000000011176\n",
      "step:    4012, loss: 0.1671327203512192, accuracy-micro: 0.7627254724502563, accuracy-macro: 0.0037000000011176\n",
      "step:    4013, loss: 0.1671336889266968, accuracy-micro: 0.7627137303352356, accuracy-macro: 0.0037000000011176\n",
      "step:    4014, loss: 0.1671340614557266, accuracy-micro: 0.7626867294311523, accuracy-macro: 0.0037000000011176\n",
      "step:    4015, loss: 0.1671337336301804, accuracy-micro: 0.7627247571945190, accuracy-macro: 0.0037000000011176\n",
      "step:    4016, loss: 0.1671332567930222, accuracy-micro: 0.7626994848251343, accuracy-macro: 0.0037000000011176\n",
      "step:    4017, loss: 0.1671350598335266, accuracy-micro: 0.7627274990081787, accuracy-macro: 0.0037000000011176\n",
      "step:    4018, loss: 0.1671371906995773, accuracy-micro: 0.7627065181732178, accuracy-macro: 0.0037000000011176\n",
      "step:    4019, loss: 0.1671396195888519, accuracy-micro: 0.7627034783363342, accuracy-macro: 0.0037000000011176\n",
      "step:    4020, loss: 0.1671417802572250, accuracy-micro: 0.7626777291297913, accuracy-macro: 0.0037000000011176\n",
      "step:    4021, loss: 0.1671423465013504, accuracy-micro: 0.7626774907112122, accuracy-macro: 0.0037000000011176\n",
      "step:    4022, loss: 0.1671424806118011, accuracy-micro: 0.7626820206642151, accuracy-macro: 0.0037000000011176\n",
      "step:    4023, loss: 0.1671411693096161, accuracy-micro: 0.7626860141754150, accuracy-macro: 0.0037000000011176\n",
      "step:    4024, loss: 0.1671388894319534, accuracy-micro: 0.7626912593841553, accuracy-macro: 0.0037000000011176\n",
      "step:    4025, loss: 0.1671353280544281, accuracy-micro: 0.7627102732658386, accuracy-macro: 0.0037000000011176\n",
      "step:    4026, loss: 0.1671312451362610, accuracy-micro: 0.7626979947090149, accuracy-macro: 0.0037000000011176\n",
      "step:    4027, loss: 0.1671262979507446, accuracy-micro: 0.7627295255661011, accuracy-macro: 0.0037000000011176\n",
      "step:    4028, loss: 0.1671230047941208, accuracy-micro: 0.7627335190773010, accuracy-macro: 0.0037000000011176\n",
      "step:    4029, loss: 0.1671202629804611, accuracy-micro: 0.7627437710762024, accuracy-macro: 0.0037000000011176\n",
      "step:    4030, loss: 0.1671180427074432, accuracy-micro: 0.7627382278442383, accuracy-macro: 0.0037000000011176\n",
      "step:    4031, loss: 0.1671166121959686, accuracy-micro: 0.7627584934234619, accuracy-macro: 0.0037000000011176\n",
      "step:    4032, loss: 0.1671152859926224, accuracy-micro: 0.7627377510070801, accuracy-macro: 0.0037000000011176\n",
      "step:    4033, loss: 0.1671147942543030, accuracy-micro: 0.7627492547035217, accuracy-macro: 0.0037000000011176\n",
      "step:    4034, loss: 0.1671144068241119, accuracy-micro: 0.7627547383308411, accuracy-macro: 0.0037000000011176\n",
      "step:    4035, loss: 0.1671132296323776, accuracy-micro: 0.7627492547035217, accuracy-macro: 0.0037000000011176\n",
      "step:    4036, loss: 0.1671126484870911, accuracy-micro: 0.7627639770507812, accuracy-macro: 0.0037000000011176\n",
      "step:    4037, loss: 0.1671124994754791, accuracy-micro: 0.7627487778663635, accuracy-macro: 0.0037000000011176\n",
      "step:    4038, loss: 0.1671117842197418, accuracy-micro: 0.7627737522125244, accuracy-macro: 0.0037000000011176\n",
      "step:    4039, loss: 0.1671121567487717, accuracy-micro: 0.7627262473106384, accuracy-macro: 0.0037000000011176\n",
      "step:    4040, loss: 0.1671123057603836, accuracy-micro: 0.7627472281455994, accuracy-macro: 0.0037000000011176\n",
      "step:    4041, loss: 0.1671118885278702, accuracy-micro: 0.7627409696578979, accuracy-macro: 0.0037000000011176\n",
      "step:    4042, loss: 0.1671109050512314, accuracy-micro: 0.7627630233764648, accuracy-macro: 0.0037000000011176\n",
      "step:    4043, loss: 0.1671093702316284, accuracy-micro: 0.7627522349357605, accuracy-macro: 0.0037000000011176\n",
      "step:    4044, loss: 0.1671080887317657, accuracy-micro: 0.7627704739570618, accuracy-macro: 0.0037000000011176\n",
      "step:    4045, loss: 0.1671064794063568, accuracy-micro: 0.7627614736557007, accuracy-macro: 0.0037000000011176\n",
      "step:    4046, loss: 0.1671047061681747, accuracy-micro: 0.7627875208854675, accuracy-macro: 0.0037000000011176\n",
      "step:    4047, loss: 0.1671034842729568, accuracy-micro: 0.7627402544021606, accuracy-macro: 0.0037000000011176\n",
      "step:    4048, loss: 0.1671027094125748, accuracy-micro: 0.7627465128898621, accuracy-macro: 0.0037000000011176\n",
      "step:    4049, loss: 0.1671022772789001, accuracy-micro: 0.7627810239791870, accuracy-macro: 0.0037000000011176\n",
      "step:    4050, loss: 0.1671015471220016, accuracy-micro: 0.7627517580986023, accuracy-macro: 0.0037000000011176\n",
      "step:    4051, loss: 0.1671022772789001, accuracy-micro: 0.7627909779548645, accuracy-macro: 0.0037000000011176\n",
      "step:    4052, loss: 0.1671028435230255, accuracy-micro: 0.7627760171890259, accuracy-macro: 0.0037000000011176\n",
      "step:    4053, loss: 0.1671040505170822, accuracy-micro: 0.7627639770507812, accuracy-macro: 0.0037000000011176\n",
      "step:    4054, loss: 0.1671053916215897, accuracy-micro: 0.7627674937248230, accuracy-macro: 0.0037000000011176\n",
      "step:    4055, loss: 0.1671053469181061, accuracy-micro: 0.7627279758453369, accuracy-macro: 0.0037000000011176\n",
      "step:    4056, loss: 0.1671040207147598, accuracy-micro: 0.7627639770507812, accuracy-macro: 0.0037000000011176\n",
      "step:    4057, loss: 0.1671020239591599, accuracy-micro: 0.7627270221710205, accuracy-macro: 0.0037000000011176\n",
      "step:    4058, loss: 0.1671011149883270, accuracy-micro: 0.7627682685852051, accuracy-macro: 0.0037000000011176\n",
      "step:    4059, loss: 0.1670989394187927, accuracy-micro: 0.7627595067024231, accuracy-macro: 0.0037000000011176\n",
      "step:    4060, loss: 0.1670973449945450, accuracy-micro: 0.7627865076065063, accuracy-macro: 0.0037000000011176\n",
      "step:    4061, loss: 0.1670950502157211, accuracy-micro: 0.7628022432327271, accuracy-macro: 0.0037000000011176\n",
      "step:    4062, loss: 0.1670920997858047, accuracy-micro: 0.7627714872360229, accuracy-macro: 0.0037000000011176\n",
      "step:    4063, loss: 0.1670912504196167, accuracy-micro: 0.7627927660942078, accuracy-macro: 0.0037000000011176\n",
      "step:    4064, loss: 0.1670909970998764, accuracy-micro: 0.7628002762794495, accuracy-macro: 0.0037000000011176\n",
      "step:    4065, loss: 0.1670925021171570, accuracy-micro: 0.7627875208854675, accuracy-macro: 0.0037000000011176\n",
      "step:    4066, loss: 0.1670945286750793, accuracy-micro: 0.7627699971199036, accuracy-macro: 0.0037000000011176\n",
      "step:    4067, loss: 0.1670962721109390, accuracy-micro: 0.7627737522125244, accuracy-macro: 0.0037000000011176\n",
      "step:    4068, loss: 0.1670978963375092, accuracy-micro: 0.7627447247505188, accuracy-macro: 0.0037000000011176\n",
      "step:    4069, loss: 0.1671006381511688, accuracy-micro: 0.7627617716789246, accuracy-macro: 0.0037000000011176\n",
      "step:    4070, loss: 0.1671037822961807, accuracy-micro: 0.7627367377281189, accuracy-macro: 0.0037000000011176\n",
      "step:    4071, loss: 0.1671044081449509, accuracy-micro: 0.7627782225608826, accuracy-macro: 0.0037000000011176\n",
      "step:    4072, loss: 0.1671047955751419, accuracy-micro: 0.7627162337303162, accuracy-macro: 0.0037000000011176\n",
      "step:    4073, loss: 0.1671052128076553, accuracy-micro: 0.7627772688865662, accuracy-macro: 0.0037000000011176\n",
      "step:    4074, loss: 0.1671043485403061, accuracy-micro: 0.7627339959144592, accuracy-macro: 0.0037000000011176\n",
      "step:    4075, loss: 0.1671018153429031, accuracy-micro: 0.7627787590026855, accuracy-macro: 0.0037000000011176\n",
      "step:    4076, loss: 0.1670993268489838, accuracy-micro: 0.7627462744712830, accuracy-macro: 0.0037000000011176\n",
      "step:    4077, loss: 0.1670967042446136, accuracy-micro: 0.7627589702606201, accuracy-macro: 0.0037000000011176\n",
      "step:    4078, loss: 0.1670928895473480, accuracy-micro: 0.7627622485160828, accuracy-macro: 0.0037000000011176\n",
      "step:    4079, loss: 0.1670895665884018, accuracy-micro: 0.7627922296524048, accuracy-macro: 0.0037000000011176\n",
      "step:    4080, loss: 0.1670854687690735, accuracy-micro: 0.7627667188644409, accuracy-macro: 0.0037000000011176\n",
      "step:    4081, loss: 0.1670832633972168, accuracy-micro: 0.7628042697906494, accuracy-macro: 0.0037000000011176\n",
      "step:    4082, loss: 0.1670811921358109, accuracy-micro: 0.7627664804458618, accuracy-macro: 0.0037000000011176\n",
      "step:    4083, loss: 0.1670790761709213, accuracy-micro: 0.7628087401390076, accuracy-macro: 0.0037000000011176\n",
      "step:    4084, loss: 0.1670766621828079, accuracy-micro: 0.7627982497215271, accuracy-macro: 0.0037000000011176\n",
      "step:    4085, loss: 0.1670746207237244, accuracy-micro: 0.7628170251846313, accuracy-macro: 0.0037000000011176\n",
      "step:    4086, loss: 0.1670736521482468, accuracy-micro: 0.7628164887428284, accuracy-macro: 0.0037000000011176\n",
      "step:    4087, loss: 0.1670723408460617, accuracy-micro: 0.7628145217895508, accuracy-macro: 0.0037000000011176\n",
      "step:    4088, loss: 0.1670717746019363, accuracy-micro: 0.7628045082092285, accuracy-macro: 0.0037000000011176\n",
      "step:    4089, loss: 0.1670708805322647, accuracy-micro: 0.7627967596054077, accuracy-macro: 0.0037000000011176\n",
      "step:    4090, loss: 0.1670713722705841, accuracy-micro: 0.7628229856491089, accuracy-macro: 0.0037000000011176\n",
      "step:    4091, loss: 0.1670729070901871, accuracy-micro: 0.7628039717674255, accuracy-macro: 0.0037000000011176\n",
      "step:    4092, loss: 0.1670756936073303, accuracy-micro: 0.7627900242805481, accuracy-macro: 0.0037000000011176\n",
      "step:    4093, loss: 0.1670796275138855, accuracy-micro: 0.7627402544021606, accuracy-macro: 0.0037000000011176\n",
      "step:    4094, loss: 0.1670866608619690, accuracy-micro: 0.7627997398376465, accuracy-macro: 0.0037000000011176\n",
      "step:    4095, loss: 0.1670960634946823, accuracy-micro: 0.7627432346343994, accuracy-macro: 0.0037000000011176\n",
      "step:    4096, loss: 0.1671055108308792, accuracy-micro: 0.7627682685852051, accuracy-macro: 0.0037000000011176\n",
      "step:    4097, loss: 0.1671104878187180, accuracy-micro: 0.7627022266387939, accuracy-macro: 0.0037000000011176\n",
      "step:    4098, loss: 0.1671133488416672, accuracy-micro: 0.7627542614936829, accuracy-macro: 0.0037000000011176\n",
      "step:    4099, loss: 0.1671089679002762, accuracy-micro: 0.7626994848251343, accuracy-macro: 0.0037000000011176\n",
      "step:    4100, loss: 0.1670995801687241, accuracy-micro: 0.7627642750740051, accuracy-macro: 0.0037000000011176\n",
      "step:    4101, loss: 0.1670852601528168, accuracy-micro: 0.7627229690551758, accuracy-macro: 0.0037000000011176\n",
      "step:    4102, loss: 0.1670720279216766, accuracy-micro: 0.7628014683723450, accuracy-macro: 0.0037000000011176\n",
      "step:    4103, loss: 0.1670634001493454, accuracy-micro: 0.7628387212753296, accuracy-macro: 0.0037000000011176\n",
      "step:    4104, loss: 0.1670590341091156, accuracy-micro: 0.7628252506256104, accuracy-macro: 0.0037000000011176\n",
      "step:    4105, loss: 0.1670633107423782, accuracy-micro: 0.7628302574157715, accuracy-macro: 0.0037000000011176\n",
      "step:    4106, loss: 0.1670732945203781, accuracy-micro: 0.7627622485160828, accuracy-macro: 0.0037000000011176\n",
      "step:    4107, loss: 0.1670849621295929, accuracy-micro: 0.7627990245819092, accuracy-macro: 0.0037000000011176\n",
      "step:    4108, loss: 0.1670912504196167, accuracy-micro: 0.7627605199813843, accuracy-macro: 0.0037000000011176\n",
      "step:    4109, loss: 0.1670888960361481, accuracy-micro: 0.7627952694892883, accuracy-macro: 0.0037000000011176\n",
      "step:    4110, loss: 0.1670779436826706, accuracy-micro: 0.7627499699592590, accuracy-macro: 0.0037000000011176\n",
      "step:    4111, loss: 0.1670657545328140, accuracy-micro: 0.7628152370452881, accuracy-macro: 0.0037000000011176\n",
      "step:    4112, loss: 0.1670555621385574, accuracy-micro: 0.7628387212753296, accuracy-macro: 0.0037000000011176\n",
      "step:    4113, loss: 0.1670530587434769, accuracy-micro: 0.7628560066223145, accuracy-macro: 0.0037000000011176\n",
      "step:    4114, loss: 0.1670542657375336, accuracy-micro: 0.7628185153007507, accuracy-macro: 0.0037000000011176\n",
      "step:    4115, loss: 0.1670596897602081, accuracy-micro: 0.7627872228622437, accuracy-macro: 0.0037000000011176\n",
      "step:    4116, loss: 0.1670652031898499, accuracy-micro: 0.7628045082092285, accuracy-macro: 0.0037000000011176\n",
      "step:    4117, loss: 0.1670691817998886, accuracy-micro: 0.7627647519111633, accuracy-macro: 0.0037000000011176\n",
      "step:    4118, loss: 0.1670713126659393, accuracy-micro: 0.7628014683723450, accuracy-macro: 0.0037000000011176\n",
      "step:    4119, loss: 0.1670706570148468, accuracy-micro: 0.7627444863319397, accuracy-macro: 0.0037000000011176\n",
      "step:    4120, loss: 0.1670669317245483, accuracy-micro: 0.7628022432327271, accuracy-macro: 0.0037000000011176\n",
      "step:    4121, loss: 0.1670591533184052, accuracy-micro: 0.7627865076065063, accuracy-macro: 0.0037000000011176\n",
      "step:    4122, loss: 0.1670495271682739, accuracy-micro: 0.7628427743911743, accuracy-macro: 0.0037000000011176\n",
      "step:    4123, loss: 0.1670442819595337, accuracy-micro: 0.7628317475318909, accuracy-macro: 0.0037000000011176\n",
      "step:    4124, loss: 0.1670443713665009, accuracy-micro: 0.7628572583198547, accuracy-macro: 0.0037000000011176\n",
      "step:    4125, loss: 0.1670463681221008, accuracy-micro: 0.7628394961357117, accuracy-macro: 0.0037000000011176\n",
      "step:    4126, loss: 0.1670504957437515, accuracy-micro: 0.7628154754638672, accuracy-macro: 0.0037000000011176\n",
      "step:    4127, loss: 0.1670536994934082, accuracy-micro: 0.7628177404403687, accuracy-macro: 0.0037000000011176\n",
      "step:    4128, loss: 0.1670559346675873, accuracy-micro: 0.7627779841423035, accuracy-macro: 0.0037000000011176\n",
      "step:    4129, loss: 0.1670576632022858, accuracy-micro: 0.7628145217895508, accuracy-macro: 0.0037000000011176\n",
      "step:    4130, loss: 0.1670555919408798, accuracy-micro: 0.7627762556076050, accuracy-macro: 0.0037000000011176\n",
      "step:    4131, loss: 0.1670495867729187, accuracy-micro: 0.7628312706947327, accuracy-macro: 0.0037000000011176\n",
      "step:    4132, loss: 0.1670426428318024, accuracy-micro: 0.7628325223922729, accuracy-macro: 0.0037000000011176\n",
      "step:    4133, loss: 0.1670371443033218, accuracy-micro: 0.7628522515296936, accuracy-macro: 0.0037000000011176\n",
      "step:    4134, loss: 0.1670367270708084, accuracy-micro: 0.7628782391548157, accuracy-macro: 0.0037000000011176\n",
      "step:    4135, loss: 0.1670392155647278, accuracy-micro: 0.7628672719001770, accuracy-macro: 0.0037000000011176\n",
      "step:    4136, loss: 0.1670418083667755, accuracy-micro: 0.7628374695777893, accuracy-macro: 0.0037000000011176\n",
      "step:    4137, loss: 0.1670428663492203, accuracy-micro: 0.7628210186958313, accuracy-macro: 0.0037000000011176\n",
      "step:    4138, loss: 0.1670430153608322, accuracy-micro: 0.7628162503242493, accuracy-macro: 0.0037000000011176\n",
      "step:    4139, loss: 0.1670398414134979, accuracy-micro: 0.7628532648086548, accuracy-macro: 0.0037000000011176\n",
      "step:    4140, loss: 0.1670351773500443, accuracy-micro: 0.7628737688064575, accuracy-macro: 0.0037000000011176\n",
      "step:    4141, loss: 0.1670302003622055, accuracy-micro: 0.7628754973411560, accuracy-macro: 0.0037000000011176\n",
      "step:    4142, loss: 0.1670302003622055, accuracy-micro: 0.7628802657127380, accuracy-macro: 0.0037000000011176\n",
      "step:    4143, loss: 0.1670317649841309, accuracy-micro: 0.7628792524337769, accuracy-macro: 0.0037000000011176\n",
      "step:    4144, loss: 0.1670344173908234, accuracy-micro: 0.7628767490386963, accuracy-macro: 0.0037000000011176\n",
      "step:    4145, loss: 0.1670370995998383, accuracy-micro: 0.7628347277641296, accuracy-macro: 0.0037000000011176\n",
      "step:    4146, loss: 0.1670391857624054, accuracy-micro: 0.7628287672996521, accuracy-macro: 0.0037000000011176\n",
      "step:    4147, loss: 0.1670395284891129, accuracy-micro: 0.7628329992294312, accuracy-macro: 0.0037000000011176\n",
      "step:    4148, loss: 0.1670361608266830, accuracy-micro: 0.7628312706947327, accuracy-macro: 0.0037000000011176\n",
      "step:    4149, loss: 0.1670295000076294, accuracy-micro: 0.7628440260887146, accuracy-macro: 0.0037000000011176\n",
      "step:    4150, loss: 0.1670245081186295, accuracy-micro: 0.7628880143165588, accuracy-macro: 0.0037000000011176\n",
      "step:    4151, loss: 0.1670235991477966, accuracy-micro: 0.7628937363624573, accuracy-macro: 0.0037000000011176\n",
      "step:    4152, loss: 0.1670236885547638, accuracy-micro: 0.7628985047340393, accuracy-macro: 0.0037000000011176\n",
      "step:    4153, loss: 0.1670231819152832, accuracy-micro: 0.7628857493400574, accuracy-macro: 0.0037000000011176\n",
      "step:    4154, loss: 0.1670216917991638, accuracy-micro: 0.7628970146179199, accuracy-macro: 0.0037000000011176\n",
      "step:    4155, loss: 0.1670207530260086, accuracy-micro: 0.7628967761993408, accuracy-macro: 0.0037000000011176\n",
      "step:    4156, loss: 0.1670192480087280, accuracy-micro: 0.7628855109214783, accuracy-macro: 0.0037000000011176\n",
      "step:    4157, loss: 0.1670192629098892, accuracy-micro: 0.7628822326660156, accuracy-macro: 0.0037000000011176\n",
      "step:    4158, loss: 0.1670192480087280, accuracy-micro: 0.7628802657127380, accuracy-macro: 0.0037000000011176\n",
      "step:    4159, loss: 0.1670182198286057, accuracy-micro: 0.7628852725028992, accuracy-macro: 0.0037000000011176\n",
      "step:    4160, loss: 0.1670178174972534, accuracy-micro: 0.7628922462463379, accuracy-macro: 0.0037000000011176\n",
      "step:    4161, loss: 0.1670172214508057, accuracy-micro: 0.7629067301750183, accuracy-macro: 0.0037000000011176\n",
      "step:    4162, loss: 0.1670169681310654, accuracy-micro: 0.7628842592239380, accuracy-macro: 0.0037000000011176\n",
      "step:    4163, loss: 0.1670156568288803, accuracy-micro: 0.7628922462463379, accuracy-macro: 0.0037000000011176\n",
      "step:    4164, loss: 0.1670147776603699, accuracy-micro: 0.7628880143165588, accuracy-macro: 0.0037000000011176\n",
      "step:    4165, loss: 0.1670134663581848, accuracy-micro: 0.7628849744796753, accuracy-macro: 0.0037000000011176\n",
      "step:    4166, loss: 0.1670121848583221, accuracy-micro: 0.7629172205924988, accuracy-macro: 0.0037000000011176\n",
      "step:    4167, loss: 0.1670113801956177, accuracy-micro: 0.7628987431526184, accuracy-macro: 0.0037000000011176\n",
      "step:    4168, loss: 0.1670108735561371, accuracy-micro: 0.7629029750823975, accuracy-macro: 0.0037000000011176\n",
      "step:    4169, loss: 0.1670096516609192, accuracy-micro: 0.7629237771034241, accuracy-macro: 0.0037000000011176\n",
      "step:    4170, loss: 0.1670089960098267, accuracy-micro: 0.7629152536392212, accuracy-macro: 0.0037000000011176\n",
      "step:    4171, loss: 0.1670082956552505, accuracy-micro: 0.7629154920578003, accuracy-macro: 0.0037000000011176\n",
      "step:    4172, loss: 0.1670075356960297, accuracy-micro: 0.7629152536392212, accuracy-macro: 0.0037000000011176\n",
      "step:    4173, loss: 0.1670070290565491, accuracy-micro: 0.7629107236862183, accuracy-macro: 0.0037000000011176\n",
      "step:    4174, loss: 0.1670067161321640, accuracy-micro: 0.7629107236862183, accuracy-macro: 0.0037000000011176\n",
      "step:    4175, loss: 0.1670065224170685, accuracy-micro: 0.7629234790802002, accuracy-macro: 0.0037000000011176\n",
      "step:    4176, loss: 0.1670056283473969, accuracy-micro: 0.7629200220108032, accuracy-macro: 0.0037000000011176\n",
      "step:    4177, loss: 0.1670044958591461, accuracy-micro: 0.7629140019416809, accuracy-macro: 0.0037000000011176\n",
      "step:    4178, loss: 0.1670031696557999, accuracy-micro: 0.7629255056381226, accuracy-macro: 0.0037000000011176\n",
      "step:    4179, loss: 0.1670021265745163, accuracy-micro: 0.7629069685935974, accuracy-macro: 0.0037000000011176\n",
      "step:    4180, loss: 0.1670013070106506, accuracy-micro: 0.7629187703132629, accuracy-macro: 0.0037000000011176\n",
      "step:    4181, loss: 0.1670014411211014, accuracy-micro: 0.7629172205924988, accuracy-macro: 0.0037000000011176\n",
      "step:    4182, loss: 0.1669994741678238, accuracy-micro: 0.7629237771034241, accuracy-macro: 0.0037000000011176\n",
      "step:    4183, loss: 0.1669995635747910, accuracy-micro: 0.7629172205924988, accuracy-macro: 0.0037000000011176\n",
      "step:    4184, loss: 0.1669993549585342, accuracy-micro: 0.7629085183143616, accuracy-macro: 0.0037000000011176\n",
      "step:    4185, loss: 0.1669999361038208, accuracy-micro: 0.7629247307777405, accuracy-macro: 0.0037000000011176\n",
      "step:    4186, loss: 0.1669993102550507, accuracy-micro: 0.7629097700119019, accuracy-macro: 0.0037000000011176\n",
      "step:    4187, loss: 0.1670002043247223, accuracy-micro: 0.7629202604293823, accuracy-macro: 0.0037000000011176\n",
      "step:    4188, loss: 0.1670004725456238, accuracy-micro: 0.7628970146179199, accuracy-macro: 0.0037000000011176\n",
      "step:    4189, loss: 0.1669993698596954, accuracy-micro: 0.7629204988479614, accuracy-macro: 0.0037000000011176\n",
      "step:    4190, loss: 0.1669989079236984, accuracy-micro: 0.7629257440567017, accuracy-macro: 0.0037000000011176\n",
      "step:    4191, loss: 0.1669963151216507, accuracy-micro: 0.7629417777061462, accuracy-macro: 0.0037000000011176\n",
      "step:    4192, loss: 0.1669948250055313, accuracy-micro: 0.7629249691963196, accuracy-macro: 0.0037000000011176\n",
      "step:    4193, loss: 0.1669928729534149, accuracy-micro: 0.7629474997520447, accuracy-macro: 0.0037000000011176\n",
      "step:    4194, loss: 0.1669911295175552, accuracy-micro: 0.7629259824752808, accuracy-macro: 0.0037000000011176\n",
      "step:    4195, loss: 0.1669905930757523, accuracy-micro: 0.7629197239875793, accuracy-macro: 0.0037000000011176\n",
      "step:    4196, loss: 0.1669915318489075, accuracy-micro: 0.7629405260086060, accuracy-macro: 0.0037000000011176\n",
      "step:    4197, loss: 0.1669916361570358, accuracy-micro: 0.7629312276840210, accuracy-macro: 0.0037000000011176\n",
      "step:    4198, loss: 0.1669917255640030, accuracy-micro: 0.7629382610321045, accuracy-macro: 0.0037000000011176\n",
      "step:    4199, loss: 0.1669907122850418, accuracy-micro: 0.7629037499427795, accuracy-macro: 0.0037000000011176\n",
      "step:    4200, loss: 0.1669902801513672, accuracy-micro: 0.7629529833793640, accuracy-macro: 0.0037000000011176\n",
      "step:    4201, loss: 0.1669898182153702, accuracy-micro: 0.7629447579383850, accuracy-macro: 0.0037000000011176\n",
      "step:    4202, loss: 0.1669900268316269, accuracy-micro: 0.7629422545433044, accuracy-macro: 0.0037000000011176\n",
      "step:    4203, loss: 0.1669909209012985, accuracy-micro: 0.7628982663154602, accuracy-macro: 0.0037000000011176\n",
      "step:    4204, loss: 0.1669905632734299, accuracy-micro: 0.7629237771034241, accuracy-macro: 0.0037000000011176\n",
      "step:    4205, loss: 0.1669897437095642, accuracy-micro: 0.7628960013389587, accuracy-macro: 0.0037000000011176\n",
      "step:    4206, loss: 0.1669896692037582, accuracy-micro: 0.7629362344741821, accuracy-macro: 0.0037000000011176\n",
      "step:    4207, loss: 0.1669891625642776, accuracy-micro: 0.7628882527351379, accuracy-macro: 0.0037000000011176\n",
      "step:    4208, loss: 0.1669901609420776, accuracy-micro: 0.7629457712173462, accuracy-macro: 0.0037000000011176\n",
      "step:    4209, loss: 0.1669903695583344, accuracy-micro: 0.7628742456436157, accuracy-macro: 0.0037000000011176\n",
      "step:    4210, loss: 0.1669911146163940, accuracy-micro: 0.7629454731941223, accuracy-macro: 0.0037000000011176\n",
      "step:    4211, loss: 0.1669899970293045, accuracy-micro: 0.7628937363624573, accuracy-macro: 0.0037000000011176\n",
      "step:    4212, loss: 0.1669880002737045, accuracy-micro: 0.7629617452621460, accuracy-macro: 0.0037000000011176\n",
      "step:    4213, loss: 0.1669857501983643, accuracy-micro: 0.7629142403602600, accuracy-macro: 0.0037000000011176\n",
      "step:    4214, loss: 0.1669825166463852, accuracy-micro: 0.7629579901695251, accuracy-macro: 0.0037000000011176\n",
      "step:    4215, loss: 0.1669797301292419, accuracy-micro: 0.7629634737968445, accuracy-macro: 0.0037000000011176\n",
      "step:    4216, loss: 0.1669766604900360, accuracy-micro: 0.7629814743995667, accuracy-macro: 0.0037000000011176\n",
      "step:    4217, loss: 0.1669752150774002, accuracy-micro: 0.7629197239875793, accuracy-macro: 0.0037000000011176\n",
      "step:    4218, loss: 0.1669739633798599, accuracy-micro: 0.7629297375679016, accuracy-macro: 0.0037000000011176\n",
      "step:    4219, loss: 0.1669729053974152, accuracy-micro: 0.7629619836807251, accuracy-macro: 0.0037000000011176\n",
      "step:    4220, loss: 0.1669740676879883, accuracy-micro: 0.7629535198211670, accuracy-macro: 0.0037000000011176\n",
      "step:    4221, loss: 0.1669741421937943, accuracy-micro: 0.7629817724227905, accuracy-macro: 0.0037000000011176\n",
      "step:    4222, loss: 0.1669734865427017, accuracy-micro: 0.7629410028457642, accuracy-macro: 0.0037000000011176\n",
      "step:    4223, loss: 0.1669727265834808, accuracy-micro: 0.7629757523536682, accuracy-macro: 0.0037000000011176\n",
      "step:    4224, loss: 0.1669713407754898, accuracy-micro: 0.7629542350769043, accuracy-macro: 0.0037000000011176\n",
      "step:    4225, loss: 0.1669694930315018, accuracy-micro: 0.7629642486572266, accuracy-macro: 0.0037000000011176\n",
      "step:    4226, loss: 0.1669684797525406, accuracy-micro: 0.7629579901695251, accuracy-macro: 0.0037000000011176\n",
      "step:    4227, loss: 0.1669671386480331, accuracy-micro: 0.7629657387733459, accuracy-macro: 0.0037000000011176\n",
      "step:    4228, loss: 0.1669666916131973, accuracy-micro: 0.7629602551460266, accuracy-macro: 0.0037000000011176\n",
      "step:    4229, loss: 0.1669661551713943, accuracy-micro: 0.7629682421684265, accuracy-macro: 0.0037000000011176\n",
      "step:    4230, loss: 0.1669666320085526, accuracy-micro: 0.7629802227020264, accuracy-macro: 0.0037000000011176\n",
      "step:    4231, loss: 0.1669674664735794, accuracy-micro: 0.7629547715187073, accuracy-macro: 0.0037000000011176\n",
      "step:    4232, loss: 0.1669692695140839, accuracy-micro: 0.7629812359809875, accuracy-macro: 0.0037000000011176\n",
      "step:    4233, loss: 0.1669712811708450, accuracy-micro: 0.7629482746124268, accuracy-macro: 0.0037000000011176\n",
      "step:    4234, loss: 0.1669728457927704, accuracy-micro: 0.7629907727241516, accuracy-macro: 0.0037000000011176\n",
      "step:    4235, loss: 0.1669738590717316, accuracy-micro: 0.7629240155220032, accuracy-macro: 0.0037000000011176\n",
      "step:    4236, loss: 0.1669738739728928, accuracy-micro: 0.7630192637443542, accuracy-macro: 0.0037000000011176\n",
      "step:    4237, loss: 0.1669715940952301, accuracy-micro: 0.7629287242889404, accuracy-macro: 0.0037000000011176\n",
      "step:    4238, loss: 0.1669693440198898, accuracy-micro: 0.7629960179328918, accuracy-macro: 0.0037000000011176\n",
      "step:    4239, loss: 0.1669667512178421, accuracy-micro: 0.7629662752151489, accuracy-macro: 0.0037000000011176\n",
      "step:    4240, loss: 0.1669646203517914, accuracy-micro: 0.7630149722099304, accuracy-macro: 0.0037000000011176\n",
      "step:    4241, loss: 0.1669630706310272, accuracy-micro: 0.7629770040512085, accuracy-macro: 0.0037000000011176\n",
      "step:    4242, loss: 0.1669622212648392, accuracy-micro: 0.7629892230033875, accuracy-macro: 0.0037000000011176\n",
      "step:    4243, loss: 0.1669600903987885, accuracy-micro: 0.7629792690277100, accuracy-macro: 0.0037000000011176\n",
      "step:    4244, loss: 0.1669589132070541, accuracy-micro: 0.7629964947700500, accuracy-macro: 0.0037000000011176\n",
      "step:    4245, loss: 0.1669566929340363, accuracy-micro: 0.7629987597465515, accuracy-macro: 0.0037000000011176\n",
      "step:    4246, loss: 0.1669553965330124, accuracy-micro: 0.7629864811897278, accuracy-macro: 0.0037000000011176\n",
      "step:    4247, loss: 0.1669537425041199, accuracy-micro: 0.7629784941673279, accuracy-macro: 0.0037000000011176\n",
      "step:    4248, loss: 0.1669525504112244, accuracy-micro: 0.7630132436752319, accuracy-macro: 0.0037000000011176\n",
      "step:    4249, loss: 0.1669517308473587, accuracy-micro: 0.7630019783973694, accuracy-macro: 0.0037000000011176\n",
      "step:    4250, loss: 0.1669510006904602, accuracy-micro: 0.7630059719085693, accuracy-macro: 0.0037000000011176\n",
      "step:    4251, loss: 0.1669498682022095, accuracy-micro: 0.7629962563514709, accuracy-macro: 0.0037000000011176\n",
      "step:    4252, loss: 0.1669490933418274, accuracy-micro: 0.7630007266998291, accuracy-macro: 0.0037000000011176\n",
      "step:    4253, loss: 0.1669478714466095, accuracy-micro: 0.7630109786987305, accuracy-macro: 0.0037000000011176\n",
      "step:    4254, loss: 0.1669471561908722, accuracy-micro: 0.7630017399787903, accuracy-macro: 0.0037000000011176\n",
      "step:    4255, loss: 0.1669464260339737, accuracy-micro: 0.7630025148391724, accuracy-macro: 0.0037000000011176\n",
      "step:    4256, loss: 0.1669454425573349, accuracy-micro: 0.7629925012588501, accuracy-macro: 0.0037000000011176\n",
      "step:    4257, loss: 0.1669450849294662, accuracy-micro: 0.7629987597465515, accuracy-macro: 0.0037000000011176\n",
      "step:    4258, loss: 0.1669450998306274, accuracy-micro: 0.7630267739295959, accuracy-macro: 0.0037000000011176\n",
      "step:    4259, loss: 0.1669436693191528, accuracy-micro: 0.7630159854888916, accuracy-macro: 0.0037000000011176\n",
      "step:    4260, loss: 0.1669436544179916, accuracy-micro: 0.7629899978637695, accuracy-macro: 0.0037000000011176\n",
      "step:    4261, loss: 0.1669430285692215, accuracy-micro: 0.7630214691162109, accuracy-macro: 0.0037000000011176\n",
      "step:    4262, loss: 0.1669425070285797, accuracy-micro: 0.7630199790000916, accuracy-macro: 0.0037000000011176\n",
      "step:    4263, loss: 0.1669414937496185, accuracy-micro: 0.7630167603492737, accuracy-macro: 0.0037000000011176\n",
      "step:    4264, loss: 0.1669422686100006, accuracy-micro: 0.7630065083503723, accuracy-macro: 0.0037000000011176\n",
      "step:    4265, loss: 0.1669411957263947, accuracy-micro: 0.7630010247230530, accuracy-macro: 0.0037000000011176\n",
      "step:    4266, loss: 0.1669409573078156, accuracy-micro: 0.7630207538604736, accuracy-macro: 0.0037000000011176\n",
      "step:    4267, loss: 0.1669399738311768, accuracy-micro: 0.7630167603492737, accuracy-macro: 0.0037000000011176\n",
      "step:    4268, loss: 0.1669386178255081, accuracy-micro: 0.7630062699317932, accuracy-macro: 0.0037000000011176\n",
      "step:    4269, loss: 0.1669376939535141, accuracy-micro: 0.7630062699317932, accuracy-macro: 0.0037000000011176\n",
      "step:    4270, loss: 0.1669366210699081, accuracy-micro: 0.7630274891853333, accuracy-macro: 0.0037000000011176\n",
      "step:    4271, loss: 0.1669360548257828, accuracy-micro: 0.7630067467689514, accuracy-macro: 0.0037000000011176\n",
      "step:    4272, loss: 0.1669352650642395, accuracy-micro: 0.7630469799041748, accuracy-macro: 0.0037000000011176\n",
      "step:    4273, loss: 0.1669347137212753, accuracy-micro: 0.7630267739295959, accuracy-macro: 0.0037000000011176\n",
      "step:    4274, loss: 0.1669335812330246, accuracy-micro: 0.7630492448806763, accuracy-macro: 0.0037000000011176\n",
      "step:    4275, loss: 0.1669323444366455, accuracy-micro: 0.7630199790000916, accuracy-macro: 0.0037000000011176\n",
      "step:    4276, loss: 0.1669315546751022, accuracy-micro: 0.7630444765090942, accuracy-macro: 0.0037000000011176\n",
      "step:    4277, loss: 0.1669303923845291, accuracy-micro: 0.7630222439765930, accuracy-macro: 0.0037000000011176\n",
      "step:    4278, loss: 0.1669297665357590, accuracy-micro: 0.7630332708358765, accuracy-macro: 0.0037000000011176\n",
      "step:    4279, loss: 0.1669292449951172, accuracy-micro: 0.7630427479743958, accuracy-macro: 0.0037000000011176\n",
      "step:    4280, loss: 0.1669285893440247, accuracy-micro: 0.7630324959754944, accuracy-macro: 0.0037000000011176\n",
      "step:    4281, loss: 0.1669274419546127, accuracy-micro: 0.7630299925804138, accuracy-macro: 0.0037000000011176\n",
      "step:    4282, loss: 0.1669277697801590, accuracy-micro: 0.7630322575569153, accuracy-macro: 0.0037000000011176\n",
      "step:    4283, loss: 0.1669285446405411, accuracy-micro: 0.7630487680435181, accuracy-macro: 0.0037000000011176\n",
      "step:    4284, loss: 0.1669285446405411, accuracy-micro: 0.7630562186241150, accuracy-macro: 0.0037000000011176\n",
      "step:    4285, loss: 0.1669300198554993, accuracy-micro: 0.7630252242088318, accuracy-macro: 0.0037000000011176\n",
      "step:    4286, loss: 0.1669315248727798, accuracy-micro: 0.7630687355995178, accuracy-macro: 0.0037000000011176\n",
      "step:    4287, loss: 0.1669326573610306, accuracy-micro: 0.7630327343940735, accuracy-macro: 0.0037000000011176\n",
      "step:    4288, loss: 0.1669345349073410, accuracy-micro: 0.7630617618560791, accuracy-macro: 0.0037000000011176\n",
      "step:    4289, loss: 0.1669360995292664, accuracy-micro: 0.7629642486572266, accuracy-macro: 0.0037000000011176\n",
      "step:    4290, loss: 0.1669386625289917, accuracy-micro: 0.7630552649497986, accuracy-macro: 0.0037000000011176\n",
      "step:    4291, loss: 0.1669391691684723, accuracy-micro: 0.7629817724227905, accuracy-macro: 0.0037000000011176\n",
      "step:    4292, loss: 0.1669378429651260, accuracy-micro: 0.7630667686462402, accuracy-macro: 0.0037000000011176\n",
      "step:    4293, loss: 0.1669345945119858, accuracy-micro: 0.7629987597465515, accuracy-macro: 0.0037000000011176\n",
      "step:    4294, loss: 0.1669294685125351, accuracy-micro: 0.7630609869956970, accuracy-macro: 0.0037000000011176\n",
      "step:    4295, loss: 0.1669244766235352, accuracy-micro: 0.7630272507667542, accuracy-macro: 0.0037000000011176\n",
      "step:    4296, loss: 0.1669201850891113, accuracy-micro: 0.7630762457847595, accuracy-macro: 0.0037000000011176\n",
      "step:    4297, loss: 0.1669184267520905, accuracy-micro: 0.7630469799041748, accuracy-macro: 0.0037000000011176\n",
      "step:    4298, loss: 0.1669176518917084, accuracy-micro: 0.7630710005760193, accuracy-macro: 0.0037000000011176\n",
      "step:    4299, loss: 0.1669166386127472, accuracy-micro: 0.7630339860916138, accuracy-macro: 0.0037000000011176\n",
      "step:    4300, loss: 0.1669170558452606, accuracy-micro: 0.7630850076675415, accuracy-macro: 0.0037000000011176\n",
      "step:    4301, loss: 0.1669168472290039, accuracy-micro: 0.7630500197410583, accuracy-macro: 0.0037000000011176\n",
      "step:    4302, loss: 0.1669171899557114, accuracy-micro: 0.7630792260169983, accuracy-macro: 0.0037000000011176\n",
      "step:    4303, loss: 0.1669167429208755, accuracy-micro: 0.7630532383918762, accuracy-macro: 0.0037000000011176\n",
      "step:    4304, loss: 0.1669150143861771, accuracy-micro: 0.7630875110626221, accuracy-macro: 0.0037000000011176\n",
      "step:    4305, loss: 0.1669130027294159, accuracy-micro: 0.7630414962768555, accuracy-macro: 0.0037000000011176\n",
      "step:    4306, loss: 0.1669112741947174, accuracy-micro: 0.7630634903907776, accuracy-macro: 0.0037000000011176\n",
      "step:    4307, loss: 0.1669096201658249, accuracy-micro: 0.7630527615547180, accuracy-macro: 0.0037000000011176\n",
      "step:    4308, loss: 0.1669084727764130, accuracy-micro: 0.7630680203437805, accuracy-macro: 0.0037000000011176\n",
      "step:    4309, loss: 0.1669073998928070, accuracy-micro: 0.7630522251129150, accuracy-macro: 0.0037000000011176\n",
      "step:    4310, loss: 0.1669066548347473, accuracy-micro: 0.7630772590637207, accuracy-macro: 0.0037000000011176\n",
      "step:    4311, loss: 0.1669057905673981, accuracy-micro: 0.7630714774131775, accuracy-macro: 0.0037000000011176\n",
      "step:    4312, loss: 0.1669047474861145, accuracy-micro: 0.7630692720413208, accuracy-macro: 0.0037000000011176\n",
      "step:    4313, loss: 0.1669048070907593, accuracy-micro: 0.7630742192268372, accuracy-macro: 0.0037000000011176\n",
      "step:    4314, loss: 0.1669038087129593, accuracy-micro: 0.7630705237388611, accuracy-macro: 0.0037000000011176\n",
      "step:    4315, loss: 0.1669038832187653, accuracy-micro: 0.7630354762077332, accuracy-macro: 0.0037000000011176\n",
      "step:    4316, loss: 0.1669034957885742, accuracy-micro: 0.7630837559700012, accuracy-macro: 0.0037000000011176\n",
      "step:    4317, loss: 0.1669034957885742, accuracy-micro: 0.7630565166473389, accuracy-macro: 0.0037000000011176\n",
      "step:    4318, loss: 0.1669034361839294, accuracy-micro: 0.7631012201309204, accuracy-macro: 0.0037000000011176\n",
      "step:    4319, loss: 0.1669036895036697, accuracy-micro: 0.7630544900894165, accuracy-macro: 0.0037000000011176\n",
      "step:    4320, loss: 0.1669040620326996, accuracy-micro: 0.7631254792213440, accuracy-macro: 0.0037000000011176\n",
      "step:    4321, loss: 0.1669039726257324, accuracy-micro: 0.7630782723426819, accuracy-macro: 0.0037000000011176\n",
      "step:    4322, loss: 0.1669015586376190, accuracy-micro: 0.7631117701530457, accuracy-macro: 0.0037000000011176\n",
      "step:    4323, loss: 0.1668986529111862, accuracy-micro: 0.7630574703216553, accuracy-macro: 0.0037000000011176\n",
      "step:    4324, loss: 0.1668972522020340, accuracy-micro: 0.7630875110626221, accuracy-macro: 0.0037000000011176\n",
      "step:    4325, loss: 0.1668960601091385, accuracy-micro: 0.7630825042724609, accuracy-macro: 0.0037000000011176\n",
      "step:    4326, loss: 0.1668955087661743, accuracy-micro: 0.7630839943885803, accuracy-macro: 0.0037000000011176\n",
      "step:    4327, loss: 0.1668951809406281, accuracy-micro: 0.7630707621574402, accuracy-macro: 0.0037000000011176\n",
      "step:    4328, loss: 0.1668957769870758, accuracy-micro: 0.7630752325057983, accuracy-macro: 0.0037000000011176\n",
      "step:    4329, loss: 0.1668964028358459, accuracy-micro: 0.7631214857101440, accuracy-macro: 0.0037000000011176\n",
      "step:    4330, loss: 0.1668979376554489, accuracy-micro: 0.7630814909934998, accuracy-macro: 0.0037000000011176\n",
      "step:    4331, loss: 0.1669012308120728, accuracy-micro: 0.7631232738494873, accuracy-macro: 0.0037000000011176\n",
      "step:    4332, loss: 0.1669063717126846, accuracy-micro: 0.7630362510681152, accuracy-macro: 0.0037000000011176\n",
      "step:    4333, loss: 0.1669089794158936, accuracy-micro: 0.7631055116653442, accuracy-macro: 0.0037000000011176\n",
      "step:    4334, loss: 0.1669114381074905, accuracy-micro: 0.7630304694175720, accuracy-macro: 0.0037000000011176\n",
      "step:    4335, loss: 0.1669134795665741, accuracy-micro: 0.7631122469902039, accuracy-macro: 0.0037000000011176\n",
      "step:    4336, loss: 0.1669140905141830, accuracy-micro: 0.7630247473716736, accuracy-macro: 0.0037000000011176\n",
      "step:    4337, loss: 0.1669137179851532, accuracy-micro: 0.7631082534790039, accuracy-macro: 0.0037000000011176\n",
      "step:    4338, loss: 0.1669094860553741, accuracy-micro: 0.7630310058593750, accuracy-macro: 0.0037000000011176\n",
      "step:    4339, loss: 0.1669063419103622, accuracy-micro: 0.7631335258483887, accuracy-macro: 0.0037000000011176\n",
      "step:    4340, loss: 0.1669038087129593, accuracy-micro: 0.7630427479743958, accuracy-macro: 0.0037000000011176\n",
      "step:    4341, loss: 0.1668997853994370, accuracy-micro: 0.7631379961967468, accuracy-macro: 0.0037000000011176\n",
      "step:    4342, loss: 0.1668965667486191, accuracy-micro: 0.7630609869956970, accuracy-macro: 0.0037000000011176\n",
      "step:    4343, loss: 0.1668936908245087, accuracy-micro: 0.7631354928016663, accuracy-macro: 0.0037000000011176\n",
      "step:    4344, loss: 0.1668925285339355, accuracy-micro: 0.7630607485771179, accuracy-macro: 0.0037000000011176\n",
      "step:    4345, loss: 0.1668907403945923, accuracy-micro: 0.7631415128707886, accuracy-macro: 0.0037000000011176\n",
      "step:    4346, loss: 0.1668876409530640, accuracy-micro: 0.7630745172500610, accuracy-macro: 0.0037000000011176\n",
      "step:    4347, loss: 0.1668859869241714, accuracy-micro: 0.7631275057792664, accuracy-macro: 0.0037000000011176\n",
      "step:    4348, loss: 0.1668831855058670, accuracy-micro: 0.7630975246429443, accuracy-macro: 0.0037000000011176\n",
      "step:    4349, loss: 0.1668814420700073, accuracy-micro: 0.7631267309188843, accuracy-macro: 0.0037000000011176\n",
      "step:    4350, loss: 0.1668801307678223, accuracy-micro: 0.7631055116653442, accuracy-macro: 0.0037000000011176\n",
      "step:    4351, loss: 0.1668783128261566, accuracy-micro: 0.7631070017814636, accuracy-macro: 0.0037000000011176\n",
      "step:    4352, loss: 0.1668776869773865, accuracy-micro: 0.7631047368049622, accuracy-macro: 0.0037000000011176\n",
      "step:    4353, loss: 0.1668775975704193, accuracy-micro: 0.7631155252456665, accuracy-macro: 0.0037000000011176\n",
      "step:    4354, loss: 0.1668763160705566, accuracy-micro: 0.7631202340126038, accuracy-macro: 0.0037000000011176\n",
      "step:    4355, loss: 0.1668771356344223, accuracy-micro: 0.7631057500839233, accuracy-macro: 0.0037000000011176\n",
      "step:    4356, loss: 0.1668765991926193, accuracy-micro: 0.7631515264511108, accuracy-macro: 0.0037000000011176\n",
      "step:    4357, loss: 0.1668767780065536, accuracy-micro: 0.7630877494812012, accuracy-macro: 0.0037000000011176\n",
      "step:    4358, loss: 0.1668766438961029, accuracy-micro: 0.7631572484970093, accuracy-macro: 0.0037000000011176\n",
      "step:    4359, loss: 0.1668768674135208, accuracy-micro: 0.7630802392959595, accuracy-macro: 0.0037000000011176\n",
      "step:    4360, loss: 0.1668758690357208, accuracy-micro: 0.7631622552871704, accuracy-macro: 0.0037000000011176\n",
      "step:    4361, loss: 0.1668749302625656, accuracy-micro: 0.7630982398986816, accuracy-macro: 0.0037000000011176\n",
      "step:    4362, loss: 0.1668725311756134, accuracy-micro: 0.7631555199623108, accuracy-macro: 0.0037000000011176\n",
      "step:    4363, loss: 0.1668713986873627, accuracy-micro: 0.7631030082702637, accuracy-macro: 0.0037000000011176\n",
      "step:    4364, loss: 0.1668700277805328, accuracy-micro: 0.7631449699401855, accuracy-macro: 0.0037000000011176\n",
      "step:    4365, loss: 0.1668694019317627, accuracy-micro: 0.7631170153617859, accuracy-macro: 0.0037000000011176\n",
      "step:    4366, loss: 0.1668684929609299, accuracy-micro: 0.7631342411041260, accuracy-macro: 0.0037000000011176\n",
      "step:    4367, loss: 0.1668678075075150, accuracy-micro: 0.7631207704544067, accuracy-macro: 0.0037000000011176\n",
      "step:    4368, loss: 0.1668668091297150, accuracy-micro: 0.7631312608718872, accuracy-macro: 0.0037000000011176\n",
      "step:    4369, loss: 0.1668661087751389, accuracy-micro: 0.7631247639656067, accuracy-macro: 0.0037000000011176\n",
      "step:    4370, loss: 0.1668653190135956, accuracy-micro: 0.7631207704544067, accuracy-macro: 0.0037000000011176\n",
      "step:    4371, loss: 0.1668649017810822, accuracy-micro: 0.7631397247314453, accuracy-macro: 0.0037000000011176\n",
      "step:    4372, loss: 0.1668639034032822, accuracy-micro: 0.7631052732467651, accuracy-macro: 0.0037000000011176\n",
      "step:    4373, loss: 0.1668646037578583, accuracy-micro: 0.7631682753562927, accuracy-macro: 0.0037000000011176\n",
      "step:    4374, loss: 0.1668656617403030, accuracy-micro: 0.7631087303161621, accuracy-macro: 0.0037000000011176\n",
      "step:    4375, loss: 0.1668665707111359, accuracy-micro: 0.7631737589836121, accuracy-macro: 0.0037000000011176\n",
      "step:    4376, loss: 0.1668670326471329, accuracy-micro: 0.7631097435951233, accuracy-macro: 0.0037000000011176\n",
      "step:    4377, loss: 0.1668670028448105, accuracy-micro: 0.7631882429122925, accuracy-macro: 0.0037000000011176\n",
      "step:    4378, loss: 0.1668653637170792, accuracy-micro: 0.7631070017814636, accuracy-macro: 0.0037000000011176\n",
      "step:    4379, loss: 0.1668635606765747, accuracy-micro: 0.7631802558898926, accuracy-macro: 0.0037000000011176\n",
      "step:    4380, loss: 0.1668609231710434, accuracy-micro: 0.7631264925003052, accuracy-macro: 0.0037000000011176\n",
      "step:    4381, loss: 0.1668587327003479, accuracy-micro: 0.7631492614746094, accuracy-macro: 0.0037000000011176\n",
      "step:    4382, loss: 0.1668570935726166, accuracy-micro: 0.7631235122680664, accuracy-macro: 0.0037000000011176\n",
      "step:    4383, loss: 0.1668563485145569, accuracy-micro: 0.7631409764289856, accuracy-macro: 0.0037000000011176\n",
      "step:    4384, loss: 0.1668555736541748, accuracy-micro: 0.7631637454032898, accuracy-macro: 0.0037000000011176\n",
      "step:    4385, loss: 0.1668551266193390, accuracy-micro: 0.7631427645683289, accuracy-macro: 0.0037000000011176\n",
      "step:    4386, loss: 0.1668538153171539, accuracy-micro: 0.7631769776344299, accuracy-macro: 0.0037000000011176\n",
      "step:    4387, loss: 0.1668542474508286, accuracy-micro: 0.7631397247314453, accuracy-macro: 0.0037000000011176\n",
      "step:    4388, loss: 0.1668539494276047, accuracy-micro: 0.7631924748420715, accuracy-macro: 0.0037000000011176\n",
      "step:    4389, loss: 0.1668539941310883, accuracy-micro: 0.7631400227546692, accuracy-macro: 0.0037000000011176\n",
      "step:    4390, loss: 0.1668538749217987, accuracy-micro: 0.7631867527961731, accuracy-macro: 0.0037000000011176\n",
      "step:    4391, loss: 0.1668567508459091, accuracy-micro: 0.7631390094757080, accuracy-macro: 0.0037000000011176\n",
      "step:    4392, loss: 0.1668603569269180, accuracy-micro: 0.7631829977035522, accuracy-macro: 0.0037000000011176\n",
      "step:    4393, loss: 0.1668658703565598, accuracy-micro: 0.7631164789199829, accuracy-macro: 0.0037000000011176\n",
      "step:    4394, loss: 0.1668747663497925, accuracy-micro: 0.7632290124893188, accuracy-macro: 0.0037000000011176\n",
      "step:    4395, loss: 0.1668848097324371, accuracy-micro: 0.7630422711372375, accuracy-macro: 0.0037000000011176\n",
      "step:    4396, loss: 0.1668972820043564, accuracy-micro: 0.7631689906120300, accuracy-macro: 0.0037000000011176\n",
      "step:    4397, loss: 0.1669090986251831, accuracy-micro: 0.7629665136337280, accuracy-macro: 0.0037000000011176\n",
      "step:    4398, loss: 0.1669219732284546, accuracy-micro: 0.7631472349166870, accuracy-macro: 0.0037000000011176\n",
      "step:    4399, loss: 0.1669247746467590, accuracy-micro: 0.7629525065422058, accuracy-macro: 0.0037000000011176\n",
      "step:    4400, loss: 0.1669194102287292, accuracy-micro: 0.7631739974021912, accuracy-macro: 0.0037000000011176\n",
      "step:    4401, loss: 0.1669017821550369, accuracy-micro: 0.7629747390747070, accuracy-macro: 0.0037000000011176\n",
      "step:    4402, loss: 0.1668803989887238, accuracy-micro: 0.7631967663764954, accuracy-macro: 0.0037000000011176\n",
      "step:    4403, loss: 0.1668600738048553, accuracy-micro: 0.7631394863128662, accuracy-macro: 0.0037000000011176\n",
      "step:    4404, loss: 0.1668468117713928, accuracy-micro: 0.7632242441177368, accuracy-macro: 0.0037000000011176\n",
      "step:    4405, loss: 0.1668406873941422, accuracy-micro: 0.7631732225418091, accuracy-macro: 0.0037000000011176\n",
      "step:    4406, loss: 0.1668401360511780, accuracy-micro: 0.7631695270538330, accuracy-macro: 0.0037000000011176\n",
      "step:    4407, loss: 0.1668434143066406, accuracy-micro: 0.7632085084915161, accuracy-macro: 0.0037000000011176\n",
      "step:    4408, loss: 0.1668474525213242, accuracy-micro: 0.7631617188453674, accuracy-macro: 0.0037000000011176\n",
      "step:    4409, loss: 0.1668504625558853, accuracy-micro: 0.7632240056991577, accuracy-macro: 0.0037000000011176\n",
      "step:    4410, loss: 0.1668513417243958, accuracy-micro: 0.7631539702415466, accuracy-macro: 0.0037000000011176\n",
      "step:    4411, loss: 0.1668494790792465, accuracy-micro: 0.7632427215576172, accuracy-macro: 0.0037000000011176\n",
      "step:    4412, loss: 0.1668457239866257, accuracy-micro: 0.7631660103797913, accuracy-macro: 0.0037000000011176\n",
      "step:    4413, loss: 0.1668417304754257, accuracy-micro: 0.7632254958152771, accuracy-macro: 0.0037000000011176\n",
      "step:    4414, loss: 0.1668378114700317, accuracy-micro: 0.7631692290306091, accuracy-macro: 0.0037000000011176\n",
      "step:    4415, loss: 0.1668337434530258, accuracy-micro: 0.7632395029067993, accuracy-macro: 0.0037000000011176\n",
      "step:    4416, loss: 0.1668319702148438, accuracy-micro: 0.7632102370262146, accuracy-macro: 0.0037000000011176\n",
      "step:    4417, loss: 0.1668332219123840, accuracy-micro: 0.7631815075874329, accuracy-macro: 0.0037000000011176\n",
      "step:    4418, loss: 0.1668364703655243, accuracy-micro: 0.7632347345352173, accuracy-macro: 0.0037000000011176\n",
      "step:    4419, loss: 0.1668430268764496, accuracy-micro: 0.7631717324256897, accuracy-macro: 0.0037000000011176\n",
      "step:    4420, loss: 0.1668486595153809, accuracy-micro: 0.7632317543029785, accuracy-macro: 0.0037000000011176\n",
      "step:    4421, loss: 0.1668535917997360, accuracy-micro: 0.7631297707557678, accuracy-macro: 0.0037000000011176\n",
      "step:    4422, loss: 0.1668538302183151, accuracy-micro: 0.7632507681846619, accuracy-macro: 0.0037000000011176\n",
      "step:    4423, loss: 0.1668490022420883, accuracy-micro: 0.7631425261497498, accuracy-macro: 0.0037000000011176\n",
      "step:    4424, loss: 0.1668415218591690, accuracy-micro: 0.7632387280464172, accuracy-macro: 0.0037000000011176\n",
      "step:    4425, loss: 0.1668313145637512, accuracy-micro: 0.7631777524948120, accuracy-macro: 0.0037000000011176\n",
      "step:    4426, loss: 0.1668246388435364, accuracy-micro: 0.7632380127906799, accuracy-macro: 0.0037000000011176\n",
      "step:    4427, loss: 0.1668245196342468, accuracy-micro: 0.7632527351379395, accuracy-macro: 0.0037000000011176\n",
      "step:    4428, loss: 0.1668290048837662, accuracy-micro: 0.7631922364234924, accuracy-macro: 0.0037000000011176\n",
      "step:    4429, loss: 0.1668340265750885, accuracy-micro: 0.7632644772529602, accuracy-macro: 0.0037000000011176\n",
      "step:    4430, loss: 0.1668364703655243, accuracy-micro: 0.7631775140762329, accuracy-macro: 0.0037000000011176\n",
      "step:    4431, loss: 0.1668353527784348, accuracy-micro: 0.7632610201835632, accuracy-macro: 0.0037000000011176\n",
      "step:    4432, loss: 0.1668319702148438, accuracy-micro: 0.7631629705429077, accuracy-macro: 0.0037000000011176\n",
      "step:    4433, loss: 0.1668280959129333, accuracy-micro: 0.7632572650909424, accuracy-macro: 0.0037000000011176\n",
      "step:    4434, loss: 0.1668241173028946, accuracy-micro: 0.7631959915161133, accuracy-macro: 0.0037000000011176\n",
      "step:    4435, loss: 0.1668208837509155, accuracy-micro: 0.7632594704627991, accuracy-macro: 0.0037000000011176\n",
      "step:    4436, loss: 0.1668177694082260, accuracy-micro: 0.7632322311401367, accuracy-macro: 0.0037000000011176\n",
      "step:    4437, loss: 0.1668169796466827, accuracy-micro: 0.7632459998130798, accuracy-macro: 0.0037000000011176\n",
      "step:    4438, loss: 0.1668169647455215, accuracy-micro: 0.7632767558097839, accuracy-macro: 0.0037000000011176\n",
      "step:    4439, loss: 0.1668172180652618, accuracy-micro: 0.7632337212562561, accuracy-macro: 0.0037000000011176\n",
      "step:    4440, loss: 0.1668171882629395, accuracy-micro: 0.7632672190666199, accuracy-macro: 0.0037000000011176\n",
      "step:    4441, loss: 0.1668153405189514, accuracy-micro: 0.7632250189781189, accuracy-macro: 0.0037000000011176\n",
      "step:    4442, loss: 0.1668141931295395, accuracy-micro: 0.7632667422294617, accuracy-macro: 0.0037000000011176\n",
      "step:    4443, loss: 0.1668125241994858, accuracy-micro: 0.7632275223731995, accuracy-macro: 0.0037000000011176\n",
      "step:    4444, loss: 0.1668117195367813, accuracy-micro: 0.7632740139961243, accuracy-macro: 0.0037000000011176\n",
      "step:    4445, loss: 0.1668110638856888, accuracy-micro: 0.7632702589035034, accuracy-macro: 0.0037000000011176\n",
      "step:    4446, loss: 0.1668112874031067, accuracy-micro: 0.7632482647895813, accuracy-macro: 0.0037000000011176\n",
      "step:    4447, loss: 0.1668108254671097, accuracy-micro: 0.7632855176925659, accuracy-macro: 0.0037000000011176\n",
      "step:    4448, loss: 0.1668100655078888, accuracy-micro: 0.7632407546043396, accuracy-macro: 0.0037000000011176\n",
      "step:    4449, loss: 0.1668094992637634, accuracy-micro: 0.7632765173912048, accuracy-macro: 0.0037000000011176\n",
      "step:    4450, loss: 0.1668087691068649, accuracy-micro: 0.7632322311401367, accuracy-macro: 0.0037000000011176\n",
      "step:    4451, loss: 0.1668078005313873, accuracy-micro: 0.7632742524147034, accuracy-macro: 0.0037000000011176\n",
      "step:    4452, loss: 0.1668071895837784, accuracy-micro: 0.7632550001144409, accuracy-macro: 0.0037000000011176\n",
      "step:    4453, loss: 0.1668058633804321, accuracy-micro: 0.7633042335510254, accuracy-macro: 0.0037000000011176\n",
      "step:    4454, loss: 0.1668051779270172, accuracy-micro: 0.7632487416267395, accuracy-macro: 0.0037000000011176\n",
      "step:    4455, loss: 0.1668057441711426, accuracy-micro: 0.7633115053176880, accuracy-macro: 0.0037000000011176\n",
      "step:    4456, loss: 0.1668064445257187, accuracy-micro: 0.7632514834403992, accuracy-macro: 0.0037000000011176\n",
      "step:    4457, loss: 0.1668071895837784, accuracy-micro: 0.7632750272750854, accuracy-macro: 0.0037000000011176\n",
      "step:    4458, loss: 0.1668076813220978, accuracy-micro: 0.7632257342338562, accuracy-macro: 0.0037000000011176\n",
      "step:    4459, loss: 0.1668062210083008, accuracy-micro: 0.7632845044136047, accuracy-macro: 0.0037000000011176\n",
      "step:    4460, loss: 0.1668039113283157, accuracy-micro: 0.7632242441177368, accuracy-macro: 0.0037000000011176\n",
      "step:    4461, loss: 0.1668030321598053, accuracy-micro: 0.7633062601089478, accuracy-macro: 0.0037000000011176\n",
      "step:    4462, loss: 0.1668008267879486, accuracy-micro: 0.7632575035095215, accuracy-macro: 0.0037000000011176\n",
      "step:    4463, loss: 0.1667994707822800, accuracy-micro: 0.7632970213890076, accuracy-macro: 0.0037000000011176\n",
      "step:    4464, loss: 0.1667987406253815, accuracy-micro: 0.7632782459259033, accuracy-macro: 0.0037000000011176\n",
      "step:    4465, loss: 0.1667971909046173, accuracy-micro: 0.7632830142974854, accuracy-macro: 0.0037000000011176\n",
      "step:    4466, loss: 0.1667965352535248, accuracy-micro: 0.7633060216903687, accuracy-macro: 0.0037000000011176\n",
      "step:    4467, loss: 0.1667968183755875, accuracy-micro: 0.7632557749748230, accuracy-macro: 0.0037000000011176\n",
      "step:    4468, loss: 0.1667994707822800, accuracy-micro: 0.7633292675018311, accuracy-macro: 0.0037000000011176\n",
      "step:    4469, loss: 0.1667995005846024, accuracy-micro: 0.7632330060005188, accuracy-macro: 0.0037000000011176\n",
      "step:    4470, loss: 0.1668001413345337, accuracy-micro: 0.7633052468299866, accuracy-macro: 0.0037000000011176\n",
      "step:    4471, loss: 0.1667997539043427, accuracy-micro: 0.7632247209548950, accuracy-macro: 0.0037000000011176\n",
      "step:    4472, loss: 0.1667991429567337, accuracy-micro: 0.7633192539215088, accuracy-macro: 0.0037000000011176\n",
      "step:    4473, loss: 0.1667973548173904, accuracy-micro: 0.7632367610931396, accuracy-macro: 0.0037000000011176\n",
      "step:    4474, loss: 0.1667957603931427, accuracy-micro: 0.7633272409439087, accuracy-macro: 0.0037000000011176\n",
      "step:    4475, loss: 0.1667945683002472, accuracy-micro: 0.7632464766502380, accuracy-macro: 0.0037000000011176\n",
      "step:    4476, loss: 0.1667917817831039, accuracy-micro: 0.7633202672004700, accuracy-macro: 0.0037000000011176\n",
      "step:    4477, loss: 0.1667902171611786, accuracy-micro: 0.7632767558097839, accuracy-macro: 0.0037000000011176\n",
      "step:    4478, loss: 0.1667884439229965, accuracy-micro: 0.7633232474327087, accuracy-macro: 0.0037000000011176\n",
      "step:    4479, loss: 0.1667873561382294, accuracy-micro: 0.7632977366447449, accuracy-macro: 0.0037000000011176\n",
      "step:    4480, loss: 0.1667869985103607, accuracy-micro: 0.7632939815521240, accuracy-macro: 0.0037000000011176\n",
      "step:    4481, loss: 0.1667868793010712, accuracy-micro: 0.7633257508277893, accuracy-macro: 0.0037000000011176\n",
      "step:    4482, loss: 0.1667864620685577, accuracy-micro: 0.7632954716682434, accuracy-macro: 0.0037000000011176\n",
      "step:    4483, loss: 0.1667857766151428, accuracy-micro: 0.7633280158042908, accuracy-macro: 0.0037000000011176\n",
      "step:    4484, loss: 0.1667844355106354, accuracy-micro: 0.7633027434349060, accuracy-macro: 0.0037000000011176\n",
      "step:    4485, loss: 0.1667841523885727, accuracy-micro: 0.7633249759674072, accuracy-macro: 0.0037000000011176\n",
      "step:    4486, loss: 0.1667830348014832, accuracy-micro: 0.7633012533187866, accuracy-macro: 0.0037000000011176\n",
      "step:    4487, loss: 0.1667822301387787, accuracy-micro: 0.7633222341537476, accuracy-macro: 0.0037000000011176\n",
      "step:    4488, loss: 0.1667809039354324, accuracy-micro: 0.7633172273635864, accuracy-macro: 0.0037000000011176\n",
      "step:    4489, loss: 0.1667805016040802, accuracy-micro: 0.7633199691772461, accuracy-macro: 0.0037000000011176\n",
      "step:    4490, loss: 0.1667797565460205, accuracy-micro: 0.7633100152015686, accuracy-macro: 0.0037000000011176\n",
      "step:    4491, loss: 0.1667798310518265, accuracy-micro: 0.7633282542228699, accuracy-macro: 0.0037000000011176\n",
      "step:    4492, loss: 0.1667785346508026, accuracy-micro: 0.7633259892463684, accuracy-macro: 0.0037000000011176\n",
      "step:    4493, loss: 0.1667775064706802, accuracy-micro: 0.7633215188980103, accuracy-macro: 0.0037000000011176\n",
      "step:    4494, loss: 0.1667766571044922, accuracy-micro: 0.7633062601089478, accuracy-macro: 0.0037000000011176\n",
      "step:    4495, loss: 0.1667765378952026, accuracy-micro: 0.7633224725723267, accuracy-macro: 0.0037000000011176\n",
      "step:    4496, loss: 0.1667757481336594, accuracy-micro: 0.7633107304573059, accuracy-macro: 0.0037000000011176\n",
      "step:    4497, loss: 0.1667753756046295, accuracy-micro: 0.7633182406425476, accuracy-macro: 0.0037000000011176\n",
      "step:    4498, loss: 0.1667743176221848, accuracy-micro: 0.7633127570152283, accuracy-macro: 0.0037000000011176\n",
      "step:    4499, loss: 0.1667742133140564, accuracy-micro: 0.7633199691772461, accuracy-macro: 0.0037000000011176\n",
      "step:    4500, loss: 0.1667733788490295, accuracy-micro: 0.7633132338523865, accuracy-macro: 0.0037000000011176\n",
      "step:    4501, loss: 0.1667730659246445, accuracy-micro: 0.7633175253868103, accuracy-macro: 0.0037000000011176\n",
      "step:    4502, loss: 0.1667723506689072, accuracy-micro: 0.7633182406425476, accuracy-macro: 0.0037000000011176\n",
      "step:    4503, loss: 0.1667719483375549, accuracy-micro: 0.7633280158042908, accuracy-macro: 0.0037000000011176\n",
      "step:    4504, loss: 0.1667718738317490, accuracy-micro: 0.7633035182952881, accuracy-macro: 0.0037000000011176\n",
      "step:    4505, loss: 0.1667724996805191, accuracy-micro: 0.7633487582206726, accuracy-macro: 0.0037000000011176\n",
      "step:    4506, loss: 0.1667727231979370, accuracy-micro: 0.7632982730865479, accuracy-macro: 0.0037000000011176\n",
      "step:    4507, loss: 0.1667740345001221, accuracy-micro: 0.7633464932441711, accuracy-macro: 0.0037000000011176\n",
      "step:    4508, loss: 0.1667761653661728, accuracy-micro: 0.7632582187652588, accuracy-macro: 0.0037000000011176\n",
      "step:    4509, loss: 0.1667809039354324, accuracy-micro: 0.7633554935455322, accuracy-macro: 0.0037000000011176\n",
      "step:    4510, loss: 0.1667858660221100, accuracy-micro: 0.7632207274436951, accuracy-macro: 0.0037000000011176\n",
      "step:    4511, loss: 0.1667919307947159, accuracy-micro: 0.7633247375488281, accuracy-macro: 0.0037000000011176\n",
      "step:    4512, loss: 0.1667960137128830, accuracy-micro: 0.7632070183753967, accuracy-macro: 0.0037000000011176\n",
      "step:    4513, loss: 0.1667976975440979, accuracy-micro: 0.7633090019226074, accuracy-macro: 0.0037000000011176\n",
      "step:    4514, loss: 0.1667963862419128, accuracy-micro: 0.7631857395172119, accuracy-macro: 0.0037000000011176\n",
      "step:    4515, loss: 0.1667944043874741, accuracy-micro: 0.7633022665977478, accuracy-macro: 0.0037000000011176\n",
      "step:    4516, loss: 0.1667888760566711, accuracy-micro: 0.7631970047950745, accuracy-macro: 0.0037000000011176\n",
      "step:    4517, loss: 0.1667841076850891, accuracy-micro: 0.7633247375488281, accuracy-macro: 0.0037000000011176\n",
      "step:    4518, loss: 0.1667760312557220, accuracy-micro: 0.7632455229759216, accuracy-macro: 0.0037000000011176\n",
      "step:    4519, loss: 0.1667668819427490, accuracy-micro: 0.7633527517318726, accuracy-macro: 0.0037000000011176\n",
      "step:    4520, loss: 0.1667608469724655, accuracy-micro: 0.7633237242698669, accuracy-macro: 0.0037000000011176\n",
      "step:    4521, loss: 0.1667596846818924, accuracy-micro: 0.7633322477340698, accuracy-macro: 0.0037000000011176\n",
      "step:    4522, loss: 0.1667618453502655, accuracy-micro: 0.7633422613143921, accuracy-macro: 0.0037000000011176\n",
      "step:    4523, loss: 0.1667669862508774, accuracy-micro: 0.7632520198822021, accuracy-macro: 0.0037000000011176\n",
      "step:    4524, loss: 0.1667738109827042, accuracy-micro: 0.7633597254753113, accuracy-macro: 0.0037000000011176\n",
      "step:    4525, loss: 0.1667820960283279, accuracy-micro: 0.7632287740707397, accuracy-macro: 0.0037000000011176\n",
      "step:    4526, loss: 0.1667902767658234, accuracy-micro: 0.7633194923400879, accuracy-macro: 0.0037000000011176\n",
      "step:    4527, loss: 0.1667935401201248, accuracy-micro: 0.7632202506065369, accuracy-macro: 0.0037000000011176\n",
      "step:    4528, loss: 0.1667902916669846, accuracy-micro: 0.7632917761802673, accuracy-macro: 0.0037000000011176\n",
      "step:    4529, loss: 0.1667808145284653, accuracy-micro: 0.7632387280464172, accuracy-macro: 0.0037000000011176\n",
      "step:    4530, loss: 0.1667683124542236, accuracy-micro: 0.7633479833602905, accuracy-macro: 0.0037000000011176\n",
      "step:    4531, loss: 0.1667576879262924, accuracy-micro: 0.7632972598075867, accuracy-macro: 0.0037000000011176\n",
      "step:    4532, loss: 0.1667520105838776, accuracy-micro: 0.7633607387542725, accuracy-macro: 0.0037000000011176\n",
      "step:    4533, loss: 0.1667525470256805, accuracy-micro: 0.7633707523345947, accuracy-macro: 0.0037000000011176\n",
      "step:    4534, loss: 0.1667567938566208, accuracy-micro: 0.7632964849472046, accuracy-macro: 0.0037000000011176\n",
      "step:    4535, loss: 0.1667613685131073, accuracy-micro: 0.7633550167083740, accuracy-macro: 0.0037000000011176\n",
      "step:    4536, loss: 0.1667619347572327, accuracy-micro: 0.7632587552070618, accuracy-macro: 0.0037000000011176\n",
      "step:    4537, loss: 0.1667598783969879, accuracy-micro: 0.7633705139160156, accuracy-macro: 0.0037000000011176\n",
      "step:    4538, loss: 0.1667550951242447, accuracy-micro: 0.7632847428321838, accuracy-macro: 0.0037000000011176\n",
      "step:    4539, loss: 0.1667513102293015, accuracy-micro: 0.7633554935455322, accuracy-macro: 0.0037000000011176\n",
      "step:    4540, loss: 0.1667478680610657, accuracy-micro: 0.7633302211761475, accuracy-macro: 0.0037000000011176\n",
      "step:    4541, loss: 0.1667463332414627, accuracy-micro: 0.7633652687072754, accuracy-macro: 0.0037000000011176\n",
      "step:    4542, loss: 0.1667457222938538, accuracy-micro: 0.7633342742919922, accuracy-macro: 0.0037000000011176\n",
      "step:    4543, loss: 0.1667454689741135, accuracy-micro: 0.7633527517318726, accuracy-macro: 0.0037000000011176\n",
      "step:    4544, loss: 0.1667447388172150, accuracy-micro: 0.7633485198020935, accuracy-macro: 0.0037000000011176\n",
      "step:    4545, loss: 0.1667439639568329, accuracy-micro: 0.7633362412452698, accuracy-macro: 0.0037000000011176\n",
      "step:    4546, loss: 0.1667432039976120, accuracy-micro: 0.7633575201034546, accuracy-macro: 0.0037000000011176\n",
      "step:    4547, loss: 0.1667425036430359, accuracy-micro: 0.7633284926414490, accuracy-macro: 0.0037000000011176\n",
      "step:    4548, loss: 0.1667415052652359, accuracy-micro: 0.7633504867553711, accuracy-macro: 0.0037000000011176\n",
      "step:    4549, loss: 0.1667406558990479, accuracy-micro: 0.7633362412452698, accuracy-macro: 0.0037000000011176\n",
      "step:    4550, loss: 0.1667401492595673, accuracy-micro: 0.7633559703826904, accuracy-macro: 0.0037000000011176\n",
      "step:    4551, loss: 0.1667394340038300, accuracy-micro: 0.7633525133132935, accuracy-macro: 0.0037000000011176\n",
      "step:    4552, loss: 0.1667387932538986, accuracy-micro: 0.7633619904518127, accuracy-macro: 0.0037000000011176\n",
      "step:    4553, loss: 0.1667385250329971, accuracy-micro: 0.7633497714996338, accuracy-macro: 0.0037000000011176\n",
      "step:    4554, loss: 0.1667373478412628, accuracy-micro: 0.7633544802665710, accuracy-macro: 0.0037000000011176\n",
      "step:    4555, loss: 0.1667367219924927, accuracy-micro: 0.7633584737777710, accuracy-macro: 0.0037000000011176\n",
      "step:    4556, loss: 0.1667358428239822, accuracy-micro: 0.7633569836616516, accuracy-macro: 0.0037000000011176\n",
      "step:    4557, loss: 0.1667350977659225, accuracy-micro: 0.7633357644081116, accuracy-macro: 0.0037000000011176\n",
      "step:    4558, loss: 0.1667346805334091, accuracy-micro: 0.7633377313613892, accuracy-macro: 0.0037000000011176\n",
      "step:    4559, loss: 0.1667344421148300, accuracy-micro: 0.7633382678031921, accuracy-macro: 0.0037000000011176\n",
      "step:    4560, loss: 0.1667339950799942, accuracy-micro: 0.7633722424507141, accuracy-macro: 0.0037000000011176\n",
      "step:    4561, loss: 0.1667340844869614, accuracy-micro: 0.7633242607116699, accuracy-macro: 0.0037000000011176\n",
      "step:    4562, loss: 0.1667347550392151, accuracy-micro: 0.7633745074272156, accuracy-macro: 0.0037000000011176\n",
      "step:    4563, loss: 0.1667346060276031, accuracy-micro: 0.7633352279663086, accuracy-macro: 0.0037000000011176\n",
      "step:    4564, loss: 0.1667351871728897, accuracy-micro: 0.7634044885635376, accuracy-macro: 0.0037000000011176\n",
      "step:    4565, loss: 0.1667343080043793, accuracy-micro: 0.7633324861526489, accuracy-macro: 0.0037000000011176\n",
      "step:    4566, loss: 0.1667339056730270, accuracy-micro: 0.7633837461471558, accuracy-macro: 0.0037000000011176\n",
      "step:    4567, loss: 0.1667321771383286, accuracy-micro: 0.7633424997329712, accuracy-macro: 0.0037000000011176\n",
      "step:    4568, loss: 0.1667306423187256, accuracy-micro: 0.7633887529373169, accuracy-macro: 0.0037000000011176\n",
      "step:    4569, loss: 0.1667284518480301, accuracy-micro: 0.7633482217788696, accuracy-macro: 0.0037000000011176\n",
      "step:    4570, loss: 0.1667266935110092, accuracy-micro: 0.7633627653121948, accuracy-macro: 0.0037000000011176\n",
      "step:    4571, loss: 0.1667257249355316, accuracy-micro: 0.7633519768714905, accuracy-macro: 0.0037000000011176\n",
      "step:    4572, loss: 0.1667252629995346, accuracy-micro: 0.7633379697799683, accuracy-macro: 0.0037000000011176\n",
      "step:    4573, loss: 0.1667243689298630, accuracy-micro: 0.7633607387542725, accuracy-macro: 0.0037000000011176\n",
      "step:    4574, loss: 0.1667242497205734, accuracy-micro: 0.7633492350578308, accuracy-macro: 0.0037000000011176\n",
      "step:    4575, loss: 0.1667237132787704, accuracy-micro: 0.7633854746818542, accuracy-macro: 0.0037000000011176\n",
      "step:    4576, loss: 0.1667241007089615, accuracy-micro: 0.7633252739906311, accuracy-macro: 0.0037000000011176\n",
      "step:    4577, loss: 0.1667236983776093, accuracy-micro: 0.7633799910545349, accuracy-macro: 0.0037000000011176\n",
      "step:    4578, loss: 0.1667230278253555, accuracy-micro: 0.7633295059204102, accuracy-macro: 0.0037000000011176\n",
      "step:    4579, loss: 0.1667241603136063, accuracy-micro: 0.7634262442588806, accuracy-macro: 0.0037000000011176\n",
      "step:    4580, loss: 0.1667234599590302, accuracy-micro: 0.7633147239685059, accuracy-macro: 0.0037000000011176\n",
      "step:    4581, loss: 0.1667248308658600, accuracy-micro: 0.7633914947509766, accuracy-macro: 0.0037000000011176\n",
      "step:    4582, loss: 0.1667262017726898, accuracy-micro: 0.7633192539215088, accuracy-macro: 0.0037000000011176\n",
      "step:    4583, loss: 0.1667280346155167, accuracy-micro: 0.7634002566337585, accuracy-macro: 0.0037000000011176\n",
      "step:    4584, loss: 0.1667308807373047, accuracy-micro: 0.7633262276649475, accuracy-macro: 0.0037000000011176\n",
      "step:    4585, loss: 0.1667352765798569, accuracy-micro: 0.7633717656135559, accuracy-macro: 0.0037000000011176\n",
      "step:    4586, loss: 0.1667378544807434, accuracy-micro: 0.7632972598075867, accuracy-macro: 0.0037000000011176\n",
      "step:    4587, loss: 0.1667419373989105, accuracy-micro: 0.7633842229843140, accuracy-macro: 0.0037000000011176\n",
      "step:    4588, loss: 0.1667428165674210, accuracy-micro: 0.7633017301559448, accuracy-macro: 0.0037000000011176\n",
      "step:    4589, loss: 0.1667403876781464, accuracy-micro: 0.7633772492408752, accuracy-macro: 0.0037000000011176\n",
      "step:    4590, loss: 0.1667315363883972, accuracy-micro: 0.7633140087127686, accuracy-macro: 0.0037000000011176\n",
      "step:    4591, loss: 0.1667210608720779, accuracy-micro: 0.7633984684944153, accuracy-macro: 0.0037000000011176\n",
      "step:    4592, loss: 0.1667133420705795, accuracy-micro: 0.7633497714996338, accuracy-macro: 0.0037000000011176\n",
      "step:    4593, loss: 0.1667113155126572, accuracy-micro: 0.7633547186851501, accuracy-macro: 0.0037000000011176\n",
      "step:    4594, loss: 0.1667137444019318, accuracy-micro: 0.7633904814720154, accuracy-macro: 0.0037000000011176\n",
      "step:    4595, loss: 0.1667192876338959, accuracy-micro: 0.7633252739906311, accuracy-macro: 0.0037000000011176\n",
      "step:    4596, loss: 0.1667283475399017, accuracy-micro: 0.7634072303771973, accuracy-macro: 0.0037000000011176\n",
      "step:    4597, loss: 0.1667362451553345, accuracy-micro: 0.7633075118064880, accuracy-macro: 0.0037000000011176\n",
      "step:    4598, loss: 0.1667400896549225, accuracy-micro: 0.7634009718894958, accuracy-macro: 0.0037000000011176\n",
      "step:    4599, loss: 0.1667379140853882, accuracy-micro: 0.7633162736892700, accuracy-macro: 0.0037000000011176\n",
      "step:    4600, loss: 0.1667289733886719, accuracy-micro: 0.7634042501449585, accuracy-macro: 0.0037000000011176\n",
      "step:    4601, loss: 0.1667167395353317, accuracy-micro: 0.7633404731750488, accuracy-macro: 0.0037000000011176\n",
      "step:    4602, loss: 0.1667084395885468, accuracy-micro: 0.7634197473526001, accuracy-macro: 0.0037000000011176\n",
      "step:    4603, loss: 0.1667050570249557, accuracy-micro: 0.7633732557296753, accuracy-macro: 0.0037000000011176\n",
      "step:    4604, loss: 0.1667067110538483, accuracy-micro: 0.7633510231971741, accuracy-macro: 0.0037000000011176\n",
      "step:    4605, loss: 0.1667106598615646, accuracy-micro: 0.7633872628211975, accuracy-macro: 0.0037000000011176\n",
      "step:    4606, loss: 0.1667116284370422, accuracy-micro: 0.7633482217788696, accuracy-macro: 0.0037000000011176\n",
      "step:    4607, loss: 0.1667140573263168, accuracy-micro: 0.7634322643280029, accuracy-macro: 0.0037000000011176\n",
      "step:    4608, loss: 0.1667131185531616, accuracy-micro: 0.7633510231971741, accuracy-macro: 0.0037000000011176\n",
      "step:    4609, loss: 0.1667125374078751, accuracy-micro: 0.7634022235870361, accuracy-macro: 0.0037000000011176\n",
      "step:    4610, loss: 0.1667089462280273, accuracy-micro: 0.7633349895477295, accuracy-macro: 0.0037000000011176\n",
      "step:    4611, loss: 0.1667050123214722, accuracy-micro: 0.7634212374687195, accuracy-macro: 0.0037000000011176\n",
      "step:    4612, loss: 0.1667022109031677, accuracy-micro: 0.7633692622184753, accuracy-macro: 0.0037000000011176\n",
      "step:    4613, loss: 0.1666991561651230, accuracy-micro: 0.7634130120277405, accuracy-macro: 0.0037000000011176\n",
      "step:    4614, loss: 0.1666978746652603, accuracy-micro: 0.7633807659149170, accuracy-macro: 0.0037000000011176\n",
      "step:    4615, loss: 0.1666965335607529, accuracy-micro: 0.7633912563323975, accuracy-macro: 0.0037000000011176\n",
      "step:    4616, loss: 0.1666977852582932, accuracy-micro: 0.7634372711181641, accuracy-macro: 0.0037000000011176\n",
      "step:    4617, loss: 0.1666983813047409, accuracy-micro: 0.7633925080299377, accuracy-macro: 0.0037000000011176\n",
      "step:    4618, loss: 0.1666965037584305, accuracy-micro: 0.7633972764015198, accuracy-macro: 0.0037000000011176\n",
      "step:    4619, loss: 0.1666960865259171, accuracy-micro: 0.7633637189865112, accuracy-macro: 0.0037000000011176\n",
      "step:    4620, loss: 0.1666944622993469, accuracy-micro: 0.7634090185165405, accuracy-macro: 0.0037000000011176\n",
      "step:    4621, loss: 0.1666933298110962, accuracy-micro: 0.7634112238883972, accuracy-macro: 0.0037000000011176\n",
      "step:    4622, loss: 0.1666925996541977, accuracy-micro: 0.7634094953536987, accuracy-macro: 0.0037000000011176\n",
      "step:    4623, loss: 0.1666921675205231, accuracy-micro: 0.7634149789810181, accuracy-macro: 0.0037000000011176\n",
      "step:    4624, loss: 0.1666933745145798, accuracy-micro: 0.7633590102195740, accuracy-macro: 0.0037000000011176\n",
      "step:    4625, loss: 0.1666942089796066, accuracy-micro: 0.7634134888648987, accuracy-macro: 0.0037000000011176\n",
      "step:    4626, loss: 0.1666962355375290, accuracy-micro: 0.7633649706840515, accuracy-macro: 0.0037000000011176\n",
      "step:    4627, loss: 0.1666975766420364, accuracy-micro: 0.7633997201919556, accuracy-macro: 0.0037000000011176\n",
      "step:    4628, loss: 0.1666964590549469, accuracy-micro: 0.7633774876594543, accuracy-macro: 0.0037000000011176\n",
      "step:    4629, loss: 0.1666923165321350, accuracy-micro: 0.7634102702140808, accuracy-macro: 0.0037000000011176\n",
      "step:    4630, loss: 0.1666889786720276, accuracy-micro: 0.7633977532386780, accuracy-macro: 0.0037000000011176\n",
      "step:    4631, loss: 0.1666864305734634, accuracy-micro: 0.7634022235870361, accuracy-macro: 0.0037000000011176\n",
      "step:    4632, loss: 0.1666855216026306, accuracy-micro: 0.7633979916572571, accuracy-macro: 0.0037000000011176\n",
      "step:    4633, loss: 0.1666860878467560, accuracy-micro: 0.7634002566337585, accuracy-macro: 0.0037000000011176\n",
      "step:    4634, loss: 0.1666869074106216, accuracy-micro: 0.7634289860725403, accuracy-macro: 0.0037000000011176\n",
      "step:    4635, loss: 0.1666881293058395, accuracy-micro: 0.7633705139160156, accuracy-macro: 0.0037000000011176\n",
      "step:    4636, loss: 0.1666895896196365, accuracy-micro: 0.7634177207946777, accuracy-macro: 0.0037000000011176\n",
      "step:    4637, loss: 0.1666916608810425, accuracy-micro: 0.7633927464485168, accuracy-macro: 0.0037000000011176\n",
      "step:    4638, loss: 0.1666929870843887, accuracy-micro: 0.7634192705154419, accuracy-macro: 0.0037000000011176\n",
      "step:    4639, loss: 0.1666923314332962, accuracy-micro: 0.7634107470512390, accuracy-macro: 0.0037000000011176\n",
      "step:    4640, loss: 0.1666909307241440, accuracy-micro: 0.7634149789810181, accuracy-macro: 0.0037000000011176\n",
      "step:    4641, loss: 0.1666882485151291, accuracy-micro: 0.7633877396583557, accuracy-macro: 0.0037000000011176\n",
      "step:    4642, loss: 0.1666850745677948, accuracy-micro: 0.7634109854698181, accuracy-macro: 0.0037000000011176\n",
      "step:    4643, loss: 0.1666810363531113, accuracy-micro: 0.7633990049362183, accuracy-macro: 0.0037000000011176\n",
      "step:    4644, loss: 0.1666787266731262, accuracy-micro: 0.7634257674217224, accuracy-macro: 0.0037000000011176\n",
      "step:    4645, loss: 0.1666777133941650, accuracy-micro: 0.7634212374687195, accuracy-macro: 0.0037000000011176\n",
      "step:    4646, loss: 0.1666772514581680, accuracy-micro: 0.7634159922599792, accuracy-macro: 0.0037000000011176\n",
      "step:    4647, loss: 0.1666774153709412, accuracy-micro: 0.7634434700012207, accuracy-macro: 0.0037000000011176\n",
      "step:    4648, loss: 0.1666778922080994, accuracy-micro: 0.7634172439575195, accuracy-macro: 0.0037000000011176\n",
      "step:    4649, loss: 0.1666787564754486, accuracy-micro: 0.7634302377700806, accuracy-macro: 0.0037000000011176\n",
      "step:    4650, loss: 0.1666787862777710, accuracy-micro: 0.7634032368659973, accuracy-macro: 0.0037000000011176\n",
      "step:    4651, loss: 0.1666785925626755, accuracy-micro: 0.7634339928627014, accuracy-macro: 0.0037000000011176\n",
      "step:    4652, loss: 0.1666783392429352, accuracy-micro: 0.7634097337722778, accuracy-macro: 0.0037000000011176\n",
      "step:    4653, loss: 0.1666781604290009, accuracy-micro: 0.7634252309799194, accuracy-macro: 0.0037000000011176\n",
      "step:    4654, loss: 0.1666752547025681, accuracy-micro: 0.7634202241897583, accuracy-macro: 0.0037000000011176\n",
      "step:    4655, loss: 0.1666729301214218, accuracy-micro: 0.7634332776069641, accuracy-macro: 0.0037000000011176\n",
      "step:    4656, loss: 0.1666710823774338, accuracy-micro: 0.7634375095367432, accuracy-macro: 0.0037000000011176\n",
      "step:    4657, loss: 0.1666707545518875, accuracy-micro: 0.7634379863739014, accuracy-macro: 0.0037000000011176\n",
      "step:    4658, loss: 0.1666704863309860, accuracy-micro: 0.7634387612342834, accuracy-macro: 0.0037000000011176\n",
      "step:    4659, loss: 0.1666722148656845, accuracy-micro: 0.7634312510490417, accuracy-macro: 0.0037000000011176\n",
      "step:    4660, loss: 0.1666734963655472, accuracy-micro: 0.7634257674217224, accuracy-macro: 0.0037000000011176\n",
      "step:    4661, loss: 0.1666760891675949, accuracy-micro: 0.7634152770042419, accuracy-macro: 0.0037000000011176\n",
      "step:    4662, loss: 0.1666779816150665, accuracy-micro: 0.7634347677230835, accuracy-macro: 0.0037000000011176\n",
      "step:    4663, loss: 0.1666787713766098, accuracy-micro: 0.7633952498435974, accuracy-macro: 0.0037000000011176\n",
      "step:    4664, loss: 0.1666779816150665, accuracy-micro: 0.7634447216987610, accuracy-macro: 0.0037000000011176\n",
      "step:    4665, loss: 0.1666787117719650, accuracy-micro: 0.7634090185165405, accuracy-macro: 0.0037000000011176\n",
      "step:    4666, loss: 0.1666799038648605, accuracy-micro: 0.7634279727935791, accuracy-macro: 0.0037000000011176\n",
      "step:    4667, loss: 0.1666796356439590, accuracy-micro: 0.7634117603302002, accuracy-macro: 0.0037000000011176\n",
      "step:    4668, loss: 0.1666759103536606, accuracy-micro: 0.7634372711181641, accuracy-macro: 0.0037000000011176\n",
      "step:    4669, loss: 0.1666709929704666, accuracy-micro: 0.7634415030479431, accuracy-macro: 0.0037000000011176\n",
      "step:    4670, loss: 0.1666652560234070, accuracy-micro: 0.7634509801864624, accuracy-macro: 0.0037000000011176\n",
      "step:    4671, loss: 0.1666616201400757, accuracy-micro: 0.7634412646293640, accuracy-macro: 0.0037000000011176\n",
      "step:    4672, loss: 0.1666615009307861, accuracy-micro: 0.7634562253952026, accuracy-macro: 0.0037000000011176\n",
      "step:    4673, loss: 0.1666628420352936, accuracy-micro: 0.7634622454643250, accuracy-macro: 0.0037000000011176\n",
      "step:    4674, loss: 0.1666640043258667, accuracy-micro: 0.7634249925613403, accuracy-macro: 0.0037000000011176\n",
      "step:    4675, loss: 0.1666651517152786, accuracy-micro: 0.7634450197219849, accuracy-macro: 0.0037000000011176\n",
      "step:    4676, loss: 0.1666644960641861, accuracy-micro: 0.7634415030479431, accuracy-macro: 0.0037000000011176\n",
      "step:    4677, loss: 0.1666624993085861, accuracy-micro: 0.7634639739990234, accuracy-macro: 0.0037000000011176\n",
      "step:    4678, loss: 0.1666607558727264, accuracy-micro: 0.7634547352790833, accuracy-macro: 0.0037000000011176\n",
      "step:    4679, loss: 0.1666589975357056, accuracy-micro: 0.7634702324867249, accuracy-macro: 0.0037000000011176\n",
      "step:    4680, loss: 0.1666567027568817, accuracy-micro: 0.7634555101394653, accuracy-macro: 0.0037000000011176\n",
      "step:    4681, loss: 0.1666549742221832, accuracy-micro: 0.7634614706039429, accuracy-macro: 0.0037000000011176\n",
      "step:    4682, loss: 0.1666545122861862, accuracy-micro: 0.7634472250938416, accuracy-macro: 0.0037000000011176\n",
      "step:    4683, loss: 0.1666557937860489, accuracy-micro: 0.7634667754173279, accuracy-macro: 0.0037000000011176\n",
      "step:    4684, loss: 0.1666569262742996, accuracy-micro: 0.7634797692298889, accuracy-macro: 0.0037000000011176\n",
      "step:    4685, loss: 0.1666582226753235, accuracy-micro: 0.7634444832801819, accuracy-macro: 0.0037000000011176\n",
      "step:    4686, loss: 0.1666617244482040, accuracy-micro: 0.7634584903717041, accuracy-macro: 0.0037000000011176\n",
      "step:    4687, loss: 0.1666646152734756, accuracy-micro: 0.7634245157241821, accuracy-macro: 0.0037000000011176\n",
      "step:    4688, loss: 0.1666654050350189, accuracy-micro: 0.7634314894676208, accuracy-macro: 0.0037000000011176\n",
      "step:    4689, loss: 0.1666642725467682, accuracy-micro: 0.7634257674217224, accuracy-macro: 0.0037000000011176\n",
      "step:    4690, loss: 0.1666644364595413, accuracy-micro: 0.7634547352790833, accuracy-macro: 0.0037000000011176\n",
      "step:    4691, loss: 0.1666634082794189, accuracy-micro: 0.7634279727935791, accuracy-macro: 0.0037000000011176\n",
      "step:    4692, loss: 0.1666626632213593, accuracy-micro: 0.7634174823760986, accuracy-macro: 0.0037000000011176\n",
      "step:    4693, loss: 0.1666599363088608, accuracy-micro: 0.7634307742118835, accuracy-macro: 0.0037000000011176\n",
      "step:    4694, loss: 0.1666565686464310, accuracy-micro: 0.7634645104408264, accuracy-macro: 0.0037000000011176\n",
      "step:    4695, loss: 0.1666516810655594, accuracy-micro: 0.7634752392768860, accuracy-macro: 0.0037000000011176\n",
      "step:    4696, loss: 0.1666471809148788, accuracy-micro: 0.7634865045547485, accuracy-macro: 0.0037000000011176\n",
      "step:    4697, loss: 0.1666448712348938, accuracy-micro: 0.7634745240211487, accuracy-macro: 0.0037000000011176\n",
      "step:    4698, loss: 0.1666450798511505, accuracy-micro: 0.7634904980659485, accuracy-macro: 0.0037000000011176\n",
      "step:    4699, loss: 0.1666473150253296, accuracy-micro: 0.7634890079498291, accuracy-macro: 0.0037000000011176\n",
      "step:    4700, loss: 0.1666498184204102, accuracy-micro: 0.7634687423706055, accuracy-macro: 0.0037000000011176\n",
      "step:    4701, loss: 0.1666505336761475, accuracy-micro: 0.7634572386741638, accuracy-macro: 0.0037000000011176\n",
      "step:    4702, loss: 0.1666502505540848, accuracy-micro: 0.7634590268135071, accuracy-macro: 0.0037000000011176\n",
      "step:    4703, loss: 0.1666490435600281, accuracy-micro: 0.7634827494621277, accuracy-macro: 0.0037000000011176\n",
      "step:    4704, loss: 0.1666464358568192, accuracy-micro: 0.7634720206260681, accuracy-macro: 0.0037000000011176\n",
      "step:    4705, loss: 0.1666438430547714, accuracy-micro: 0.7634829878807068, accuracy-macro: 0.0037000000011176\n",
      "step:    4706, loss: 0.1666418164968491, accuracy-micro: 0.7634932398796082, accuracy-macro: 0.0037000000011176\n",
      "step:    4707, loss: 0.1666399985551834, accuracy-micro: 0.7634934782981873, accuracy-macro: 0.0037000000011176\n",
      "step:    4708, loss: 0.1666384637355804, accuracy-micro: 0.7634879946708679, accuracy-macro: 0.0037000000011176\n",
      "step:    4709, loss: 0.1666372567415237, accuracy-micro: 0.7634772658348083, accuracy-macro: 0.0037000000011176\n",
      "step:    4710, loss: 0.1666371971368790, accuracy-micro: 0.7634819746017456, accuracy-macro: 0.0037000000011176\n",
      "step:    4711, loss: 0.1666375547647476, accuracy-micro: 0.7634897232055664, accuracy-macro: 0.0037000000011176\n",
      "step:    4712, loss: 0.1666377335786819, accuracy-micro: 0.7635007500648499, accuracy-macro: 0.0037000000011176\n",
      "step:    4713, loss: 0.1666383445262909, accuracy-micro: 0.7634884715080261, accuracy-macro: 0.0037000000011176\n",
      "step:    4714, loss: 0.1666402220726013, accuracy-micro: 0.7635064721107483, accuracy-macro: 0.0037000000011176\n",
      "step:    4715, loss: 0.1666406840085983, accuracy-micro: 0.7634807229042053, accuracy-macro: 0.0037000000011176\n",
      "step:    4716, loss: 0.1666400879621506, accuracy-micro: 0.7634620070457458, accuracy-macro: 0.0037000000011176\n",
      "step:    4717, loss: 0.1666374951601028, accuracy-micro: 0.7634909749031067, accuracy-macro: 0.0037000000011176\n",
      "step:    4718, loss: 0.1666352748870850, accuracy-micro: 0.7635164856910706, accuracy-macro: 0.0037000000011176\n",
      "step:    4719, loss: 0.1666332781314850, accuracy-micro: 0.7634942531585693, accuracy-macro: 0.0037000000011176\n",
      "step:    4720, loss: 0.1666320413351059, accuracy-micro: 0.7635034918785095, accuracy-macro: 0.0037000000011176\n",
      "step:    4721, loss: 0.1666312515735626, accuracy-micro: 0.7634829878807068, accuracy-macro: 0.0037000000011176\n",
      "step:    4722, loss: 0.1666298806667328, accuracy-micro: 0.7635114789009094, accuracy-macro: 0.0037000000011176\n",
      "step:    4723, loss: 0.1666290611028671, accuracy-micro: 0.7635055184364319, accuracy-macro: 0.0037000000011176\n",
      "step:    4724, loss: 0.1666293442249298, accuracy-micro: 0.7635185122489929, accuracy-macro: 0.0037000000011176\n",
      "step:    4725, loss: 0.1666291803121567, accuracy-micro: 0.7634940147399902, accuracy-macro: 0.0037000000011176\n",
      "step:    4726, loss: 0.1666295528411865, accuracy-micro: 0.7634997367858887, accuracy-macro: 0.0037000000011176\n",
      "step:    4727, loss: 0.1666278541088104, accuracy-micro: 0.7634857296943665, accuracy-macro: 0.0037000000011176\n",
      "step:    4728, loss: 0.1666282564401627, accuracy-micro: 0.7635412216186523, accuracy-macro: 0.0037000000011176\n",
      "step:    4729, loss: 0.1666274964809418, accuracy-micro: 0.7634942531585693, accuracy-macro: 0.0037000000011176\n",
      "step:    4730, loss: 0.1666271537542343, accuracy-micro: 0.7635049819946289, accuracy-macro: 0.0037000000011176\n",
      "step:    4731, loss: 0.1666270643472672, accuracy-micro: 0.7635042667388916, accuracy-macro: 0.0037000000011176\n",
      "step:    4732, loss: 0.1666262149810791, accuracy-micro: 0.7635242342948914, accuracy-macro: 0.0037000000011176\n",
      "step:    4733, loss: 0.1666243076324463, accuracy-micro: 0.7634997367858887, accuracy-macro: 0.0037000000011176\n",
      "step:    4734, loss: 0.1666241288185120, accuracy-micro: 0.7635107636451721, accuracy-macro: 0.0037000000011176\n",
      "step:    4735, loss: 0.1666235029697418, accuracy-micro: 0.7635117769241333, accuracy-macro: 0.0037000000011176\n",
      "step:    4736, loss: 0.1666225790977478, accuracy-micro: 0.7635139822959900, accuracy-macro: 0.0037000000011176\n",
      "step:    4737, loss: 0.1666222810745239, accuracy-micro: 0.7635064721107483, accuracy-macro: 0.0037000000011176\n",
      "step:    4738, loss: 0.1666218191385269, accuracy-micro: 0.7635239958763123, accuracy-macro: 0.0037000000011176\n",
      "step:    4739, loss: 0.1666208505630493, accuracy-micro: 0.7634952664375305, accuracy-macro: 0.0037000000011176\n",
      "step:    4740, loss: 0.1666207760572433, accuracy-micro: 0.7635327577590942, accuracy-macro: 0.0037000000011176\n",
      "step:    4741, loss: 0.1666201204061508, accuracy-micro: 0.7634949684143066, accuracy-macro: 0.0037000000011176\n",
      "step:    4742, loss: 0.1666199117898941, accuracy-micro: 0.7635177373886108, accuracy-macro: 0.0037000000011176\n",
      "step:    4743, loss: 0.1666194349527359, accuracy-micro: 0.7635037302970886, accuracy-macro: 0.0037000000011176\n",
      "step:    4744, loss: 0.1666198074817657, accuracy-micro: 0.7635444998741150, accuracy-macro: 0.0037000000011176\n",
      "step:    4745, loss: 0.1666202396154404, accuracy-micro: 0.7635235190391541, accuracy-macro: 0.0037000000011176\n",
      "step:    4746, loss: 0.1666204482316971, accuracy-micro: 0.7635329961776733, accuracy-macro: 0.0037000000011176\n",
      "step:    4747, loss: 0.1666199117898941, accuracy-micro: 0.7635200023651123, accuracy-macro: 0.0037000000011176\n",
      "step:    4748, loss: 0.1666182130575180, accuracy-micro: 0.7635139822959900, accuracy-macro: 0.0037000000011176\n",
      "step:    4749, loss: 0.1666161417961121, accuracy-micro: 0.7635312676429749, accuracy-macro: 0.0037000000011176\n",
      "step:    4750, loss: 0.1666145473718643, accuracy-micro: 0.7635375261306763, accuracy-macro: 0.0037000000011176\n",
      "step:    4751, loss: 0.1666126698255539, accuracy-micro: 0.7635179758071899, accuracy-macro: 0.0037000000011176\n",
      "step:    4752, loss: 0.1666125655174255, accuracy-micro: 0.7635047435760498, accuracy-macro: 0.0037000000011176\n",
      "step:    4753, loss: 0.1666120886802673, accuracy-micro: 0.7635472416877747, accuracy-macro: 0.0037000000011176\n",
      "step:    4754, loss: 0.1666116565465927, accuracy-micro: 0.7635327577590942, accuracy-macro: 0.0037000000011176\n",
      "step:    4755, loss: 0.1666101515293121, accuracy-micro: 0.7635337710380554, accuracy-macro: 0.0037000000011176\n",
      "step:    4756, loss: 0.1666093766689301, accuracy-micro: 0.7635097503662109, accuracy-macro: 0.0037000000011176\n",
      "step:    4757, loss: 0.1666083782911301, accuracy-micro: 0.7635359764099121, accuracy-macro: 0.0037000000011176\n",
      "step:    4758, loss: 0.1666080802679062, accuracy-micro: 0.7635484933853149, accuracy-macro: 0.0037000000011176\n",
      "step:    4759, loss: 0.1666077524423599, accuracy-micro: 0.7635412216186523, accuracy-macro: 0.0037000000011176\n",
      "step:    4760, loss: 0.1666072309017181, accuracy-micro: 0.7635227441787720, accuracy-macro: 0.0037000000011176\n",
      "step:    4761, loss: 0.1666069030761719, accuracy-micro: 0.7635340094566345, accuracy-macro: 0.0037000000011176\n",
      "step:    4762, loss: 0.1666071563959122, accuracy-micro: 0.7635397315025330, accuracy-macro: 0.0037000000011176\n",
      "step:    4763, loss: 0.1666062474250793, accuracy-micro: 0.7635465264320374, accuracy-macro: 0.0037000000011176\n",
      "step:    4764, loss: 0.1666057854890823, accuracy-micro: 0.7635545134544373, accuracy-macro: 0.0037000000011176\n",
      "step:    4765, loss: 0.1666049063205719, accuracy-micro: 0.7635432481765747, accuracy-macro: 0.0037000000011176\n",
      "step:    4766, loss: 0.1666030585765839, accuracy-micro: 0.7635195255279541, accuracy-macro: 0.0037000000011176\n",
      "step:    4767, loss: 0.1666030287742615, accuracy-micro: 0.7635357379913330, accuracy-macro: 0.0037000000011176\n",
      "step:    4768, loss: 0.1666039079427719, accuracy-micro: 0.7635487318038940, accuracy-macro: 0.0037000000011176\n",
      "step:    4769, loss: 0.1666054576635361, accuracy-micro: 0.7635292410850525, accuracy-macro: 0.0037000000011176\n",
      "step:    4770, loss: 0.1666081994771957, accuracy-micro: 0.7635347247123718, accuracy-macro: 0.0037000000011176\n",
      "step:    4771, loss: 0.1666112840175629, accuracy-micro: 0.7635597586631775, accuracy-macro: 0.0037000000011176\n",
      "step:    4772, loss: 0.1666123867034912, accuracy-micro: 0.7635407447814941, accuracy-macro: 0.0037000000011176\n",
      "step:    4773, loss: 0.1666130572557449, accuracy-micro: 0.7635470032691956, accuracy-macro: 0.0037000000011176\n",
      "step:    4774, loss: 0.1666116565465927, accuracy-micro: 0.7635409832000732, accuracy-macro: 0.0037000000011176\n",
      "step:    4775, loss: 0.1666070371866226, accuracy-micro: 0.7635710239410400, accuracy-macro: 0.0037000000011176\n",
      "step:    4776, loss: 0.1666028648614883, accuracy-micro: 0.7635754942893982, accuracy-macro: 0.0037000000011176\n",
      "step:    4777, loss: 0.1665971279144287, accuracy-micro: 0.7635520100593567, accuracy-macro: 0.0037000000011176\n",
      "step:    4778, loss: 0.1665939986705780, accuracy-micro: 0.7635562419891357, accuracy-macro: 0.0037000000011176\n",
      "step:    4779, loss: 0.1665938645601273, accuracy-micro: 0.7635527253150940, accuracy-macro: 0.0037000000011176\n",
      "step:    4780, loss: 0.1665974408388138, accuracy-micro: 0.7635480165481567, accuracy-macro: 0.0037000000011176\n",
      "step:    4781, loss: 0.1666032224893570, accuracy-micro: 0.7635610103607178, accuracy-macro: 0.0037000000011176\n",
      "step:    4782, loss: 0.1666116416454315, accuracy-micro: 0.7635437250137329, accuracy-macro: 0.0037000000011176\n",
      "step:    4783, loss: 0.1666257232427597, accuracy-micro: 0.7635409832000732, accuracy-macro: 0.0037000000011176\n",
      "step:    4784, loss: 0.1666437089443207, accuracy-micro: 0.7634722590446472, accuracy-macro: 0.0037000000011176\n",
      "step:    4785, loss: 0.1666621714830399, accuracy-micro: 0.7635432481765747, accuracy-macro: 0.0037000000011176\n",
      "step:    4786, loss: 0.1666676104068756, accuracy-micro: 0.7634122371673584, accuracy-macro: 0.0037000000011176\n",
      "step:    4787, loss: 0.1666617542505264, accuracy-micro: 0.7635704874992371, accuracy-macro: 0.0037000000011176\n",
      "step:    4788, loss: 0.1666390001773834, accuracy-micro: 0.7634760141372681, accuracy-macro: 0.0037000000011176\n",
      "step:    4789, loss: 0.1666157096624374, accuracy-micro: 0.7635377645492554, accuracy-macro: 0.0037000000011176\n",
      "step:    4790, loss: 0.1665957570075989, accuracy-micro: 0.7635572552680969, accuracy-macro: 0.0037000000011176\n",
      "step:    4791, loss: 0.1665867567062378, accuracy-micro: 0.7635769844055176, accuracy-macro: 0.0037000000011176\n",
      "step:    4792, loss: 0.1665873378515244, accuracy-micro: 0.7635700106620789, accuracy-macro: 0.0037000000011176\n",
      "step:    4793, loss: 0.1665941625833511, accuracy-micro: 0.7635715007781982, accuracy-macro: 0.0037000000011176\n",
      "step:    4794, loss: 0.1665991991758347, accuracy-micro: 0.7635657191276550, accuracy-macro: 0.0037000000011176\n",
      "step:    4795, loss: 0.1666023433208466, accuracy-micro: 0.7635537385940552, accuracy-macro: 0.0037000000011176\n",
      "step:    4796, loss: 0.1666020303964615, accuracy-micro: 0.7635740041732788, accuracy-macro: 0.0037000000011176\n",
      "step:    4797, loss: 0.1665990352630615, accuracy-micro: 0.7635672688484192, accuracy-macro: 0.0037000000011176\n",
      "step:    4798, loss: 0.1665922701358795, accuracy-micro: 0.7635772228240967, accuracy-macro: 0.0037000000011176\n",
      "step:    4799, loss: 0.1665869355201721, accuracy-micro: 0.7635637521743774, accuracy-macro: 0.0037000000011176\n",
      "step:    4800, loss: 0.1665820330381393, accuracy-micro: 0.7635832428932190, accuracy-macro: 0.0037000000011176\n",
      "step:    4801, loss: 0.1665800064802170, accuracy-micro: 0.7635827660560608, accuracy-macro: 0.0037000000011176\n",
      "step:    4802, loss: 0.1665800511837006, accuracy-micro: 0.7635840177536011, accuracy-macro: 0.0037000000011176\n",
      "step:    4803, loss: 0.1665820628404617, accuracy-micro: 0.7635687589645386, accuracy-macro: 0.0037000000011176\n",
      "step:    4804, loss: 0.1665817201137543, accuracy-micro: 0.7635800242424011, accuracy-macro: 0.0037000000011176\n",
      "step:    4805, loss: 0.1665814071893692, accuracy-micro: 0.7635754942893982, accuracy-macro: 0.0037000000011176\n",
      "step:    4806, loss: 0.1665792316198349, accuracy-micro: 0.7636032700538635, accuracy-macro: 0.0037000000011176\n",
      "step:    4807, loss: 0.1665774434804916, accuracy-micro: 0.7635777592658997, accuracy-macro: 0.0037000000011176\n",
      "step:    4808, loss: 0.1665754020214081, accuracy-micro: 0.7635972499847412, accuracy-macro: 0.0037000000011176\n",
      "step:    4809, loss: 0.1665743142366409, accuracy-micro: 0.7636104822158813, accuracy-macro: 0.0037000000011176\n",
      "step:    4810, loss: 0.1665770560503006, accuracy-micro: 0.7635905146598816, accuracy-macro: 0.0037000000011176\n",
      "step:    4811, loss: 0.1665795296430588, accuracy-micro: 0.7636020183563232, accuracy-macro: 0.0037000000011176\n",
      "step:    4812, loss: 0.1665847599506378, accuracy-micro: 0.7635635137557983, accuracy-macro: 0.0037000000011176\n",
      "step:    4813, loss: 0.1665892750024796, accuracy-micro: 0.7635667324066162, accuracy-macro: 0.0037000000011176\n",
      "step:    4814, loss: 0.1665914654731750, accuracy-micro: 0.7635792493820190, accuracy-macro: 0.0037000000011176\n",
      "step:    4815, loss: 0.1665871888399124, accuracy-micro: 0.7635677456855774, accuracy-macro: 0.0037000000011176\n",
      "step:    4816, loss: 0.1665792763233185, accuracy-micro: 0.7635882496833801, accuracy-macro: 0.0037000000011176\n",
      "step:    4817, loss: 0.1665721833705902, accuracy-micro: 0.7635972499847412, accuracy-macro: 0.0037000000011176\n",
      "step:    4818, loss: 0.1665702462196350, accuracy-micro: 0.7635932564735413, accuracy-macro: 0.0037000000011176\n",
      "step:    4819, loss: 0.1665741503238678, accuracy-micro: 0.7636032700538635, accuracy-macro: 0.0037000000011176\n",
      "step:    4820, loss: 0.1665793210268021, accuracy-micro: 0.7635880112648010, accuracy-macro: 0.0037000000011176\n",
      "step:    4821, loss: 0.1665813326835632, accuracy-micro: 0.7635805010795593, accuracy-macro: 0.0037000000011176\n",
      "step:    4822, loss: 0.1665779352188110, accuracy-micro: 0.7635677456855774, accuracy-macro: 0.0037000000011176\n",
      "step:    4823, loss: 0.1665726155042648, accuracy-micro: 0.7636017203330994, accuracy-macro: 0.0037000000011176\n",
      "step:    4824, loss: 0.1665675342082977, accuracy-micro: 0.7636079788208008, accuracy-macro: 0.0037000000011176\n",
      "step:    4825, loss: 0.1665650904178619, accuracy-micro: 0.7636117339134216, accuracy-macro: 0.0037000000011176\n",
      "step:    4826, loss: 0.1665652841329575, accuracy-micro: 0.7635987401008606, accuracy-macro: 0.0037000000011176\n",
      "step:    4827, loss: 0.1665676832199097, accuracy-micro: 0.7636072635650635, accuracy-macro: 0.0037000000011176\n",
      "step:    4828, loss: 0.1665685325860977, accuracy-micro: 0.7635902762413025, accuracy-macro: 0.0037000000011176\n",
      "step:    4829, loss: 0.1665679514408112, accuracy-micro: 0.7636012434959412, accuracy-macro: 0.0037000000011176\n",
      "step:    4830, loss: 0.1665662229061127, accuracy-micro: 0.7635957598686218, accuracy-macro: 0.0037000000011176\n",
      "step:    4831, loss: 0.1665641963481903, accuracy-micro: 0.7636070251464844, accuracy-macro: 0.0037000000011176\n",
      "step:    4832, loss: 0.1665611267089844, accuracy-micro: 0.7635930180549622, accuracy-macro: 0.0037000000011176\n",
      "step:    4833, loss: 0.1665606498718262, accuracy-micro: 0.7636274695396423, accuracy-macro: 0.0037000000011176\n",
      "step:    4834, loss: 0.1665617972612381, accuracy-micro: 0.7636129856109619, accuracy-macro: 0.0037000000011176\n",
      "step:    4835, loss: 0.1665647178888321, accuracy-micro: 0.7636222243309021, accuracy-macro: 0.0037000000011176\n",
      "step:    4836, loss: 0.1665675640106201, accuracy-micro: 0.7636060118675232, accuracy-macro: 0.0037000000011176\n",
      "step:    4837, loss: 0.1665687561035156, accuracy-micro: 0.7635887265205383, accuracy-macro: 0.0037000000011176\n",
      "step:    4838, loss: 0.1665687561035156, accuracy-micro: 0.7636029720306396, accuracy-macro: 0.0037000000011176\n",
      "step:    4839, loss: 0.1665667146444321, accuracy-micro: 0.7636202573776245, accuracy-macro: 0.0037000000011176\n",
      "step:    4840, loss: 0.1665640026330948, accuracy-micro: 0.7635957598686218, accuracy-macro: 0.0037000000011176\n",
      "step:    4841, loss: 0.1665599644184113, accuracy-micro: 0.7636212706565857, accuracy-macro: 0.0037000000011176\n",
      "step:    4842, loss: 0.1665568202733994, accuracy-micro: 0.7636204957962036, accuracy-macro: 0.0037000000011176\n",
      "step:    4843, loss: 0.1665544062852859, accuracy-micro: 0.7636075019836426, accuracy-macro: 0.0037000000011176\n",
      "step:    4844, loss: 0.1665538102388382, accuracy-micro: 0.7636284828186035, accuracy-macro: 0.0037000000011176\n",
      "step:    4845, loss: 0.1665550172328949, accuracy-micro: 0.7636259794235229, accuracy-macro: 0.0037000000011176\n",
      "step:    4846, loss: 0.1665573716163635, accuracy-micro: 0.7636089920997620, accuracy-macro: 0.0037000000011176\n",
      "step:    4847, loss: 0.1665595620870590, accuracy-micro: 0.7636072635650635, accuracy-macro: 0.0037000000011176\n",
      "step:    4848, loss: 0.1665626913309097, accuracy-micro: 0.7636299729347229, accuracy-macro: 0.0037000000011176\n",
      "step:    4849, loss: 0.1665649265050888, accuracy-micro: 0.7635995149612427, accuracy-macro: 0.0037000000011176\n",
      "step:    4850, loss: 0.1665666401386261, accuracy-micro: 0.7636280059814453, accuracy-macro: 0.0037000000011176\n",
      "step:    4851, loss: 0.1665644794702530, accuracy-micro: 0.7636127471923828, accuracy-macro: 0.0037000000011176\n",
      "step:    4852, loss: 0.1665595322847366, accuracy-micro: 0.7636204957962036, accuracy-macro: 0.0037000000011176\n",
      "step:    4853, loss: 0.1665536016225815, accuracy-micro: 0.7636204957962036, accuracy-macro: 0.0037000000011176\n",
      "step:    4854, loss: 0.1665497422218323, accuracy-micro: 0.7636420130729675, accuracy-macro: 0.0037000000011176\n",
      "step:    4855, loss: 0.1665471941232681, accuracy-micro: 0.7636240124702454, accuracy-macro: 0.0037000000011176\n",
      "step:    4856, loss: 0.1665462702512741, accuracy-micro: 0.7636255025863647, accuracy-macro: 0.0037000000011176\n",
      "step:    4857, loss: 0.1665450781583786, accuracy-micro: 0.7636399865150452, accuracy-macro: 0.0037000000011176\n",
      "step:    4858, loss: 0.1665453761816025, accuracy-micro: 0.7636307477951050, accuracy-macro: 0.0037000000011176\n",
      "step:    4859, loss: 0.1665464490652084, accuracy-micro: 0.7636412382125854, accuracy-macro: 0.0037000000011176\n",
      "step:    4860, loss: 0.1665481925010681, accuracy-micro: 0.7636510133743286, accuracy-macro: 0.0037000000011176\n",
      "step:    4861, loss: 0.1665473133325577, accuracy-micro: 0.7636422514915466, accuracy-macro: 0.0037000000011176\n",
      "step:    4862, loss: 0.1665453761816025, accuracy-micro: 0.7636470198631287, accuracy-macro: 0.0037000000011176\n",
      "step:    4863, loss: 0.1665435284376144, accuracy-micro: 0.7636442184448242, accuracy-macro: 0.0037000000011176\n",
      "step:    4864, loss: 0.1665427237749100, accuracy-micro: 0.7636460065841675, accuracy-macro: 0.0037000000011176\n",
      "step:    4865, loss: 0.1665415465831757, accuracy-micro: 0.7636377215385437, accuracy-macro: 0.0037000000011176\n",
      "step:    4866, loss: 0.1665406823158264, accuracy-micro: 0.7636294960975647, accuracy-macro: 0.0037000000011176\n",
      "step:    4867, loss: 0.1665395051240921, accuracy-micro: 0.7636409997940063, accuracy-macro: 0.0037000000011176\n",
      "step:    4868, loss: 0.1665390580892563, accuracy-micro: 0.7636402249336243, accuracy-macro: 0.0037000000011176\n",
      "step:    4869, loss: 0.1665375828742981, accuracy-micro: 0.7636292576789856, accuracy-macro: 0.0037000000011176\n",
      "step:    4870, loss: 0.1665375977754593, accuracy-micro: 0.7636437416076660, accuracy-macro: 0.0037000000011176\n",
      "step:    4871, loss: 0.1665367782115936, accuracy-micro: 0.7636252641677856, accuracy-macro: 0.0037000000011176\n",
      "step:    4872, loss: 0.1665361970663071, accuracy-micro: 0.7636424899101257, accuracy-macro: 0.0037000000011176\n",
      "step:    4873, loss: 0.1665360927581787, accuracy-micro: 0.7636362314224243, accuracy-macro: 0.0037000000011176\n",
      "step:    4874, loss: 0.1665349751710892, accuracy-micro: 0.7636432647705078, accuracy-macro: 0.0037000000011176\n",
      "step:    4875, loss: 0.1665344387292862, accuracy-micro: 0.7636457681655884, accuracy-macro: 0.0037000000011176\n",
      "step:    4876, loss: 0.1665342748165131, accuracy-micro: 0.7636374831199646, accuracy-macro: 0.0037000000011176\n",
      "step:    4877, loss: 0.1665333956480026, accuracy-micro: 0.7636510133743286, accuracy-macro: 0.0037000000011176\n",
      "step:    4878, loss: 0.1665326803922653, accuracy-micro: 0.7636470198631287, accuracy-macro: 0.0037000000011176\n",
      "step:    4879, loss: 0.1665323078632355, accuracy-micro: 0.7636694908142090, accuracy-macro: 0.0037000000011176\n",
      "step:    4880, loss: 0.1665315032005310, accuracy-micro: 0.7636439800262451, accuracy-macro: 0.0037000000011176\n",
      "step:    4881, loss: 0.1665310263633728, accuracy-micro: 0.7636640071868896, accuracy-macro: 0.0037000000011176\n",
      "step:    4882, loss: 0.1665299683809280, accuracy-micro: 0.7636482715606689, accuracy-macro: 0.0037000000011176\n",
      "step:    4883, loss: 0.1665293425321579, accuracy-micro: 0.7636619806289673, accuracy-macro: 0.0037000000011176\n",
      "step:    4884, loss: 0.1665296554565430, accuracy-micro: 0.7636737227439880, accuracy-macro: 0.0037000000011176\n",
      "step:    4885, loss: 0.1665289700031281, accuracy-micro: 0.7636722326278687, accuracy-macro: 0.0037000000011176\n",
      "step:    4886, loss: 0.1665298342704773, accuracy-micro: 0.7636727690696716, accuracy-macro: 0.0037000000011176\n",
      "step:    4887, loss: 0.1665291935205460, accuracy-micro: 0.7636757493019104, accuracy-macro: 0.0037000000011176\n",
      "step:    4888, loss: 0.1665290892124176, accuracy-micro: 0.7636839747428894, accuracy-macro: 0.0037000000011176\n",
      "step:    4889, loss: 0.1665284037590027, accuracy-micro: 0.7636594772338867, accuracy-macro: 0.0037000000011176\n",
      "step:    4890, loss: 0.1665286123752594, accuracy-micro: 0.7636654973030090, accuracy-macro: 0.0037000000011176\n",
      "step:    4891, loss: 0.1665281504392624, accuracy-micro: 0.7636830210685730, accuracy-macro: 0.0037000000011176\n",
      "step:    4892, loss: 0.1665281206369400, accuracy-micro: 0.7636782526969910, accuracy-macro: 0.0037000000011176\n",
      "step:    4893, loss: 0.1665288954973221, accuracy-micro: 0.7636987566947937, accuracy-macro: 0.0037000000011176\n",
      "step:    4894, loss: 0.1665284782648087, accuracy-micro: 0.7636749744415283, accuracy-macro: 0.0037000000011176\n",
      "step:    4895, loss: 0.1665289103984833, accuracy-micro: 0.7636767625808716, accuracy-macro: 0.0037000000011176\n",
      "step:    4896, loss: 0.1665306091308594, accuracy-micro: 0.7636479735374451, accuracy-macro: 0.0037000000011176\n",
      "step:    4897, loss: 0.1665326654911041, accuracy-micro: 0.7636554837226868, accuracy-macro: 0.0037000000011176\n",
      "step:    4898, loss: 0.1665364801883698, accuracy-micro: 0.7636409997940063, accuracy-macro: 0.0037000000011176\n",
      "step:    4899, loss: 0.1665392518043518, accuracy-micro: 0.7636740207672119, accuracy-macro: 0.0037000000011176\n",
      "step:    4900, loss: 0.1665370315313339, accuracy-micro: 0.7636529803276062, accuracy-macro: 0.0037000000011176\n",
      "step:    4901, loss: 0.1665312349796295, accuracy-micro: 0.7636560201644897, accuracy-macro: 0.0037000000011176\n",
      "step:    4902, loss: 0.1665227413177490, accuracy-micro: 0.7636809945106506, accuracy-macro: 0.0037000000011176\n",
      "step:    4903, loss: 0.1665186285972595, accuracy-micro: 0.7637194991111755, accuracy-macro: 0.0037000000011176\n",
      "step:    4904, loss: 0.1665174067020416, accuracy-micro: 0.7636927366256714, accuracy-macro: 0.0037000000011176\n",
      "step:    4905, loss: 0.1665202230215073, accuracy-micro: 0.7636787295341492, accuracy-macro: 0.0037000000011176\n",
      "step:    4906, loss: 0.1665252149105072, accuracy-micro: 0.7636627554893494, accuracy-macro: 0.0037000000011176\n",
      "step:    4907, loss: 0.1665304750204086, accuracy-micro: 0.7636487483978271, accuracy-macro: 0.0037000000011176\n",
      "step:    4908, loss: 0.1665341854095459, accuracy-micro: 0.7636749744415283, accuracy-macro: 0.0037000000011176\n",
      "step:    4909, loss: 0.1665342003107071, accuracy-micro: 0.7636477351188660, accuracy-macro: 0.0037000000011176\n",
      "step:    4910, loss: 0.1665324121713638, accuracy-micro: 0.7636662721633911, accuracy-macro: 0.0037000000011176\n",
      "step:    4911, loss: 0.1665278524160385, accuracy-micro: 0.7636585235595703, accuracy-macro: 0.0037000000011176\n",
      "step:    4912, loss: 0.1665239483118057, accuracy-micro: 0.7637072205543518, accuracy-macro: 0.0037000000011176\n",
      "step:    4913, loss: 0.1665200591087341, accuracy-micro: 0.7636849880218506, accuracy-macro: 0.0037000000011176\n",
      "step:    4914, loss: 0.1665160059928894, accuracy-micro: 0.7637047767639160, accuracy-macro: 0.0037000000011176\n",
      "step:    4915, loss: 0.1665126085281372, accuracy-micro: 0.7637119889259338, accuracy-macro: 0.0037000000011176\n",
      "step:    4916, loss: 0.1665102541446686, accuracy-micro: 0.7637059688568115, accuracy-macro: 0.0037000000011176\n",
      "step:    4917, loss: 0.1665096729993820, accuracy-micro: 0.7637075185775757, accuracy-macro: 0.0037000000011176\n",
      "step:    4918, loss: 0.1665108799934387, accuracy-micro: 0.7637017369270325, accuracy-macro: 0.0037000000011176\n",
      "step:    4919, loss: 0.1665149033069611, accuracy-micro: 0.7637169957160950, accuracy-macro: 0.0037000000011176\n",
      "step:    4920, loss: 0.1665197163820267, accuracy-micro: 0.7636525034904480, accuracy-macro: 0.0037000000011176\n",
      "step:    4921, loss: 0.1665260046720505, accuracy-micro: 0.7637100219726562, accuracy-macro: 0.0037000000011176\n",
      "step:    4922, loss: 0.1665284633636475, accuracy-micro: 0.7636637687683105, accuracy-macro: 0.0037000000011176\n",
      "step:    4923, loss: 0.1665268093347549, accuracy-micro: 0.7637022733688354, accuracy-macro: 0.0037000000011176\n",
      "step:    4924, loss: 0.1665200591087341, accuracy-micro: 0.7636684775352478, accuracy-macro: 0.0037000000011176\n",
      "step:    4925, loss: 0.1665119975805283, accuracy-micro: 0.7637289762496948, accuracy-macro: 0.0037000000011176\n",
      "step:    4926, loss: 0.1665061861276627, accuracy-micro: 0.7637184858322144, accuracy-macro: 0.0037000000011176\n",
      "step:    4927, loss: 0.1665032058954239, accuracy-micro: 0.7637174725532532, accuracy-macro: 0.0037000000011176\n",
      "step:    4928, loss: 0.1665037870407104, accuracy-micro: 0.7637354731559753, accuracy-macro: 0.0037000000011176\n",
      "step:    4929, loss: 0.1665072441101074, accuracy-micro: 0.7636820077896118, accuracy-macro: 0.0037000000011176\n",
      "step:    4930, loss: 0.1665128469467163, accuracy-micro: 0.7637307643890381, accuracy-macro: 0.0037000000011176\n",
      "step:    4931, loss: 0.1665161252021790, accuracy-micro: 0.7636680006980896, accuracy-macro: 0.0037000000011176\n",
      "step:    4932, loss: 0.1665151268243790, accuracy-micro: 0.7637147307395935, accuracy-macro: 0.0037000000011176\n",
      "step:    4933, loss: 0.1665126234292984, accuracy-micro: 0.7636654973030090, accuracy-macro: 0.0037000000011176\n",
      "step:    4934, loss: 0.1665080934762955, accuracy-micro: 0.7637385129928589, accuracy-macro: 0.0037000000011176\n",
      "step:    4935, loss: 0.1665047109127045, accuracy-micro: 0.7636987566947937, accuracy-macro: 0.0037000000011176\n",
      "step:    4936, loss: 0.1665016114711761, accuracy-micro: 0.7637435197830200, accuracy-macro: 0.0037000000011176\n",
      "step:    4937, loss: 0.1665002554655075, accuracy-micro: 0.7637012600898743, accuracy-macro: 0.0037000000011176\n",
      "step:    4938, loss: 0.1664981544017792, accuracy-micro: 0.7637425065040588, accuracy-macro: 0.0037000000011176\n",
      "step:    4939, loss: 0.1664965003728867, accuracy-micro: 0.7637227773666382, accuracy-macro: 0.0037000000011176\n",
      "step:    4940, loss: 0.1664956808090210, accuracy-micro: 0.7637345194816589, accuracy-macro: 0.0037000000011176\n",
      "step:    4941, loss: 0.1664962619543076, accuracy-micro: 0.7637714743614197, accuracy-macro: 0.0037000000011176\n",
      "step:    4942, loss: 0.1664971560239792, accuracy-micro: 0.7637207508087158, accuracy-macro: 0.0037000000011176\n",
      "step:    4943, loss: 0.1664994210004807, accuracy-micro: 0.7637460231781006, accuracy-macro: 0.0037000000011176\n",
      "step:    4944, loss: 0.1665011942386627, accuracy-micro: 0.7637050151824951, accuracy-macro: 0.0037000000011176\n",
      "step:    4945, loss: 0.1665022522211075, accuracy-micro: 0.7637367248535156, accuracy-macro: 0.0037000000011176\n",
      "step:    4946, loss: 0.1665013879537582, accuracy-micro: 0.7636947631835938, accuracy-macro: 0.0037000000011176\n",
      "step:    4947, loss: 0.1664973050355911, accuracy-micro: 0.7637395262718201, accuracy-macro: 0.0037000000011176\n",
      "step:    4948, loss: 0.1664937138557434, accuracy-micro: 0.7637297511100769, accuracy-macro: 0.0037000000011176\n",
      "step:    4949, loss: 0.1664905995130539, accuracy-micro: 0.7637332677841187, accuracy-macro: 0.0037000000011176\n",
      "step:    4950, loss: 0.1664900630712509, accuracy-micro: 0.7637387514114380, accuracy-macro: 0.0037000000011176\n",
      "step:    4951, loss: 0.1664917767047882, accuracy-micro: 0.7637282609939575, accuracy-macro: 0.0037000000011176\n",
      "step:    4952, loss: 0.1664933115243912, accuracy-micro: 0.7637637257575989, accuracy-macro: 0.0037000000011176\n",
      "step:    4953, loss: 0.1664927750825882, accuracy-micro: 0.7637040019035339, accuracy-macro: 0.0037000000011176\n",
      "step:    4954, loss: 0.1664926111698151, accuracy-micro: 0.7637532353401184, accuracy-macro: 0.0037000000011176\n",
      "step:    4955, loss: 0.1664902120828629, accuracy-micro: 0.7637247443199158, accuracy-macro: 0.0037000000011176\n",
      "step:    4956, loss: 0.1664884090423584, accuracy-micro: 0.7637717723846436, accuracy-macro: 0.0037000000011176\n",
      "step:    4957, loss: 0.1664863079786301, accuracy-micro: 0.7637645006179810, accuracy-macro: 0.0037000000011176\n",
      "step:    4958, loss: 0.1664857119321823, accuracy-micro: 0.7637687325477600, accuracy-macro: 0.0037000000011176\n",
      "step:    4959, loss: 0.1664849966764450, accuracy-micro: 0.7637497186660767, accuracy-macro: 0.0037000000011176\n",
      "step:    4960, loss: 0.1664838343858719, accuracy-micro: 0.7637562751770020, accuracy-macro: 0.0037000000011176\n",
      "step:    4961, loss: 0.1664837002754211, accuracy-micro: 0.7637632489204407, accuracy-macro: 0.0037000000011176\n",
      "step:    4962, loss: 0.1664832532405853, accuracy-micro: 0.7637544870376587, accuracy-macro: 0.0037000000011176\n",
      "step:    4963, loss: 0.1664832234382629, accuracy-micro: 0.7637437582015991, accuracy-macro: 0.0037000000011176\n",
      "step:    4964, loss: 0.1664826422929764, accuracy-micro: 0.7637562751770020, accuracy-macro: 0.0037000000011176\n",
      "step:    4965, loss: 0.1664822250604630, accuracy-micro: 0.7637475132942200, accuracy-macro: 0.0037000000011176\n",
      "step:    4966, loss: 0.1664809435606003, accuracy-micro: 0.7637542486190796, accuracy-macro: 0.0037000000011176\n",
      "step:    4967, loss: 0.1664798706769943, accuracy-micro: 0.7637627720832825, accuracy-macro: 0.0037000000011176\n",
      "step:    4968, loss: 0.1664801985025406, accuracy-micro: 0.7637624740600586, accuracy-macro: 0.0037000000011176\n",
      "step:    4969, loss: 0.1664801537990570, accuracy-micro: 0.7637590169906616, accuracy-macro: 0.0037000000011176\n",
      "step:    4970, loss: 0.1664817780256271, accuracy-micro: 0.7637677192687988, accuracy-macro: 0.0037000000011176\n",
      "step:    4971, loss: 0.1664825379848480, accuracy-micro: 0.7637467384338379, accuracy-macro: 0.0037000000011176\n",
      "step:    4972, loss: 0.1664819866418839, accuracy-micro: 0.7637929916381836, accuracy-macro: 0.0037000000011176\n",
      "step:    4973, loss: 0.1664813458919525, accuracy-micro: 0.7637379765510559, accuracy-macro: 0.0037000000011176\n",
      "step:    4974, loss: 0.1664801836013794, accuracy-micro: 0.7637817263603210, accuracy-macro: 0.0037000000011176\n",
      "step:    4975, loss: 0.1664776504039764, accuracy-micro: 0.7637457251548767, accuracy-macro: 0.0037000000011176\n",
      "step:    4976, loss: 0.1664759516716003, accuracy-micro: 0.7637727260589600, accuracy-macro: 0.0037000000011176\n",
      "step:    4977, loss: 0.1664746701717377, accuracy-micro: 0.7637377381324768, accuracy-macro: 0.0037000000011176\n",
      "step:    4978, loss: 0.1664735674858093, accuracy-micro: 0.7637622356414795, accuracy-macro: 0.0037000000011176\n",
      "step:    4979, loss: 0.1664738059043884, accuracy-micro: 0.7637617588043213, accuracy-macro: 0.0037000000011176\n",
      "step:    4980, loss: 0.1664732545614243, accuracy-micro: 0.7637667655944824, accuracy-macro: 0.0037000000011176\n",
      "step:    4981, loss: 0.1664727628231049, accuracy-micro: 0.7637919783592224, accuracy-macro: 0.0037000000011176\n",
      "step:    4982, loss: 0.1664733141660690, accuracy-micro: 0.7637519836425781, accuracy-macro: 0.0037000000011176\n",
      "step:    4983, loss: 0.1664730459451675, accuracy-micro: 0.7637772560119629, accuracy-macro: 0.0037000000011176\n",
      "step:    4984, loss: 0.1664723902940750, accuracy-micro: 0.7637482285499573, accuracy-macro: 0.0037000000011176\n",
      "step:    4985, loss: 0.1664711534976959, accuracy-micro: 0.7637795209884644, accuracy-macro: 0.0037000000011176\n",
      "step:    4986, loss: 0.1664707511663437, accuracy-micro: 0.7637774944305420, accuracy-macro: 0.0037000000011176\n",
      "step:    4987, loss: 0.1664699614048004, accuracy-micro: 0.7637717723846436, accuracy-macro: 0.0037000000011176\n",
      "step:    4988, loss: 0.1664689034223557, accuracy-micro: 0.7637732625007629, accuracy-macro: 0.0037000000011176\n",
      "step:    4989, loss: 0.1664680242538452, accuracy-micro: 0.7637839913368225, accuracy-macro: 0.0037000000011176\n",
      "step:    4990, loss: 0.1664670556783676, accuracy-micro: 0.7637767195701599, accuracy-macro: 0.0037000000011176\n",
      "step:    4991, loss: 0.1664668917655945, accuracy-micro: 0.7637797594070435, accuracy-macro: 0.0037000000011176\n",
      "step:    4992, loss: 0.1664673686027527, accuracy-micro: 0.7637797594070435, accuracy-macro: 0.0037000000011176\n",
      "step:    4993, loss: 0.1664695441722870, accuracy-micro: 0.7637357711791992, accuracy-macro: 0.0037000000011176\n",
      "step:    4994, loss: 0.1664733141660690, accuracy-micro: 0.7637954950332642, accuracy-macro: 0.0037000000011176\n",
      "step:    4995, loss: 0.1664779931306839, accuracy-micro: 0.7637247443199158, accuracy-macro: 0.0037000000011176\n",
      "step:    4996, loss: 0.1664835810661316, accuracy-micro: 0.7637607455253601, accuracy-macro: 0.0037000000011176\n",
      "step:    4997, loss: 0.1664874404668808, accuracy-micro: 0.7636787295341492, accuracy-macro: 0.0037000000011176\n",
      "step:    4998, loss: 0.1664868146181107, accuracy-micro: 0.7637500166893005, accuracy-macro: 0.0037000000011176\n",
      "step:    4999, loss: 0.1664805859327316, accuracy-micro: 0.7637054920196533, accuracy-macro: 0.0037000000011176\n",
      "step:    5000, loss: 0.1664728671312332, accuracy-micro: 0.7638059854507446, accuracy-macro: 0.0037000000011176\n",
      "step:    5001, loss: 0.1664651334285736, accuracy-micro: 0.7637607455253601, accuracy-macro: 0.0037000000011176\n",
      "step:    5002, loss: 0.1664608716964722, accuracy-micro: 0.7637950181961060, accuracy-macro: 0.0037000000011176\n",
      "step:    5003, loss: 0.1664603501558304, accuracy-micro: 0.7637972235679626, accuracy-macro: 0.0037000000011176\n",
      "step:    5004, loss: 0.1664626449346542, accuracy-micro: 0.7637454867362976, accuracy-macro: 0.0037000000011176\n",
      "step:    5005, loss: 0.1664646267890930, accuracy-micro: 0.7638040184974670, accuracy-macro: 0.0037000000011176\n",
      "step:    5006, loss: 0.1664675027132034, accuracy-micro: 0.7637354731559753, accuracy-macro: 0.0037000000011176\n",
      "step:    5007, loss: 0.1664693057537079, accuracy-micro: 0.7638164758682251, accuracy-macro: 0.0037000000011176\n",
      "step:    5008, loss: 0.1664713621139526, accuracy-micro: 0.7637327313423157, accuracy-macro: 0.0037000000011176\n",
      "step:    5009, loss: 0.1664709001779556, accuracy-micro: 0.7637919783592224, accuracy-macro: 0.0037000000011176\n",
      "step:    5010, loss: 0.1664698421955109, accuracy-micro: 0.7637097239494324, accuracy-macro: 0.0037000000011176\n",
      "step:    5011, loss: 0.1664699316024780, accuracy-micro: 0.7638074755668640, accuracy-macro: 0.0037000000011176\n",
      "step:    5012, loss: 0.1664700806140900, accuracy-micro: 0.7637249827384949, accuracy-macro: 0.0037000000011176\n",
      "step:    5013, loss: 0.1664681881666183, accuracy-micro: 0.7638024687767029, accuracy-macro: 0.0037000000011176\n",
      "step:    5014, loss: 0.1664646118879318, accuracy-micro: 0.7637525200843811, accuracy-macro: 0.0037000000011176\n",
      "step:    5015, loss: 0.1664593070745468, accuracy-micro: 0.7638124823570251, accuracy-macro: 0.0037000000011176\n",
      "step:    5016, loss: 0.1664545536041260, accuracy-micro: 0.7637577652931213, accuracy-macro: 0.0037000000011176\n",
      "step:    5017, loss: 0.1664527207612991, accuracy-micro: 0.7638052701950073, accuracy-macro: 0.0037000000011176\n",
      "step:    5018, loss: 0.1664524376392365, accuracy-micro: 0.7637954950332642, accuracy-macro: 0.0037000000011176\n",
      "step:    5019, loss: 0.1664532274007797, accuracy-micro: 0.7637737393379211, accuracy-macro: 0.0037000000011176\n",
      "step:    5020, loss: 0.1664554029703140, accuracy-micro: 0.7638407349586487, accuracy-macro: 0.0037000000011176\n",
      "step:    5021, loss: 0.1664580255746841, accuracy-micro: 0.7637624740600586, accuracy-macro: 0.0037000000011176\n",
      "step:    5022, loss: 0.1664625406265259, accuracy-micro: 0.7638317346572876, accuracy-macro: 0.0037000000011176\n",
      "step:    5023, loss: 0.1664679497480392, accuracy-micro: 0.7637230157852173, accuracy-macro: 0.0037000000011176\n",
      "step:    5024, loss: 0.1664725244045258, accuracy-micro: 0.7637797594070435, accuracy-macro: 0.0037000000011176\n",
      "step:    5025, loss: 0.1664742231369019, accuracy-micro: 0.7636950016021729, accuracy-macro: 0.0037000000011176\n",
      "step:    5026, loss: 0.1664718389511108, accuracy-micro: 0.7637645006179810, accuracy-macro: 0.0037000000011176\n",
      "step:    5027, loss: 0.1664659678936005, accuracy-micro: 0.7636979818344116, accuracy-macro: 0.0037000000011176\n",
      "step:    5028, loss: 0.1664587855339050, accuracy-micro: 0.7638072371482849, accuracy-macro: 0.0037000000011176\n",
      "step:    5029, loss: 0.1664512604475021, accuracy-micro: 0.7637677192687988, accuracy-macro: 0.0037000000011176\n",
      "step:    5030, loss: 0.1664468795061111, accuracy-micro: 0.7638325095176697, accuracy-macro: 0.0037000000011176\n",
      "step:    5031, loss: 0.1664454042911530, accuracy-micro: 0.7638237476348877, accuracy-macro: 0.0037000000011176\n",
      "step:    5032, loss: 0.1664466559886932, accuracy-micro: 0.7638017535209656, accuracy-macro: 0.0037000000011176\n",
      "step:    5033, loss: 0.1664512157440186, accuracy-micro: 0.7638517618179321, accuracy-macro: 0.0037000000011176\n",
      "step:    5034, loss: 0.1664581298828125, accuracy-micro: 0.7637395262718201, accuracy-macro: 0.0037000000011176\n",
      "step:    5035, loss: 0.1664644628763199, accuracy-micro: 0.7637714743614197, accuracy-macro: 0.0037000000011176\n",
      "step:    5036, loss: 0.1664670407772064, accuracy-micro: 0.7637004852294922, accuracy-macro: 0.0037000000011176\n",
      "step:    5037, loss: 0.1664660871028900, accuracy-micro: 0.7637919783592224, accuracy-macro: 0.0037000000011176\n",
      "step:    5038, loss: 0.1664613932371140, accuracy-micro: 0.7637255191802979, accuracy-macro: 0.0037000000011176\n",
      "step:    5039, loss: 0.1664537936449051, accuracy-micro: 0.7638347744941711, accuracy-macro: 0.0037000000011176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_507998/159032837.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints_grok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrun_checkpoint_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_507998/830839422.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, loss_fn, checkpoint_path, max_steps, patience, run_state)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# SPLIT UP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;31m# log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             print(f'step: {run_state[\"step\"]:7d},',\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;34mf'loss: {run_state[\"loss\"]:1.16f},'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;34mf'accuracy-micro: {run_state[\"accuracy_micro\"]:1.16f},'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_checkpoint_path = Path('checkpoints_grok')\n",
    "run_checkpoint_path.mkdir(exist_ok=True)\n",
    "run_state = train(model, dataloader, optimizer, loss_fn, run_checkpoint_path)\n",
    "# https://wandb.ai/llottenbach/cgol/runs/lgvb539lg\n",
    "# model too large or batch size to small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b949459",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
